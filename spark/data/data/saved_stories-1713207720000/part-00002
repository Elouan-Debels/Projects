{"aid": "40039993", "title": "Antidotes to Cynicism Creep in Academia", "url": "https://eiko-fried.com/antidotes-to-cynicism-creep/", "domain": "eiko-fried.com", "votes": 2, "user": "EndXA", "posted_at": "2024-04-15 13:00:30", "comments": 0, "source_title": "Antidotes to cynicism creep in academia", "source_text": "Antidotes to cynicism creep in academia \u00bb Eiko Fried\n\nMENU\n\n  * Blog\n  * Publications\n  * Data\n  * Talks, workshops & videos\n  * Eiko & team\n  * WARN-D\n\n# Antidotes to cynicism creep in academia\n\nEiko March 4, 2024 March 24, 2024 30 Comments on Antidotes to cynicism creep\nin academia\n\nThis is one of these blog posts that doesn\u2019t read well if you stop halfway.\nFirst, I provide evidence that academia can look pretty broken: there is low-\nquality work everywhere you look, the peer-review system has long outlived its\nutility, and academic publishing is a dumpster fire. Add considerable work\npressure, the publish-or-perish culture, and precarious employment situations,\nand things can look gloomy and disheartening. Second, and this is where the\nblog becomes a bit personal, I stress how important it is for me not to become\na science cynic, because of the responsibility towards my mental health and\nwork, my team, my colleagues, and my students. Third, I then highlight\nantidotes to cynicism creep, and the many things that have greatly helped me\nwith motivation and staying positive.\n\nTable of Contents\n\nToggle\n\n# 1\\. So. Many. Problems.\n\nMy most central claim in the blog post is that there are so many reasons to be\ndisheartened and disillusioned. This pertains to many areas of the system we\nwork in, including published papers, peer-review, the publishing industry,\nsevere issues with workload and job insecurity, and so on. I will talk about\nsome of them, and later come back to discuss how I maintain motivation and\nenergy, and why.\n\n# 2\\. Problems with scientific papers\n\nWithout exaggeration, I believe that the majority of published works in my\nfield (broadly defined as psychology) do not add value. Many papers draw\nconclusions that are not supported by evidence, which cascades through the\nliterature, because these papers are cited for the conclusions, not the\nevidence. The majority of published works are not reproducible, in the sense\nthat authors conduct science behind closed doors without sharing data or code.\nMany published works are not replicable, i.e., will not hold up to scrutiny\nover time. Theories are verbal and vague, which means they can never get\nproperly rejected. Instead, as Paul Meehl famously wrote, they sort of just\nslowly fade away as people lose interest. Let me try to convince you that this\nis an entirely reasonable position, based on the evidence we have.\n\n(1) There are scientific disciplines dedicated to interrogating the scientific\nliterature for potential flaws. Resulting work includes flashy papers such as\n\u201cWhy Most Published Research Findings Are False\u201c, but also nuanced work\nhighlighting considerable problems in several of areas, e.g. issues of\nreplicability in psychology and cancer biology, large surveys of researchers\nadmitting to engaging in questionable practices (including making up data), an\never-growing number of high-profile fraud cases who have now started suing\nresearchers pointing out problems, and so on.\n\n(2) Like many others, I have also made my own experiences by reading papers\nand engaging with the literature, and believe that a substantial proportion\ndraw invalid inferences. I have written many commentaries to point out the\nmost egregious flaws, but there aren\u2019t enough hours in the week to engage with\nand rebut even 10% of bizarre claims in the literature.\n\n(3) Each year, a dramatic number of papers, surpassing 10,000 in 2023 alone,\nare retracted. These papers are likely only the tip of the iceberg. In fact,\n\u201cthe number of articles produced by businesses that sell bogus work and\nauthorships to scientists [..] is estimated to be in the hundreds of\nthousands\u201c. This doesn\u2019t speak to a system working as intended where we can\nrely on inferences we read.\n\n(4) These problems are hard to demonstrate abstractly, so I will list a few\nconcrete examples below. I have also written many dozens of blog posts on\nproblematic papers that you can find on this website \u2014 for example, just in\nthe last few months, on depression & temperature, the default mode network,\nand the disease factor. Below are four papers from our psychedelics overview\npaper where authors wrote things that were not correct based on their\nevidence:\n\n> \u201cAbbar et al. found in a randomized controlled trial (RCT) comparing\n> ketamine against placebo that there was no persistent benefit of ketamine\n> over placebo at the exit timepoint of the trial in week 6, but concluded in\n> the abstract that \u2018ketamine [..] has persistent benefits for acute care in\n> suicidal patients\u2019. Ionescu et al. found in an open-label ketamine study\n> that only 2 of 14 patients show sustained improvement at 3-month follow-up\n> (which may well be due to the placebo effect or other factors), but the\n> title of the paper reads \u2018Rapid and Sustained Reductions in Current Suicidal\n> Ideation\u2019. Palhano-Fontes et al. concluded in their ayahuasca study (n = 14\n> treatment, n = 15 placebo) that \u2018blindness was adequately preserved\u2019, when\n> all participants in the treatment group said they believed they had received\n> ayahuasca, but less than half of participants in the placebo group said so.\n> And Daws et al. compared two treatment arms, including one using psilocybin-\n> assisted psychotherapy, against each other, concluding that one treatment\n> outperformed the other despite the lack of a statistically significant\n> interaction term between the treatments.\u201d\n\nJoin 1,056 other subscribers\n\n## 2.1 Small detour: Mindfulness and brain morphology\n\nLet me provide you with a specific example, and then I\u2019ll zoom out and embed\nthis in a broader context. A few days ago, I complained (apologies, it happens\nwhen I become cynical) that especially the neuroimaging literature in\npsychology is riddled with studies that are false positive findings and do not\nreplicate subsequently, and posted about a recent paper that found no relation\nbetween mindfulness training and changes in brain morphology, contrasting\nprior work. I embedded this point in broader criticism of the literature at\nlarge^1, problems that lead to a massive amount of research waste (i.e. money\nthat could be spent better).\n\nAs a response to my complaint, someone posted a recent meta-analysis that\nsupposedly shows convincingly that there are relations between mindfulness\ntraining and brain morphology. Here is the relevant part of the paper\u2019s\nabstract:\n\n> \u201c[..] This study aimed to investigate the structural brain changes in\n> mindfulness-based interventions through a meta-analysis. [..] 11 studies\n> (n=581) assessing whole-brain voxel-based grey matter or cortical thickness\n> changes after a mindfulness CT were included. Anatomical likelihood\n> estimation was used to carry out voxel-based meta-analysis with leave-one-\n> out sensitivity analysis and behavioural analysis as follow-ups. One\n> significant cluster (p<0.001, Z=4.76, cluster size=632 mm3) emerged in the\n> right insula and precentral gyrus region (MNI=48, 10, 4) for structural\n> volume increases in intervention group compared to controls. Behavioural\n> analysis revealed that the cluster was associated with mental processes of\n> attention and somesthesis (pain). Mindfulness interventions have the ability\n> to affect neural plasticity in areas associated with better pain modulation\n> and increased sustained attention. This further cements the long-term\n> benefits and neuropsychological basis of mindfulness-based interventions.\u201d\n\nThis all looks fine, and only because I was supposed to grade assignments and\nreally looked for something else to do, I scrolled down a little, and found\nthat the authors actually removed 4 of 15 studies that contained null-findings\nfrom their meta-analysis. That is, they removed 4 studies that did not find a\nrelationship between brain morphology and mindfulness, and then concluded that\nthe results \u201ccements the [..] neuropsychological basis of mindfulness-based\ninterventions\u201d. This is not a valid conclusion.\n\nThat the authors excluded null-findings is unclear from the title or abstract.\nDigging a little deeper, the sample sizes of the removed studies were nearly\ntwice as large as the sample sizes of the included studies. And of the 11\nanalyzed studies, only 2 provided any significant effects, with fewer than 70\ncombined participants \u2014 one of which is a study on Yoga with female\nparticipants at risk for developing Alzheimer\u2019s disease. Even without the\nissue of dropping null-findings, this does not qualify as robust evidence\nusing meta-analytic guidelines (1, 2).\n\n# 3\\. Problems with peer-review\n\nAs a result of the above, when someone sends me a paper in which a particular\nfinding is reported, or when a colleague publishes a paper, I have little a\npriori confidence that what is communicated follows from the presented data.\nBut wait, aren\u2019t all scientific papers vetted through a system of peer-review?\nYes, most journals have systems in place where reviewers critically evaluate\npapers. In practice, this system does not work very well, which often comes as\na surprise to journalists or friends outside of academia I talk to. Here are\nsome reasons why peer-review does not work well.\n\n(1) Authors are often asked to recommend reviewers; you can immediately see\nhow this can lead to problems. \u201cYou recommend me and I recommend you\u201d is\ncommon, or just recommending academic friends who are not impartial. There are\nno structural mechanisms in place at scientific journals to interrogate or\nprevent these issues other than perhaps checking if researchers have published\ntogether.\n\n(2) Peer-reviewers often disagree with each other when they rate the quality\nof a manuscript. When we work as editors as read several peer-reviews, we\noften face situations where one reviewer is very unhappy with a paper and\nrecommends rejection, but the second reviewer is very enthusiastic. We see\nthis as authors when we often (not always) get conflicting feedback. And we\nsee this in scientific studies on the topic.\n\n(3) There are no real scientific standards for who becomes a reviewer, and\nsome journals like Frontiers use software that automatically selects and\ninvites reviewers. I am regularly invited to review geological work on\ndepression \u2014 \u201ca landform sunken or depressed below the surrounding area\u201d \u2014\nbecause I work on major depressive disorder. PhD students I supervise are\noften invited in the second year of their PhD by an automated system. This\nisn\u2019t to say they aren\u2019t qualified, but I don\u2019t think the public, when they\nsee \u2018peer-review\u2019, would think PhD students vet papers.\n\n(4) Most papers are reviewed by 2 or 3 reviewers. They in most cases do not\nget reimbursed, and there is little motivation other than scientific integrity\nand the importance of service to the field to take the work seriously. Given\nhow stressed researchers can be, I have seen many, many, many low-quality\nreviews. This is supported by pretty devastating experimental work showing\nthat reviewers usually miss fatal flaws when being asked to review flawed\npapers (1, 2, 3). ^2\n\n(5) There is no accountability for a bad review, because reviews are nearly\nnever public. So even if you just wrote \u201cfuck you\u201d in a review and do nothing\nelse (please don\u2019t), the worst that happens is that the editor or the journal\nno longer invite you to review again. Journals stress that peer-reviews are\nconfidential, which means they wouldn\u2019t even be allowed to broadly share that\nyou are a terrible reviewer (e.g. to other journals), following their own\nrules.\n\nIn the previous section, I tried to explain why I don\u2019t have a lot of\nconfidence in the conclusions of any random paper before vetting it. Now you\nknow why the fact that this paper was peer-reviewed does not in any\nfundamental sense increase my trust in the veracity of presented findings.\n\n# 4\\. Problems with the publishing industry\n\nBut Eiko, these papers are published by journals like Science and Nature. Are\nthose not cornerstones of truth in the world? Are they not beyond reproach?\nWell .. I believe that the scientific publishing industry is inherently tied\nto some of these problems. I\u2019ve written about the industry in some detail\npreviously, and recommend the blog to catch up if you don\u2019t work in academia.\n\n(1) In sum, most scientific publishers are for-profit companies. They sell\nscientific papers in the way Apple sells smartphones or computers, and they\nhave no inherent interest in scientific integrity or cumulative knowledge\nbuilding because these are not goods that inherently increase profits. I don\u2019t\neven think this is morally bankrupt: it is just a business, and it is our\nfault that we have let a system happen in which scientific publishing is a\nbusiness, rather than organized by states or governments or non-profits or\nuniversities, with the goal to make scientific findings available to everyone.\n\n(2) In a nutshell, a researcher does research and submits a paper; other\nresearchers serve as editors for a journal and help select appropriate papers\nfor publication; other researchers peer-review the paper; and a journal\neventually publishes the paper, for a profit. None of the researchers\n(authors, editors, reviewers) usually get compensated. Essentially, tax payers\npay researchers who then do work that publishers sell back to tax payers for a\nridiculously high profit margin. The procedure varies a bit, but in clinical\npsychology, psychiatry, and methodology, the above is standard practice and\nrepresentative of publishing in these fields. How is this not disheartening?\n\n(3) The publisher \u2018MDPI\u2019 owns many journals, and in recent years most of these\njournals, on average, published one special issue per week. Several journals\neven published more than 2 special issues per day (Wikipedia). There is no way\nthat all of this is robust, thorough, carefully vetted science, especially\nwhen one considers the very short times from submission to publication. This\nmay be one of the reasons why some MDPI journals were recently delisted from a\nlist of legitimate journals, and why some researchers have long considered\nMDPI a predatory publisher. MDPI is not alone here, Frontiers journals and\nother publishers have also received serious criticism.\n\n(4) I already mentioned that last year, over 10000 papers were retracted.\nRelated headlines such as \u2018Scammers impersonate guest editors to get sham\npapers published\u2018 don\u2019t exactly inspire confidence either.\n\n# 5\\. Problems with work pressure and incentives\n\nLet\u2019s move to us: researchers and educators.\n\n(1) I\u2019ll start showing you how bad things are, describing my own situation.\nIt\u2019s never nice to hear a privileged German white guy complaining, but the\npoint I\u2019m making is that even with my level of privilege, things were barely\nmanageable. During my PhD in Germany, I was in a precarious employment\nsituation, earning less than \u20ac1250 per month, from which I needed to pay for\nmy healthcare. This is because we were employed as \u2018freelancers\u2019, a trick\nuniversities do to save social welfare and other contributions (they also did\nnot pay into my pension fund). Many of my friends and colleagues during their\nPhDs were employed and paid for half-time positions, but expected to work full\ntime. I then had 2 temporary postdoc positions for 2 years each. And then I\nworked as an Assistant Professor, in a temporary position. Only recently, at\nthe age of 39, did I obtain tenure, i.e., my very first permanent job.\n\n(2) This is related to situations surrounding \u201cpublish or perish\u201d, long work\nhours, mental health problems and burnout, and a lack of sustainable and\npermanent jobs (1, 2, 3). A recent OECD study summarizes the situation:\n\n> \u201cAcademic careers have become increasingly precarious, endangering rights,\n> subjecting workers to difficult working conditions and stress. [..] Most\n> were on short-term contracts or did not have any employment relationship\n> [..] The problem has long been severe and has gotten worse over time. [..]\n> Many countries are experiencing the emergence of a dual labour market, with\n> the coexistence of a shrinking protected research elite and a large\n> precarious research class that now represents the majority in most academic\n> systems.\u201d\n\n(3) I want to get back to scientific evidence and quality: these issues\ndramatically exacerbate the problems I discussed above surrounding the\nvalidity of findings. Especially when we are employed in precarious\nsituations, there is little overlap between the goals and motivations of\nscientists, and the core goal of science itself. My colleague Anna van\u2019t Veer\ncreated a really nice figure on this topic as part of our workshop on\nResponsible Scholarship, showing that pressures in the system (e.g. publish or\nperish, competitiveness, hectic research pace) lead to scientists doing work\nthat benefits their careers at the moment (such as flashy publications), but\ndo not contribute to a rigorous, robust pyramid of cumulative science (cf.\n\u201cSlow Science\u201c). Scientists are largely still evaluated based on traditional\nmetrics such as the number of publications, journal impact factors, citations\nrates, and so on, and optimizing those has little to do with optimizing\nscientific quality \u2014 especially if you optimize these in situations of duress\n(i.e. worried to be unemployment next year).\n\n# 6\\. Antidotes to cynicism creep\n\nLet me reiterate what I said before: when someone sends me a paper or a\nnewspaper article about a paper, my view today is that the conclusions may or\nmay not be valid. I don\u2019t expect things to hold up just because this is a\nscientific paper (compared to a blog post), or because it is peer-reviewed\n(compared to a preprint), or because it is published in Nature or Science, or\nbecause it is published by a famous scientist. I think my view is reasonable\nand supported by evidence, at least in the fields I work in.\n\nThis view can lead to cynicism, which is what I want to avoid for myself \u2014\ncynicism drains my motivation and energy. It\u2019s not enjoyable to do this sort\nof work when you doubt the validity of much of the literature. Cynicism can\nalso be contagious, potentially affecting junior colleagues and students. And\nthen you\u2019re disheartened, your team is discouraged, your students are bummed\nout ... not a good place to be in, for you or anyone else. I believe my team\ndoes the best work when we\u2019re both critical and motivated. Motivation can of\ncourse come from a sense of urgency, but it becomes dangerous (for me anyway)\nwhen it tips over into cynicism.\n\nBut this view that many scientific conclusions are invalid also implies a call\nto action, because the status quo threatens the idea of building a robust,\ncumulative pyramid of foundational blocks that stand the test of time.\n\nAnd this is where the energy lies. The motivation and hope and amazing\nopportunities to make things better, together with smart and kind people all\naround us. There is a good chance we can make a dent in the problems I\u2019ve\nsummarized above, in my lifetime, and we have already seen a lot of\nimprovements over the last years. We need to do so not only to prevent\nresearch waste, but also to prevent a further erosion of society\u2019s trust in\nscience, which can be deadly as we have seen during the COVID-19 pandemic in\nrelation to vaccines.\n\nHere\u2019s how I get my energy. This is necessarily idiosyncratic, but I hope some\nof these will work for you, too.\n\n## 6.1 Watch\n\nI listed so many problems above, but none of them have to be permanent, and\nthere is progress for all of them.\n\n(1) I\u2019m privileged to get to see a lot of amazing people in action. People\nlike Jessica Schleider, Jennifer Tackett, Don Robinaugh, Marc Molendijk,\nPraveetha Patalay, Laura Bringmann, Anna van\u2019t Veer, Anna van Duijvenvoorde\nand so many others who not only do amazing work following modern open science\nprinciples: they are also fantastic peers, mentors, and teachers. I find it\ninspiring and motivating to watch them work. Generally, seeing the massive\ngrassroots movements that have popped up in the last half-decade, such as open\nscience communities and reproducibiliteas, give me a lot of hope for the\nfuture. There are too many people and initiatives to list here, but recently,\nfolks have started putting out bounties to find errors in their own work,\noffering either payments or donations to charity if mistakes are identified\n(1, 2, 3). And a few weeks ago, ERROR went online, \u201ca bug bounty program to\nsystematically detect and report errors in scientific publications, modelled\nafter bug bounty programs in the technology industry\u201d where investigators are\npaid for discovering errors.\n\n(2) In terms of precarious contracts, there is progress in the Netherlands\nboth on the national level, and the level of specific universities and\nfaculties. For instance, the Faculty of Science at the Free University\nAmsterdam decided to discontinue the tenure track system (which is quite\nunique: other jobs don\u2019t require you to perform very well for 5 years before\nyou are perhaps offered a permanent job). They will replace the tenure track\nsystem with a career track policy that assumes a permanent contract after 18\nmonths.\n\n(3) The Netherlands is also among the leading countries for rewards and\nrecognition initiatives, i.e., for initiatives that try to change what\ncriteria we are evaluated on. Away from traditional metrics such as impact\nfactors and fancy journals, to the question of how open and transparent our\nworks are, how effectively we engage with the public, and how much help and\ncollaborative opportunities we can provide to colleagues. If you are primarily\nteaching, you ought to be evaluated based on .. surprise .. TEACHING rather\nthan on your publications. Utrecht University has taken bold steps, for\ninstance, moving towards a much more collaborative and inclusive environment.\n\n## 6.2 Do\n\n(1) I get a lot of energy from activism to improve things in academia, for\nexample, as co-founder of the Open Science Community Leiden, member of the\nYoung Academy Leiden, and all activities that come with these groups and\ninitiatives. Being in the privileged position to talk about the issues that\nplague researchers, research, and public trust is a huge responsibility, but\ncan also be very motivating when folks in charge respond positively. I highly\nrecommend activism. This is why I find it so utterly alienating when people on\nTwitter shit on the \u2018open science movement\u2019, which to 99% consists of super\nenthusiastic early career researchers who have learned their lessons from\nflawed literature, and try to make things better in their own work.\n\n(2) More broadly, for me personally, the way forward is to incentivize,\nchampion, and promote better and more robust scientific work. I find this\nmotivating and encouraging, and an efficient antidote against cynicism creep.\nI find it intellectually rewarding because it is an effort that spans many\nareas including teaching science, doing science, and communicating science.\nAnd I find it socially rewarding because it is a teamwork effort embedded in a\nlarge group of (largely early career) scientists trying to improve our fields\nand build a more robust, cumulative science. In the best case, these efforts\nnot only safeguard the quality of science and its application, but also enable\ntrust, foster equal opportunities and outcomes, and prevent research waste.\n\n(3) Teach! I\u2019ve been teaching a research methods course to clinical master\nstudents in Leiden for a few years, and I love how quickly and clearly they\nunderstand problems in the literature, and what can be done to address these\nissues. I\u2019ve been able to teach workshops for international audiences, e.g. on\nthe importance of proper theory building and testing (rather than vague,\nnarrative ideas that can\u2019t ever be rejected) together with Don Robinaugh; on\nthe importance of improving our measurement practices with Jessica Flake; and\non network analysis and other statistical methods with a host of other amazing\nresearchers. Students are skeptical, and they are ready to identify and tackle\nchallenges.\n\n(4) Practice and celebrate, for your own work and that of others, what Merton\nreferred to as a crucial norm in science: organized scepticism, i.e., that\n\u201cscientific claims should be exposed to critical scrutiny\u201d. And while we do\nso, lets try to make sure to call out problematic work, not people (at least\nfor a while, unless we have called out work by the same people too many\ntimes). Tough on the issue, soft on the person. Science is a social enterprise\nas well, and it\u2019s no fun to be criticized. Let\u2019s practice together, and start\nteaching folks earlier on in their careers, that they are not their science,\nand rejected hypotheses and theories say nothing about you as a person. Let\u2019s\npractice criticism, for instance, following Rapaport\u2019s rules, and let\u2019s\npractice being criticized. Quote:\n\n  1. You should attempt to re-express your target\u2019s position so clearly, vividly, and fairly that your target says, \u201cThanks, I wish I\u2019d thought of putting it that way.\u201d\n  2. You should list any points of agreement (especially if they are not matters of general or widespread agreement).\n  3. You should mention anything you have learned from your target.\n  4. Only then are you permitted to say so much as a word of rebuttal or criticism.\n\n(5) Write about the problems you see. When I joined Denny Borsboom\u2019s lab in\n2014 and learned about network models and estimated coefficients, one of my\nfirst thoughts was that current estimation routines don\u2019t provide information\non model stability, such as confidence regions. So I teamed up with Sacha\nEpskamp and we wrote a tutorial paper on the topic, urging researchers to\nestimate and communicate uncertainty about the estimated model results. The\ncommunity embraced the paper and practice quickly, which was very rewarding to\nsee. Similar things happened when I teamed up with Michiel van Elk to write\nabout problems in psychedelic science, or Jessica Flake to write about\nproblems in psychological measurement. This gives me energy because scientists\nand teachers and journalists and policy-makers are willing to engage with\ncritical material: it just needs to be out there, in accessible ways.\n\n(6) Publish reviews. If we really keep ye good olde peer-review system, the\nleast we must do is put them online. I would very much like to see the reviews\nfor the mindfulness paper I listed above, what the handling editor wrote, and\nhow the authors responded. Were these issues not caught? Did the reviewers\ncatch them but the editor did not ask the authors to fix the problems? Perhaps\nmost imporantantly, did the authors have good counter-arguments, making my\ncriticism potentially invalid? Publishing reviews resolves these questions,\nand while it is rare, some publishers have implemented this practice for a\nlong time (e.g., BMC journals for several journals in 2001 already). Modern\njournals such as Meta Psychology publish all communication. How cool is that?\n(Sidenote: I sign my reviews, because I think I should be held accountable,\nbut I am also one of the most privileged groups in academia and have a\npermanent job \u2014 there is little objective danger here. But I would never ask\nearly career folks or folks in precarious employment conditions to sign.)\n\n(7) Publish code and data, whenever possible. Researchers should be asked to\nshare their data and code (i.e., their exact statistical analyses, which is\nusually a programming code). Pushling such information can be incredibly\nuseful because it allows the scientific community at large to practice\norganized skepticism \u2014 mistakes happen, in every job, and we must make sure to\ncatch them when they happen. I have shared code for all my papers since 2015\n(because that is free, I don\u2019t think there are ever reasons not to), and data\nwhen possible, and doing so enabled the scientific community to identify a\nmistake in one of my statistical analyses, resulting in a correction of my\nwork.\n\nOf course, some of the proposed solutions and initiatives above may not work\nout, and some may even put us a step back \u2014 I hear you. But there is actual\nprogress, coming from motivated folks in different areas of academia, thinking\nabout these issues and how to solve them in good faith. This gives me a lot of\nenergy. It\u2019s a bit like a first therapy session for PTSD, where one of the\nmost important things to do is normalize: \u201cYou may think your symptoms are\nbizarre or abnormal, but actually, these are quite common symptoms many people\nexperience, and they are quite normal given what you have been through!\u201d I\nexperience the current initiatives as very normalizing for me (it\u2019s not you\nEiko, it\u2019s the system, stupid).\n\nAnd everybody is different, and my answer to the question of what gives energy\nmay not be correct for you. I still hope it may inspire.\n\nWhich make me wonder: what inspires you?\n\n# 7\\. Conclusion\n\nThere are plenty of reasons to be disillusioned about the system as a whole.\nBut maybe that\u2019s the first necessary step: dis-illusionment, seeing things for\nwhat they are. This provides energy and motivation for change. So many people\nhave been dis-illusioned, and we stand on the shoulders of giants who have\nhelped to dispel false beliefs, including that peer-review guarantees\nscientific quality, that journals with high impact factors publish higher\nquality work, that Nature charging \u20ac10,000 for open access fees is fair, or\nthat precarious employment is normal and fine.\n\nThe last decade has shown that we can really make a dent into some of these\nissues, just looking at the reforms we have seen, at the national level (e.g.,\nthe Dutch Taverne amendment allowing researchers to share their work in\npublic), international level (e.g., UNESCO\u2019s recommendations on Open Science),\njournal level (e.g., TOP guidelines and Registered Reports), and level of\nfunders (e.g., the Dutch funder NWO mandates much more transparency than was\nthe case a decade ago). While we share values of open science, work is in\nprogress figuring out how to best implement these values, and this is a\ngenuinely difficult process that will take time. But let\u2019s not mistake\nimportant debates on what practices are best suited to implement our values\noptimally with a lack of progress generally.\n\n### Share this:\n\n  * Click to share on Twitter (Opens in new window)\n  * Click to share on Facebook (Opens in new window)\n  * Click to share on Reddit (Opens in new window)\n  * Click to share on LinkedIn (Opens in new window)\n  * Click to share on Tumblr (Opens in new window)\n\n  1. In case you\u2019re interested in evidence for this claim, see e.g. here, here, and here for the depression literature\n  2. Adam Mastroianni wrote a great piece on problems of peer-review.\n\n### Related\n\nPsychology, Publishing, Scientific journals, Things gone wrong\n\n## 30 thoughts on \u201cAntidotes to cynicism creep in academia\u201d\n\n  1. Pingback: Scientific publishers *not* adding value \u00bb Eiko Fried\n\n  2. Pingback: The Risks We Take For Others \u2013 Living With Evidence\n\n  3. gabriel March 30, 2024 at 7:54 am\n\nthe merits of open everything is undeniable. data and code should be open. but\none of the problems today is plagiarism. this will weight heavily on new\nacademics who will have a risk all bet to open their data vs stabiliahed peers\nwho will just het better visibility anyway. I don\u2019t think anyone have proposed\nany solution, practically speaking.\n\nthen removing renure is throwing the baby with the baby water. tenure is an\nawesome mechanism to keep fields moving. the problem is that most academics\nclosed themselves in their little circle of close peers (like you are already\ndoing in this very text) and now the system is being abused. problem is the\nabuse, not the system. it doesn\u2019t have safe guards against abuse by the\nacademics abusing it because all the safeguards are for the academics against\nthe institutions! and that\u2019s a great thing that should be preserved. likewise\non praising the new neoliberal overly capitalistic system Netherlands find\nitself in now is detrimental to decades of labour conflict I won\u2019t even go\ninto as it is all too obvious and not even veiled.\n\nReply \u2193\n\n  4. Pingback: Thursday assorted links | Factuel News | News that is Facts\n\n  5. No\u00e9mi Schuurman March 27, 2024 at 1:01 pm\n\nThanks for sharing these findings, thoughts, experiences and feelings down\nEiko. I think it nicely summarizes a lot of real problems we encounter daily\nin our work as academics.\n\nDropping a line to emphasize one of your points \u201cTeach\u201d. I very much believe\n(no, I have no concrete evidence to back this) that the most impact any\nacademic will have is through teaching and supervision \u2013 that is, it is a way\nto have A LOT of impact, through other people.\n\nUnfortunately, the value of teaching is in practice often underestimated and\nundervalued, perhaps in part because it is indirect impact and hard to\nquantify. But, teaching is increasingly being valued more in academia in\nvarious places (for example here at Utrecht University). In any case, valuing\nteaching and rolemodeling more in academia could also be one way forward to\nremove some of the publish or perish pressure, next to efforts that focus on\nimproving specific aspects of research practice.\n\nReply \u2193\n\n  6. Bernard March 27, 2024 at 8:11 am\n\nThank you for your article. Maybe 2 effective solutions should be also\nhighlighted. The PCI initiative (https://peercommunityin.org/). We review the\npreprints and share online our reviewing, then preprints are (or not)\nrecommended to PCI friendly journals or PCI journal\n(https://peercommunityin.org/pci-and-journals/). A PCI psychology is in\npreparation. Collective resignation of editorial board to create a new\nacademic journal with an diamond/gold OA model\n(https://www.statnews.com/2024/02/01/scientific-publishing-neuroimage-\neditorial-board-resignation-imaging-neuroscience-open-access/)\n\nReply \u2193\n\n  7. Anon_ECR March 23, 2024 at 9:35 pm\n\nI have to say I\u2019m in two minds about this post. I like the first half because\nit nicely collates key problems in science and academia in one place. The\nsecond part moves to an antidote to the cynicism built up. But it reads mostly\nlike a list of virtuous actions that you are personally doing and which we\nshould be doing too. I don\u2019t find that helpful at all. It\u2019s like writing an\narticle about climate change and how we\u2019re pretty doomed, and to list personal\nacts of activism as an antidote to pessimism, and that we should watch our own\nCO2 output. Calls to action are great, but I think they should be\ncontextualized as such to not provide false hope to the disillusioned. Ways to\nmake systems better are not an antidote to cynicism about that system...\nFurthermore, I suspect many would lose and not gain energy from doing the\nthings you suggest, because they require (exhausted) academics to confront the\nproblems we were supposed to get an antidote for directly instead of keeping\nthem at an arm\u2019s length.\n\nI think if the goal was to give an antidote, there are much better routes: (i)\nA line of arguments about how academia may still be the best game in town for\ncurious and serious people. The thing about academia is that it purports to\nunderstand the world and make things better, and there are obvious efforts in\nthis direction. So even if one is reasonably disheartened by academia, in for\nexample the corporate world, usually people aren\u2019t interested in figuring out\nhow things work at all. In many cases, the implicit goal outside of academia\nis rather to convince people internal and external to companies that the world\nworks in ways that it expressly doesn\u2019t (to sell things). (ii) You could have\nprovided a critical evaluation of the first half of your article. For example,\nyou point out retraction numbers, sharing a graph that shows a stark increase.\nBut the numbers you show are absolute and don\u2019t factor in the overall amount\nof published articles anually. What are the trends in retraction proportions?\nIf you look at PubMed or other sources, it seems that the absolute number of\npublished research articles is outpacing the number of retractions (especially\nif you exclude 2023, which as per your graph is an anomalous year). So instead\nof using incomplete information to potentially make folks more rather than\nless worried, there\u2019s a missed opportunity for a more substantive antidotes to\npessimism.\n\nReply \u2193\n\n    1. Eiko Post authorMarch 24, 2024 at 2:04 pm\n\nThanks for the feedback. It sounds like you\u2019re saying you could have written a\nbetter blog post than this, with better arguments (e.g. there is no\nalternative to science, which is a great argument), less personal highlights,\nbeing more critical about some cited sources in part I, etc.\n\nI absolutely believe you \u2014 much can be improved. I would love to read a better\nversion of this blog post, and I am sure others would like to as well, so\nplease leave a comment here when you\u2019re done, I\u2019d be happy to link to it in\nthe piece!\n\nFor me personally, a blog like this takes around 8-10 hours to write / check /\nclean-up / tag / thumbnail / share, and I just don\u2019t have more resources to\ndevote to a single blog, unfortunately.\n\nReply \u2193\n\n    2. Anon_MCR March 24, 2024 at 10:26 pm\n\nThanks Anon_ECR. The original blog post was fine but from the title, I was\nlooking for exactly those two last points, which really do give me heart.\n\nReply \u2193\n\n    3. No\u00e9mi March 27, 2024 at 12:38 pm\n\nI personally feel the progress and change people are making in academia, does\nprovide an antidote to cynism for me, to some extent. I feel this shows that\nacademia/science is to some extent self-correcting, and to some extent things\nare working as they should. There is room in academia for criticism and to\nlearn from them, even if sometimes that room seems small and change goes\nslowly. That is not something to take for granted, something to protect, and\nsomething that gives me hope.\n\nYour point i) is also something I feel needs to be pointed out more, but it\ndoes not personally make me feel less cynical :p (that is, it seems close to\n\u201dsome places are even worse/have it much worse then you, don\u2019t you feel better\nnow ?\u201d).\n\nReply \u2193\n\n  8. Boris Barbour March 23, 2024 at 5:42 pm\n\nAmen to nearly all of that.\n\nI think, in the end, we need not just to say nice things about the good\nscience, but to make it pay, and also to make bad science not pay. It may\nsound a bit aggressive, but I think we should all make use of whatever\ninfluence we have \u2013 grant, hiring and promotion committees being obvious\npossibilities \u2013 to direct funds towards good science and scientists and away\nfrom those who produce bad science.\n\nIt would be terrific if your analyses of specific papers were linked from\nPubPeer. It shouldn\u2019t take more that a minute to post a link...\n\nReply \u2193\n\n    1. Eiko Post authorMarch 23, 2024 at 6:22 pm\n\nGood call /re pubpeer. Goes on the very long to do list of \u201cthings to do that\nwould only take a few minutes\u201d ;).\n\nReply \u2193\n\n  9. Matt Patton March 21, 2024 at 6:54 pm\n\nThanks for writing about this Eiko. I\u2019ve been mulling over how to address my\nown cynicism creep for a couple weeks.\n\nI can\u2019t shake the feeling that the open science movement has a pretty narrow\nview of activism. Most open science discussion is just scientists talking to\nother scientists, as if no one else has a stake in science working well. But\nit\u2019s safe to say non-scientists would prefer that health research be\ntrustworthy, that their taxes not go to support fraud and waste, that\nscientists not mislead them with hype in the media, that scientists should\nadhere to agreed-upon standards of transparency, etc.\n\nI\u2019m still not sure why the open science movement hasn\u2019t done a better job\nmobilizing public support. Perhaps it is fear of politicization, or perhaps it\nis just that scientists are so busy under the current system. Maybe it\u2019s\nelitism. Maybe it\u2019s cynicism about public opinion. Whatever the reason, this\nsituation has left non-scientists who are concerned about these problems with\nlittle we can do to help. I don\u2019t know of any major non-profits educating the\ngeneral public, connecting the dots between the problems in science and normal\npeople\u2019s lives.\n\nTo me it seems especially frustrating because there\u2019s so much agreement around\nkey reforms. Reforms aren\u2019t implemented because of collective action problems\nwe know how to overcome in other labor sectors. I don\u2019t know what the solution\nis, but I think it starts with broadening our imaginations about what\neffective open science activism can look like. We don\u2019t really lack for\nsolutions anymore. We lack the coordination to get them implemented.\n\nReply \u2193\n\n    1. Eiko Post authorMarch 21, 2024 at 8:09 pm\n\nHey Matt.\n\nThree thoughts. First, I think at least here in the NL things are happening. I\ndon\u2019t think the public is involved much, which isn\u2019t great, but there are\ndefinitely many committees also outside of universities where OS debates are\nhappening, with OS activists being involved.\n\nSecond, of course not enough is happening, it is a somewhat insular\ndiscussion, but I doubt this is because folks love their ivory towers. It\u2019s\ngenuinely difficult. As a teacher and administrator and leader of a team and\nresearcher and writer and blogger and programmer and science communicator and\nand and and, you know, all the stuff academics do in their daily lives, it\u2019s\ndifficult to also be a implementation scientist, political organizer, being\nable to easily mobilize politicians or the public to stand behind topics, etc.\nSo I fully agree that some paths forward are clear, but I honestly just don\u2019t\nknow exactly what the next steps ought to be. We wrote the Elsevier piece.\nIt\u2019s outrageous what we describe. But I just don\u2019t really know any Dutch\npoliticians, and I really have no time left in my week to start some sort of\nextra initiative now trying to take down Elsevier. I think it\u2019s super fair to\ncounter that this sounds a little defensive: it honestly is, because I would\nLOVE to see shit getting done rather than just being talked about.\n\nAnd that leads to point three: perhaps good to step back, talk to\nimplementation scientists, and figure out how time could be spent most\neffectively on actually getting reforms on the way, rather than creating a\nbunch of literature just narrating the need for reforms!\n\nReply \u2193\n\n      1. Matt Patton March 21, 2024 at 8:47 pm\n\nOh I completely understand. I should have been more specific that I think it\u2019s\na problem with the conversation in the open science movement in general. You\nmore than do your part educating the public (including educating me). You\u2019re\nthe last person who should feel defensive about not doing enough.\n\nBut I feel like that also speaks to the larger issue. The labor needs to be\nmore equitably distributed. People like me need to be networking to do things\nlike set up nonprofit advocacy orgs or a researchers\u2019 unions. I just think the\nconversation in the movement doesn\u2019t pay enough attention to the practical\nbusiness of organizing to achieve goals. I\u2019ll give some more thought to what\ncan facilitate that.\n\nJust my take from the outside. Speaking of public education, thanks for doing\nyour three (!) talks today. I hope you\u2019re taking some proper holiday time this\nsummer.\n\nReply \u2193\n\n        1. Eiko Post authorMarch 21, 2024 at 8:55 pm\n\nI definitely don\u2019t do enough, looking at awesome colleagues like Anna van\u2019t\nVeer who is SO INVOLVED in these issues. Big role model who devotes a lot more\ntime than me to this. So good reasons to be defensive for sure ;) !! Thanks\nMatt!\n\nReply \u2193\n\n    2. One thought March 24, 2024 at 10:28 pm\n\nOne reason might be that there has (and continues to be) a \u2018holier than thou\u2019\nclique attitude within the open science movement, unfortunately. The \u2018bropen-\nscience\u2019 term still applies.\n\nReply \u2193\n\n  10. Mahmut Ruzi March 19, 2024 at 10:30 am\n\nVery well thought out and written on a vital issue. I am a chemist and the\nissues are the same in that field. I think most researchers are aware of the\nproblem but have very little to no incentive to do something about it, so most\nof us take the path of least resistance and keep publishing and reviewing\npapers of little significance. I have written a blog post about the issue and\nsuggested some solutions that are similar to yours: publishing reviews, paying\nreviewers, and a bit radical solution to get rid of the whole commercial as\nwell as society-based publishing and adopt an arxiv-like system.\n\nI would love to hear your thoughts.\n\nhttps://mahmutruzi.medium.com/addressing-and-resolving-critical-issues-in-\nacademic-publishing-ad13f5f85c43\n\nReply \u2193\n\n    1. Eiko Post authorMarch 19, 2024 at 10:45 am\n\nThanks for sharing, browsed it and will read in detail on the weekend. By the\nway, if you\u2019re looking for harder evidence for statement / reference 8 in your\nblog:\n\nhttps://eiko-fried.com/welcome-to-hotel-elsevier-you-can-check-out-any-time-\nyou-like-not/\n\nReply \u2193\n\n      1. Mahmut Ruzi March 19, 2024 at 1:42 pm\n\nThanks for reading.\n\nYes, the evidence you provided is much more broad and detailed. I will add\nyour post to the reference list and revise my writing.\n\nReply \u2193\n\n  11. Reihaneh March 7, 2024 at 10:01 pm\n\nYou just stated my biggest fear in the first sentence, Eiko! I was lucky to\nhave the chance to express that in the PSYNETS workshop and you were really\nkind to give me confidence. However, I keep asking myself what if my work does\nnot add value? I suppose some people may think that would be too much to think\nabout for a master-level project/assignment but I disagree. Unfortunately, I\nthink this fear has taken me to a stage where I just can\u2019t make progress or\nmove forward with my assignments/PhD projects in the way that I like!\n\nReply \u2193\n\n    1. Eiko Post authorMarch 7, 2024 at 10:50 pm\n\nOne way to think of science is the effort of building a cumulative system of\nknowledge together \u2014 a pyramid of sorts. All science relies on prior science,\nin many cases, thousands of tiny, solid, reliable rocks of knowledge. So all\nwe can do is try to make our units of science \u2014 paper, master theses, blog\nposts \u2014 as solid as we can. I don\u2019t think solid means perfect, or having a\nsample size of 1 million, or having assessed all variables with perfect\nmeasurement. Something is solid if the INFERENCE follows from the presented\nEVIDENCE.\n\nI think n=1 studies can be solid, as long as authors report flaws and\nlimitations honestly. So please don\u2019t let concerns about perfect stop your\nwork, no matter how small. But you should carefully spell out limitations of\nyour work for other people reading your work who may not know as much as you\ndo. Does that make sense?\n\nReply \u2193\n\n      1. Reihaneh March 8, 2024 at 9:02 am\n\nThanks a lot for your reply, Eiko. That makes perfect sense. \u201cSomething is\nsolid if the INFERENCE follows from the presented EVIDENCE\u201d -> I will put this\non my desk to remind myself every day! I had a conversation with a lecturer a\ncouple of weeks ago for an assignment. She asked, \u201cHow will you know whether\nyour chosen statistical analysis has produced a productive analysis?\u201d I said I\nwould discuss why I want to use a specific method based on its relevance to my\nRQ, its underlying assumptions, and once conducted, based on the robustness of\nthe analysis. I think my answer was close to what she was looking for.\nHowever, it made me think about what is actually meant by productive analysis?\nCan we ever know with certainty if a chosen statistical analysis produced a\nPRODUCTIVE analysis?\n\nReply \u2193\n\n        1. Eiko Post authorMarch 8, 2024 at 9:52 am\n\nI don\u2019t think like that, so find the question hard to answer. We select\nstatistical models because we have questions about the world, but we cannot\nask the world, so we ask data. Statistical models help us do that.\n\nMy thoughts on models and data are spelled out here in some detail.\n\nhttps://eiko-fried.com/on-theory/\n\nReply \u2193\n\n          1. Reihaneh March 8, 2024 at 10:59 am\n\nThank you!\n\n  12. Simon Disillusioned March 7, 2024 at 9:18 am\n\nThanks for a great article, especially the data on retractions. I reported a\nPaper for fraud and the Head of Anthropology at my London Uni then attempted\nto get me to withdraw the complaint. UK Freedom of Speech in Higher Education\n2023 is a useful tool imo. Ultimately it\u2019s sad to say it but Academia is\nneither well paid, nor high status, nor stress free to work in. Pay peanuts\nget monkeys. And the other issue in the humanities is Silos. Academics\ndefending their own sub discipline for fear of being found out as irrelevant\nor meaningless on its own. They then employ as Research Assistants and PhDs\npeople who parrot their Academic bosses, with predictable consequences.\nQuality is low low low everywhere I see. The more you look at any humanities\npaper the more problems you see. It\u2019s a serious mess that the current wokerati\nare only worsening. At least in the private sector research has a measurable\ngoal. In academia that goal is to defend the current orthodoxy and maintain\njobs for those who have floated to the top, like sc...m\n\nReply \u2193\n\n    1. Eiko Post authorMarch 7, 2024 at 9:20 am\n\nSorry the cynicism creep got to you! I feel like that too sometimes, but being\ninvolved in a ton of initiatives, and seeing so many young people full of\nenergy to change things, I really don\u2019t think it\u2019s an option to give up just\nyet.\n\nReply \u2193\n\n  13. Adam March 6, 2024 at 11:56 pm\n\n\u201cThings are terrible but you should still have blind optimism\u201d sounds unwise .\nOptimism is stupidity if there is little chance things will change\n\nReply \u2193\n\n    1. Eiko Post authorMarch 7, 2024 at 1:02 am\n\nPeople who know me wouldn\u2019t consider me a blind optimist\u2014far from it. Unwise?\nProbably.\n\nReply \u2193\n\n  14. a tired PhD student March 6, 2024 at 9:18 am\n\nThis article hits too close to home. Very well written! I struggled to\novercome the cynicism with the rigid structures within my department, which\noften stifled \u201cinnovation\u201d (proper science) and collaboration. While I\u2019ve\ndecided to leave academia this summer, I\u2019m hopeful that future changes can\naddress these issues.\n\nReply \u2193\n\n### Leave a Reply Cancel reply\n\nThis site uses Akismet to reduce spam. Learn how your comment data is\nprocessed.\n\nDr Eiko Fried is a psychologist, methodologist, and nearly photographer. He\nworks as Associate Professor at Leiden University. He runs this website, and\nif anything is broken, you should probably blame him.\n\nJoin 1,056 other subscribers\n\n### Recent posts\n\n  * Scientific publishers *not* adding value\n\n  * Which depression measure is best?\n\n  * Antidotes to cynicism creep in academia\n\n  * Blood tests for mental health problems\n\n  * Fact-check: depression & temperatures study\n\n  * Is the \u2018default mode network\u2019 responsible for the mental health crisis in youth?\n\n  * Does the d (disease) factor really exist?\n\n### RSS feed\n\n  * RSS - Posts\n\nIn case you\u2019re interested in evidence for this claim, see e.g. here, here, and\nhere for the depression literature\n\nAdam Mastroianni wrote a great piece on problems of peer-review.\n\n", "frontpage": false}

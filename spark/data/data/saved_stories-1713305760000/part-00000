{"aid": "40053867", "title": "Basic building blocks of dependent type theory (2022)", "url": "https://www.lesswrong.com/posts/ccbsYSpTcTqXwukH8/basic-building-blocks-of-dependent-type-theory", "domain": "lesswrong.com", "votes": 1, "user": "jstrieb", "posted_at": "2024-04-16 16:14:48", "comments": 0, "source_title": "Basic building blocks of dependent type theory \u2014 LessWrong", "source_text": "Basic building blocks of dependent type theory \u2014 LessWrong\n\n##\n\nLESSWRONG\n\nLW\n\nIntroduction to Dependent Type Theory\n\n# Basic building blocks of dependent type theory\n\nby Thomas Kehrenberg\n\n15 min read15th Dec 20228 comments\n\n# 47\n\nLogic & Mathematics World Modeling\n\nFrontpage\n\nBasic building blocks of dependent type theory\n\n15th Dec 2022\n\nType judgments\n\nProduct types\n\nAside on Lambda Calculus\n\nFunction types\n\nSum types\n\nExamples\n\n8 comments\n\nThis post is the first in a sequence of posts meant to be an introduction to\npragmatic type theory. \u201cType theory\u201d here refers to Martin-L\u00f6f dependent type\ntheory (MLTT), as opposed to theories like the simply-typed lambda calculus;\nthe main difference being that in MLTT, functions can also act on types and\nnot just values, which makes it a more powerful theory.\n\nI was initially motivated to study type theory because of a remark in the\nAlignment Research Field Guide about how defining terms and adding type\nannotations to them can make the topic of alignment research discussions more\nprecise, as an intermediate step between vague idea and fully formalized\nproof.\n\nYou might also be aware that type theory can serve as an alternative\nfoundation for mathematics, in place of set theory. And some people think type\ntheory is the more elegant choice of the two; a point which this article is\nfor example arguing for. Another reason to learn type theory is that it serves\nas the basis of most theorem provers.\n\nI\u2019m not aware of any short-ish but still pretty comprehensive introductions to\nMLTT, so that's why I wrote this sequence of posts. The content is mostly\nbased on the book Homotopy Type Theory, with the main difference that the book\ntries to convince you to do constructive mathematics, whereas I won\u2019t. (I also\nwon\u2019t talk about any homotopies at all.) This means though that if you\u2019re\ninterested in constructive mathematics (or homotopies), you should probably\njust read the book instead.\n\nI will sometimes compare type concepts to concepts found in programming\nlanguages, but if you don\u2019t have any programming experience, you can just\nignore that. What you should have though, is a good understanding of set\ntheory, because I will reference it frequently.\n\nWith that said, let\u2019s get into it!\n\n## Type judgments\n\nA simple type annotation looks like this:\n\nx:T\n\nwhere T is a type and x is an element of this type. This looks very similar to\nthe statement \u201cx\u2208T\u201d where T is a set, and it is quite similar, but there are\nsome important differences.\n\nFor one, types are usually stricter than sets when it comes to membership. In\nset theory, an object can easily be a member of multiple sets. In type theory,\nan object usually only belongs to a single type (though maybe that's not quite\nthe case when union types are involved).\n\nThe other difference is that \u201cx\u2208T\u201d can be used as a proposition within a logic\nformula like this:\n\n\u2200x(x\u2209A\u2228x\u2208B)\n\nbut you cannot do that in type theory. For example, something like\n\u201c(x:T)\u21d2(x<y)\u201d doesn\u2019t make any sense. Type judgements (i.e., the \u201c:T\u201d part)\ncan only be applied from the outside to a full statement. For example, you\ncould have some formula \u03a6, describing the result of some computation, and then\nyou can claim \u201c\u03a6:T\u201d (formula \u03a6 is of type T) and that is then either true\n(more precisely, \u201cwell-typed\u201d) or false (\u201cnot well-typed\u201d) as seen from the\noutside. But type judgments cannot be used inside a statement as a true-or-\nfalse-valued term.\n\nIt\u2019s like if you had a programming language that lacked any kind of type\nintrospection, such that at runtime you couldn\u2019t write an if-statement that\nbranches based on the type of some object. But external programs like the\ncompiler and static analysis tools identify the type, and tell us if we wrote\nour program correctly; for example, whether the values we are passing to\nfunctions have the appropriate type.\n\nThere is a caveat to the rule that something like \u201cx:A\u201d may not appear within\nformulas and this concerns universal and existential quantification. Later, we\nwill define these two quantifiers to write formulas like\n\n\u2200(x:A).\u2203(y:A).(y>x)\n\nbut even here, \u201cx:A\u201d is not something that can be true or false; it\u2019s just an\nindicator for the \u201cdomain\u201d of the quantifier.\n\nSo, membership in a type cannot be used as a proposition in type theory, but\nthen how do we express things like \u201c(x:S)\u21d2(x<0)\u201d where S is, for example, some\n\u201csubset\u201d on the integers? The solution we\u2019ll use is to define \u201csubsets\u201d as\npredicates (or characteristic functions) on some base type. So, you could, for\nexample, define a set in N via a predicate function, i.e., a function that\ntakes in an n:N and returns true or false. And then you could ask questions\nabout membership in this \u201cset\u201d by just applying the predicate function. We\nwill later see how this works in detail.\n\n## Product types\n\nSpeaking of functions, how do we type-annotate those? Before we get there,\nlet\u2019s talk about something simpler first: pairs of values. If we have two\nvalues: a:A and b:B, then we can form a pair that has the type A\u00d7B:\n\n(a,b):A\u00d7B .\n\nIn contrast to (the usual definition of) set theory, type theory has ordered\npairs as a native building block. The definition of ordered pairs goes along\nwith a definition of projection functions (going from (a,b) to, e.g., just a)\nbut we\u2019ll get there later.\n\nFor n-tuples, we can pair repeatedly:\n\n(a,(b,(c,(d,e)))):A\u00d7(B\u00d7(C\u00d7(D\u00d7E))) .\n\nHowever, we usually leave out the extra parentheses:\n\n(a,b,c,d,e):A\u00d7B\u00d7C\u00d7D\u00d7E\n\nwhile always implying that parentheses open after any \u201cT\u00d7\u201d and close at the\nvery end of the expression.\n\nNow, back to functions. If we have a function f(x), one thing we can annotate\nis its return type. We could maybe do it like this:\n\nf(x):Y .\n\nHowever, we would also like to know the type of the argument x, so that we can\nknow what values we can pass to this function. Say that our function f maps\nvalues from X to Y. Type theorists have developed a brilliant notation for\nthis:\n\nf:\u220fx:XY\n\nNow, you might be saying: what the heck is this? And I\u2019d agree with you, but\nthere is some justification for writing a function type like this. You see, a\nfunction could be seen as a very long ordered tuple, where each entry of the\ntuple is associated with a particular input value. The entries of the tuple\nall have type Y, so the type of the tuple is kind of\n\nY\u00d7Y\u00d7Y\u00d7Y\u00d7Y\u00d7...\n\nwith one entry for every value x:X. Hence, we write it as a product: \u220fx:XY. In\nset theory, the set of all functions from X to Y is written YX for a similar\nreason. (Why are we not writing it like that in type theory? We\u2019ll see later\nhow the x:X is useful.)\n\nIn contrast to set theory, functions are a fundamental concept in type theory,\nand are not defined in terms of other things. There are three basic building\nblocks in type theory: values, functions, and types. (And then you can\nadditionally construct ordered pairs out of any combination of these.) Values\ncould also be seen as constant functions that don\u2019t accept any arguments, so,\nin a sense there are only functions and types, but we will talk about \u201cvalues\u201d\nas separate things nevertheless.\n\nThe basic theory of functions that type theory is built on is lambda calculus.\nI will just quickly summarize it here. Feel free to skip this next section if\nyou are already familiar.\n\n## Aside on Lambda Calculus\n\nSay you have a function like:\n\nf(x):\u2261x\u22c5x .\n\nIf you want to apply this function now to the number 4, then the rules of\nlambda calculus tell you to replace all x\u2019s with \u201c4\u201d:\n\nf(4)\u22614\u22c54\n\nwhich probably doesn\u2019t come as a surprise.\n\nNow, in this example, f was a named function (its name is \u201cf\u201d), but often it\u2019s\ninconvenient to give every function a name, so we need a notation for\nanonymous functions. This is most useful when some function takes another\nfunction as an argument.\n\nFor example, the Fourier transform transforms functions and if we let the\ntransform be denoted by F then applying it to a function f looks like this:\nF(f). However, we might not always want to give the function passed to F a\nname. In this case we can pass it an anonymous function. My preferred notation\nfor anonymous functions is something like\n\nx\u21a6x\u22c5x\n\nwhere x is mapped to x\u22c5x. So that you can write F(x\u21a6x\u22c5x) for its Fourier\ntransform. But the notation used in lambda calculus is this:\n\n\u03bbx.x\u22c5x\n\n(and so we\u2019ll be using this notation). The lambda (\u03bb) is not meant to be a\nvariable here, but a marker that marks the beginning of a function. The\nvariable that comes after the \u03bb is the input argument and what comes after the\ndot (.) is the function body. Applying the Fourier transform to it looks like\nthis: F(\u03bbx.x\u22c5x).\n\nAnonymous functions (and named function too, actually) may only take a single\nargument, but as we\u2019ll later see, we can get around this restriction by\npassing in n-tuples as arguments or by using nested functions. I know this\nnotation takes some getting used to, but it won\u2019t feel strange after a while.\nAs before, we\u2019ll have the convention that the function body extends until the\nend of the expression (if there are no parentheses).\n\nThe following two are completely equivalent then:\n\nf(x):\u22613+xf:\u2261(\u03bbx.3+x)\n\n(However, whenever possible, we will prefer the first notation.) Applying\nanonymous functions works exactly like named functions; all occurrences of the\ninput argument are replaced and we can drop the part before the dot:\n\n(\u03bbx.x\u22c5x)(4)\u22614\u22c54 .\n\nThe variable following the \u03bb is a temporary variable and the concrete letter\nused doesn\u2019t matter. So the following two functions are completely identical:\n\n(\u03bbx.2\u22c5x)\u2261(\u03bby.2\u22c5y) .\n\nSometimes you have to be a bit careful in function application when there is a\nrisk of a naming clash. This can happen when you have nested functions.^[1]\n\n## Function types\n\nThe identity function on the integers Z has the following type:\n\n(\u03bbx.x):\u220fx:ZZ\n\nNotice that functions are instances of some function type; a single function\ntype can be associated with many different concrete functions.\n\nSometimes we also explicitly annotate the type of the input argument:\n\n(\u03bb(x:Z).x):\u220fx:ZZ\n\nHowever, we usually only do this if the type is not fixed, as in the following\nexample.\n\nAs it is, our identity function only works for one type: Z. But it would be\nnice if it worked for any type. We can achieve this by constructing a function\nthat takes in a type as an additional argument, which in programming languages\nis known as a generic function. To do this, we need to talk about the type of\ntypes, so that we can specify the type of that additional argument.\n\nThe type of a type is called a universe U. However, there can\u2019t be a single\nuniverse that contains all types because then it would have to contain itself,\nwhich leads to problems like Russell\u2019s paradox. So, instead, there will be an\ninfinite hierarchy of type universes where each universe is contained in the\nnext universe on the hierarchy: Ui:Ui+1. Additionally, we\u2019ll say this\nhierarchy is cumulative, so if T:Ui then also T:Ui+1. These detail doesn\u2019t\nreally matter to us though. What\u2019s important to know is that for any type T,\nthere is some universe Ui in the hierarchy of universes that contains this\ntype: T:Ui. As the exact universe is usually not important, we\u2019ll usually drop\nthe index i.\n\nWith this knowledge, we can now define the generic identity function:\n\nid:\u2261(\u03bbT.(\u03bb(x:T).x)):\u220fT:U(\u220fx:TT)\n\nLet\u2019s take a moment to understand this. We have nested functions: the outer\nfunction takes a type parameter T and then returns the inner function, which\nis just the identity function, but on type T (which we annotated explicitly).\nTo get the identity function on the integers, you would do: id(Z), and then\nid(Z)(3)\u22613. For notational convenience, people often write the first type\nargument as a subscript:\n\nidZ(3)\u22613\n\nIn general, functions with more than one argument can be realized in two ways:\neither by modeling them as nested functions that each only take one argument\n(also called currying), or by modeling them as a single function that takes an\nordered pair or n-tuple as argument. However, we could not have realized the\ngeneric identity function using the latter method, because the type of the\nsecond argument depended on the value of the first argument. Currying is\nstrictly more flexible than using tuples. Additionally, you always need\nprojection functions when working with tuples. Speaking of which, here they\nare for an ordered pair:\n\npr1:\u2261\u03bb(a,b).a:\u220fp:A\u00d7BApr2:\u2261\u03bb(a,b).b:\u220fp:A\u00d7BB\n\nThe way we have defined these functions here is called function definition by\npattern matching, because we have written the input argument in an unpacked\nform. The non-pattern-matching notation would have been \u03bbp.(...), where p is\nan ordered pair. However, with that notation we cannot express what this\nfunction does because... we haven\u2019t defined any way to unpack a tuple yet;\nthat\u2019s what we\u2019re trying to do right now! So, pattern matching is a very\nconvenient way to describe new functionality that our theory didn\u2019t have yet,\neven though it\u2019s not technically legal in lambda calculus. (Don\u2019t worry\nthough, pattern matching can be defined rigorously; we just won\u2019t do that\nhere.) We will use pattern matching for later function definitions as well.\n\nJust as a further example, here is the type of the add function on the reals,\nusing currying:\n\nadd:\u220fx:R\u220fy:RR\n\nWe left out the parentheses in the type, as is customary. And here it is using\npairs:\n\nadd:\u220fp:R\u00d7RR\n\nMultiplication has the same type, of course.\n\n## Sum types\n\nIn the beginning I said that type theory has no type introspection that most\nprogramming languages have. But actually, through some cleverness, we can get\nsomething very similar. The setup is that we have some value x, but we want to\nallow for it to be either of type A or of type B. The problem is that nothing\nwithin our theory can query the type. But we can solve this through tagged\nunions. Instead of a bare value x, we\u2019ll have a pair (t,x) where the first\nelement is a tag and the type of the second element depends on the value of\nthe tag. This way, we can find out the type of x simply by checking the value\nof the tag! (Assuming of course that we tagged everything correctly.)\n\nYou might think we could just use the pair type for this \u2013 like A\u00d7B \u2013 but\nthat\u2019s not possible because we need the type of the second entry to depend on\nthe value of the first entry. This can\u2019t be done with what we already have, so\nwe need to introduce a new type formation rule. And that is the sum type, also\ncalled dependent pair type (because it\u2019s a pair where the type of the second\nentry is dependent on the first entry):\n\n(t,x):\u2211t:AB(t)\n\nThis means that t is of type A, and the type of x is B(t), which is a function\nwith takes in t and returns a type (so, it\u2019s a type-valued function). Now, why\nis this written as a sum? It makes sense in a certain way: As we learned, the\ntype of a pair is X\u00d7Y, which is kind of like a multiplication. But a\nmultiplication is just repeated addition, so we could say\n\nX\u00d7Y\u2261\u2211x:XY .\n\nThus, if we have an ordered pair where the second element depends on the value\nof the first, then the sum \u2211x:XY(x) is a somewhat reasonable way to write\nthis. The sum can also be seen as a disjoint union over the family of \u201csets\u201d\nB(t) that is indexed by t:A where the tag ensures that the \u201csets\u201d are\ndefinitely disjoint. The resulting type can have elements from all the\nindividual types B(t).\n\nIn order to do anything with an instance of this tagged union, we need to\nhandle all possible types that the second element of the pair (t,x) can have.\nThis means we can\u2019t easily write down a projection function for the second\nelement, because we don\u2019t know what the return type will be.\n\nSo, instead of defining a projection function, we\u2019ll define how some function\ng could consume a tagged union. g will need to accept two arguments: the tag t\nand the actual value x. The type has to be something like this:\n\ng:\u220ft:A\u220fx:B(t)C\n\nwhere C is simply an arbitrary return type of g (which could be another\nproduct or sum type). We can now define the function rec which every sum type\nhas its own version of; it takes in a return type C, a function g and an\nelement of the sum type:\n\nrec\u03a3t:AB(t):\u220fC:U \u220fg:\u03a0t:A\u03a0x:B(t)C \u220fp:\u03a3t:AB(t)Crec\u03a3t:AB(t)(C,g,(t,x)):\u2261g(t)(x)\n\nNote that we had to make rec(\u22c5) generic in C in order to make sure that the\noverall return type matches the return type of g. Note also that this is\nanother instance of function definition by pattern matching; we\u2019re unpacking\nthe (t,x) pair in the input argument definition, which isn\u2019t normally a legal\noperation.\n\nIf you only have a handful of types that you want to take the union over, the\nthis whole \u2211x:XY(x) setup can be a bit overkill. For that case, there is a\nsimpler notation that doesn\u2019t mention the tags explicitly. If A and B are\ntypes, then the following is also a type:\n\nA+B\n\nIt\u2019s called a binary sum type and the notation follows straightforwardly from\nthe idea that we were taking a sum over types.\n\nEven though you can\u2019t see any explicit tags in this definition, they are still\nkind of there, because for example if a:A then we do not have a:A+B. The\nelements of A+B are different from the elements of A and B. In order to turn\nan a:A into an element of A+B, we have to use a special function, one of which\nis associated with every binary sum type, and there is of course also one for\nB. These \u201ctagging functions\u201d will get the names left and right:\n\nleft:\u220fa:A(A+B)right:\u220fb:B(A+B)left(a):A+B ,right(b):A+B\n\nYou can see how they can turn an element of A into an element of A+B. In order\nto use one of the values of A+B, you again need a way to handle both\npossibilities. So, say you have functions g0 and g1 which take an argument of\ntype A and B respectively, but both return something of type C:\n\ng0:\u220fa:ACg1:\u220fb:BC\n\nThen we can use a function called rec to map an element of A+B to the right\nfunction:\n\nrecA+B:\u220fC:U \u220fg0:\u03a0a:AC \u220fg1:\u03a0b:BC \u220fp:A+BC\n\nIt\u2019s a bit tricky to give the implementation of recA+B, because we don\u2019t have\nexplicit tags \u2013 we only have the tagging functions. This means, we can only\ndescribe from the outside how recA+B will work; if the element of A+B was\ntagged with left, then we execute g0, and if it was tagged with right, then we\nexecute g1:\n\nrecA+B(C,g0,g1,left(a)):\u2261g0(a)recA+B(C,g0,g1,right(b)):\u2261g1(b)\n\nThe knowledge of whether an element of A+B comes from A or B is never encoded\nanywhere within the system, but from the outside, we can choose the correct\nfunction definition to execute. We have to assert that this function exists,\nbecause it cannot be defined with the other building blocks that we have. This\nis again an instance of a function definition by pattern matching; the\nsuitable definition can be found by pattern matching any value against left(a)\nand right(b).\n\nIt\u2019s important to state here that in practice, you would likely not use the\nrecA+B function explicitly. Rather, you can just allude to the fact that it\u2019s\npossible to do two different things depending on which original type an\nelement of a union had. Like, you would say \u201clet x:A+B, if x came from A, do\nthis; otherwise do that.\u201d\n\n## Examples\n\nAn example of a function that can be modeled as returning a union is division\non the rational numbers, including 0. As we know, division by 0 is not\ndefined, but you could return a special symbol when dividing by 0. So, let\u2019s\nsay 1 is the type that only contains one element, for which we could use the\nsymbol \u22c6:1, and we return that symbol when dividing by 0. Then the function\nwould have this type:\n\ndiv:\u220fx:Q\u220fy:QQ+1\n\nWhen dealing with the output of this function in your derivation, you could\n(sloppily) say: \u201cIf the output is some z:Q, then we do X next; otherwise we\nhandle it with Y.\u201d\n\nAn example of a use case for non-binary sum types is the definition of\nmathematical \u201cdata structures\u201d like a ring or a group. These data structures\nare usually defined as a tuple, where the first element is a set, and the\nother elements are functions or other structures based on that set. In type\ntheory, the set would be a type, obviously, but when we try to just define the\ndata structure as a tuple, we will encounter the problem that the type of\nlater tuple entries depends on the value of the first tuple entry.\n\nTo make this concrete, let\u2019s consider groups. A group is a set with a binary\noperation, \u22c5, and a neutral element, e. So, groups should have this type:\n\n(T,\u22c5,e) : U\u00d7(\u220fx:T\u220fy:TT)\u00d7T\n\nA tuple of a type, a binary operation and an element of the type. However, how\ndo we ensure that T is actually the type given in the first entry of the\ntuple? Clearly, we need a sum type here; after all, a sum type is just a pair\nwhere the type of the second element depends on the value of the first\nelement:\n\nGroup :\u2261 \u2211T:U(\u220fx:T\u220fy:TT)\u00d7T\n\nAs usual, we left out the parentheses around the last two terms. This type of\nall groups is a union over all pairs of a binary operation and a neutral\nelement, tagged with the type that they\u2019re operating in. With this type, we\ncould now write a function that takes in an arbitrary group, and it would know\nexactly what to do with it, because the \u201ctag\u201d (the first element of this\n3-tuple) would tell the function what the underlying type is and what to\nexpect with the binary operation and the neutral element.\n\nSimilarly, in set theory, an ordered set is technically a tuple of a set and\nan order relation. In type theory, we can analogously have a dependent pair\n(aka a sum type) of a type and an order relation on that type: (T,>) where \u201c>\u201d\nis a relation on T. However, we haven\u2019t discussed how to define relations yet.\n\nThis concludes the first part of this series. In the next post, we\u2019ll learn\nhow to define functions that return truth values, which includes predicate\nfunctions and relations.\n\nThanks to Simon Fischer for comments on a draft of this post.\n\n  1. ^^\n\nFor example, the following function returns another function that always\nreturns a constant, which is set by the outer function:\n\n\u03bbx.(\u03bby.x)\n\nSo, for example, this returns a function that always returns 4:\n\n(\u03bbx.(\u03bby.x))(4)\u2261\u03bby.4\n\nIt might be a little clearer if we write this with the other notation:\n\n(x\u21a6(y\u21a6x))(4)\u2261(y\u21a64) .\n\nNow, the problem appears if we re-use one of the inner argument variables\noutside:\n\n(\u03bbx.(\u03bby.x))(y)\u2261?\n\nIf we were just blindly following the substitution rule, we would get this:\n\n(\u03bbx.(\u03bby.x))(y)\u2261\u03bby.y\n\nwhich is of course not correct, because the result of a function application\nshouldn\u2019t change just because we renamed some variables. To get the correct\nresult, we need to avoid the naming clash by renaming the inner argument\nvariable:\n\n(\u03bbx.(\u03bbz.x))(y)\u2261\u03bbz.y .\n\n## New to LessWrong?\n\nGetting Started\n\nFAQ\n\nLibrary\n\nLogic & Mathematics 1World Modeling2\n\nFrontpage\n\n# 47\n\nNext:\n\nRecreating logic in type theory\n\nNo comments12 karma\n\nLog in to save where you left off\n\nBasic building blocks of dependent type theory\n\n15th Dec 2022\n\n3Algon\n\n2Viliam\n\n2\u03b2-redex\n\n1zanzibar7\n\n1DPiepgrass\n\n1Dacyn\n\n1DPiepgrass\n\n1philip_b\n\nNew Comment\n\n8 comments, sorted by\n\ntop scoring\n\nClick to highlight new comments since: Today at 5:14 PM\n\n[-]Algon1y32\n\nThis introduction is fantastic. I don't think I've seen something as\ncomprehensive, clear and short as this before.\n\nEdit: That said, I would have loved it if you introduced a few exercises\nthroughout, or perhaps spoilered the types of some objects so people who are\nnew to the area could guess things in advance. I remember a lot of things\nclicked for me when I set about trying to \"discover\" the type theory formalism\nmyself.\n\nReply\n\n[-]Viliam1y21\n\nI am also very happy about this; I learned something new, and the explanations\nfelt perfectly clear.\n\nEspecially I liked the explanations \"from outside perspective\", like lambda\nnotation vs arrow notation, or why the product symbol is used. These things\nare typically not mentioned in textbooks, because they teach the official\nnotation, but this is exactly what you need as a beginner, to connect what you\nalready know with the new things.\n\nReply\n\n[-]\u03b2-redex1y20\n\nCool! (Nitpick: You should probably mention that you are deviating from the\nnaming in the HoTT book. AFAIK usually \u03a0 and \u03a3 types are called Pi and Sigma\ntypes respectively, while the words \"product\" and \"sum\" (or \"coproduct\" in the\nHoTT book) are reserved for A\u00d7B and A+B.)\n\nI am especially looking forward to discussion on how MLTT relates to alignment\nresearch and how it can be used for informal reasoning as Alignment Research\nField Guide mentions.\n\nI always get confused when the term \"type signature\" is used in text unrelated\nto type theory. Like what do people mean when they say things like \"What\u2019s the\ntype signature of an agent?\" or \"the type of agency is (A\u2192B)\u2192A\"?\n\nReply\n\n[-]zanzibar710mo10\n\nThanks for these posts. I've just started working through them, but great so\nfar.\n\nI became curious recently if some concept of homogenous sets should be serving\nfoundation for applied mathematics, and that's lead me to a deeper curiousity\nabout type theory. Types are already been a core concept in programming and\ndatabases for decades. Working on sympy, it was distressing how much work had\nto go on under the hood to make sure objects were really of right type to do a\ncalculation, and how dis-organized, bug-prone, and inefficient this became.\nHow many engineering mistakes could be avoided if physics and chemistry\nvariables used in compuations had types accounted for their units\nautomatically, or mismatched units could raise a warning? Or the conceptual\ndifference between a date and a duration? It seems like something that should\nbe a core part of university math sometimes.\n\nBut type theory has always felt like a rabbit hole when it comes to doing\nstuff. Your specification above reminded me of this.\n\n>There are three basic building blocks in type theory: values, functions, and\ntypes. (And then you can additionally construct ordered pairs out of any\ncombination of these.) Values could also be seen as constant functions that\ndon\u2019t accept any arguments, so, in a sense there are only functions and types,\nbut we will talk about \u201cvalues\u201d as separate things nevertheless.\n\nIf we define everything in terms of functions, than we don't need values. For\nthe same reason, its just useful to think of many undergraduate calculations\nas taking place over C rather than Q or R. But that means you need to\nunderstand C before you should really be doing anything. But then we've got\nvectors, and matrices, and tensors ... With python's numpy, it's extra\ncognitive load to have to worry about whether a returned value's type is a\nfloat or a 1x1 array, or maybe even some other equivalent type.\n\nAnd that's where I start to get turned off from type theory. Instead of giving\nme the foundation to express the ideas I'm really interested it, it is getting\nin the way.\n\nReply\n\n[-]DPiepgrass1y1-4\n\nPlease don't defend the \"\u220f\" notation.\n\nf:\u220fx:XY\n\nIt's nonsensical. It implies that\n\n\u03bb(x:N).x\n\nhas type \" \u221e! \u00d7 0\"!\n\nReply\n\n[-]Dacyn1y10\n\nHow so? It looks like you have confused \u220fx:XY with \u220fx:Xx. In this example we\nhave X=Y=N, so the type of \u03bb(x:N).x is \u220fx:NN.\n\nReply\n\n[-]DPiepgrass1y10\n\nPardon me. I guess its type is N\u221e.\n\nReply\n\n[-]philip_b1y10\n\nI have recently read The Little Typer by Friedman and Christiansen. I suspect\nthat this book can serve as an introduction similarly to this (planned, so\nfar) sequence of posts. However, the book is not concise at all.\n\nReply\n\nModeration Log\n\n", "frontpage": false}

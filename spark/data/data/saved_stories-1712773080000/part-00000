{"aid": "39989854", "title": "Show HN: ai(\"question\", data) infers the ML model and answers with Python type", "url": "https://github.com/jmaczan/text-to-ml", "domain": "github.com/jmaczan", "votes": 1, "user": "yu3zhou4", "posted_at": "2024-04-10 12:16:39", "comments": 0, "source_title": "GitHub - jmaczan/text-to-ml: \ud83c\udfae Run AutoML using natural text. Like HuggingGPT + LangChain + type inference", "source_text": "GitHub - jmaczan/text-to-ml: \ud83c\udfae Run AutoML using natural text. Like HuggingGPT\n+ LangChain + type inference\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\njmaczan / text-to-ml Public\n\n  * Notifications\n  * Fork 0\n  * Star 6\n\n\ud83c\udfae Run AutoML using natural text. Like HuggingGPT + LangChain + type inference\n\nmaczan.pl/p/lets-build-text-to-ml-an-automl-library\n\n### License\n\nGPL-3.0 license\n\n6 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# jmaczan/text-to-ml\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\njmaczanUpdate README.mdfb1b47f \u00b7\n\n## History\n\n8 Commits  \n  \n### test_data\n\n|\n\n### test_data\n\n| Initial commit  \n  \n### .env.example\n\n|\n\n### .env.example\n\n| Initial commit  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial commit  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md  \n  \n### __init__.py\n\n|\n\n### __init__.py\n\n| Initial commit  \n  \n### ai.py\n\n|\n\n### ai.py\n\n| Initial commit  \n  \n### api.py\n\n|\n\n### api.py\n\n| Initial commit  \n  \n### app.py\n\n|\n\n### app.py\n\n| Initial commit  \n  \n### experiments.py\n\n|\n\n### experiments.py\n\n| Initial commit  \n  \n### image.png\n\n|\n\n### image.png\n\n| Initial commit  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Initial commit  \n  \n## Repository files navigation\n\n# \ud83c\udfae text-to-ml\n\nRun AutoML using natural text. Like HuggingGPT + LangChain + type inference\n\n> \ud83c\udfed A breakdown of what is going on in code you can read on my blog: maczan.pl\n\nIt picks a right model from Hugging Face library based on user natural\nlanguage query and then runs the model and parses the output to a type,\ninferred from the query\n\n> \u26a1 You can run this code in Lightning AI Studio template\n\nIt's still an early project and you are welcome to contribute!\n\n## Setup\n\n  1. Get OpenAI API Key\n  2. Get Hugging Face API Key\n  3. Create an assistant and copy its id\n  4. Create .env file and fill it with values:\n\n    \n    \n    OPENAI_API_KEY= HF_TOKEN=\n\n## Build\n\n    \n    \n    conda create -n text-to-ml python=3.9 conda activate text-to-ml conda install --file requirements.txt\n\n## Run\n\n    \n    \n    python app.py\n\n## Run experiments\n\n    \n    \n    python experiments.py\n\n## License\n\nGPLv3\n\n## Author\n\nJ\u0119drzej Pawe\u0142 Maczan, Poland, 2024\n\n## About\n\n\ud83c\udfae Run AutoML using natural text. Like HuggingGPT + LangChain + type inference\n\nmaczan.pl/p/lets-build-text-to-ml-an-automl-library\n\n### Topics\n\npython machine-learning deep-learning automl huggingface hugginggpt\n\n### Resources\n\nReadme\n\n### License\n\nGPL-3.0 license\n\nActivity\n\n### Stars\n\n6 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

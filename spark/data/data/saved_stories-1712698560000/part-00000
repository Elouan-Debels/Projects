{"aid": "39980544", "title": "Scaling your ComfyUI workflow behind a API endpoint", "url": "https://www.cerebrium.ai/blog/productionize-your-comfy-ui-workflow", "domain": "cerebrium.ai", "votes": 1, "user": "za_mike157", "posted_at": "2024-04-09 15:33:22", "comments": 0, "source_title": "Productionize your Comfy UI Workflow", "source_text": "Productionize your Comfy UI Workflow\n\nLogin\n\ndrag_handle\n\nclose\n\nhome\n\nnavigate_next\n\nBlog\n\nnavigate_next\n\nTutorials\n\n# Productionize your Comfy UI Workflow\n\n###### Michael Louis\n\nCo-Founder & CEO\n\n### Introduction\n\nComyUI is a popular no-code interface for building complex stable diffusion\nworkflows. Due to its ease of use, modular setup as well as its intuitive\nflowchart interface, the community of ComfyUI users have built a pretty\nphenomenal collection of workflows! There are even websites dedicated to the\nsharing of workflows built to help get you started:\n\n  * https://comfyworkflows.com/\n  * https://openart.ai/workflows/home\n\nWhile it is currently easy to experiment with ComfyUI workflows, there isn\u2019t a\nlot of guidance or tutorials on how to productionise these workflows at scale.\nIn this tutorial, I am going to show you how you can use Cerebrium to deploy\nyour pipelines to an API endpoint so they can autoscale based on demand and\nthat you only pay for the compute you use. You can find the full example code\nhere.\n\n### Creating your Comfy UI workflow locally\n\nWe first need to create our workflow which you can do locally on your machine\nor by renting a GPU from Lambda Labs.\n\nBefore we get started, make sure ComfyUI is installed properly on your local\nenvironment.\n\nFor our use case we are going to use Stable Diffusion XL and ControlNet to\ncreate a cool QR code. If you have a existing workflow setup, you can simply\nskip to the step \u201cExport ComfyUI Workflow\u201d\n\n  1. Let us first create our Cerebrium project with: cerebrium init comfyUI\n  2. Inside your project, lets copy the ComfyUI GitHub project: git clone https://github.com/comfyanonymous/ComfyUI\n  3. Download the following models and install them in the appropriate folders within the ComfyUI folder:\n\n     * SDXL base in models/checkpoints.\n     * ControlNet in models/ControlNet.\n  4. In order to run ComfyUI locally, run the command: python main.py --force-fp16 on MacOS. Make sure you run this inside the ComfyUI folder you just cloned.\n  5. A server should be loaded locally at http://127.0.0.1:8188/\n\nIn this view, you should be able to see the default user interface for a\nComfyUI workflow. You can use this locally running instance to create your\nimage generation pipeline.\n\n### Export ComfyUI Workflow\n\nIn our example Github repository, we have a worklow.json file. You can click\nthe \u201cLoad\u201d button on the right in order to load in our workflow. You then\nshould see the workflow populated\n\nDon\u2019t worry about the pre-filled values and prompts, we will edit these values\non inference when we run our workflow.\n\nIn order to export this workflow to work with Cerebrium, we need to export\nthis to an API format. In the top right over that hovering box on the right.\nClick the gear icon (settings). You must then make sure that \u201cEnable dev mode\u201d\nis selected and then can close the popup.\n\nYou should then see that a button appear on the right hover box that reads\n\u201cSave (API format)\u201d. Use that to save your workflow with the name\n\u201cworkflow_api.json\u201d\n\n### ComfyUI Application\n\nOur main application code lives in main.py so we now use the exported ComfyUI\nAPI workflow file above in order to create an API endpoint for our workflow.\nIn the code below we initialize the ComfyUI server and load in our workflow\nAPI template. In our predict function, we then send in the various values we\nwould like to alter in our workflow ie: prompt, image and run the workflow.\nOur function then users the inputs to alter the ComfyUI workflow values and\nthen generates the output which in this case is base64 encoded images.\n\nIn Cerebrium, the code outside the predict function runs only on\ninitialisation (ie: startup) where as subsequent requests will only run the\npredict function.\n\nWe need to alter our workflow_api.json file to have placeholders so that we\ncan replace user values on inference. You can alter the file as follows.\n\n  * Replace line 4, the seed input, with: \u201c{{seed}}\u201d\n  * Replace line 45, the input text of node 6 with: \u201c{{positive_prompt}}\u201d\n  * Replace line 58, the input text of node 7 with: \u201c{{negative_prompt}}\u201d\n  * Replace line 108, the image of node 11 with: \u201c{{controlnet_image}}\u201d\n\nWe created a file that contains utility functions to make it easier to work\nwith ComfyUI. You can find the code here. Create a file named helpers.py and\ncopy the code into there.\n\n    \n    \n    from typing import Optional from pydantic import BaseModel import copy import json import os import time import uuid from multiprocessing import Process from typing import Dict import websocket from helpers import ( convert_outputs_to_base64, convert_request_file_url_to_path, fill_template, get_images, setup_comfyui, ) server_address = \"127.0.0.1:8188\" client_id = str(uuid.uuid4()) original_working_directory = os.getcwd() global json_workflow json_workflow = None global side_process side_process = None if side_process is None: side_process = Process( target=setup_comfyui, kwargs=dict( original_working_directory=original_working_directory, data_dir=\"\", ), ) side_process.start() # Load the workflow file as a python dictionary with open( os.path.join(\"./\", \"workflow_api.json\"), \"r\" ) as json_file: json_workflow = json.load(json_file) # Connect to the ComfyUI server via websockets socket_connected = False while not socket_connected: try: ws = websocket.WebSocket() ws.connect( \"ws://{}/ws?clientId={}\".format(server_address, client_id) ) socket_connected = True except Exception as e: print(\"Could not connect to comfyUI server. Trying again...\") time.sleep(5) print(\"Successfully connected to the ComfyUI server!\") class Item(BaseModel): workflow_values: Optional[Dict] = None def predict(item, run_id, logger): item = Item(**item) template_values = item.workflow_values template_values, tempfiles = convert_request_file_url_to_path(template_values) json_workflow_copy = copy.deepcopy(json_workflow) json_workflow_copy = fill_template(json_workflow_copy, template_values) outputs = {} # Initialize outputs to an empty dictionary try: outputs = get_images( ws, json_workflow_copy, client_id, server_address ) except Exception as e: print('did it get here') print(\"Error occurred while running Comfy workflow: \", e) for file in tempfiles: file.close() result = [] print('here') for node_id in outputs: for unit in outputs[node_id]: file_name = unit.get(\"filename\") file_data = unit.get(\"data\") output = convert_outputs_to_base64( node_id=node_id, file_name=file_name, file_data=file_data ) result.append(output) return {\"result\": result}\n\n### Deploy ComfyUI Application\n\nIf we run cerebrium deploy it will upload the ComfyUI directory and our ~10GB\nof model weights so if you have a slow internet connection this can be a pain.\nHowever, in our repo we have a helper file that will download the models\nweights for us and put it in the appropriate folder. Create a file called\nmodel.json with the following contents:\n\n    \n    \n    [ { \"url\": \"\", \"path\": \"models/checkpoints/sd_xl_base_1.0.safetensors\" }, { \"url\": \"\", \"path\": \"models/controlnet/diffusers_xl_canny_full.safetensors\" } ]\n\nThis file is basically telling our helper function the url to download the\nmodel from and the directory to save the file in. It will only download the\nfile on first deploy. On subsequent deploys, we wrote the logic to skip\ndownloading the model if the file already exists.\n\nThis is what your file folder structure should look like:\n\nYou can now deploy your application by running: cerebrium deploy\n\nOnce your ComfyUI application has been deployed successfully, you should be\nable to make a request to the endpoint using the following JSON payload:\n\n    \n    \n    curl --location 'https://run.cerebrium.ai/v3/p-xxxx/comfyui/predict' \\ --header 'Content-Type: application/json' \\ --header 'Authorization: ' \\ --data '{\"workflow_values\": { \"positive_prompt\": \"A top down view of a mountain with large trees and green plants\", \"negative_prompt\": \"blurry, text, low quality\", \"controlnet_image\": \"https://cerebrium-assets.s3.eu-west-1.amazonaws.com/qr-code.png\", \"seed\": 1000 } }'\n\nYou will get two responses from the output:\n\n  * The base64 encoded image of the outline of your original ControlNet image. This is what it uses as a input in your flow.\n  * A base64 encoded image of the final result.\n\n### Conclusion\n\nWith Cerebrium, companies can implement productionised instances of their\nComfyUI workflows to create unique user experiences. Users can have peace of\nmine that their workloads will autoscale with demand and will only charge\nbased on the compute used. We are excited to see what you build and please tag\n@cerebriumai so we can share your work\n\narrow_back\n\nBack to blog\n\n###### Decart & Cerebrium Commit to Empowering Next Million Users With LLM\nApplications\n\nFebruary 27, 2024\n\n###### Installing Python Packages via UV leads to 3.75x increase in build\nperformance\n\nFebruary 28, 2024\n\n## Get started with your new ML project today\n\nStart a project\n\nDocumentation\n\n\u00a9 Cerebrium, Inc.Privacy PolicyTerms of Service\n\n", "frontpage": false}

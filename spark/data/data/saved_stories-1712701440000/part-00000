{"aid": "39981032", "title": "Intel Gaudi 3 AI Accelerator", "url": "https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html", "domain": "intel.com", "votes": 11, "user": "goldemerald", "posted_at": "2024-04-09 16:21:40", "comments": 0, "source_title": "Intel Breaks Down Proprietary Walls to Bring Choice to Enterprise...", "source_text": "Intel Breaks Down Proprietary Walls to Bring Choice to Enterprise...\n\nSkip To Main Content\n\nIntroducing 4th Gen Intel\u00ae Xeon\u00ae Scalable Processors Introducing 4th Gen\nIntel\u00ae Xeon\u00ae Scalable Processors\n\nIntroducing 4th Gen Intel\u00ae Xeon\u00ae Scalable Processors\n\nThe browser version you are using is not recommended for this site. Please\nconsider upgrading to the latest version of your browser by clicking one of\nthe following links.\n\n  * Safari\n  * Chrome\n  * Edge\n  * Firefox\n\n# Intel Breaks Down Proprietary Walls to Bring Choice to Enterprise GenAI\nMarket\n\nIntel Gaudi 3 AI accelerator brings global enterprises choice for generative\nAI, building on the performance and scalability of its Gaudi 2 predecessor.\n\n## News\n\n  * April 9, 2024\n\n  * Contact Intel PR\n\n  * #### Follow Intel Newsroom on social:\n\nMore Artificial Intelligence News\n\nBy\n\nIntel introduced the Intel Gaudi 3 AI accelerator on April 9, 2024, at the\nIntel Vision event in Phoenix, Arizona. The accelerator delivers 4x AI compute\nfor BF16 and 1.5x increase in memory bandwidth compared with its predecessor.\n(Credit: Intel Corporation)\n\nIntel introduced the Intel Gaudi 3 AI accelerator on April 9, 2024, at the\nIntel Vision event in Phoenix, Arizona. The accelerator meets the unserved\ndemands for choice while offering versatility through open and community-based\nsoftware and open industry-standard Ethernet, helping businesses flexibly\nscale their systems. (Credit: Intel Corporation)\n\nIntel introduced the Intel Gaudi 3 AI accelerator on April 9, 2024, at the\nIntel Vision event in Phoenix, Arizona. It is designed to bring global\nenterprises choice for generative AI, building on the performance and\nscalability of its Gaudi 2 predecessor. (Credit: Intel Corporation)\n\nIntel tackles the generative AI gap by introducing the Intel Gaudi 3 AI\naccelerator at the Intel Vision event on April 9, 2024, in Phoenix, Arizona.\nGaudi 3 gives customers choice with open community-based software and\nindustry-standard Ethernet networking to scale their systems more flexibly.\n(Credit: Intel Corporation)\n\nIntel tackles the generative AI gap by introducing the Intel Gaudi 3 AI\naccelerator at the Intel Vision event on April 9, 2024, in Phoenix, Arizona.\nGaudi 3 gives customers choice with open community-based software and\nindustry-standard Ethernet networking to scale their systems more flexibly.\n(Credit: Intel Corporation)\n\nDownload all images (ZIP, 27 MB)\n\nWhat\u2019s New: At Intel Vision, Intel introduces the Intel\u00ae Gaudi\u00ae 3 AI\naccelerator, which delivers 4x AI compute for BF16, 1.5x increase in memory\nbandwidth, and 2x networking bandwidth for massive system scale out compared\nto its predecessor \u2013 a significant leap in performance and productivity for AI\ntraining and inference on popular large language models (LLMs) and multimodal\nmodels. Building on the proven performance and efficiency of the Intel\u00ae Gaudi\u00ae\n2 AI accelerator \u2013 the only MLPerf-benchmarked alternative for LLMs on the\nmarket \u2013 Intel gives customers a choice with open community-based software and\nindustry-standard Ethernet networking to scale their systems more flexibly.\n\n> \u201cIn the ever-evolving landscape of the AI market, a significant gap persists\n> in the current offerings. Feedback from our customers and the broader market\n> underscores a desire for increased choice. Enterprises weigh considerations\n> such as availability, scalability, performance, cost, and energy efficiency.\n> Intel Gaudi 3 stands out as the GenAI alternative presenting a compelling\n> combination of price performance, system scalability, and time-to-value\n> advantage.\u201d\n>\n> \u2013Justin Hotard, Intel executive vice president and general manager of the\n> Data Center and AI Group\n\nWhy It Matters: Today, enterprises across critical sectors such as finance,\nmanufacturing and healthcare are rapidly seeking to broaden accessibility to\nAI and transitioning generative AI (GenAI) projects from experimental phases\nto full-scale implementation. To manage this transition, fuel innovation and\nrealize revenue growth goals, businesses require open, cost-effective and more\nenergy-efficient solutions and products that meet return-on-investment (ROI)\nand operational efficiency needs.\n\nThe Intel Gaudi 3 accelerator will meet these requirements and offer\nversatility through open community-based software and open industry-standard\nEthernet, helping businesses flexibly scale their AI systems and applications.\n\nHow Custom Architecture Delivers GenAI Performance and Efficiency: The Intel\nGaudi 3 accelerator, architected for efficient large-scale AI compute, is\nmanufactured on a 5 nanometer (nm) process and offers significant advancements\nover its predecessor. It is designed to allow activation of all engines in\nparallel \u2014 with the Matrix Multiplication Engine (MME), Tensor Processor Cores\n(TPCs) and Networking Interface Cards (NICs) \u2014 enabling the acceleration\nneeded for fast, efficient deep learning computation and scale. Key features\ninclude:\n\n  * AI-Dedicated Compute Engine: The Intel Gaudi 3 accelerator was purpose-built for high-performance, high-efficiency GenAI compute. Each accelerator uniquely features a heterogenous compute engine comprised of 64 AI-custom and programmable TPCs and eight MMEs. Each Intel Gaudi 3 MME is capable of performing an impressive 64,000 parallel operations, allowing a high degree of computational efficiency, making them adept at handling complex matrix operations, a type of computation that is fundamental to deep learning algorithms. This unique design accelerates speed and efficiency of parallel AI operations and supports multiple data types, including FP8 and BF16.\n\n  * Memory Boost for LLM Capacity Requirements: 128 gigabytes (GB) of HBMe2 memory capacity, 3.7 terabytes (TB) of memory bandwidth and 96 megabytes (MB) of on-board static random access memory (SRAM) provide ample memory for processing large GenAI datasets on fewer Intel Gaudi 3s, particularly useful in serving large language and multimodal models, resulting in increased workload performance and data center cost efficiency.\n\n  * Efficient System Scaling for Enterprise GenAI: Twenty-four 200 gigabit (Gb) Ethernet ports are integrated into every Intel Gaudi 3 accelerator, providing flexible and open-standard networking. They enable efficient scaling to support large compute clusters and eliminate vendor lock-in from proprietary networking fabrics. The Intel Gaudi 3 accelerator is designed to scale up and scale out efficiently from a single node to thousands to meet the expansive requirements of GenAI models.\n\n  * Open Industry Software for Developer Productivity: Intel Gaudi software integrates the PyTorch framework and provides optimized Hugging Face community-based models \u2013 the most-common AI framework for GenAI developers today. This allows GenAI developers to operate at a high abstraction level for ease of use and productivity and ease of model porting across hardware types.\n\n  * Gaudi 3 PCIe: New to the product line is the Gaudi 3 peripheral component interconnect express (PCIe) add-in card. Tailored to bring high efficiency with lower power, this new form factor is ideal for workloads such as fine-tuning, inference and retrieval-augmented generation (RAG). It is equipped as a full-height form factor at 600 watts, with a memory capacity of 128GB and a bandwidth of 3.7TB per second.\n\nIntel Gaudi 3 accelerator will deliver significant performance improvements\nfor training and inference tasks on leading GenAI models. Specifically, the\nIntel Gaudi 3 accelerator is projected to deliver on average versus Nvidia\nH100:\n\n  * 50% faster time-to-train^1 across Llama2 7B and 13B parameters, and GPT-3 175B parameter models.\n  * 50% faster inference throughput^2 and 40% greater inference power-efficiency^3 across Llama 7B and 70B parameters, and Falcon 180B parameter models. An even greater inference performance advantage on longer input and output sequences.\n  * 30% faster inferencing^4 on Llama 7B and 70B parameters, and Falcon 180B parameter models against Nvidia H200.\n\nAbout Market Adoption and Availability: The Intel Gaudi 3 accelerator will be\navailable to original equipment manufacturers (OEMs) in the second quarter of\n2024 in industry-standard configurations of Universal Baseboard and open\naccelerator module (OAM). Among the notable OEM adopters that will bring Gaudi\n3 to market are Dell Technologies, HPE, Lenovo and Supermicro. General\navailability of Intel Gaudi 3 accelerators is anticipated for the third\nquarter of 2024, and the Intel Gaudi 3 PCIe add-in card is anticipated to be\navailable in the last quarter of 2024.\n\nThe Intel Gaudi 3 accelerator will also power several cost-effective cloud LLM\ninfrastructures for training and inference, offering price-performance\nadvantages and choices to organizations that now include NAVER.\n\nDevelopers can get started today with access to Intel Gaudi 2-based instances\non the developer cloud to learn, prototype, test, and run applications and\nworkloads\n\nWhat\u2019s Next: Intel Gaudi 3 accelerators' momentum will be foundational for\nFalcon Shores, Intel\u2019s next-generation graphics processing unit (GPU) for AI\nand high-performance computing (HPC). Falcon Shores will integrate the Intel\nGaudi and Intel\u00ae Xe intellectual property (IP) with a single GPU programming\ninterface built on the Intel\u00ae oneAPI specification.\n\nMore Context: Intel Unleashes Enterprise AI with Gaudi 3, AI Open Systems Strategy and New Customer Wins (News) | Intel Gaudi 3 AI Accelerator (Product Page) | Intel Gaudi 3 AI Accelerator (White Paper) | Intel Gaudi 2 Remains Only Benchmarked Alternative to NV H100 for GenAI Performance (News)\n\n_The Small Print:\n\n_Intel does not control or audit third-party data. You should consult other\nsources to evaluate accuracy.\n\n^1 _NV H100 comparison based on: https://developer.nvidia.com/deep-learning-\nperformance-training-inference/training, Mar 28th 2024 \u00e0 \u201cLarge Language\nModel\u201d tab Vs Intel\u00ae Gaudi\u00ae 3 projections for LLAMA2-7B, LLAMA2-13B &\nGPT3-175B as of 3/28/2024. Results may vary\n\n^2 _NV H100 comparison based on https://nvidia.github.io/TensorRT-\nLLM/performance.html#h100-gpus-fp8 , Mar 28th, 2024. Reported numbers are per\nGPU. Vs Intel\u00ae Gaudi\u00ae 3 projections for LLAMA2-7B, LLAMA2-70B & Falcon 180B\nprojections. Results may vary.\n\n^3 _NV comparison based on https://nvidia.github.io/TensorRT-\nLLM/performance.html#h100-gpus-fp8 , Mar 28th, 2024. Reported numbers are per\nGPU. Vs Intel\u00ae Gaudi\u00ae 3 projections for LLAMA2-7B, LLAMA2-70B & Falcon 180B\nPower efficiency for both Nvidia and Gaudi 3 based on internal estimates.\nResults may vary.\n\n^4 _NV H200 comparison based on https://nvidia.github.io/TensorRT-\nLLM/performance.html#h100-gpus-fp8 , Mar 28th, 2024. Reported numbers are per\nGPU.Vs Intel\u00ae Gaudi\u00ae 3 projections for LLAMA2-7B, LLAMA2-70B & Falcon 180B\nprojections. Results may vary.\n\n## Tags\n\nArtificial Intelligence, Data Center & HPC\n\nAbout Intel\n\nIntel (Nasdaq: INTC) is an industry leader, creating world-changing technology\nthat enables global progress and enriches lives. Inspired by Moore\u2019s Law, we\ncontinuously work to advance the design and manufacturing of semiconductors to\nhelp address our customers\u2019 greatest challenges. By embedding intelligence in\nthe cloud, network, edge and every kind of computing device, we unleash the\npotential of data to transform business and society for the better. To learn\nmore about Intel\u2019s innovations, go to newsroom.intel.com and intel.com.\n\n\u00a9 Intel Corporation. Intel, the Intel logo and other Intel marks are\ntrademarks of Intel Corporation or its subsidiaries. Other names and brands\nmay be claimed as the property of others.\n\n  * Company Overview\n  * Contact Intel\n  * Newsroom\n  * Investors\n  * Careers\n  * Corporate Responsibility\n  * Diversity & Inclusion\n  * Public Policy\n\n  * \u00a9 Intel Corporation\n  * Terms of Use\n  * *Trademarks\n  * Cookies\n  * Privacy\n  * Supply Chain Transparency\n  * Site Map\n  * Your Privacy Choices\n  * Notice at Collection\n  * Recycling\n\nIntel technologies may require enabled hardware, software or service\nactivation. // No product or component can be absolutely secure. // Your costs\nand results may vary. // Performance varies by use, configuration and other\nfactors. // See our complete legal Notices and Disclaimers. // Intel is\ncommitted to respecting human rights and avoiding causing or contributing to\nadverse impacts on human rights. See Intel\u2019s Global Human Rights Principles.\nIntel\u2019s products and software are intended only to be used in applications\nthat do not cause or contribute to adverse impacts on human rights.\n\n", "frontpage": true}

{"aid": "40066277", "title": "Automatic differentiation in geophysical inverse problems", "url": "https://academic.oup.com/gji/article/170/1/1/2018933", "domain": "oup.com", "votes": 1, "user": "teleforce", "posted_at": "2024-04-17 15:44:19", "comments": 0, "source_title": "Automatic differentiation in geophysical inverse problems", "source_text": "Automatic differentiation in geophysical inverse problems | Geophysical Journal International | Oxford Academic\n\nSkip to Main Content\n\nAdvertisement\n\nJournals\n\nBooks\n\n  * Search Menu\n  * Menu\n\nSearch\n\n  * Issues\n\n    * Volume 237, Issue 3, June 2024 (In Progress)\n    * Volume 237, Issue 2, May 2024\n    * Browse all\n  * Advance Access\n  * Subject\n\n    * Applied and Marine Geophysics\n    * General Geophysical Methods\n    * Geodynamics and Tectonics\n    * Gravity, Geodesy and Tides\n    * Heat Flow and Volcanology\n    * Magnetic and Electrical Fields\n    * Rock and Mineral Physics, Rheology\n    * Seismology\n  * More Content\n\n    * 100 Influential Papers\n    * Advance Articles\n    * Express Letters\n    * Hunga Volcano Special Issue\n    * East Anatolia Fault Special Issue\n    * Special Issues\n  * Submit\n\n    * Why Publish\n    * Author Guidelines\n    * Submission Site\n    * Read & Publish\n    * Waivers\n    * Developing Countries Initiative\n    * Author Resources\n    * Self-Archiving policy\n    * Rights and Permissions\n  * Alerts\n  * About\n\n    * About Geophysical Journal International\n    * Editorial Board\n    * About the Royal Astronomical Society\n    * About the DGG\n  * Journals on Oxford Academic\n  * Books on Oxford Academic\n\nRAS Journals\n\nClose\n\nSearch\n\nAdvanced Search\n\nSearch Menu\n\nArticle Navigation\n\nVolume 170\n\nIssue 1\n\nJuly 2007\n\n### Article Contents\n\n  * Summary\n\n  * 1 Introduction\n\n  * 2 Elements of Automatic Differentiation\n\n  * 3 Numerical Experiments\n\n  * 4 Conclusion\n\n  * References\n\n  * Next >\n\nJournal Article\n\n# Automatic differentiation in geophysical inverse problems\n\n,\n\nM. Sambridge\n\nResearch School of Earth Sciences, Australian National University, Canberra,\nACT 0200, Australia. E-mail. malcolm.sambridge@anu.edu.au\n\nSearch for other works by this author on:\n\nOxford Academic\n\nGoogle Scholar\n\nADS\n\n,\n\nP. Rickwood\n\nResearch School of Earth Sciences, Australian National University, Canberra,\nACT 0200, Australia. E-mail. malcolm.sambridge@anu.edu.au\n\nSearch for other works by this author on:\n\nOxford Academic\n\nGoogle Scholar\n\nADS\n\n,\n\nN. Rawlinson\n\nResearch School of Earth Sciences, Australian National University, Canberra,\nACT 0200, Australia. E-mail. malcolm.sambridge@anu.edu.au\n\nSearch for other works by this author on:\n\nOxford Academic\n\nGoogle Scholar\n\nADS\n\nS. Sommacal\n\nResearch School of Earth Sciences, Australian National University, Canberra,\nACT 0200, Australia. E-mail. malcolm.sambridge@anu.edu.au\n\nSearch for other works by this author on:\n\nOxford Academic\n\nGoogle Scholar\n\nADS\n\nGeophysical Journal International, Volume 170, Issue 1, July 2007, Pages 1\u20138,\nhttps://doi.org/10.1111/j.1365-246X.2007.03400.x\n\nPublished:\n\n01 July 2007\n\nArticle history\n\nReceived:\n\n11 February 2007\n\nAccepted:\n\n13 February 2007\n\nPublished:\n\n01 July 2007\n\n  * PDF\n  * Views\n\n    * Article contents\n    * Figures & tables\n  * Cite\n\n### Cite\n\nM. Sambridge, P. Rickwood, N. Rawlinson, S. Sommacal, Automatic\ndifferentiation in geophysical inverse problems, Geophysical Journal\nInternational, Volume 170, Issue 1, July 2007, Pages 1\u20138,\nhttps://doi.org/10.1111/j.1365-246X.2007.03400.x\n\nClose\n\n  * Permissions Icon Permissions\n\n  * Share Icon Share\n\n    * Facebook\n    * Twitter\n    * LinkedIn\n    * Email\n\nSearch\n\nClose\n\nSearch\n\nAdvanced Search\n\nSearch Menu\n\n## Summary\n\nAutomatic differentiation (AD) is the technique whereby output variables of a\ncomputer code evaluating any complicated function (e.g. the solution to a\ndifferential equation) can be differentiated with respect to the input\nvariables. Often AD tools take the form of source to source translators and\nproduce computer code without the need for deriving and hand coding of\nexplicit mathematical formulae by the user. The power of AD lies in the fact\nthat it combines the generality of finite difference techniques and the\naccuracy and efficiency of analytical derivatives, while at the same time\neliminating \u2018human\u2019 coding errors. It also provides the possibility of\naccurate, efficient derivative calculation from complex \u2018forward\u2019 codes where\nno analytical derivatives are possible and finite difference techniques are\ntoo cumbersome. AD is already having a major impact in areas such as\noptimization, meteorology and oceanography. Similarly it has considerable\npotential for use in non-linear inverse problems in geophysics where\nlinearization is desirable, or for sensitivity analysis of large numerical\nsimulation codes, for example, wave propagation and geodynamic modelling. At\npresent, however, AD tools appear to be little used in the geosciences. Here\nwe report on experiments using a state of the art AD tool to perform source to\nsource code translation in a range of geoscience problems. These include\ncalculating derivatives for Gibbs free energy minimization, seismic receiver\nfunction inversion, and seismic ray tracing. Issues of accuracy and efficiency\nare discussed.\n\nDerivatives, inverse problems, sensitivity kernel\n\nIssue Section:\n\nGeneral Geophysical Methods\n\n## 1 Introduction\n\nOver the past 20 yr numerical simulation of geophysical processes has become\nwidespread. The availability of high performance computing and advanced\nnumerical techniques has led researchers to develop increasingly sophisticated\nnumerical algorithms for modelling physical processes such as deformation\nwithin the Earth's lithosphere (Moresi et al. 2003), convection within the\ndeep interior (Moresi et al. 2000) and propagation of seismic waves through\nfully 3-D models of the whole Earth (Komatitsch et al. 2005). The primary use\nof such tools is to make predictions that can be compared to observations. An\nissue of much concern is to determine the sensitivity of these predictions to\nthe input parameters upon which they are based, for example, how a synthetic\nseismogram calculated for a particular earthquake at a particular point on the\nsurface varies with parameters controlling the source, or the assumed earth\nmodel between source and receiver. Here sensitivity means the derivatives, or\nJacobian, of the output variables with respect to input variables. Many areas\nof the sciences have need of derivatives and indeed one could argue that there\nis often little point in knowing what a mathematical model predicts if one\ndoesn't know the sensitivity of that prediction to the parameters controlling\nthe model.\n\nAnother area where derivatives are much used is inversion of geophysical data\n(Aster et al. 2005; Tarantola 2005). In this case one fits models of the Earth\nto observations, often in an automated manner making use of optimization\ntechniques, which themselves depend on derivatives. Not all inversion\ntechniques are based on derivatives (see Sambridge & Mosegaard 2002), but if\nthe number of unknowns is large, say in the 100 s or greater, and the\nmathematical relationship between data and the unknowns is non-linear, then\nderivative calculations are unavoidable. In non-linear inverse problems such\nas seismic tomography of the Earth's mantle and lithosphere (see Rawlinson &\nSambridge 2003, for a recent review), iterative algorithms making use of\nderivative information have become the norm over the past 10 yr.\n\nThe calculation of derivatives can be problematic in many cases. If analytical\nexpressions are available then these can be hand coded. This has the\n(potential) advantage of efficiency in the final code, but at the cost of much\ndevelopment time (in debugging hand coded expressions) and a certain amount of\ninflexibility. For example, in an inverse problem, if the misfit function, or\nparametrization, is changed then derivatives must be recoded. If no analytical\nformulae are available then one often resorts to numerical estimates of\nderivatives, for example, using finite difference techniques. In this case one\nwould typically perturb each input variable one at a time by a specified\namount and recalculate the output variables with the \u2018source\u2019 code. This has\nthe advantage of flexibility since there is no dependence on the details of\nthe source code, however, the accuracy will depend on the size of the\nperturbation and may require tuning. Furthermore, the overall computational\ncost scales with the number of input variables. For computationally intensive\nsource codes with large numbers of input variables (e.g. 10^2\u201310^6) this can\nbecome prohibitive.\n\nWith these issues in mind, one might define an \u2018ideal\u2019 derivative method as\nhaving the following properties.\n\n  * (i)\n\nCalculates exact derivatives (i.e. to within machine precision).\n\n  * (ii)\n\nComputational cost independent of the number of input variables.\n\n  * (iii)\n\nMinimal human effort to generate and update a Jacobian.\n\nComputer scientists have grappled with these issues for many years and the\nfield of automatic differentiation (AD) has emerged as a result. To date these\ndevelopments seem to have made little impact on the Geosciences. The purpose\nof this paper is to help bring AD tools to the attention of the wider\ngeoscience community, provide some useful references and illustrate its\npotential through a series of numerical experiments on common geoscience\nproblems. We begin with a brief outline of how current AD methods work. We\nthen present results of our experiments applying current state-of-the art AD\ntools to particular geoscience problems. Performance is evaluated in terms of\nthe three ideals above, with particular attention given to issues of accuracy\nand efficiency.\n\n## 2 Elements of Automatic Differentiation\n\nThe origins of AD date back to the 1950s and 1960s, and in particular to the\nworks of Beda et al. (1959),Wengert (1964). Modern developments can be traced\nto a resurgence in activity in the 1970s and 1980s. Reviews can be found in\nRall (1981), Griewank (1991), Rall & Corliss (1996), Griewank (2000) and\nCusdin & M\u00fcller (2003), while a recent work containing many applications of AD\nto engineering and optimization, as well as an extensive bibliography, is\nCorliss et al. (2002). A comprehensive online resource has also emerged and\nmay be found at www.autodiff.org.\n\nThe underlying principle of AD is that computer programs can be decomposed\ninto a finite set of instructions (usually executed serially). The source code\nthen represents a (composite) function which takes a set of n input variables\nand produces a set of m output variables thorough application of a set of\nelementary functions. The Jacobian of each elementary function can be obtained\nusing simple rules, for example, from tables of differentiation (see Talagrand\n1991; Giering & Kaminski 1998). Repeated application of the chain rule of\ndifferentiation yields the desired Jacobian of the composite function. An\nimportant issue here is that at the elementary level differentiation can be\ncarried out exactly, that is, without the need to introduce numerical\napproximations like finite difference operators, (an example is given below).\nFrom the user's perspective modern AD tools act the same way as a compiler,\nbut rather than producing object or executable code, they create a second\nsource code which evaluates the derivatives of the original function for any\nvalues of the input variables. In this sense \u2018source to source\u2019 translator AD\ntools directly replace the hand coding of derivatives (see Fig. 1).\n\nFigure 1.\n\nOpen in new tabDownload slide\n\nSchematic illustration of how a code-to-code translation is performed by an AD\ntool.\n\n### 2.1 Forward mode\n\nAD methods are divided into two types depending on the order in which they\nevaluate the elementary functions and their Jacobians. The forward or \u2018Tangent\nlinear\u2019 mode evaluates them in the same order as the source (often called\n\u2018primal\u2019) code. This can be easier to implement and efficient on storage\nbecause once variables are no longer needed in the source code they can be\ndiscarded (overwritten) which reduces the storage needed to keep track of\nassociated derivative variables. Fig. 2 shows an example of the elementary\noperations (code list) required to evaluate a simple trigonometrical function\n\n1\n\nAs can be seen this is decomposed into five steps involving five separate\nvariables (t _i, i = 1, ..., 5). (Note that t _1 = x, t _2 = y and t _5 = f).\nThe corresponding tangent code for each step is shown in the central column\nand the equivalent mathematical expression for the derivative is shown in the\nfourth column. For the input variable x the tangent code list is initialized\nwith\n\n2\n\nAs each step proceeds a new intermediate variable t _i is determined and the\ncorresponding derivatives with respect to the input variable are found by\nevaluating the expression in the third column. By the time the fifth line is\ncompleted the required derivative of f has been assembled. The whole process\nis repeated for the second input variable y by changing the initial values to\n\n3\n\nIt is clear from this example that in forward mode the computational cost of\nevaluating the Jacobian is proportional to the number of input variables n,\nmultiplied by the number of steps in the code list, the latter often being\nlinear in n also. This is the same as a finite difference operator, however\nthe accuracy of the resulting derivatives will be at machine precision due to\nthe exact differentiation at the elemental level. Forward mode then satisfies\nproperty 1 and 3 of an idealized method but not property 2 (see Section 1).\n[Note, however, very recent developments of AD include a vector mode which\ninvolves simultaneous propagation of all partial derivatives (see Kaminski et\nal. 2003, for an example).]\n\nFigure 2.\n\nOpen in new tabDownload slide\n\nExample of AD of a simple function in forward mode. The first column shows the\nevaluation of the expression in eq. (1) broken down into five steps each\ndefining a new variable t _i(i = 1..., 5). The second column shows\ncorresponding expressions being evaluated. The third column is the\ndifferentiation of each intermediate variable with respect to input variable\n(x or y) using the chain rule expression written at the base of the figure.\nThe fourth column shows the derivative expression corresponding to each line\nof the third column for the case where x is the independent variable. After a\nsweep through all five statements the derivative expression for x is\nconstructed. The third column can then be repeated for y.\n\n### 2.2 Reverse mode\n\nThe second way of performing AD is to reverse the order in which the\nelementary functions and their Jacobians are determined. This is known as the\nreverse or \u2018Adjoint\u2019 mode. Again at the elemental level exact derivatives are\ncalculated, but they are combined in the opposite order to before. Fig. 3\nshows how reverse mode is carried out for the simple expression in (1). In\nthis case the code list in the first two columns are reversed with respect to\nthe forward case shown in Fig. 2. However, in the ith line of the third column\nthe expression for the derivative is evaluated using the chain rule. By the\ntime the fifth line is completed, expressions for the derivatives of f(= t _5)\nwith respect to both x(= t _1) and y(= t _2) have been determined. Hence with\na single reverse sweep through the code list the derivatives of an output\nvariable with respect to all input variables are available. The whole\nprocedure must be repeated for every output variable, and hence a major\nadvantage of the reverse mode is that the computational cost of evaluating the\nderivatives is proportional to the number of output variables m (multiplied by\nthe length of the code list) rather than the number of input variables. We see\nthen that unlike forward mode, the reverse mode of AD is the only one which\ncan satisfy all three properties of an ideal method.\n\nFigure 3.\n\nOpen in new tabDownload slide\n\nExample of AD of a simple function in reverse mode. The first two columns are\nthe reverse of those in Fig. 2. The third column shows how the chain rule\nexpression at the base is applied to each line. The fourth column shows the\ncorresponding evaluation of the third column. Note that after a single sweep\nthrough derivatives of f with respect to both y (fourth line) and x (fifth\nline) have been constructed.\n\nImplementation of this mode for arbitrary source codes presents a major\nchallenge because the information flow must be reversed. In the simple example\nabove this is trivial, however to do it in an automatic manner for a\ncomplicated code can become a challenging task, and this is a subject of\nongoing research (Giering & Kaminski 2002). The simple example above\nhighlights one of the main difficulties. At each stage of the reverse list,\nevaluation of the elemental Jacobians in the third column requires numerical\nvalues of the corresponding intermediate variables (t _i, i = 1, ..., n). (In\ngeneral the entire state of the code including the values of all variables\nneeds to be known at each time step.) In the forward mode this is not a\nproblem, because the state of all variables is updated as the source code\nproceeds (using the primal code). However, in reverse mode variables are\nneeded in the reverse order in which they are calculated, which can be a major\nobstacle if variables get overwritten. The situation is illustrated\nschematically in Fig. 4, where each dot represents a state of the source code.\nAs time proceeds we move from the far right of the dotted line, the final\nstate, to the initial state on the left.\n\nFigure 4.\n\nOpen in new tabDownload slide\n\nSchematic illustration of strategies for recovering the state of a\ncomputational system required by reverse mode of AD. (a) Recalculate all\nstrategy, (b) store all strategy and (c) the checkpointing strategy which is a\ncombination of the two.\n\nFig. 4(a) shows the \u2018recalculate all\u2019 strategy whereby the source code is\nrestarted from the beginning each time the state changes. This involves a\nlarge amount of computation, especially if there are a large number of states,\nbut it requires relatively little extra storage. A second strategy is to store\nthe complete values of all intermediate variables at every state, illustrated\nby Fig. 4(b). In this case there is little extra computation but the amount of\nstorage required may be prohibitive. A compromise between the two extremes is\na checkpointing strategy, illustrated by Fig. 4(c). Here the state is\npreserved at only selected points and recalculation proceeds from the last\ncheckpointed position to the current state. Again it can be a complex task\nstriking the best balance between these approaches. The main differences\nbetween various AD tools lies in whether they perform forward or reverse mode\nand if the latter, what type of strategy they use to recover the program\nstate.\n\nAs has been noted previously (e.g. Griewank 1989) adjoint or reverse mode of\nAD is closely related to the determination of sensitivity kernels through\nadjoint differential equations. The latter has been used to determine partial\nderivatives in a range of areas where numerical simulation of complicated\nphenomena are involved. Examples include applications in nuclear reactor\ndesign for derivatives of temperature with respect to thousands of design\nparameters (Cacuci 1981a,b); in meteorology and oceanography for gradients of\nresidual norms with respect to initial conditions (Talagrand & Courtier 1987;\nThacker & Long 1988); in seismology for derivatives of seismic waveform\nresiduals with respect to Earth structure parameters (Tarantola 1984, 1988;\nTromp et al. 2005; Sieminski et al. 2007), and also in geodynamic calculations\nof mantle convection (Bunge et al. 2003). In each case the adjoint of the\ngoverning partial differential equation (PDE) is solved numerically and\ncombined with the numerical solution of the original PDE to yield the required\npartial derivatives. For this reason the approach is often referred to as the\ncontinuous adjoint method, whereas the reverse mode of AD is often called the\ndiscrete adjoint method, since it is a line by line application of the chain\nrule. In principal, the discrete adjoint method has an advantage over the\ncontinuous approach in that it can avoid the build up of numerical error\nassociated with solving of the differential equations. (With the discrete\nadjoint all calculations are essentially at machine precision). However, the\ncontinuous adjoint can be relatively straightforward to implement involving\nonly a few repeat runs of the primal code. More importantly however, both have\nthe property that the computational cost scales directly with the number of\noutput parameters and not with the number of input parameters.\n\nAt present awareness of AD tools seems to be rather limited in the Earth\nSciences. To our knowledge the first application in this field was in a PhD\nthesis by Sommacal (2004) for calculating derivatives in a Gibbs free energy\nminimization problem. (This is one of the test cases presented below.) More\nrecently, applications have appeared in inverse problems in groundwater flow\n(Rath et al. 2006), and geodynamic modelling (Iaffaldano et al. 2007). Below\nwe present results of some experiments with one of the most advanced AD tools\navailable. This is known as Transformation of Algorithms in Fortran (TAF,\navailable from www.fastopt.de) see Giering & Kaminski (2003). In all cases we\ncompare performance to finite difference estimates, since this is a comparably\ngeneral approach, requiring little human intervention.\n\n## 3 Numerical Experiments\n\n### 3.1 Gibbs free energy minimization\n\nA common problem in igneous and metamorphic petrology is the calculation of\nequilibrium phase assemblages as a function of temperature, pressure and\ncomposition. Differing formulations of this problem have been proposed\ntogether with algorithms for their solution (e.g. Storey & van Zeggeren 1964;\nDe Capitani & Brown 1987; Harvie et al. 1987). All of these use optimization\ntechniques based on gradients for minimizing the Gibbs free energy. In this\nexample we follow the formulation of Sommacal (2004) and write the Gibbs free\nenergy of a single phase \u03c6 as a sum of three terms,\n\n4\n\nwhere G ^end-members is the free energy of its end-member constituents, G\n^ideal is the free energy due to an idealized configurational entropy from\nmixing, and G ^excess is the excess free energy of mixing (see works cited\nabove for details). Each of the these terms depend on various thermodynamic\nvariables including the number and type of phases present in the system. The\ntotal Gibbs free energy must be minimized as a function of the variables X\n_i,j, which are the site occupancies of cation i on sublattice j. However,\nonly the second and third terms depend on X _i,j. Specifically, we have\n\n5\n\n6\n\nwhere R is the gas constant, T is temperature, q _j are stoichiometry factors\nwhich have values 1 or 2 depending on the type of phase, and W _l,i,j, W\n_i,l,k,j are the three and four index Margules parameters describing the\nvarious interaction energies between sites. Summation occurs over sublattices\nand cations. All parameters other then the site occupancies X _i,j may be\ntreated as constants for our purposes, as minimization is performed with\nrespect to these parameters only. The Gibbs free energy over all phases\npresent in a system, G, is a weighted sum of G ^\u03c6 terms. The Gibbs free energy\nhas to be minimized (subject to certain constraints) and this can be done with\ngradient methods. Hence the derivatives are required. Since this is an\nanalytical expression then it may in principal be differentiated analytically\nand coded by hand into a derivative routine. This would be both tedious and\nprone to human coding errors.\n\nWe applied the TAF AD tool to generate derivative code in both forward and\nreverse mode to this problem (note the source code was written in Fortran77).\nIn this case we have one output variable, G, and by varying the number of\nphases present we can adjust the number of input variables, X _i,j. Fig. 5\nshows the relative compute time for execution of the resulting derivative code\nas a function of the number of input variables. In each case the same\nderivatives were also computed with finite differences (after some tuning of\nthe perturbation to achieve accuracy). The total number of derivatives\ncalculated across all trials was 638. For forward mode we observe a quadratic\ndependence of CPU time on number of independent variables, N, for both the AD\ngenerated code and the finite difference code. This is consistent with\ntheoretical predictions. From (5) and (6) we see that the compute cost of\nevaluating the Gibbs free energy depends linearly on the number of input\nvariables, N. Hence if the derivative calculation requires of the order of N\nforward solutions the overall dependence will be quadratic in N. We note that\nin all cases the AD generated code is more efficient than the finite\ndifference derivatives (by up to a factor of 2). Given that the average\ndifference in derivative values is less than 0.006 per cent, we see that in\nforward mode the AD tool has automatically generated code which gives correct\nvalues and is an efficient alternative to finite differences.\n\nFigure 5.\n\nOpen in new tabDownload slide\n\nScaling of CPU time with number of input variables to evaluate the Jacobian\nfor the Gibbs free energy objective function, (a) in forward mode and (b) in\nreverse mode. Note that the observed CPU time for the forward mode scales\napproximately linearly with the N while in reverse mode it is independent of\nN, as predicted by theory.\n\nIn reverse mode Fig. 5 clearly shows the independence between the CPU time for\nderivative evaluation, and the number of input variables. Again this is as\npredicted by theory, but nevertheless quite remarkable. As N grows the ratio\nof compute times varies between 4.1 and 41.2. Differences between derivative\nvalues for forward and reverse mode are within machine precision. In this case\nthe AD tool has managed to automatically reverse the flow of the code and\ngenerate derivative routines whose computational cost is independent of the\nnumber of input parameters.\n\n### 3.2 Seismic receiver functions\n\nOur second test problem arises in the inversion of seismic body waveforms for\ncrustal structure. Receiver function inversion (Langston 1989; Ammon et al.\n1990) is a much used technique for estimating shear wave speeds in the Earth's\ncrust as a function of depth beneath a seismic recorder. Receiver functions\nare derived from observed seismograms of distant events and may be compared to\nthose predicted from a crustal velocity profile. A misfit function measuring\nthe discrepancy between the two waveforms is specified, and minimized as a\nfunction of the parameters controlling the velocity model (see Fig. 6). Here\nthe profile consists of a series of six linear segments with depth. Also there\nis the potential for discontinuities in wave speed between layers, which are\nthemselves of variable thickness (see Shibutani et al. 1996, for full details\nof the parametrization).\n\nFigure 6.\n\nOpen in new tabDownload slide\n\n(a) Parametrization of shear wave velocity model used in the receiver function\nproblem. Here, 24 parameters control the profile as a function of depth using\nlinear segments between variable thickness layers; (b) an \u2018observed\u2019 and\npredicted receiver function. The squared difference between the two traces\ncorresponds to the data misfit function used in the inversion and (c) two\nexamples of the data misfit surface defined by the difference in receiver\nfunctions, plotted as a function of two pairs of model parameters. The\nirregular (non-quadratic) shape is due to the high non-linearity in the misfit\nsurface. In the second example AD generated code is used to calculate\nderivatives of this misfit surface at any point.\n\nReceiver function inversion is similar to other waveform fitting problems in\nseismology, where the relationship between parameters describing the Earth\nmodel are non-linearly related to the observed seismograms. Fig. 6 shows a\nwaveform misfit surface (based on the L2 norm of the waveform discrepancy) as\na function of two of the velocity model parameters. In this case the surfaces\nare clearly not quadratic. Their multimodal character means that gradient\nmethods of optimization require many iterations and hence many derivative\nevaluations.\n\nIn contrast to the Gibbs free energy example the evaluation of the synthetic\nreceiver function from a given velocity profile is purely numerical, that is,\nno analytical expression is available. Here we use a standard approach known\nas the Thomson-Haskell method (Thomson 1950; Haskell 1953). For this problem\nwe applied the AD tool in forward mode to generate derivative code; in this\nexample there is one output variable (the waveform misfit function) and 24\ninput variables (describing the velocity profile). Again the accuracy was\ncompared to finite differences. With the latter we experienced some difficulty\nin tuning the step size to achieve a stable result. As a consequence the\naverage difference between the two sets of derivatives was approximately 4 per\ncent which is greater than in the first example and probably due to inaccuracy\nof the finite difference estimates. In this case the AD generated derivative\ncode took 2.28 s to evaluate all 24 derivatives compared to 3.03 s with finite\nderivatives (all calculations performed on a P4 Linux desktop workstation with\n1Gb RAM). We also calculated gradients \u2018element by element\u2019, where the\nderivative code was executed once for each input parameter. This gave the same\nnumerical values to within machine precision and took 3.67 s. The difference\nin time reflects the repeated execution of overhead in the element by element\ncase.\n\nFor this problem we were unsuccessful in getting a result in reverse mode.\nAlthough the AD tool successfully generated derivative code, upon execution it\nfailed to complete. It seems likely that this was due to some difficulty in\nefficiently reversing the flow of the synthetic receiver function algorithm.\nAs noted above this can be a major problem. We did not investigate the cause\nin any great detail, nor employ any of the advanced features of this\nparticular AD tool which allows users to insert directives in the code to\nassist in differentiation. Our results, therefore, reflect the experience of a\n\u2018novice\u2019 or \u2018hands off\u2019 user of AD, who, as noted above, is the intended\ntarget of the idealized AD tool. Nevertheless, for the receiver function\nproblem forward mode has stably and efficiently generated derivatives in an\nautomated fashion.\n\n### 3.3 Seismic ray tracing\n\nOur final test problem is the most numerically intensive of all. The\nexperimental setup is shown in Fig. 7. Here we apply the AD tool to calculate\nthe derivatives of seismic traveltimes with respect to seismic velocities of a\nlaterally varying medium. This is a common problem in seismic tomography with\nbody wave arrival times (see Rawlinson & Sambridge 2003).\n\nFigure 7.\n\nOpen in new tabDownload slide\n\nSeismic rays produced by the ray tracer in highly heterogeneous 2-D medium.\nHere rays are initially shot out at equal angles and their trajectory depends\non the local wave speed variations. The source point is denoted by a yellow\ndot. In this example AD generated code is used to calculate derivatives of\ntraveltime with respect to the parameters controlling the seismic velocity\nfield.\n\nHere we use a simple spline mesh to represent a 2-D laterally varying Gaussian\nrandom field of seismic velocities, and 400 rays are shot out at equal angles\nfrom a source placed in the centre of the model (see Fig. 7). As in the\nprevious example no analytical solution exists for finding the path of the ray\nin a medium of this complexity. For each ray a set of non-linear initial value\nODE's are solved using a Runge-Kutta algorithm. The result is the endpoint of\nthe ray as a function of traveltime (see Rawlinson & Sambridge 2003, for\ndetails). All rays are stopped when they meet the edge of the 2-D medium.\n\nAs the spatial scale length of the heterogeneity decreases and the amplitude\nincreases the rays become highly distorted by the velocity gradients in the\nmodel. In this experiment the amplitude of heterogeneity varies by more than a\nfactor of 10 (which is extreme for the real Earth) and rays soon become\nchaotic. The spline mesh has 299 coefficients controlling the velocity model\ngiving a Jacobian with 18 338 non-zero entries in a matrix with 119 600\nelements. We used the AD tool to generate derivative code in forward mode.\n(Note here the number of output variables is 400 which outnumber the input\nvariables, 299, and hence forward mode is to be preferred.) Again to make\nresults comparable to previous examples we also calculated derivatives with a\nsimple finite difference code (after some tuning of step size). Note that, in\nthis case, derivatives could also be determined by integrating the basis\nfunction of each spline in the velocity mesh along each ray which would\nrequire some significant hand coding.\n\nThe entire Jacobian was determined by both approaches. The average difference\nin estimated derivatives was less than 10^\u22125 per cent, hence the accuracy of\nthe AD generated code is effectively at machine precision (as theory\npredicts). The compute time for the entire Jacobian with finite differences\nwas 2502.6 s. The AD generated code in an element by element mode took 829.2 s\nand in an \u2018all at once\u2019 mode took 108.9 s. Hence in this case the forward mode\nis highly accurate and more than an order of magnitude faster than the\ncorresponding finite difference algorithm. As with the previous example we\nwere unable to get reverse mode to work.\n\n## 4 Conclusion\n\nWe have presented results of several experiments with a particular AD tool,\nTAF of Giering & Kaminski (2003). In all cases efficient and accurate\nderivative code has been generated using forward mode, and in the simplest\nexample reverse mode was equally successful. The accuracy and computation cost\nof forward mode was consistent with theoretical predictions. We observed an\nindependence of the reverse mode CPU time on the number of input parameters.\nThis is an unusual result, given that the cost of the source code in this case\nscales linearly with the number of input parameters. (We can only speculate\nthat there is an underlying linear dependence which has not reached above the\nnoise level in our experiments.)\n\nOur experiments were conducted in a deliberately \u2018hands off\u2019 manner, as our\nintention was to test whether such tools were truly \u2018Automatic\u2019 in this sense.\nIt is clear that AD tools in forward mode have reached a level of\nsophistication which makes them reliably automatic, accurate and stable. In\nreverse mode this is not yet the case, although we were impressed that it\nworked as well as it did. This is quite unsurprising given the difficulty\ninvolved in automatically reversing the flow of complex source codes. AD is an\nactive field of research and one can expect AD tools to continue to develop.\nThe one used here (TAF) is probably the most sophisticated in the world to\ndate. (During the course of this work we actually tested several other AD\ntools, including ADIFOR2.0, TAMC and TAPENADE. See www.autodiff.org for full\ndetails of these packages.) At present AD is not yet fully automatic in\nreverse mode, as is acknowledged by experts in the field (see Griewank 1989;\nCorliss et al. 2002). It seems likely that for the foreseeable future human\nintervention will be required to get the most out of AD in reverse mode, in\nmuch the same way that directives are used to optimize the performance of most\nmodern compilers. We expect a careful re-examination of the cases where\nreverse mode failed, together with appropriate use of AD directives would most\nlikely improve performance.\n\nCurrent directions in AD research include ways of incorporating parallel\nlibraries such as MPI, extending the range of programming languages and also\nallowing a combination of languages such as Fortran90 and C (see Corliss et\nal. 2002, for discussions). At the same time the number of applications are\nsteadily growing. It seems inevitable that over the next 10 yr AD will become\nan indispensable part of numerical modelling and optimization software, used\nacross the physical sciences. We hope the present paper encourages further\napplications in the geosciences.\n\n### Acknowledgments\n\nWe thank Drs Thomas, Kaminski and Ralf Giering of FastOpt the creators of TAMC\nand TAF, for their advice and assistance, and also in providing us access to\ntheir software.\n\n## References\n\nAmmon\n\nC.J.\n\nRandall\n\nG.E.\n\nZandt\n\nG.\n\n,\n\n1990\n\n.\n\nOn the nonuniqueness of receiver function inversions\n\n,\n\nJ. Geophys. Res.\n\n,\n\n95\n\n,\n\n15\u2013303\n\n\u2013\n\n15 318\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nAster\n\nR.\n\nBorchers\n\nB.\n\nThurber\n\nC.H.\n\n,\n\n2005\n\n.\n\nParameter estimation and inverse problems\n\n, in\n\nInternational Geophysics Series\n\n, Vol.\n\n90\n\n,\n\nElsevier\n\n,\n\nAmsterdam\n\n.\n\nGoogle Scholar\n\nGoogle Preview\n\nOpenURL Placeholder Text\n\nWorldCat\n\nCOPAC\n\nBeda\n\nL.M.\n\nKorolev\n\nL.N.\n\nSukkikh\n\nN.V.\n\nFrolova\n\nT.S.\n\n,\n\n1959\n\n.\n\nPrograms for automatic differentiation for the machine BESM, Technical Report,\nInstitute for Precise Mechanics and Computation Techniques, Academy of Science\n\n,\n\nMoscow, USSR (In Russian)\n\n.\n\nBunge\n\nH.-P.\n\nHagelberg\n\nC.R.\n\nTravis\n\nB.J.\n\n,\n\n2003\n\n.\n\nMantle circulation models with variational data assimilation: inferring past\nmantle flow and structure from plate motion histories and seismic tomography\n\n,\n\nGeophys. J. Int.\n\n,\n\n152\n\n,\n\n280\n\n\u2013\n\n301\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nCacuci\n\nD.G.\n\n,\n\n1981\n\n.\n\nSensitivity theory for nonlinear systems. I. Nonlinear functional analysis\napproach\n\n,\n\nJ. Math. Phys.\n\n,\n\n22\n\n,\n\n2794\n\n\u2013\n\n2802\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nCacuci\n\nD.G.\n\n,\n\n1981\n\n.\n\nSensitivity theory for nonlinear systems. II. Extension to additional classes\nof responses\n\n,\n\nJ. Math. Phys.\n\n,\n\n22\n\n,\n\n2803\n\n\u2013\n\n2812\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nCorliss\n\nG.\n\nFaure\n\nC.\n\nGriewank\n\nA.\n\nHasco\u00ebt\n\nL.\n\nNaumann\n\nU.\n\n,\n\n2002\n\n.\n\nAutomatic Differentiation of Algorithms: From Simulation to Optimization\n\n,\n\nSpringer, New York\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nCusdin\n\nP.\n\nM\u00fcller\n\nJ.-D.\n\n,\n\n2003\n\n.\n\nAutomatic Differetiation: Learning to Speak AD\n\n, Qub-sae-03-05, Queen's Unversity Belfast.\n\nDe Capitani\n\nC.\n\nBrown\n\nT.H.\n\n,\n\n1987\n\n.\n\nThe computation of chemical equilibrium in complex systems containing non-\nideal solutions\n\n,\n\nGeochim. Cosmochim. Acta\n\n,\n\n51\n\n,\n\n2639\n\n\u2013\n\n2652\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nGiering\n\nR.\n\nKaminski\n\nT.\n\n,\n\n1998\n\n.\n\nRecipes for Adjoint code construction\n\n,\n\nACM Trans. Math Software\n\n,\n\n24\n\n,\n\n437\n\n\u2013\n\n474\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nGiering\n\nR.\n\nKaminski\n\nT.\n\n,\n\n2002\n\n.\n\nRecomputations in reverse mode AD\n\n, in\n\nAutomatic Differentiation of Algorithms: From Simulation to Optimization\n\n, Chap. 33, pp.\n\n283\n\n\u2013\n\n291\n\n, eds\n\nCorliss\n\nG.\n\nFaure\n\nC.\n\nGriewank\n\nA.\n\nHasco\u00ebt\n\nL.\n\nNaumann\n\nU.\n\n,\n\nSpringer\n\n,\n\nNew York, NY\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nGiering\n\nR.\n\nKaminski\n\nT.\n\n,\n\n2003\n\n.\n\nApplying TAF to generate efficient derivative code of Fortran 77\u201395 programs\n\n,\n\nProc. Appl. Math. Mech\n\n.\n\nGoogle Scholar\n\nOpenURL Placeholder Text\n\nWorldCat\n\nGriewank\n\nA.\n\n,\n\n1989\n\n.\n\nOn automatic differentiation\n\n, in\n\nMathematical Programming: Recent Developments and Applications\n\n, pp.\n\n83\n\n\u2013\n\n108\n\n, eds\n\nIri\n\nM.\n\nTanabe\n\nK.\n\n,\n\nKluwer Academic Publishers\n\n,\n\nDordecht\n\n.\n\nGoogle Scholar\n\nGoogle Preview\n\nOpenURL Placeholder Text\n\nWorldCat\n\nCOPAC\n\nGriewank\n\nA.\n\n,\n\n1991\n\n.\n\nThe chain rule revisited in scientific computing\n\n,\n\nSIAM News\n\n,\n\n24\n\n(No.\n\n3\n\n), p.\n\n20\n\n&(No. 4) p. 8.\n\nGoogle Scholar\n\nOpenURL Placeholder Text\n\nWorldCat\n\nGriewank\n\nA.\n\n,\n\n2000\n\n.\n\nEvaluating derivatives: principles and techniques of algorithmic\ndifferentiation\n\n, in\n\nFrontiers in Appl. Math.\n\n, No. 19,\n\nSIAM\n\n,\n\nPhiladelphia, PA\n\n.\n\nGoogle Scholar\n\nGoogle Preview\n\nOpenURL Placeholder Text\n\nWorldCat\n\nCOPAC\n\nHarvie\n\nC.E.\n\nGreenberg\n\nJ.P.\n\nWeare\n\nJ.H.\n\n,\n\n1987\n\n.\n\nA chemical equilibrium algorithm for highly non-ideal multiphase systems: Free\nenergy minimization\n\n,\n\nGeochim. Cosmochim. Acta\n\n,\n\n51\n\n,\n\n1045\n\n\u2013\n\n1057\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nHaskell\n\nN.A.\n\n,\n\n1953\n\n.\n\nThe dispersion of surface waves in multilayered media\n\n,\n\nBull. Seism. Soc. Am.\n\n,\n\n43\n\n,\n\n17\n\n\u2013\n\n34\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nIaffaldano\n\nG.\n\nBunge\n\nH.-P.\n\nB\u00fccker\n\nM.\n\n,\n\n2007\n\n.\n\nMountain belt growth inferred from past plate convergence: a new tectonic\ninverse problem\n\n,\n\nEarth planet. Sci. Lett.\n\n, submitted.\n\nGoogle Scholar\n\nOpenURL Placeholder Text\n\nWorldCat\n\nKaminski\n\nT.\n\nGiering\n\nR.\n\nScholze\n\nM.\n\nRayner\n\nP.J.\n\nKnorr\n\nW.\n\n,\n\n2003\n\n.\n\nAn example of an automatic differentiation-based modelling system\n\n, in\n\nComputational Science and its Applications-ICCSA 2003, Proceedings of the\nInternational Conference on Computer Science and its Applications\n\n, Montreal, Canada, May 18\u201321, 2003. Part - II, Lecture Notes in Computer\nScience, pp.\n\n95\n\n\u2013\n\n104\n\n,\n\nSpringer\n\n,\n\nBerlin\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nKomatitsch\n\nD.\n\nTsuboi\n\nS.\n\nTromp\n\nJ.\n\n,\n\n2005\n\n.\n\nThe spectral-element method in seismology\n\n, in\n\nSeismic Earth: Array Analysis of Broadband Seismograms\n\n, pp.\n\n49\n\n\u2013\n\n65\n\n, eds\n\nLavender\n\nA.\n\nNolet\n\nG.\n\n,\n\nAGU\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nLangston\n\nC.A.\n\n,\n\n1989\n\n.\n\nScattering of teleseismic body waves under Pasadena, California\n\n,\n\nJ. Geophys. Res.\n\n,\n\n94\n\n,\n\n1935\n\n\u2013\n\n1951\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nMoresi\n\nL.\n\nGurnis\n\nM.\n\nZhong\n\nS.J.\n\n,\n\n2000\n\n.\n\nPlate tectonics and convection in the earth's mantle: toward a numerical\nsimulation\n\n,\n\nComput. Sci. Eng.\n\n,\n\n2\n\n,\n\n22\n\n\u2013\n\n33\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nMoresi\n\nL.\n\nDufor\n\nF.\n\nMulhlaus\n\nH.B.\n\n,\n\n2003\n\n.\n\nLagrangian integration point finite element method for large deformation\nmodeling of viscoelastic geomaterials\n\n,\n\nJ. Comp. Phys.\n\n,\n\n184\n\n,\n\n476\n\n\u2013\n\n497\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nRall\n\nL.B.\n\n,\n\n1981\n\n.\n\nAutomatic Differentiation: Techniques and Applications\n\n, Vol. 120 of Lecture Notes in Computer Science,\n\nSpringer-Verlag\n\n,\n\nBerlin\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nRall\n\nL.B.\n\nCorliss\n\nG.F.\n\n,\n\n1996\n\n.\n\nAn introduction to automatic differentiation\n\n, in\n\nComputational Differentiation: Techniques, Applications, and Tools\n\n, pp.\n\n1\n\n\u2013\n\n17\n\n, eds\n\nBerz\n\nM.\n\nBischof\n\nC.H.\n\nCorliss\n\nG.F.\n\nGriewank\n\nA.\n\n,\n\nSIAM\n\n,\n\nPhiladelphia, PA\n\n.\n\nGoogle Scholar\n\nGoogle Preview\n\nOpenURL Placeholder Text\n\nWorldCat\n\nCOPAC\n\nRath\n\nV.\n\nWolf\n\nA.\n\nB\u00fccker\n\nH.\n\n,\n\n2006\n\n.\n\nJoint three-dimensional inversion of coupled groundwater flow and heat\ntransfer based on automatic differentiation: Sensitivity calculation,\nverification, and synthetic examples\n\n,\n\nGeophys. J. Int.\n\n,\n\n167\n\n,\n\n453\n\n\u2013\n\n466\n\n,\n\narXiv\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nRawlinson\n\nN.\n\nSambridge\n\nM.\n\n,\n\n2003\n\n.\n\nSeismic traveltime tomography of the crust and lithosphere\n\n,\n\nGeophys. J. Int.\n\n,\n\n46\n\n,\n\n81\n\n\u2013\n\n197\n\n.\n\nGoogle Scholar\n\nOpenURL Placeholder Text\n\nWorldCat\n\nSambridge\n\nM.\n\nMosegaard\n\nK.\n\n,\n\n2002\n\n.\n\nMonte Carlo methods in geophysical inverse problems\n\n,\n\nRev. of Geophys.\n\n,\n\n40\n\n,\n\n3.1\u20133.29\n\n,\n\narXiv\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nShibutani\n\nT.\n\nSambridge\n\nM.\n\nKennett\n\nB.L.N.\n\n,\n\n1996\n\n.\n\nGenetic algorithm inversion for receiver functions with application to crust\nand uppermost mantle structure beneath eastern australia\n\n,\n\nGeophys. Res. Lett.\n\n,\n\n23\n\n,\n\n1829\n\n\u2013\n\n1832\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nSieminski\n\nA.\n\nLiu\n\nQ.\n\nTrampert\n\nJ.\n\nTromp\n\nJ.\n\n,\n\n2007\n\n.\n\nFinite-frequency sensitivity of surface waves to anisotropy based on adjoint\nmethods\n\n,\n\nGeophys. J. Int.\n\n,\n\n16\n\n(\n\n3\n\n),\n\n1153\n\n\u2013\n\n1174\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nSommacal\n\nS.\n\n,\n\n2004\n\n.\n\nComputational petrology: Subsolidus equilibria in the upper mantle\n\n, PhD thesis,\n\nThe Australian National University\n\n.\n\nStorey\n\nS.H.\n\nVan Zeggeren\n\nF.\n\n,\n\n1964\n\n.\n\nComputation of chemical equilibrium compositions\n\n,\n\nCan. J. Chem. Eng.\n\n,\n\n42\n\n,\n\n54\n\n\u2013\n\n55\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nTalagrand\n\nO.\n\n,\n\n1991\n\n.\n\nThe use of adjoint equations in numerical modelling of the atmospheric\ncirculation\n\n, in\n\nAutomatic Differentiation of Algorithms: Theory, Implementation, and\nApplication\n\n, pp.\n\n169\n\n\u2013\n\n180\n\n, eds\n\nGriewank\n\nA.\n\nCorlis\n\nG.F.\n\n,\n\nSIAM\n\n,\n\nPhiladelphia, PA\n\n.\n\nGoogle Scholar\n\nGoogle Preview\n\nOpenURL Placeholder Text\n\nWorldCat\n\nCOPAC\n\nTalagrand\n\nO.\n\nCourtier\n\nP.\n\n,\n\n1987\n\n.\n\nVariational assimilation of meteorological observarions with the adjoint\nvorticity equation. I: theory\n\n,\n\nQ. J. R. Meteorol. Soc.\n\n,\n\n113\n\n,\n\n1311\n\n\u2013\n\n1328\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nTarantola\n\nA.\n\n,\n\n1984\n\n.\n\nInversion of seismic reflection data in the acoustic approximation\n\n,\n\nGeophysics\n\n,\n\n49\n\n,\n\n1259\n\n\u2013\n\n1266\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nTarantola\n\nA.\n\n,\n\n1988\n\n.\n\nTheoretical background for the inversion of seismic waveforms, including\nelasticity and attenuation\n\n,\n\nPure Appl. Geophys.\n\n,\n\n128\n\n,\n\n365\n\n\u2013\n\n399\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nTarantola\n\nA.\n\n,\n\n2005\n\n.\n\nInverse Problem Theory and Methods for Model Parameter Estimation\n\n,\n\nSIAM\n\n,\n\nPhiladelphia\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nGoogle Preview\n\nWorldCat\n\nCOPAC\n\nThacker\n\nW.\n\nLong\n\nR.B.\n\n,\n\n1988\n\n.\n\nFitting dynamics to data\n\n,\n\nJ. Geophys. Res.\n\n,\n\n93\n\n,\n\n1227\n\n\u2013\n\n1240\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nThomson\n\nW.T.\n\n,\n\n1950\n\n.\n\nTransmission of elastic waves through a stratified solid\n\n,\n\nJ. Appl. Phys.\n\n,\n\n21\n\n,\n\n89\n\n\u2013\n\n93\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nTromp\n\nJ.\n\nTape\n\nC.\n\nLiu\n\nQ.\n\n,\n\n2005\n\n.\n\nSeismic tomography, adjoint methods, time reversal, and banana-donut kernels\n\n,\n\nGeophys. J. Int.\n\n,\n\n160\n\n,\n\n195\n\n\u2013\n\n216\n\n,\n\narXiv\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\nWengert\n\nR.\n\n,\n\n1964\n\n.\n\nA simple automatic derivative evaluation program\n\n,\n\nCommun. ACM\n\n,\n\n7\n\n(\n\n8\n\n),\n\n463\n\n\u2013\n\n464\n\n.\n\nGoogle Scholar\n\nCrossref\n\nSearch ADS\n\nWorldCat\n\n\u00a9 2007 The Author Journal compilation \u00a9 2007 RAS\n\nDownload all slides\n\nAdvertisement\n\n### Citations\n\n32\n\nCITATIONS\n\n### Views\n\n1,899\n\n### Altmetric\n\nMore metrics information\n\nMetrics\n\nTotal Views 1,899\n\n1,336 Pageviews\n\n563 PDF Downloads\n\nSince 12/1/2016\n\nMonth:| Total Views:  \n---|---  \nDecember 2016| 1  \nJanuary 2017| 2  \nFebruary 2017| 10  \nMarch 2017| 7  \nApril 2017| 4  \nMay 2017| 4  \nJuly 2017| 4  \nAugust 2017| 3  \nSeptember 2017| 2  \nOctober 2017| 3  \nNovember 2017| 29  \nDecember 2017| 20  \nJanuary 2018| 16  \nFebruary 2018| 11  \nMarch 2018| 20  \nApril 2018| 13  \nMay 2018| 17  \nJune 2018| 8  \nJuly 2018| 29  \nAugust 2018| 19  \nSeptember 2018| 16  \nOctober 2018| 30  \nNovember 2018| 36  \nDecember 2018| 30  \nJanuary 2019| 17  \nFebruary 2019| 22  \nMarch 2019| 19  \nApril 2019| 18  \nMay 2019| 20  \nJune 2019| 14  \nJuly 2019| 20  \nAugust 2019| 21  \nSeptember 2019| 33  \nOctober 2019| 41  \nNovember 2019| 25  \nDecember 2019| 30  \nJanuary 2020| 24  \nFebruary 2020| 38  \nMarch 2020| 12  \nApril 2020| 19  \nMay 2020| 14  \nJune 2020| 36  \nJuly 2020| 15  \nAugust 2020| 27  \nSeptember 2020| 33  \nOctober 2020| 35  \nNovember 2020| 22  \nDecember 2020| 28  \nJanuary 2021| 8  \nFebruary 2021| 40  \nMarch 2021| 34  \nApril 2021| 20  \nMay 2021| 19  \nJune 2021| 15  \nJuly 2021| 12  \nAugust 2021| 26  \nSeptember 2021| 25  \nOctober 2021| 26  \nNovember 2021| 25  \nDecember 2021| 12  \nJanuary 2022| 20  \nFebruary 2022| 24  \nMarch 2022| 11  \nApril 2022| 23  \nMay 2022| 18  \nJune 2022| 19  \nJuly 2022| 20  \nAugust 2022| 26  \nSeptember 2022| 37  \nOctober 2022| 41  \nNovember 2022| 25  \nDecember 2022| 12  \nJanuary 2023| 23  \nFebruary 2023| 24  \nMarch 2023| 34  \nApril 2023| 33  \nMay 2023| 32  \nJune 2023| 32  \nJuly 2023| 33  \nAugust 2023| 46  \nSeptember 2023| 33  \nOctober 2023| 23  \nNovember 2023| 30  \nDecember 2023| 21  \nJanuary 2024| 19  \nFebruary 2024| 21  \nMarch 2024| 35  \nApril 2024| 5  \n  \nCitations\n\n32\n\nCITATIONS\n\n32 Total citations\n\n8 Recent citations\n\n3.65 Field Citation Ratio\n\nn/a Relative Citation Ratio\n\nPowered by Dimensions\n\n29 Web of Science\n\nAltmetrics\n\n\u00d7\n\n### Email alerts\n\nArticle activity alert\n\nAdvance article alerts\n\nNew issue alert\n\nIn progress issue alert\n\nSubject alert\n\nReceive exclusive offers and updates from Oxford Academic\n\n### Astrophysics Data System\n\nADS Abstract\n\n### Citing articles via\n\nWeb of Science (29)\n\nGoogle Scholar\n\n  * ### Latest\n\n  * ### Most Read\n\n  * ### Most Cited\n\nAdjoint sensitivity kernels for free oscillation spectra\n\nSimultaneous Magnitude and Slip Distribution Characterization from High Rate\nGNSS using Deep Learning: Case Studies of the 2021 M_w 7.4 Maduo and 2023\nTurkey Doublet Events\n\nSeamount detection using SWOT-derived vertical gravity gradient: advancements\nand challenges\n\n2D probabilistic inversion of MT data and uncertainty quantification using the\nHamiltonian Monte Carlo method\n\n\u201cThe Last Gasp of the Rogaland Igneous Province, Norway: A Paleopole for the\n920 Ma Tellnes Intrusion\u201d\n\nMore from Oxford Academic\n\nEarth Sciences and Geography\n\nGeophysics\n\nScience and Mathematics\n\nBooks\n\nJournals\n\nAdvertisement\n\nAdvertisement\n\nAdvertisement\n\n  * About Geophysical Journal International\n  * Editorial Board\n  * Author Guidelines\n  * Contact Us\n  * Facebook\n\n  * Twitter\n  * YouTube\n  * LinkedIn\n  * Purchase\n  * Recommend to your Library\n\n  * Advertising and Corporate Services\n  * Journals Career Network\n\n  * Online ISSN 1365-246X\n  * Print ISSN 0956-540X\n  * Copyright \u00a9 2024 The Royal Astronomical Society\n\n  * About Oxford Academic\n  * Publish journals with us\n  * University press partners\n  * What we publish\n  * New features\n\n  * Authoring\n  * Open access\n  * Purchasing\n  * Institutional account management\n  * Rights and permissions\n\n  * Get help with access\n  * Accessibility\n  * Contact us\n  * Advertising\n  * Media enquiries\n\n  * Oxford University Press\n  * News\n  * Oxford Languages\n  * University of Oxford\n\nOxford University Press is a department of the University of Oxford. It\nfurthers the University's objective of excellence in research, scholarship,\nand education by publishing worldwide\n\n  * Copyright \u00a9 2024 Oxford University Press\n  * Cookie policy\n  * Privacy policy\n  * Legal notice\n\nClose\n\nClose\n\n##### This Feature Is Available To Subscribers Only\n\nSign In or Create an Account\n\nClose\n\nThis PDF is available to Subscribers Only\n\nView Article Abstract & Purchase Options\n\nFor full access to this pdf, sign in to an existing account, or purchase an\nannual subscription.\n\nClose\n\nManage Cookies\n\nWhen you visit web sites, they may store or retrieve data in your web browser.\nThis storage is often necessary for basic functionality of the web site or the\nstorage may be used for the purposes of marketing, analytics, and\npersonalization of the web site such as storing your preferences.\n\nPowered by Privado\n\nOxford University Press uses cookies to enhance your experience on our\nwebsite. By selecting \u2018accept all\u2019 you are agreeing to our use of cookies. You\ncan change your cookie settings at any time. More information can be found in\nour Cookie Policy.\n\n", "frontpage": false}

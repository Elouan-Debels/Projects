{"aid": "40006052", "title": "Zero-Trust Architecture with Caddy", "url": "https://www.caffeinatedwonders.com/2024/02/05/zero-trust-caddy/", "domain": "caffeinatedwonders.com", "votes": 2, "user": "ingve", "posted_at": "2024-04-11 19:46:46", "comments": 0, "source_title": "Zero-Trust Architecture with Caddy", "source_text": "Zero-Trust Architecture with Caddy | Caffeinated Wonders\n\n# Zero-Trust Architecture with Caddy\n\nFebruary 5, 2024\n\nMohammed Al-Sahaf\n\nNote: This post is an elaboration on the content of the GitHub repository\nZero-Trust, TLS Everywhere Caddy Deployment.\n\nFor the sake of fun and research, I decided to attempt building a zero-trust\ndeployment of Caddy on DigitalOcean. It is sensible to assume this is doable\ngiven Caddy\u2019s PKI and TLS management capabilities. It also allows us to peek\ninto potential gaps in Caddy if it were to be used to deploy zero-trust\ninfrastructure.\n\n\u26a0\ufe0f The project aims to develop a Terraform deployment where the drafted files\nare likely to be templates for an HCL configuration file, thus the variables\n(template placeholders) are likely to be HCL variables interpolated rather\nthan environment variables to be interpreted by Caddy. In other words, the\nprior note explains the reason for using ${variable_name} rather than\n{$VARIABLE_NAME}. \u26a0\ufe0f\n\ni\ufe0f Throughout this article, you will come across a collection of placeholders\ninterpolated by Terraform that are either defined as variables, come from\nTerraform resources, or come from Terraform data sources. These are the\ndefinitions of the variables defined and used in Terraform:\n\n> base_domain: This is the domain that will be used to deploy the\n> infrastructure, e.g. example.com\n>\n> base_subdomain: This is the sub-domain which each component of the\n> infrastructure is suffixed by. It can be empty or must end with a period .\n>\n> ca_name: This is the name of the CA defined in the pki app of Caddy and will\n> be used to sign the certificates for the infrastructure. In this article,\n> it\u2019s often referred to as internal_acme.\n\nFor the sake of this experiment, the adopted zero-trust definition is the one\npresented in Smallstep\u2019s Practical Zero Trust saying:\n\n> Zero Trust or BeyondProd approaches require authenticated and encrypted\n> communications everywhere. TLS is the cryptographic protocol that powers\n> encryption for all your technologies.\n\nAh, TLS, so Caddy can do it! To distribute TLS certificates for the various\ncomponents in our infrastrcture, we will need a PKI provider. Fortunately,\nCaddy comes with a PKI app that allows it to act as a certificate authority.\nThroughout this tutorial, we will build the configuration files progressively\nto have a grasp on how Caddy works and how to adapt this experiemnt to your\nneeds. This article was not written progressively as I was developing the\ninfrastructure; rather it is developed after the fact by retracing my steps\nand generally avoiding mistakes I made as I was learning.\n\nThe infrastructure developed throughout this article will have:\n\n  * PostgreSQL database cluster acting as shared storage\n  * acme_server: an ACME server acting as the PKI provider for the all nodes in the infrastructure, including itself\n  * upstream_server: an \u201capplication\u201d server, which simply replies with \u201cOK!\u201d for the purpose of this experiment, that is served by the Caddy server over HTTPS whose TLS certificate is issued by the acme_server; it validates requires incoming connections to be verified with mTLS and the certificate of the client TLS to be issued by acme_server\n  * edge_server: the node is the TLS-termination node facing the Internet, and it reverse-proxies the requests to the upstream_server over HTTPS. It procures a certificate from acme_server to use for mTLS with the upstream_server.\n\n## ACME Server, the PKI Provider\n\nThe PKI app of Caddy can be configured in the Caddyfile using the pki global\noption. We will use internal_acme as the referencing name of the internal PKI\nauthority and the user-facing name is Corp ACME Root, and thus the starting\nCaddyfile is:\n\n    \n    \n    1 2 3 4 5 6 7 8 9\n\n|\n\n    \n    \n    { # added to avoid installing the CA into the running system skip_install_trust pki { ca ${ca_name} { name \"Corp ACME Root\" } } }  \n  \n---|---  \n  \nBy default, Caddy uses the file-system as the storage backend for its data.\nThis is not ideal because it is not scalable due to not being distributed. It\nallows for the data to be shared amongst our different infrastructure pieces.\nFor this need, we will use the postgres-storage module (Github Repo) by Cory\nCooper to store the data into a PostgreSQL database. This requires compiling a\ncustom build of Caddy with the module, which can be easily done using xcaddy.\nBuilding the custom Caddy binary is as simple as running the following\ncommand:\n\n    \n    \n    1\n\n|\n\n    \n    \n    xcaddy build --with github.com/yroc92/postgres-storage  \n  \n---|---  \n  \nThe postgres-storage module supports the Caddyfile unmarshalling, so we can\nuse our existing Caddyfile. Since our goal is to have verified TLS everywhere\nin our infrastructure, we will set sslmode to verify-full:\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n\n|\n\n    \n    \n    { # added to avoid installing the CA into the running system; not needed. skip_install_trust pki { ca ${ca_name} { name \"Corp ACME Root\" } } storage postgres { # sslrootcert defaults to \"~/.postgresql/root.crt\", but can be provided # in the connection string. # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING sslmode \"verify-full\" connection_string \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" } }  \n  \n---|---  \n  \nWe will add to the PKI provider an ACME server capability to issue\ncertificates to infrastructure components. The ACME server will only handle\nrequests from within the internal network. The ACME server will be configured\nto use the internal PKI authority we created earlier. We also want to use the\nsame certificate authority to provide the TLS certificate to the ACME server\nitself, so we\u2019ll add tls directive saying exactly that. Also, let\u2019s have the\nadmin endpoint listen on the private IP address of the node. Because the admin\naddress is a not a wild interface, Caddy will check the Host header of the API\nrequests against the admin endpoint and expect them to match the given list in\norigins sub-option in the admin global option in the Caddyfile. Unfortunately,\nthis nuance is not explicitly stated in Caddy documentation, but we are\nremedying this soon. Nonetheless, this instance of Caddy will be reachable by\na domain name whose IP address (A record) is the private IP address of the\ndroplet. We need tell Caddy to expect the defined domain name in origins,\nwhich it will use for checking the Host header.\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30\n\n|\n\n    \n    \n    { admin ${private_ip}:2019 { origins acme.internal.${base_subdomain}${base_domain}:2019 } # added to avoid installing the CA into the running system; not needed. skip_install_trust pki { ca ${ca_name} { name \"Corp ACME Root\" } } storage postgres { # sslrootcert defaults to \"~/.postgresql/root.crt\", but can be provided # in the connection string. # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING sslmode \"verify-full\" connection_string \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" } } acme.internal.${base_subdomain}${base_domain} { tls { issuer internal { ca ${ca_name} } } @internal remote_ip ${ip_range} acme_server @internal { ca ${ca_name} } }  \n  \n---|---  \n  \nThe @internal remote_ip ${ip_range} line is called matcher. It tells Caddy\nthat the acme_server handler should only handle requests that match this\ncondition, i.e. the remote IP address (the connection client) falls within the\ndefined IP CIDR. This sets up the guts of the acme_server node. However, there\nare 2 issues here, and both highlight a gap in Caddy.\n\nThe first issue is a catch-22. Downstream clients will fail to connect to the\nACME server to obtain a certificate because the certificate ACME server\u2019s\ncertificate authority is still not trusted by them (the client). We need to\nobtain the certificate authority certificate and add it to the trusted\ncertificate store of the client. We can tell other Caddy instance to also be\nPKI providers, sharing the same storage to give them access to the defined CA,\nbut it does not feel right because it mixes the roles of the nodes. We can\nalso call the admin endpoint of the acme_server node from the other nodes, but\nthat will be over HTTP and not HTTPS and means there\u2019s a gap of verification\nat that step. In short, certificates of CAs cannot be shared across Caddy\ninstances without either breaking the security model or sharing the\ncertificate through separate channel. I aimed to address this gap in PR #5784.\n\nFor now, the workaround is to download the certificate on the acme_server node\nusing curl and Caddy admin API, then copying the file to the other nodes.\nRemember that I am developing Terraform templates, so the placeholders are for\nHCL to interpolate. The --resolve flag is used because Terraform has not\ncreated the DNS record yet because the droplet provisioning is not complete,\nso we cannot rely on DNS to point to our droplet and Caddy is told to do\nstrict origin checking.\n\n    \n    \n    1 2 3 4 5 6 7\n\n|\n\n    \n    \n    curl \\ --retry 10 \\ --retry-connrefused \\ --retry-delay 0 \\ --resolve acme.internal.${var.base_subdomain}${var.base_domain}:2019:${self.ipv4_address_private} \\ http://acme.internal.${var.base_subdomain}${var.base_domain}:2019/pki/ca/${var.ca_name} \\ | jq -r .root_certificate > /etc/caddy/ca-root.pem  \n  \n---|---  \n  \nThe second issue is the implicit trust in anyone within the network permiter\nto be an ACME client and receive certificates from the acme_server for any\ndomain they want as long as the DNS records for the target domain name is\nreachable from the network to fulfill the challenge. This is a no-bueno. We\nonly want to issue certificates for a particular subdomain of our domain name\nthat identifies it as internal. The smallstep library Caddy uses for ACME\ncapabilities offers the notion of Certificate Issuance Policies to control\ncertificate issuance. This was not extended into Caddy\u2019s usage of the library,\nand I tried to address this in PR #5796. Once merged, we will be able to\ndefine a policy that only allows issuance of certificates for the specified\nsubdomain, e.g. *.internal.${var.base_subdomain}${var.base_domain}. It is for\nthis reason you will notice that every service is configured with the domain\n<label>.internal.${var.base_subdomain}${var.base_domain}. Having the ability\nto configure this policy allows us to piggyback on the ability to update DNS\nrecord as the authorization mechanism to receive certificate. It also allows\nus to limit the scope of a particular ACME server to a particular subdomain,\namongst others.\n\nAnyways, in Terraform, I am using the remote provider to copy the content of\nthe downloaded certificate of the CA into memory, subsequently into other\nnodes and as output.\n\n## The (Mock) Application Server\n\nThe application server does the hard work of responding to the user request by\nexecuting the defined business logic. It may interact with the database to\nfulfill the incoming request. In our use case, the application server will\nsimply answer with \u201cOK!\u201d. It\u2019s called upstream_server because it\u2019s upstream\nfrom the TLS-termination node.\n\nLike the acme_server, the admin endpoint of the application server will be on\nthe private IP address of the droplet and will use PostgreSQL for storage.\nHence, the global options section of the Caddyfile will similar to the\nacme_server node except for the pki configuration:\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12\n\n|\n\n    \n    \n    { admin \"${private_ip}:2019\" { origins app-1.internal.${base_subdomain}${base_domain}:2019 } storage postgres { # sslrootcert defaults to \"~/.postgresql/root.crt\", but can be provided # in the connection string. # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING sslmode \"verify-full\" connection_string \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" } }  \n  \n---|---  \n  \nThe site definition part for this server for this server is rather simple.\nI\u2019ll summarize them in bulletpoints so it is easier to follow:\n\n  * It will declare the domain name app-1.internal.${base_subdomain}${base_domain}\n  * Tell Caddy to use our ACME server (i.e. https://acme.internal.${base_subdomain}${base_domain}/acme/${ca_name}/directory) for the TLS certificate\n\n    * Trust the CA file which we\u2019ve semi-manually copied into the node\n  * Require mTLS with successful verification for the client certificate to have been issued by acme_server\n  * Respond with \u201cOK!\u201d\n\nWe result with a simple Caddyfile\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n\n|\n\n    \n    \n    { admin \"${private_ip}:2019\" { origins app-1.internal.${base_subdomain}${base_domain}:2019 } storage postgres { # sslrootcert defaults to \"~/.postgresql/root.crt\", but can be provided # in the connection string. # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING sslmode \"verify-full\" connection_string \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" } } app-1.internal.${base_subdomain}${base_domain} { tls { client_auth { mode require_and_verify trusted_ca_cert_file /etc/caddy/ca-root.pem } issuer acme { dir https://acme.internal.${base_subdomain}${base_domain}/acme/${ca_name}/directory trusted_roots /etc/caddy/ca-root.pem } } respond \"OK!\" }  \n  \n---|---  \n  \nThere is not much more to it. Of course for this setup to function, there must\nbe a DNS record for app-1.internal.${base_subdomain}${base_domain} pointing to\nthe private IP address of the droplet. It allows this Caddy server to interact\nwith the ACME server to solve the challenge and obtain the certificate.\n\n## The Edge, TLS-Terminator\n\nThe TLS-terminator is the node that terminates public TLS connections. It is\nthe node that is exposed to the outside world. It will be the node that\nreceives the TLS connection from the user, and will forward it to the\napplication server. To communicate with the application server, AKA\nupstream_server, it needs to have a client certifiate issued by acme_server to\nfulfill the mTLS authentication.\n\nUnfortunately, because we have a certificate to procure from a private ACME\nserver and automate without the definition of a website, we have to use JSON\nfor configuration instead of the Caddyfile. This is a very tedious task.\nWhenever I have to use JSON, I start with a Caddyfile that fulfills the basic\nneed, adapt it, clean up the produced JSON if necessary, then add to it the\npieces that are missing. The content of the global options section of the\nCaddyfile resembles the others we have seen so far, in the sense that it\namends the admin endpoint to listen on the private IP address of the droplet,\nsets an expected origin within the internal subdomain, and configures postgres\nas the storage backend. For the site definition, we will have to use dummy\ndomain names instead of the placeholders we have been using so far because the\nadapter is very particular about some of those values as they make a\ndifference in the adaptor branching logic. The site body should merely\nreverse-proxy the requests to the upstream address with HTTPS scheme, give a\ndomain name identifier for Caddy to automate the client-certificate for, and\ndefine the trusted certificate authority that has issued the certificate for\nthe upstream (application) server, i.e. acme_server. Here is the Caddyfile we\nare starting with:\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n\n|\n\n    \n    \n    { admin \"${private_ip}:2019\" { origins edge.internal.${base_subdomain}${base_domain}:2019 } storage postgres { # sslrootcert defaults to \"~/.postgresql/root.crt\", but can be provided # in the connection string. # https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING sslmode \"verify-full\" connection_string \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" } } example.com { reverse_proxy https://app-1.internal { transport http { tls tls_client_auth client-cert.com tls_trusted_ca_certs /etc/caddy/ca-cert.pem } } }  \n  \n---|---  \n  \nNote that to adapt the Caddyfile, your existing Caddy binary must support the\npostgres-storage module. If it doesn\u2019t, you may exclude it from the Caddyfile\nand manually add the storage configuration to the produced JSON, similar to\nwhat we will do for the custom configuration of the tls app. Here\u2019s the JSON\nproduced from adapting the earlier Caddyfile and placing the varibales where\nthey vary:\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63\n\n|\n\n    \n    \n    { \"admin\": { \"listen\": \"${private_ip}:2019\", \"origins\": [ \"edge.internal.${base_subdomain}${base_domain}:2019\" ] }, \"storage\": { \"module\": \"postgres\", \"connection_string\": \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" }, \"apps\": { \"http\": { \"servers\": { \"srv0\": { \"listen\": [ \":443\" ], \"routes\": [ { \"match\": [ { \"host\": [ \"www.${base_subdomain}${base_domain}\" ] } ], \"handle\": [ { \"handler\": \"subroute\", \"routes\": [ { \"handle\": [ { \"handler\": \"reverse_proxy\", \"transport\": { \"protocol\": \"http\", \"tls\": { \"client_certificate_automate\": \"edge.internal.${base_subdomain}${base_domain}\", \"root_ca_pem_files\": [ \"/etc/caddy/ca-cert.pem\" ] } }, \"upstreams\": [ { \"dial\": \"app-1.internal.${base_subdomain}${base_domain}:443\" } ] } ] } ] } ], \"terminal\": true } ] } } } } }  \n  \n---|---  \n  \nTo automate the procurement and management of the client certificate from the\nacme_server, we add configuration for the tls app, inside of which we define\nan object automation with an array of policies inside it. The array contains 1\npolicy for the subject edge.internal.${base_subdomain}${base_domain}. The\nissuer is acme, whose ca URL is\nhttps://acme.internal.${base_subdomain}${base_domain}/acme/${ca_name}/directory\nas we\u2019ve been using earlier. Of course we shouldn\u2019t forget to trust\n/etc/caddy/ca-root.pem, which we copied from acme_server. We arrive to this\nJSON configurtion file:\n\n    \n    \n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92\n\n|\n\n    \n    \n    { \"admin\": { \"listen\": \"${private_ip}:2019\", \"origins\": [ \"edge.internal.${base_subdomain}${base_domain}:2019\" ] }, \"storage\": { \"module\": \"postgres\", \"connection_string\": \"postgres://${db_user}:${db_password}@${db_host}:${db_port}/${db_name}?sslmode=verify-full&sslrootcert=${root_cert}\" }, \"apps\": { \"tls\": { \"automation\": { \"policies\": [ { \"subjects\": [ \"edge.internal.${base_subdomain}${base_domain}\" ], \"issuers\": [ { \"module\": \"acme\", \"ca\": \"https://acme.internal.${base_subdomain}${base_domain}/acme/${ca_name}/directory\", \"trusted_roots_pem_files\": [ \"/etc/caddy/ca-root.pem\" ] } ] } ] } }, \"http\": { \"servers\": { \"srv0\": { \"listen\": [ \":443\" ], \"routes\": [ { \"match\": [ { \"host\": [ \"www.${base_subdomain}${base_domain}\" ] } ], \"handle\": [ { \"handler\": \"subroute\", \"routes\": [ { \"handle\": [ { \"handler\": \"reverse_proxy\", \"headers\": { \"request\": { \"set\": { \"Host\": [ \"{http.reverse_proxy.upstream.host}\" ] } } }, \"transport\": { \"protocol\": \"http\", \"tls\": { \"client_certificate_automate\": \"edge.internal.${base_subdomain}${base_domain}\", \"root_ca_pem_files\": [ \"/etc/caddy/ca-cert.pem\" ] } }, \"upstreams\": [ { \"dial\": \"app-1.internal.${base_subdomain}${base_domain}:443\" } ] } ] } ] } ], \"terminal\": true } ] } } } } }  \n  \n---|---  \n  \nI have injected the header manipulation in reverse-proxy because I am trust\nissues and like to be explicit in this regard. This configuration will start\nby obtaining a certificate for the domain www.${base_subdomain}${base_domain}\nfrom Let\u2019s Encrypt or ZeroSSL, and it will obtain a certificate for the domain\nedge.internal.${base_subdomain}${base_domain} from the ACME CA.\n\n# Conclusion\n\nFor all intents and purposes, the experiment to develop fully authenticated\ninfrastructure with mTLS and Caddy being the PKI provider is successful. Caddy\nis able to facilitate the needs to provide and utilize TLS certificates to\ndeploy zero-trust infrastructure. The experiemnt is also successful in its\npurpose to highlight areas of improvement for Caddy to be better PKI provider\nfor full automation of mTLS deployment.\n\nI opted to exclude the Terraform definitions of the droplets, firewalls,\ndatabase cluster, and DNS record because Terraform is not the focus of this\nwalkthrough. The GitHub repository contains runnable Terraform project of the\ninfrastructure. If you\u2019re interested in seeing the full project, which I have\ndeployed numerous times as I developed this post, visit the GitHub repository,\nplay with the code, and let me know what you think.\n\nNoteworthy theme\n\n|\n\nBuilt with Hugo\n\n", "frontpage": false}

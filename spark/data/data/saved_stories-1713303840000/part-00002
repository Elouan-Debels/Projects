{"aid": "40053489", "title": "The implicit decision theory of non-philosophers", "url": "https://link.springer.com/article/10.1007/s11229-023-04478-8", "domain": "springer.com", "votes": 1, "user": "photonthug", "posted_at": "2024-04-16 15:42:45", "comments": 0, "source_title": "The implicit decision theory of non-philosophers - Synthese", "source_text": "The implicit decision theory of non-philosophers | Synthese\n\nLoading [MathJax]/jax/output/HTML-CSS/config.js\n\nSkip to main content\n\nLog in\n\n## Search\n\n## Navigation\n\n  * Find a journal\n  * Publish with us\n  * Track your research\n\n# The implicit decision theory of non-philosophers\n\n  * Original Research\n  * Open access\n  * Published: 07 February 2024\n\n  * Volume 203, article number 61, (2024)\n  * Cite this article\n\nDownload PDF\n\nYou have full access to this open access article\n\nSynthese Aims and scope Submit manuscript\n\nThe implicit decision theory of non-philosophers\n\nDownload PDF\n\n  * Preston Greene^1,\n  * Andrew J. Latham^2,\n  * Kristie Miller ORCID: orcid.org/0000-0002-5092-8419^3 &\n  * ...\n  * Michael Nielsen^3\n\n  * 787 Accesses\n\n  * Explore all metrics\n\nA Correction to this article was published on 07 March 2024\n\nThis article has been updated\n\n## Abstract\n\nThis paper empirically investigates whether people\u2019s implicit decision theory\nis more like causal decision theory or more like a non-causal decision theory\n(such as evidential decision theory). We also aim to determine whether\nimplicit causalists, without prompting and without prior education, make a\ndistinction that is crucial to causal decision theorists: preferring something\nas a news item and preferring it as an object of choice. Finally, we\ninvestigate whether differences in people\u2019s implicit decision theory correlate\nwith differences in their level of future bias: the preference for positively\nvalenced events to be located in the future and not the past, and negatively\nvalenced events to be located in the past and not the future. We find that\npeople are overwhelmingly non-causalists. We also find that implicit\ncausalists do not make the distinction between news items and objects of\nchoice, and that there is little to no correlation between people\u2019s future\nbias and their implicit decision theory. We end by discussing the\nphilosophical upshots of this work.\n\n### Similar content being viewed by others\n\n### What Is the Function of Confirmation Bias?\n\nArticle Open access 20 April 2020\n\nUwe Peters\n\n### The Relationship Between Social Media Use and Beliefs in Conspiracy\nTheories and Misinformation\n\nArticle 07 July 2021\n\nAdam M. Enders, Joseph E. Uscinski, ... Justin Stoler\n\n### The pragmatic turn in the scientific realism debate\n\nArticle Open access 29 March 2024\n\nSandy C. Boucher & Curtis Forbes\n\nUse our pre-submission checklist\n\nAvoid common mistakes on your manuscript.\n\n## 1 Introduction\n\nNewcomb\u2019s problem is one of the most widely discussed cases in decision\ntheory. Here is a standard formulation:\n\n> You must choose between taking (and keeping the contents of) (i) an opaque\n> box now facing you or (ii) that same opaque box and a transparent box next\n> to it containing $1000. Yesterday, a being with an excellent track record of\n> predicting human behaviour in this situation made a prediction about your\n> choice. If it predicted that you would take only the opaque box (\u2018one-\n> boxing\u2019), it placed $1M in the opaque box. If it predicted that you would\n> take both (\u2018two-boxing\u2019), it put nothing in the opaque box. (Ahmed, 2018, p.\n> 1)\n\nIn Newcomb\u2019s problem, the available acts are one- or two-boxing, and the\nstates are that the $1 Million is present or it is not. There is an evidential\ndependence between $1 Million being present and one-boxing, but there is no\ncausal dependence. While some (e.g., evidential decision theorists) see the\nevidential dependence between the state and the act as decision-relevant and\nthus think that one-boxing is rational,^Footnote 1 others (e.g., causal\ndecision theorists) do not see this dependency as decision-relevant. They\nfocus their attention on the causal dependencies alone, and from that focus,\nthey see no good reason to one-box: the causal effect of one-boxing is merely\nto leave one a thousand dollars poorer than if one had two-boxed.\n\nOur aim in this paper is to probe non-philosophers\u2019 judgements about Newcomb-\nstyle cases. Bourget and Chalmers (2020) recently probed philosophers\u2019\njudgements about the Newcomb case. They found that ~ 31% of philosophers\naccept or lean towards one-boxing, while ~ 40% accept or lean towards two-\nboxing (with the remaining ~ 30% being unsure, unfamiliar with the issue, or\nhaving some other view).\n\nThere is also some much older research that looks at non-philosophers\u2019\njudgements regarding Newcomb cases. In 1974, after discussion of the Newcomb\nproblem in the Scientific American by Martin Gardner, readers were invited to\nsend in their opinion, and 652 responded. Of these, 483 (i.e. ~ 74%) said that\nthey would one-box, while the remaining said they would two-box. There are\nseveral notable features of this data. First, the article included discussion\nof an argument for one-boxing and an argument for two-boxing. Thus, in\nreporting their choice, respondents were in part directly reporting which of\nthe two arguments they found most persuasive. Second, this was not a\ncontrolled study, and respondents were surely not a random sample. In 1979,\nMacCrimmon and Larson ran the first controlled study. They found that of 19\nparticipants, all but two would one-box (i.e., ~ 89.5%). This study, however,\nhas several notable drawbacks. First, it used a very small sample size, and\nsecond, it was unclear whether participants understood that there was no\ncausal relationship between their choice and the prediction. Specifically, it\nseemed that participants might have supposed that there was some kind of\nbackwards causation between choice and prior prediction. Considering this, in\n1992 Shafir and Tversky ran a follow-up study that aimed to present\nparticipants with a version of the Newcomb Problem that more clearly did not\ninvolve backwards causation. To do this, in their vignette the role of the\npredictor was played by a fictitious computer program that predicted\nparticipant\u2019s choices based on a previously established database. They found\nthat of 40 participants, 14 (35%) chose both boxes, while the remaining 65%\nchose one box.\n\nShafir and Tversky claimed that in the absence of backwards causation, there\nare no grounds to one-box, and they hypothesised that what explains people\u2019s\nchoice is quasi-magical thinking. They take quasi-magical thinking to be\nthinking in which people act as though they have the magical beliefs in\nquestion, even though they do not explicitly endorse these beliefs. Thus,\nShafir and Tversky concluded, on the basis of their empirical data, that 65%\nof people had these quasi-magical beliefs.\n\nIn all, we see that across the three sets of data, ~ 89.5%, ~ 74%, and ~ 65%\nof participants chose to one-box. While in all these cases this is a majority,\nthere are substantial differences in these results. This may in part be the\nresult of (a) different samples and sample sizes, (b) different vignettes\nwhich better control, or not, for beliefs about backwards causation between\nchoice and prediction, and (c) differences in whether the arguments for each\nposition are mentioned or not. We take it to be of interest to run a new\nversion of the Newcomb problem, which, like that of Shafir and Tversky,\nattempts to better rule out the possibility of backwards causation between\nchoice and prediction, but which has larger sample sizes than the previous\nstudies and does not make any mention of the arguments in favour of each\nchoice. We also take it to be desirable to run a study that includes\ncomprehension questions to ensure that participants understand what they are\nbeing asked.\n\nGiven the results of these previous studies, we predict that non-philosophers\nare more likely to be one-boxers. Thus, our first hypothesis is:\n\nH1: A majority of people will one-box.\n\nIt is natural to wonder, in addition, whether two-boxers (even if it turns out\nthat they are in the minority) draw a conceptual distinction between news-item\npreferences and choice preferences. Consider that we can ask someone what they\ndecide in a Newcomb-style case. This is to ask them for their choice\npreference. But we can also ask them about their news-item preference. Suppose\nyou wake up after a Newcomb-type decision but cannot remember what choice you\nmade. What do you prefer to learn that you chose? Even if you are a two-boxer,\nyou may well prefer to learn that you one-boxed. For preferring to learn that\nyou one-boxed is preferring that you are a certain kind of person, namely, a\nperson who is now almost certainly rich! (More on this below.) Thus,\nreflective two-boxers will treat choice preferences and news-item preferences\ndifferently. Could this help explain why two-boxers choose as they do?\n\nThe distinction between news-item and choice preferences is critical for\ncausal decision theorists because it helps them explain why they think two-\nboxing is rational even though it would be good news to learn that one is a\none-boxer. This is because when making decisions, causal decision theorists\nonly aim to causally promote good outcomes, and, unlike evidential decision\ntheorists, they do not aim to create good news. More specifically, the crucial\ndifference between causal decision theory and evidential decision theory is\nfound in their views on which types of dependencies between states of the\nworld and acts are decision-relevant. Evidential decision theory views all\nevidential dependencies between states and acts as relevant to evaluating the\nrationality of the agent\u2019s decision, whereas causal decision theory takes a\nmore restricted view. Causal decision theory views only causal dependencies\nbetween states and acts as decision-relevant. Since causal dependencies are\nalso evidential dependencies (if A causally promotes B, then A also provides\nevidence for B), causal decision theory claims that only a subset of the\nevidential dependencies is decision-relevant. This subset is captured by the\nagent\u2019s causal dependency hypothesis. A causal dependency hypothesis picks out\nthe dependencies that are causal.\n\nEvidential decision theorists, like Jeffrey (1965), do not distinguish between\nthe \u201cnews value\u201d of an act and its value as an object of choice. As Jeffrey\n(1965, pp. 73\u201374) writes, \u201cIf the agent is deliberating about performing act A\nor act B, and if AB is impossible, there is no effective difference between\nasking whether he prefers A to B as a news item or as an act, for he makes the\nnews.\u201d In contrast, causal decision theorists, like Joyce (1999), believe that\nit is crucial to distinguish between the news value of acts and their value as\nobjects of choice. Joyce calls the news value of an act its \u201causpiciousness\u201d\nand its value as an object of choice its \u201cefficacy.\u201d According to causal\ndecision theorists like Joyce, only efficacy matters when it comes to choosing\nan act, though auspiciousness plays a role in evaluating how desirable an act\nis.\n\nJoyce (1999, pp. 151\u2013154) devotes several pages to explaining this distinction\nthrough an imagined dialogue between a causal decision theorist and a one-\nboxer. Joyce\u2019s protagonist explains: It would have been \u201cbetter for me\u201d to be\nthe one-boxing type, but that gives me no reason to one-box when actually\nfaced with the decision. Joyce (1999, p. 154) concludes:\n\n> When [the causal decision theorist] wishes she would refuse the extra $1,000\n> she is wishing for good news about herself, and when she decides not to take\n> it she is deciding on the basis of efficacy. There is nothing wrong with\n> simultaneously evaluating acts in both these ways. It should not be any part\n> of causal decision theory to deny that acts have auspiciousness values or\n> that these play a central role in our thinking about the desirability of\n> prospects. Quite to the contrary, it turns out to be quite useful for causal\n> decision theorists to have news values around since they help to explain why\n> people so often feel \u201ctorn\u201d when thinking about what to do in Newcomb-type\n> problems. The deliberative tension is the result of auspiciousness pulling\n> one way and efficacy pulling the other. The only thing we causal decision\n> theorists are committed to is that efficacy should always win out in this\n> tug-of-war when the issue is one of deciding how to act.^Footnote 2\n\nAn implication of Joyce\u2019s discussion\u2014and, indeed, a suggestion made by causal\ndecision theorists more generally\u2014is that two-boxers choose the way they do\npartly because they comprehend the distinction between news-item preferences\nand choice preferences. The distinction allows two-boxers like Joyce to\nacknowledge that one-boxing is desirable insofar as they\u2019d prefer to learn\nthat they are one-boxers. It is thus natural to wonder whether non-philosopher\ntwo-boxers make this distinction. In short, does seeing the difference between\nnews-item preferences and choice preferences help explain why some people are\ntwo-boxers? Hence, we introduce the following exploratory hypothesis:\n\nH2: People who choose to two-box will prefer to learn that they had one-boxed\n(i.e., there will be a difference between two-boxers\u2019 choice preferences and\ntheir news-item preferences in response to our Newcomb vignette).\n\n## 2 Decision and future bias\n\nPeople are sometimes sensitive not only to the relative values and\nprobabilities of events, but also to whether the events are in the future or\nthe past. Most important for the purposes of this paper is the fact that, all\nelse being equal, many people prefer positively valenced events to be located\nin the future rather than the past, and negatively valenced events to be\nlocated in the past rather than the future (Greene et al., 2021a). This\npreference is known as future bias.^Footnote 3\n\nOver the last few years, we have come to learn a good deal about future-biased\npreferences. We know not only that people have such preferences, but also that\nthey are often strong. People\u2019s preference for positive events to be in the\nfuture persists even when the future positive event is of less value than the\npast event (Greene et al., 2022). The same is true, mutatis mutandis, of\nnegative events. One study found that people prefer ten units of pain in the\npast to a single unit of pain in the future (Greene et al., 2021b) while\nanother found that people prefer one unit of pleasure in the future, to two in\nthe past (Greene et al., 2022). Having said that, results here have been\nmixed. Lee, Hoerl, Burns, Fernandes, O\u2019Connor and McCormack (2020 asked both\nchildren and adults whether they would prefer to be someone who experienced a\npleasurable or painful state of affairs in the past or someone who will have\nthat same experience in the future. They found that when the experience is\nequally painful or pleasurable, people prefer to be someone with pain in the\npast and pleasure in the future. However, when the amount of pleasure or pain\nin the past would be greater, this preference was abandoned by a majority of\nchildren, and roughly half of adults.^Footnote 4\n\nAt the very least, we can say that many people prefer that, overall, from a\ntime-neutral perspective, they are worse off. There are also various arguments\nthat future bias can influence choice preferences, such as when future-biased\nagents are also risk averse (Dougherty, 2011), regret averse (Greene &\nSullivan, 2015), or evidential decision theorists (Tarsney, 2017).\n\nOf particular interest to us is the way that future bias may interact with\nchoice preferences in the standard Newcomb case. According to evidential\ndecision theory, there is sometimes a decision-relevant dependency between an\nact and a past state of the world. For example, consider the standard Newcomb\nproblem introduced above. Evidential decision theorists point out that one-\nboxing is evidence that a prediction has been made in the past, and they claim\nthat this evidence is relevant in deciding what to do. In contrast, causal\ndecision theorists claim that the decision-relevant dependencies are always\nbetween acts and future states (the possibility of backwards-causation aside).\nCausal decision theorists do not care about dependencies between acts and past\nstates, because the past cannot be causally influenced. Thus, when deciding\nwhat to do, evidentialists will sometimes consider how choices bear on past\nevents, whereas causalists will only consider how choices bear on future\nevents.\n\nSince two-boxing is associated with causal decision theory and one-boxing\nboxing is associated with evidential decision theory, we might hypothesize\nthat two-boxers will display greater levels of future bias than one-boxers.\nTwo-boxers often point out that whether one has been allocated a million\ndollars has already occurred and cannot be causally influenced, and is thus an\nirrelevant consideration for decision making. In this way, their argument\nbears a similarity to that of philosophers who draw a connection between\nfuture bias and the causal inaccessibility of the past. Some philosophers have\nargued in support of future bias by appealing to the idea that the quality of\npast states is irrelevant because they are \u2018over and done with\u2019 (Craig, 1999;\nPearson, 2018; Prior, 1959; Schlesinger, 1976), while others have argued that\nthis characteristic of past states of affairs explains why we are future\nbiased, even though it does not rationalise our having that preference\n(Horwich, 1987, pp. 194\u2013196, and developed by Maclaurin and Dyke, 2002 and\nSuhler and Callender, 2012).\n\nThose who think that the fact that past states of affairs are causally\ninaccessible explains why we are future biased hold that we attach less\nevaluative weight to past events because there is nothing that we can do to\naffect the past, which means that past events cannot count for, or against,\npresent choices in the way that potential future events can. This has become\nknown as the practical irrelevance explanation (Latham et al., 2020).^Footnote\n5\n\nBy contrast, philosophers who defend the rationality of future bias often\npoint to a somewhat different respect in which states of affairs are \u2018over and\ndone with\u2019: namely the sense in which we are moving through time from the past\ntoward the future, and therefore past experiences lie \u2018behind us\u2019 while future\nones lie \u2018ahead of us\u2019. This explanation has become known as the temporal\nmetaphysics explanation since it connects the presence of temporal\nmetaphysical facts\u2014irreducibly tensed facts about which states of affairs are\nobjectively past, present, and future\u2014to the presence of future bias (Latham\net al., 2020, 2021, 2022).\n\nThis explanation, in turn, is often connected to the presence of tensed\nemotions, which are emotions that are differentially elicited depending on\nwhere in time a state of affairs is represented as being located. For\ninstance, we anticipate future states of affairs, not past ones; we regret\npast states of affairs, not future ones, and we feel a certain sort of\ndistinctive relief that certain negative states of affairs are \u2018over and done\nwith\u2019 only when they are past, and not when they are future. This sort of\nrelief is what Hoerl (2015) calls temporal relief. The idea, then, is that it\nis because past states of affairs are, metaphysically speaking, \u2018over and done\nwith\u2019, that we experience temporal relief and associated tensed emotions, and\nthat it is because we experience such emotions that we are future biased\n(Craig, 1999; Pearson, 2018; Prior, 1959; Schlesinger, 1976).^Footnote 6\n\nIf the practical irrelevance explanation is true, then we might find that two-\nboxers are more likely to be future biased than are one-boxers. By contrast,\nif the temporal metaphysics explanation is correct, then we would have little\nreason to make this prediction. Since there is some evidence in favour of this\nexplanation (Latham et al., 2020) and little evidence in favour of the\ntemporal metaphysics explanation (Latham et al., 2021, 2022) our third\nhypothesis was as follows:\n\nH3: More two-boxers will be future biased than one-boxers.\n\nIf this hypothesis is vindicated, it could provide additional insight into how\npeople make decisions. Just as H2 probes whether two-boxing is correlated with\na recognition of the distinction between news-item preferences and choice\npreferences, H3 probes whether two-boxing is correlated with future bias. In\nshort, does future bias help explain why some people are two-boxers?\n\nIn what follows we report the methodology and results of the two experiments\nthat we ran. The experiments are very similar and differ only in two respects.\nFirst, our first experiment simply talks about a predictor making a prediction\nabout what will occur, but does not specify how the predictor does so, leaving\nopen that perhaps the predictor has information about the future via backwards\ncausation. Second, our first experiment used only two comprehension questions\nrather than four.\n\nIn Sect. 3, we outline the methodology of these two experiments and present\ntheir results. In Sect. 4, we consider the upshot of those results for\ntheorising about both decision theory and future bias.\n\n## 3 Methodology and results\n\n### 3.1 Experiment 1 methodology\n\n#### 3.1.1 Participants\n\n343 people participated in the study. Participants were U.S. residents,\nrecruited and tested online using Amazon Mechanical Turk, and compensated $1\nfor their time. Participants had a HIT (task) approval rate of at least 95%\nand had at least 1000 HITs (tasks) approved. This means that all our\nparticipants had already successfully completed at least 1000 other tasks and\nreceived at least a 95% approval rating on these tasks. 244 participants had\nto be excluded for failing to follow task instructions and attention checks,\nor for failing to correctly answer all comprehension questions for the Newcomb\nvignette and the future-bias vignette. The remaining sample was composed of 99\nparticipants (48 female; aged 21\u201369 mean age 41.03 (SD = 11.49)). Ethics\napproval for these studies was obtained from the University of Sydney Human\nResearch Ethics Committee. Informed consent was obtained from all participants\nprior to testing. The survey was conducted online using Qualtrics.\n\n#### 3.1.2 Materials and procedure\n\nParticipants saw one of two vignettes in random order. A Newcomb vignette\n(below) modelled after Joyce\u2019s (1999, pp. 146\u2013147) presentation,^Footnote 7\nand a future-bias vignette, which will be presented shortly, and which is\neither positive or negatively valenced.\n\nAfter reading the vignette, participants responded to two comprehension\nquestions in random order. \u201cIf you refuse the $1000 dollars and the predictor\npredicted that you would refuse the $1000, then you will receive\u201d. To which\nthey could respond:\n\n  1. (a)\n\n$ 1 million\n\n  2. (b)\n\n$1000\n\n  3. (c)\n\nNothing\n\n  4. (d)\n\n$1.01 million\n\nAnd \u201cIf you take the $1000 dollars and the predictor predicted that you would\ntake the $1000, then you will receive\u201d. To which they could respond:\n\n  1. (a)\n\n$ 1 million\n\n  2. (b)\n\n$1000\n\n  3. (c)\n\nNothing\n\n  4. (d)\n\n$1.01 million\n\nParticipants were then asked: \u201cWhat do you do?\u201d. To which they could respond:\n\n  1. (a)\n\nTake the thousand dollars.\n\n  2. (b)\n\nRefuse the thousand dollars.\n\nParticipants then read the following text: \u201cYou wake up the morning after a\nhard night on the town, and for a moment you cannot remember what decision you\nmade.\u201d\n\nThey were then asked: \u201cWhat would you prefer to learn that you had done?\u201d To\nwhich they could respond:\n\n  1. (a)\n\nTake the thousand dollars.\n\n  2. (b)\n\nRefuse the thousand dollars.\n\nThe other vignette was the future-bias vignette, which was either positively\nor negatively valenced. Since the positive and negative vignettes differ only\nminimally, we present them together below.\n\nAfter reading the vignette, participants responded to four comprehension\nquestions in random order. \u201cIn order to remain disease free, you must take the\npill\u201d. To which they could respond:\n\n  1. (a)\n\nAt some point during the 12-month period after the treatment\n\n  2. (b)\n\nThe week after treatment\n\n  3. (c)\n\nTwice in six months\n\n  4. (d)\n\nNot more than 6 months after treatment\n\n\u201cIf you took the pill in the previous 6 months, then\u201d. To which they could\nrespond:\n\n  1. (a)\n\nThe pill caused three days of pain\n\n  2. (b)\n\nThe pill caused three days of pleasure\n\n  3. (c)\n\nThe pill caused one day of pain\n\n  4. (d)\n\nThe pill caused one day of pleasure\n\n\u201cIf you will take the pill in the next 6 months then\u201d. To which they could\nrespond:\n\n  1. (a)\n\nThe pill will cause three days of pain\n\n  2. (b)\n\nThe pill will cause three days of pleasure\n\n  3. (c)\n\nThe pill will cause one day of pain\n\n  4. (d)\n\nThe pill will cause one day of pleasure.\n\nAnd \u201cWhen you awake in the morning\u201d. To which they could respond:\n\n  1. (a)\n\nYou remember that you already took the pill\n\n  2. (b)\n\nYou remember that you need to take the pill\n\n  3. (c)\n\nYou cannot remember whether you took the pill already or not\n\n  4. (d)\n\nYou remember that you are about to take the pill\n\nFinally, participants were asked to \u201cPlease indicate your preference using one\nof the following statements:\n\n  1. (a)\n\nI would prefer to learn that I will take the pill in the next 6 months and did\nnot take it in the last 6 months.\n\n  2. (b)\n\nI would prefer to learn that I took the pill in the last 6 months, and will\nnot take it in the next 6 months.\n\n  3. (c)\n\nI have no preference between these options.\n\n### 3.2 Results\n\nBefore presenting our analysis, we will start by summarising our main findings\nregarding each hypothesis. We first hypothesised that (H1) most people will be\none-boxers. This hypothesis was supported, with the vast majority of people\nchoosing to one-box rather than two-box. Next, we hypothesised (H2) that\npeople who chose to two-box will prefer to learn that they had one-boxed. This\nhypothesis was not supported. People who had chosen to two-box preferred to\nlearn that they had two-boxed (and equally, we found that people who had\nchosen to one-box also preferred to learn that they had one-boxed). There was\nno difference between choice and news-preferences. Finally, we hypothesised\n(H3) that two-boxers will be more future biased than one-boxers. This\nhypothesis was not supported. There was no association between being a two-\nboxer (or not) and future-biased preferences.\n\nTo assess whether most people were one-boxers (H1) we conducted a one-way chi-\nsquare test.^Footnote 8 As predicted, the results of this test showed that the\nmajority of people were one-boxers (84; 84.8%) rather than two-boxers (15;\n15.2%), \u03c7^2(1, N = 99) = 48.091, p < 0.001).\n\nNext, to assess whether people that choose to two-box would prefer to learn\nthat they had one-boxed, we conducted a chi-square test of independence. If\nthere is an association between what people choose and what they prefer to\nlearn, then this test will produce a significant result. The result of this\ntest was significant, \u03c7^2(1, N = 99) = 22.799, p < 0.001, however, the\nassociation was not the one that we predicted. Instead, choosing to two-box\nwas associated with preferring to learn that you had two-boxed. Similarly,\nchoosing to one-box was associated with preferring to learn that you had one-\nboxed (see Table 1 below).\n\nTable 1 People\u2019s choice and news preferences\n\nFull size table\n\nFinally, to assess whether people who choose to two-box are more future biased\nthan people who choose to one-box, we conducted another chi-square test of\nindependence. For the purposes of this analysis, we combined past-biased\npreferences and time-neutral preference into a single new category: non-\nfuture-biased. The result of this test was not significant, \u03c7^2 (1, N = 99) =\n0.101, p = 0.751, which suggests there is no evidence of an association\nbetween people\u2019s decision to one-box or two-box and future-biased preferences\n(see Table 2 below).^Footnote 9\n\nTable 2 People\u2019s decision to one-box or two-box and people\u2019s future-bias\npreferences\n\nFull size table\n\n## 4 Experiment 2 methodology\n\n### 4.1 Participants\n\n320 people participated in the study. Participants were U.S. residents,\nrecruited and tested online using Prolific, and compensated $1.50 for their\ntime. 228 participants had to be excluded for failing to follow task\ninstructions and attention checks, or for failing to correctly answer all four\ncomprehension questions for the Newcomb vignette and all four comprehension\nquestions for the future-bias vignette. The remaining sample was composed of\n92 participants (47 female, 5 trans or non-binary; aged 18\u201369 mean age 36.57\n(SD = 12.95)). Ethics approval for these studies was obtained from the\n[blanked] Human Research Ethics Committee. Informed consent was obtained from\nall participants prior to testing. The survey was conducted online using\nQualtrics.\n\n### 4.2 Materials and procedure\n\nParticipants saw one of two vignettes in random order. A Newcomb vignette\n(below) modelled after Joyce\u2019s (1999, pp. 146\u2013147) presentation, and a future-\nbias vignette, which will be presented shortly, and which is either positively\nor negatively valenced. We have highlighted the portion of the Newcomb\nVignette that is different from the version we ran in Experiment 1.\n\n## 5 Newcomb vignette\n\nYou are on a game show. The host offers you one thousand dollars and you must\nchoose whether to take it or refuse it. If you choose to take it, then you\nwill receive that thousand dollars. However, the show also has a special\n\u2018predicting\u2019 machine. The machine predicts whether you will take or refuse the\nthousand dollars. The machine collects information about you prior to arriving\non the gameshow, and then uses that information to predict what you will do\nwhen you go on the show. The predictor has made 2 million predictions, and it\nhas yet to make an incorrect prediction. It is an extremely reliable\npredictor. The show works like this. Before the show, the predictor made a\nprediction about which choice you would make. If the predictor predicted that\nyou would refuse the thousand dollars, then $1 million was transferred to your\nbank account. If the predictor predicted that you would take the thousand\ndollars, then no money was transferred. You are not allowed to check your bank\naccount before the show starts, so you do not know what the predicting machine\npredicted and thus you do not know whether you have received $1 million or not\nin your bank account.\n\nAfter reading the vignette, participants responded to four comprehension\nquestions in random order:\n\n> If you refuse the $1000 dollars and the predictor predicted that you would\n> take the $1000, then how much money in total will you have made by appearing\n> on the game show\n>\n> If you refuse the $1000 dollars and the predictor predicted that you would\n> refuse the $1000, then how much money in total will you have made by\n> appearing on the game show.\n>\n> If you take the $1000 dollars and the predictor predicted that you would\n> refuse the $1000, then how much money in total will you have made by\n> appearing on the game show.\n>\n> If you take the $1000 dollars and the predictor predicted that you would\n> refuse the $1000, then how much money in total will you have made by\n> appearing on the game show.\n\nIn response to each of these questions participants could respond:\n\n  1. (a)\n\n$ 1 million\n\n  2. (b)\n\n$1000\n\n  3. (c)\n\nNothing\n\n  4. (d)\n\n$1million plus $1000\n\nParticipants were then asked: \u201cWhat do you do?\u201d. To which they could respond:\n\n  1. (a)\n\nTake the thousand dollars.\n\n  2. (b)\n\nRefuse the thousand dollars.\n\nParticipants then read the following text: \u201cYou wake up the morning after a\nhard night on the town, and for a moment you cannot remember what decision you\nmade.\u201d\n\nThey were then asked: \u201cWhat would you prefer to learn that you had done?\u201d To\nwhich they could respond:\n\n  1. (a)\n\nTake the thousand dollars.\n\n  2. (b)\n\nRefuse the thousand dollars.\n\nThe other vignette was the future-bias vignette, which was either positively\nor negatively valenced. Since the positive and negative vignettes differ only\nminimally, we present them together below.\n\nThe future bias vignette and questions were the same as in experiment 1.\n\n### 5.1 Results\n\nBefore presenting our analysis, we will start by summarising our main findings\nregarding each hypothesis. We first hypothesised that (H1) most people will be\none-boxers. This hypothesis was not supported. In fact, we found that most\npeople chose to two-box rather than one-box. Next, we hypothesised (H2) that\npeople who chose to two-box will prefer to learn that they had one-boxed. This\nhypothesis was not supported. People who chose to two-box preferred to learn\nthat they had two-boxed (and equally, people who chose to one-box also\npreferred to learn that they had one-boxed). There was no difference between\nchoice and news-preferences. Finally, we hypothesised (H3) that two-boxers\nwill be more future biased than one-boxers. This hypothesis was not supported.\nThere was no association between being a two-boxer (or not) and future-biased\npreferences.\n\nTo assess whether most people were one-boxers (H1) we conducted a one-way chi-\nsquare test. Contra our prediction, the result of this test showed that most\npeople were two-boxers (61; 66.3%) rather than one-boxers (31; 33.7%), \u03c7^2(1,\nN = 92) = 9.783, p = 0.002).\n\nNext, to assess whether people that choose to two-box would prefer to learn\nthat they had one-boxed, we conducted a chi-square test of independence. If\nthere is an association between what people choose and what they prefer to\nlearn, then this test will produce a significant result. The result of this\ntest was significant, \u03c7^2(1, N = 92) = 68.420, p < 0.001, however, the\nassociation was not the one that we predicted. Instead, choosing to two-box\nwas associated with preferring to learn that you had two-boxed. Similarly,\nchoosing to one-box was associated with preferring to learn that you had one-\nboxed (see Table 3).\n\nTable 3 People\u2019s choice and news preferences\n\nFull size table\n\nFinally, to assess whether people who choose to two-box are more future biased\nthan people who choose to one-box, we conducted another chi-square test of\nindependence. For the purposes of this analysis, we combined past-biased\npreferences and time-neutral preference into a single new category: non-\nfuture-biased. The result of this test was not significant, \u03c7^2 (1, N = 92) =\n0.154, p = 0.694, which suggests there is no evidence of an association\nbetween people\u2019s decision to one-box or two-box and future-biased preferences\n(see Table 4).^Footnote 10\n\nTable 4 People\u2019s decision to one-box or two-box and people\u2019s future-bias\npreferences\n\nFull size table\n\n## 6 Discussion\n\nThere are several notable aspects of our results.\n\nFirst, in our first study we found that a majority (84%) of people were one-\nboxers, while in our second study we found that a majority (66%) were two-\nboxers.\n\nThere were three differences between these two studies. First, the Newcomb\nVignettes were identical except that in the second study we included the\nsentence \u201cThe machine collects information about you prior to arriving on the\ngameshow, and then uses that information to predict what you will do when you\ngo on the show.\u201d Thus, while our first study did not suggest that the\npredictor used information about the future to inform the prediction, our\nsecond study went further in attempting to rule this out. Having said this,\none might still think that even our second vignette is compatible with some\nkind of backward causation.^Footnote 11 For instance, perhaps the information\nthat the machine collects includes \u201cfacts from the future.\u201d On this reading,\nalthough there is no direct backwards causation between your choice and the\nmachine\u2019s prediction, there might be backwards causation involved in producing\nthe information on which the machine\u2019s prediction is based. In other words,\nparticipants might read \u201cThe machine collects information about you prior to\narriving on the gameshow\u201d as \u201cBefore you arrive on the gameshow, the machine\ncollects pre-existing information, caused by future events, about what you\nwill do in the future.\u201d We do not think that this is a particularly natural\nreading and doubt that a significant number of participants understood our\nvignette this way. So, we think that our second experiment goes significantly\nfurther in controlling for the effect of backwards causation than previous\nones, even if it does not entirely rule it out.\n\nSecond, in our first study we presented participants with two rather than four\ncomprehension questions. They were presented only with the questions, \u201cIf you\nrefuse the $1000 dollars and the predictor predicted that you would refuse the\n$1000, then you will receive...\u201d and \u201cIf you take the $1000 dollars and the\npredictor predicted that you would take the $1000, then you will receive...\u201d.\nIn our second study we included the further two comprehension questions\nregarding what would happen if one made a choice which was not the one the\npredictor predicted. This is because it may be that by presenting only these\ntwo comprehension questions, we primed participants to choose a one-boxing\noption over a two-boxing option. Third, in this study we used Prolific as a\nplatform, whereas in our first study we used MTurk.\n\nThese three small differences made a huge difference to the results. We think\nthis suggests two things. First, it suggests that more people are two-boxers\nthan was previously supposed once we better control for relevant factors.\nSecond, it suggests that how people respond to the Newcomb problem is very\nsensitive to its presentation, and to which factors are salient in making the\ndecision.\n\nOur results show that under conditions in which backwards causation is better\ncontrolled for, and in which all four outcomes are made salient, a majority of\npeople choose to two-box. This suggests that the extent to which it has been\nassumed that people are \u2018naturally\u2019 one-boxers has been unwarranted. We return\nto this idea shortly.\n\nHaving said this, we also think that the totality of results of empirical work\nin this area show that people\u2019s decision in Newcomb cases is much more\nsensitive to the presentation of the case than one might have expected. The\ndifference in results between our current study and prior studies is extreme.\nIndeed, the difference between our results across our two studies is very\nlarge. The extra sentence added to the vignette in the second study to better\ncontrol for backwards causation between choice and prediction might play some\nrole in altering the results. However, given that Shafir and Tversky also\nincluded material in the vignette that was very similar to the sentences we\nadded, but still found that a majority of people chose to one-box, we are\ninclined to the view that the presentation of all four outcomes, via the\ncomprehension questions, is the larger factor in explaining why in our second\nstudy we found that a majority of people chose to two-box.\n\nConsider our first study, which presented only two comprehension questions. By\ndoing so we draw attention to the outcomes in which the predictor is correct.\nSo, presenting only these questions may have primed people to choose to one-\nbox by making salient only those outcomes. We think it plausible that the\nresults of the other earlier studies might also be partly explained by the\ndifferential salience of the outcomes. Those studies did not include\ncomprehension questions. However, it is plausible that participants tend to\nfocus almost exclusively on the two outcomes in which the predictor predicts\ncorrectly, given that they are told that the predictor almost always predicts\ncorrectly. By including four comprehension questions in our second study, we\nmade salient to participants the two outcomes in which the predictor is\nincorrect in their prediction, something that we take was not salient in any\nof the previous experiments. Drawing attention to the fact that the predictor\ncan be incorrect, and what would happen if that were so, makes salient the\nfact that the money is now either in the opaque box (or in your account) or\nnot, regardless of what you now choose. While Shafir and Tversky\u2019s study (and\nour second study) do better at ruling out backwards causation, only our second\nstudy draws attention to why it is that the absence of backwards causation\nmatters: namely the fact that whether the money is there or not does not\ncausally depend on what you choose.\n\nIn all, we think that these results jointly tend to suggest that non-\nphilosophers\u2019 one-boxing intuitions about the Newcomb case are primarily\ndriven by the, likely tacit, idea that the location of the money causally\ndepends on the choice made. Shafir and Tversky, recall, think that people\nchoose to one-box because they are engaged in quasi-magical thinking. We see\nno reason to think that people explicitly endorse quasi-magical thinking.\nRather, we suspect that people probably tacitly employ a heuristic according\nto which if an extremely strong correlation obtains between x and y, then x\nand y are taken to be causally connected. In such cases people may not\nexplicitly token a belief that there is a causal relation present, but act and\nchoose as though this is the case. If that is right, then even if a vignette\nmanaged to completely rule out backwards causation in the description of the\nNewcomb case, because it is a case of extremely strong correlation people may\nstill act and choose as though there is a causal connection present, thus\nexplaining why they one-box. By drawing attention to the outcomes in which the\npredictor is wrong, however, our second study undermined the use of that\nheuristic by making clear that the location of the money is not causally\ndependent on choice. In those conditions, with this heuristic removed, people\ntend to two-box.\n\nIf this is right, then the totality of results would suggest that it is much\nmore difficult than previously assumed to design studies that test non-\nphilosophers\u2019 intuitions about the Newcomb case under the assumption that\nthere is no causal dependence between the location of the money and\nparticipant\u2019s choice. However, the more that this can be done, the more likely\nnon-philosophers are to be two-boxers.\n\nAt this point we want to return to the question of how reflecting on these\nresults is relevant to theorising about decision theory.\n\nThere are three ways our results could potentially be put to use in this\nregard. First, they could be used to respond to an argument from the\ndescriptive facts regarding people\u2019s tendency to one\u2013box, to a normative claim\nregarding which decision theory is the correct one. Here is a stab at how that\nargument might go.\n\n### 6.1 The theory choice argument\n\n  1. 1.\n\nChoosing to one-box reveals an evidential decision theory intuition.\n\n  2. 2.\n\nIf most people have a particular decision theory intuition, then that is a\nreason to adopt a normative decision theory that vindicates that intuition.\n\n  3. 3.\n\nMost people choose to one-box.\n\n  4. 4.\n\nTherefore, most people have an evidential decision theory intuition (from 1,\n3)\n\n  5. 5.\n\nTherefore, we have a reason to adopt evidential decision theory (from 2, 4).\n\nConsider (1). You might think that choosing to one-box just manifests an\nevidential decision theory intuition. Indeed, not only have most\nevidentialists accepted this, but so have some causal decision theorists\n(Gibbard and Harper, 1978, p. 183 and Joyce, 1999, p. 154). Of course, one\nmight reject (1). First, there are other normative theories that vindicate\none-boxing.^Footnote 12 Second, Ninan (2014) argues that the fact that people\nare drawn to one-boxing does not show that they have evidential decision\ntheory intuitions. First, he argues that this cannot be so, since in so-called\nmedical Newcomb cases we no longer have the same intuitions even though the\ncases are structurally similar with respect to evidential and causal factors.\nThis is taken to show that our intuitions in the original Newcomb case are not\nreally evidential intuitions at all. Second, Ninan argues that we can explain\npeople\u2019s tendency to one-box without supposing that they have evidential\nintuitions. His idea is that faced with the Newcomb problem, anyone ought to\nhave some, at least small, credence in the hypothesis that their choice will\nhave a causal effect on the contents of the boxes. And if people do give some\nsuch small credence, then causal decision theory tells them that they should\none-box.\n\nNext, consider (2). Various philosophers working in decision theory have\naccepted something like (2). They hold that intuitions about Newcomb\u2019s\nproblem\u2014to wit, the sorts of considerations we adumbrated earlier with respect\nto the money either being or failing to be, in the opaque box\u2014have been taken\nto motivate causal decision theory. Nozick (1993, pp. 41\u201350) goes further, and\nargues that we should incorporate both causal and evidential intuitions into a\nsingle decision theory, in part based on the idea that Newcomb\u2019s problem\nelicits both sets of intuitions. If that\u2019s right, then we have reason to\naccept (2).\n\nOf course, one might resist (2) on the grounds that intuition is not a good\nguide to normative theorising either (a) in general or (b) at least when it\ncomes to theorising about decision theory. For one might be inclined to say\nthat intuitions about decision theory itself are likely to be of little value\nsince there is good evidence that, across various domains of decision-making,\npeople are systematically irrational (see Kahneman, 2011 for a good summary).\nIt may be, then, that our intuitions about decision making are a poor guide to\nany such normative theory.\n\nOur current results, however, show that even if one accepts (1) and (2) there\nis reason to reject (3). Thus, our results give us a reason to reject this\nargument for the conclusion that we should endorse evidential decision theory.\n\nThat brings us to another argument on which our results shed light.\n\n### 6.2 The evaluation argument\n\n  1. 6.\n\nCausal decision theory is correct.\n\n  2. 7.\n\nIf causal decision theory is correct, then we should two-box in a Newcomb\ncase.\n\n  3. 8.\n\nMost people choose to one-box in a Newcomb case.\n\n  4. 9.\n\nTherefore, most people make the wrong choice in a Newcomb case.\n\nWe take (9) to be philosophically interesting. Again, one might resist this\nargument. (6) is controversial. And against (7), we note that while most\ncausal decision theorists accept that if causal decision theory is correct\nthen we should two-box in a Newcomb case,^Footnote 13 some do not.^Footnote 14\nNotably though, if one accepts (6) and (7), then previous empirical results\nsuggest that this argument is sound. Our current results, however, suggest\notherwise. Instead, the picture they paint of people\u2019s decisions in Newcomb\ncases is much more nuanced than (8). Granting (6) and (7), the strongest\nconclusion our results support is that most people seem to make the \u201cwrong\u201d\nchoice in a Newcomb case only because they are assuming a causal connection\nbetween choice and prediction. But, of course, if there really were such a\ncausal connection, then one-boxing would be the correct choice even according\nto causal decision theory.\n\nMoving on to other aspects of our results. We did not find that people who\nchoose to two-box will prefer to learn that they had one-boxed. Rather, most\npeople who chose to two-box preferred to learn that this is what they had\ndone. Moreover, there was no significant difference between these two\nconditions (i.e., there was no significant difference between two-boxers\u2019\nresponses in the choice and news-item conditions).\n\nThis result suggests that non-philosopher two-boxers generally do not make the\ndistinction between choice preferences and news-item preferences. There are\ntwo ways this finding could be used to advance debate in this area. First,\nnon-causalists might argue that it undercuts a potential argument in favour of\ncausal decision theory: that non-philosopher two-boxers decide as they do\nbecause they understand the difference between choice and news-item\npreferences. If this were the case, then it could be argued that two-boxing\namongst non-philosophers is associated with a higher level of conceptual\nsophistication when evaluating choices. Given the prominent role this\ndistinction plays in philosophical motivations for causal decision theory\n(e.g., in Joyce, 1999), it would be impressive if non-philosopher two-boxers\ndecide as they do for seemingly similar reasons. Instead, it seems that\nsomething other than the choice-versus-news-item distinction motivates two-\nboxing for non-philosophers.\n\nNext, let\u2019s turn to what our results tell us about the connection between\ndecision and future bias. First, it is worth noting that we found lower levels\nof future bias in this study than have been found in some studies. Depending\non the exact features of the vignettes used, prior studies have found somewhat\ndifferent levels of future bias in the population. Some of that difference\nreflects a difference in whether the state of affairs over which people are\nforming the preference are of equal value (see Greene et al., 2022). But even\nfocussing only on studies in which the past state of affairs is of the same\nmagnitude as the future state of affairs, we find significant differences in\nfuture bias reported. Greene et al., (2021a, 2021b) found that ~ 80% of people\nwere future biased about hedonic events (76% for positive events and 86% for\nnegative ones), while Latham et al. (2023) and Latham et al. (2022) both found\nthat approximately 75% of people were future biased. These studies all used\nsimilar vignettes in which participants were to imagine receiving either a\npleasant or unpleasant food. Other studies have found much more variation\nusing different vignettes. Latham et al. (2023) compared future bias with\nrespect to various kinds of sensations and with respect to mood, and they\nfound that about 50% of people were future biased about positive/negative\nsensations and 40% about positive/negative mood. Our results are at the lower\nend of these findings. We think that is almost certainly due to some\ndifferences in the vignettes we used. These vignettes attempt to control for\ncertain factors, including (a) the probability of the event occurring and (b)\nits value/magnitude. We suspect that one reason levels of future bias in this\nstudy are somewhat lower than in some other studies is that the affect\ngenerated by imagining either the positive or the negative effect of the pill\nis partially swamped by the positive affect that is generated by imagining\nthat the fatal genetic disease has already been successfully treated. Future\nbias is thought to be in part the product of differential affect produced by\nimagining past versus future states of affairs (Ramos et al., 2022; Molouki et\nal., 2019). Given this, if the affect generated by imagining the\npositive/negative effects of the pill regardless of where those effects are\nlocated is in general diminished by being swamped by imagining the curing of\nthe fatal genetic disease, we would expect to see lower levels of future bias,\nwhich is indeed what we find. In all, our results are consistent with previous\nresults which suggest that the degree to which people display future bias\nvaries in part as a function of the affect generated by imagining the states\nof affairs.\n\nReturning to our hypotheses then, we found no difference between future bias\namongst one-boxers and two-boxers. If the practical irrelevance explanation\nfor future bias is correct, we might have expected to find that two-boxers\nwere more future biased than one-boxers because according to this explanation\nof future bias, the fact that past states of affairs are causally inaccessible\nmeans that we attach less evaluative weight to them (Horwich 1987, pp.\n194\u2013196; Maclaurin & Dyke, 2002; Suhler & Callender, 2012).\n\n). By contrast, if the temporal metaphysics explanation of future bias is\ncorrect, we would not have expected to find any association between future\nbias and one- or two-boxing.\n\nWhile this finding is interesting, we do not take it to provide strong\nevidence against the practical irrelevance explanation and in favour of the\ntemporal metaphysics explanation. Views on decision-relevant dependencies and\nfuture-biased preferences do not necessarily go hand in hand. It is possible\nfor one to view the evidence that choices provide about past states as\nirrelevant to decision-making, while at the same time caring very much about\npast states.\n\nIndeed, our results suggest that this is how things are. Our results suggest\nthat if the practical irrelevance explanation is correct, then the fact that\npeople attach less evaluative weight to past states of affairs because they\nare causally inaccessible^Footnote 15 does not have any impact on whether past\nstates of affairs are taken to be decision-relevant. This is also an\ninteresting upshot of this research, since it pulls apart two ways in which we\nmight care about past states of affairs: the evaluative way and the decision-\nrelevant way. While we might have thought it likely that these would go\ntogether, our data suggests that they do not.\n\nFinally, while our findings suggest that people lack the capacity to\ndistinguish choice from news-item preferences (as per H2), our findings with\nregard to H3 suggest that people often do distinguish between decision-\nrelevant dependencies and future-biased preferences. This provides some\nsupport for the view that people\u2019s decision making (at least when considering\nfuture-biased preferences) accords with normative decision theory. According\nto normative decision theory, decision rules are defined with respect to\npreviously specified preferences over outcomes (typically represented by a\nutility function). Thus, if people are rational in the way specified by\nnormative decision theory, we would expect their future-biased preferences to\nbe prior to and independent of their choice preferences in concrete decision\nproblems like the Newcomb case: people start with preferences, including\nfuture-biased preferences, and then use those preferences to make decisions.\nThis is precisely what we find.\n\n## 7 Conclusion\n\nIn our second study we found that a majority of non-philosophers are two-\nboxers in the Newcomb case. In comparison, previous research, including our\nown, has found that non-philosophers tend to endorse one-boxing. We have\nsuggested that this is the result of people employing a, quite likely tacit,\nheuristic that takes there to be a causal connection between very strongly\ncorrelated items, and hence on which there is a backwards causal connection\nbetween choice and prediction in the Newcomb case. Our study suggests than\nwhen we undermine the use of that heuristic by making salient outcomes that\nrule out the presence of a causal connection, people no longer choose to one-\nbox. In turn, we have argued that the descriptive claim that most people\nintuitively favour one-boxing cannot be marshalled in favour of evidential\ndecision theory. Further, one cannot claim that if causal decision theory is\ncorrect, then most people make the wrong choice in the Newcomb case. In fact,\naccording to our results, people\u2019s intuitive judgments are in line with causal\ndecision theory, since causal decision theorists recommend one-boxing in cases\nwhere there is a causal connection between choice and prediction, and two-\nboxing cases where there is no such connection.\n\nFinally, we did not find any evidence that two-boxing is associated with\nfuture bias. We found this surprising given the similarities in the \u201cfuture\nfocus\u201d of common rationales for both two-boxing and future bias. Instead, non-\nphilosophers\u2019 future bias seems to be independent of their choice preferences\nin Newcomb cases. In this way, their responses were in line with normative\ndecision theory, according to which decision rules are defined with respect to\npreviously specified preferences over outcomes.\n\n## Change history\n\n  * ### 07 March 2024\n\nA Correction to this paper has been published:\nhttps://doi.org/10.1007/s11229-024-04538-7\n\n## Notes\n\n  1. Even though evidential decision theory is the most prominent justification for one-boxing in the philosophical literature, there exist many alternative proposals for the rationale behind one-boxing. For example, functional decision theory proposes that one-boxing is rational based on the \u201calgorithmic,\u201d and not evidential, dependencies between state and act (Yudhowsky and Soares, 2018; Levinstein and Soares, 2020; Greene and Levinstein, 2020). Other examples of one-boxing alternatives to evidential decision theory include Gauthier (1986, Chp. 6), McClennen (1990), Meacham (2010), Spohn (2012), and Greene (2018).\n\n  2. An anonymous referee has questioned whether Joyce\u2019s distinction between auspiciousness and efficacy plays a justificatory role in his defense of causal decision theory as opposed to a merely dialectical one. We think the passage above illustrates that the distinction plays a justificatory role, since Joyce uses it to explain why people feel torn in Newcomb problems, and a theory\u2019s explanatory power contributes to its justification.\n\n  3. Future bias refers to a preference for where events are located. Connected to future bias is what is often known as the temporal value asymmetry. This refers to an asymmetry in assigning value to past and future states of affairs, in particular to the fact that people tend to assign more value to a state of affairs when it is located in the future, as opposed to being equidistant in the past (Caruso, 2010; Caruso, Gilbert and Wilson, 2008; Roh and Schuldt, 2014). It has often been thought that future bias is a manifestation of this temporal value asymmetry in that we prefer negative states of affairs to be in the past and not the future because we accord them less value (and hence less negative value) if they are in the past. By the same token, we prefer positive states of affairs to be located in the future, rather than the past, because we accord them more positive value if they are in the future. Not everyone accepts that future bias is a manifestation of the value asymmetry. Hoerl (2022) points to the fact that people only show a value asymmetry in between-subject designed experiments and not in within-subject designed experiments. In a between-subject condition of the Caruso et al (2008) experiment, each saw a single vignette: that vignette either described future boring work, or past boring work. In the within-subject condition, participants got to see both vignettes and decide on compensation. This effectively allows them to compare their compensation rates. The fact that they found no temporal value asymmetry in the within-subjects design was taken by Caruso et al (2008) to be evidence that people do not take it to be justified to differently value past over future states of affairs, and so they tend to bring their judgements in line with one another. As Hoerl points out, since people probably do think that it is justified to prefer pains to be in the past, and pleasures in the future, this suggests that future-bias may not simply be a manifestation of the value asymmetry. Lee and McCormack (2022) also raise concerns about the idea that future bias is a manifestation of the value asymmetry. They note that a preference for pain to be located in the past rather than the future has been shown to emerge considerably earlier, developmentally, than does the value asymmetry. If that is right, then it\u2019s difficult to see how future bias could simply be a manifestation of the value asymmetry.\n\n  4. There are two possible explanations for these differences. First, it could be that asking people who they would prefer to be (as in the Lee et al. study) as opposed to what experiences they would prefer to have (as in the Greene et al. study) tends to result in people taking a less temporally embedded perspective and hence in reducing future bias. A second possible explanation appeals to autobiographical memory. Lee et al. (2020) leaves open the possibility that the individuals described in the vignette remember the relevant past states of affairs, while in Greene et al., (2021b; 2022) the individual is said to temporarily fail to remember whether the past state of affairs occurred. Since the recollection of a memory can itself be a positive or negative hedonic event, the presence of such memories could play a role in mitigating future biased preferences.\n\n  5. This view has been suggested by Hume (1739, sec. 2.3.7.6), Parfit (1984, p. 186), and Horwich (1987, pp. 194\u2013196), and developed by Maclaurin & Dyke (2002) and Suhler & Callender (2012).\n\n  6. Some such authors hold that the presence of the relevant metaphysical facts explains the temporal value asymmetry, and that tensed emotions and future bias are both manifestations of that asymmetry.\n\n  7. \u201cSuppose there is a brilliant (and very rich) psychologist who knows you so well that he can predict your choices with a high degree of accuracy. One Monday as you are on the way to the bank he stops you, holds out a thousand-dollar bill, and says: \u2018You may take this if you like, but I must warn you that there is a catch. This past Friday I made a prediction about what your decision would be. I deposited $1,000,000 into your bank account on that day if I thought you would refuse my offer, but I deposited nothing if I thought you would accept.\u2019 Joyce\u2019s version is adapted from that by Sobel (1985, 198\u20139 n. 6). Sobel points out that the classic formulation of Newcomb\u2019s problem can lead to unnecessary \u201cmechanical complications.\u201d Thus, in Sobel\u2019s version there is no need for money to be described as inside boxes of varying opaqueness, and the agent is asked whether they would like to take the thousand or leave the thousand, instead of being asked the equivalent, but unnecessarily complex, question of whether they would like to take the thousand and take the million or leave the thousand and take the million.\n\n  8. We choose the chi-square test statistic because our data is a series of categorical variables. For instance, \u201cchoose\u201d (take; refuse), \u201clearn\u201d (take; refuse), and so on. The one-way chi-square tests whether the observed data differs significantly from people being evenly divided between the choice options. The chi-square test of independence tests whether there is a significant association between the categorical variables in people.\n\n  9. Our reported results do not change if we exclude people that report having a time-neutral preference, \u03c7^2 (1, N = 74) = .180, p = .672. We found no evidence that valence has any effect on the association between people\u2019s decision to one-box or two-box and future-biased preferences (Breslow-Day: p > .650).\n\n  10. Our reported results do not change if we exclude people that report having a time-neutral preference, \u03c7^2 (1, N = 69) = .261, p = .609. We found no evidence that valence has any effect on the association between people\u2019s decision to one-box or two-box and future-biased preferences (Breslow-Day: p > .513).\n\n  11. Thanks to an anonymous referee for raising this concern.\n\n  12. See Footnote 1.\n\n  13. Of course, as Ninan (2014) notes, if one gives some small but sufficiently high credence to not being in a genuine Newcomb case, then causal decision theory says that you should one-box.\n\n  14. Spohn (2012).\n\n  15. Assuming one accepts that future bias is a manifestation of the temporal value asymmetry, or at least, that the temporal value asymmetry is part of what explains why we are future biased.\n\n## References\n\n  * Ahmed, A. (2018). Introduction. In A. Ahmed (Ed.), Newcomb\u2019s problem (pp. 1\u201318). Cambridge University Press.\n\nChapter Google Scholar\n\n  * Caruso, E., Gilbert, D., & Wilson, T. (2008). A wrinkle in time: Asymmetric valuation of past and future events. Psychological Science, 19, 796\u2013801.\n\nArticle PubMed Google Scholar\n\n  * Bourget, D., & Chalmers, D. (2020). Philosophers on Philosophy: The 2020 PhilPapers Survey. https://philpapers.org/rec/BOUPOP-3\n\n  * Craig, W. L. (1999). Tensed time and our differential experience of the past and future. Southern Journal of Philosophy, 37, 515\u2013537.\n\nArticle ADS Google Scholar\n\n  * Dougherty, T. (2011). On whether to prefer pain to pass. Ethics, 121, 521\u2013537.\n\nArticle Google Scholar\n\n  * Gauthier, D. (1986). Morals by agreement. OUP.\n\nGoogle Scholar\n\n  * Gibbard, A., & Harper, W. (1978). Counterfactuals and two kinds of expected utility. In A. Hooker, J. J. Leach, & E. F. McClennen (Eds.), Foundations and applications of decision theory (pp. 125\u2013162). D. Reidel.\n\nGoogle Scholar\n\n  * Greene, P. (2018). Success-first decision theories. In A. Ahmed (Ed.), Newcomb\u2019s problem (pp. 115\u2013137). Cambridge University Press.\n\nChapter Google Scholar\n\n  * Greene, P. (2020). \u201cPure\u201d time preferences are irrelevant to the debate over time bias: A plea for zero time discounting as the normative standard. Australasian Journal of Philosophy., 58, 254.\n\nGoogle Scholar\n\n  * Greene, P., & Sullivan, M. (2015). Against time bias. Ethics, 125, 947\u2013970.\n\nArticle Google Scholar\n\n  * Greene, P., Latham, A. J., Miller, K., & Norton, J. (2021a). Hedonic and non-hedonic bias towards the future. Australasian Journal of Philosophy. https://doi.org/10.1080/00048402.2019.1703017\n\nArticle Google Scholar\n\n  * Greene, P., Latham, A. J., Miller, K., & Norton, J. (2021b). On preferring that overall, things are worse. Philosophy and Phenomenological Research. https://doi.org/10.1111/phpr.12819\n\nArticle Google Scholar\n\n  * Greene, P., Latham, A. J., Miller, K., & Norton, J. (2022). How much do we discount past pleasures? American Philosophical Quarterly, 59, 367.\n\nArticle Google Scholar\n\n  * Greene, P., & Levinstein, B. (2020). Act consequentialism without free rides. Philosophical Perspectives, 34(1), 88\u2013116.\n\nArticle Google Scholar\n\n  * Horwich, P. (1987). Asymmetries in Time: Problems in the Philosophy of Science. MIT Press.\n\nGoogle Scholar\n\n  * Jeffrey, R. C. (1965). The logic of decision. University of Chicago Press.\n\nGoogle Scholar\n\n  * Joyce, J. M. (1999). The foundations of causal decision theory. Cambridge University Press.\n\nBook Google Scholar\n\n  * Kahneman, D. (2011). Thinking fast and slow. Penguin Books.\n\nGoogle Scholar\n\n  * Lee, R., Hoerl, C., Burns, P., Fernandes, A. S., O\u2019Connor, P. A., & McCormack, T. (2020). Pain in the past and pleasure in the future: The development of past\u2013future preferences for hedonic goods. Cognitive Science. https://doi.org/10.1111/cogs.12887\n\nArticle PubMed Google Scholar\n\n  * Levinstein, B., & Soares, N. (2020). Cheating death in Damascus. Journal of Philosophy, 117(5), 237\u2013266.\n\nArticle Google Scholar\n\n  * Maclaurin, J., & Dyke, H. (2002). \u2018Thank goodness that\u2019s over\u2019: The evolutionary story. Ratio, 15(3), 276\u201392.\n\nArticle Google Scholar\n\n  * MacCrimmon, K. R., & Larsson, S. (1979). Utility theory: Axioms versus \u2018Paradoxes.\u2019 In M. Allais & O. Hagen (Eds.), Expected utility hypotheses and the Allais paradox, D (pp. 333\u2013409). Reidel Publishing Company.\n\nChapter Google Scholar\n\n  * McClennen, E. F. (1990). Rationality and dynamic choice: Foundational explorations. CUP.\n\nBook Google Scholar\n\n  * Meacham, C. (2010). Binding and its consequences. Philosophical Studies, 149(1), 49\u201371.\n\nArticle MathSciNet Google Scholar\n\n  * Miller, K. (2022). Tensed facts and the fittingness of our attitudes. Philosophical Perspectives. https://doi.org/10.1111/phpe.12166\n\nArticle Google Scholar\n\n  * Molouki, S., Hardisty, D. J., & Caruso, E. M. (2019). The sign effect in past and future discounting. Psychological Science, 30, 1674\u20131695.\n\nArticle PubMed Google Scholar\n\n  * Ninan, D. (2014). Illusions of influence in Newcomb\u2019s problem.\n\n  * http://www.dilipninan.org/papers/newcomb.pdf\n\n  * Pearson, O. (2018). Appropriate emotions and the metaphysics of time. Philosophical Studies, 175(8), 1945\u20131961.\n\nArticle Google Scholar\n\n  * Prior, A. N. (1959). Thank goodness that\u2019s over. Philosophy, 34, 12\u201317.\n\nArticle Google Scholar\n\n  * Ramos, J., Caruso, E. M., & Van Boven, L. (2022). Prospection, retrospection, and well-being. In C. Hoerl, T. McCormack, & A. Fernandes (Eds.), Temporal asymmetries in philosophy and psychology. OUP.\n\nGoogle Scholar\n\n  * Schlesinger, G. (1976). The stillness of time and philosophical equanimity. Philosophical Studies, 30, 145\u2013159.\n\nArticle Google Scholar\n\n  * Sobel, J. H. (1985). Circumstances and dominance in a causal decision theory. Synthese, 63(2), 167\u2013202.\n\nArticle MathSciNet Google Scholar\n\n  * Spohn, W. (2012). \u201cReversing 30 years of discussion: Why causal decision theorists should one-box. Synthese, 187(1), 95\u2013122.\n\nArticle MathSciNet Google Scholar\n\n  * Suhler, C., & Callender, C. (2012). Thank goodness that argument is over: Explaining the temporal value asymmetry. Philosophers\u2019 Imprint, 12, 1\u201316.\n\nGoogle Scholar\n\n  * Tarsney, C. (2017). Thank goodness that\u2019s newcomb: The practical relevance of the temporal value asymmetry. Analysis, 77(4), 750\u2013759.\n\nArticle Google Scholar\n\n  * Yudhowsky, E., & Soares, N. (2018). Functional decision theory: A new theory of instrumental rationality. arXiv:1710.05060\n\nDownload references\n\n## Funding\n\nOpen Access funding enabled and organized by CAUL and its Member Institutions.\n\n## Author information\n\n### Authors and Affiliations\n\n  1. Department of Philosophy, Nanyang Technological University, Singapore, Singapore\n\nPreston Greene\n\n  2. Department of Philosophy and History of Ideas, Aarhus University, Aarhus C, Denmark\n\nAndrew J. Latham\n\n  3. Department of Philosophy, The University of Sydney, Sydney, Australia\n\nKristie Miller & Michael Nielsen\n\nAuthors\n\n  1. Preston Greene\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  2. Andrew J. Latham\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  3. Kristie Miller\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  4. Michael Nielsen\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n### Corresponding author\n\nCorrespondence to Kristie Miller.\n\n## Ethics declarations\n\n### Conflict of interest\n\nThe authors declare that there is no conflict of interest that would affect\nthe content of the material in this paper.\n\n## Additional information\n\n### Publisher's Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional affiliations.\n\nThe original online version of this article was revised: initial was added to\nauthor name Andrew J. Latham and a correction was made to his affiliation.\n\n## Rights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0\nInternational License, which permits use, sharing, adaptation, distribution\nand reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the\nCreative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article's\nCreative Commons licence, unless indicated otherwise in a credit line to the\nmaterial. If material is not included in the article's Creative Commons\nlicence and your intended use is not permitted by statutory regulation or\nexceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder. To view a copy of this licence, visit\nhttp://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\n## About this article\n\n### Cite this article\n\nGreene, P., Latham, A.J., Miller, K. et al. The implicit decision theory of\nnon-philosophers. Synthese 203, 61 (2024).\nhttps://doi.org/10.1007/s11229-023-04478-8\n\nDownload citation\n\n  * Received: 08 February 2023\n\n  * Accepted: 22 December 2023\n\n  * Published: 07 February 2024\n\n  * DOI: https://doi.org/10.1007/s11229-023-04478-8\n\n### Share this article\n\nAnyone you share the following link with will be able to read this content:\n\nSorry, a shareable link is not currently available for this article.\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\n### Keywords\n\n  * Decision theory\n  * Newcomb\n  * Future bias\n  * Experimental philosophy\n\nUse our pre-submission checklist\n\nAvoid common mistakes on your manuscript.\n\nAdvertisement\n\n### Discover content\n\n  * Journals A-Z\n  * Books A-Z\n\n### Publish with us\n\n  * Publish your research\n  * Open access publishing\n\n### Products and services\n\n  * Our products\n  * Librarians\n  * Societies\n  * Partners and advertisers\n\n### Our imprints\n\n  * Springer\n  * Nature Portfolio\n  * BMC\n  * Palgrave Macmillan\n  * Apress\n\n128.140.102.183\n\nNot affiliated\n\n\u00a9 2024 Springer Nature\n\n", "frontpage": false}

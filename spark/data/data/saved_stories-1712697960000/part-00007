{"aid": "39979346", "title": "Magic-trace: Diagnosing tricky performance issues easily with Intel Proc (2022)", "url": "https://blog.janestreet.com/magic-trace/", "domain": "janestreet.com", "votes": 1, "user": "fanf2", "posted_at": "2024-04-09 13:42:04", "comments": 0, "source_title": "Magic-trace: Diagnosing tricky performance issues easily with Intel Processor Trace", "source_text": "Jane Street Tech Blog - Magic-trace: Diagnosing tricky performance issues\neasily with Intel Processor Trace\n\n### Magic-trace: Diagnosing tricky performance issues easily with Intel\nProcessor Trace\n\nJan 11, 2022 | 16 min read\n\n  * Share on Facebook\n  * Share on Twitter\n  * Share on LinkedIn\n\nBy: Tristan Hume\n\nIntel Processor Trace is a hardware technology that can record all program\nexecution flow along with timing information accurate to around 30ns. As far\nas I can tell almost nobody uses it, seemingly because capturing the data is\ntricky and, without any visualization tools, you\u2019re forced to read enormous\ntext dumps.\n\nMagic-trace is a tool we built and open-sourced to make it easy to capture a\ntrace of around 10ms leading up to a function call you chose to instrument,\nand then visualize the call stack on a timeline where you can zoom in and see\nevery function call and how long it took. Here\u2019s a captured trace of 5ms of\nOCaml program startup:\n\nAnd here\u2019s the same trace zoomed in to an arbitrary 500 nanoseconds. The thin\nred events are 1-3 nanoseconds:\n\nRecently we\u2019ve been using this tool to diagnose performance issues that would\nbe very difficult to solve with other tools. Using it is as easy as adding a\nMagic_trace.take_snapshot call to your code (or using a fuzzy-finder to select\nany existing function), then running magic-trace attach and using the fuzzy-\nfinder to select your process. It\u2019ll spit out a trace you can view in Google\u2019s\nPerfetto trace viewer.\n\nIn this post we\u2019ll go over why Processor Trace is so special, the difficulties\nof building something on top of a hardware technology almost nobody uses, how\nwe were beset by a kernel bug and a hardware bug, and the kinds of problems\nwe\u2019ve been able to solve with the tool.\n\n## Why Intel Processor Trace, and why not?\n\nLet\u2019s look at the major types of performance analysis tools and why magic-\ntrace serves a different niche:\n\nSampling profilers interrupt the program every 250 microseconds or so, sample\nthe current call stack, and then summarize them all together. These are great\nfor giving you a sense of where your program is spending its time. However, at\nJane Street we have lots of high-performance trading systems that spend nearly\nall of their time waiting for network packets that we want to respond to in\nfar less than the 250-microsecond sampling interval. Sampling profilers are\napproximately useless for diagnosing latency issues on that scale: you\u2019d be\nlucky to get one sample in the code you care about!\n\nEven in more traditional systems, you may want to diagnose short but rare tail\nlatency events, or notice the difference between a function being called 10\ntimes more than you expected or one call to it taking 10 times longer than\nexpected, which a sampling profiler can\u2019t tell you.\n\nInstrumentation-based tracing either patches or compiles probes into a program\nthat record when certain functions start and end, then typically visualizes\nthem on an interactive timeline UI. We re-use the UI from the Perfetto tracing\nsystem for magic-trace, although we needed to fork it to better handle events\nat the scale of single nanoseconds. High-performance tracing systems like\ntracy even manage to get the overhead down to around 2ns per call (we built a\nsimilar system for OCaml and open-sourced it). However, instrumenting every\nsingle function is risky (e.g. you might triple the cost of a 1ns function\nthat\u2019s called everywhere) so typically they require manual instrumentation,\nand sometimes your performance problems are in an app or function you haven\u2019t\nannotated.\n\nHardware tracing like Intel Processor Trace (IPT) has the advantages of\ntracing but doesn\u2019t require any instrumentation, and can have much lower\noverhead than instrumenting everything. They use a very efficient format that\nonly encodes just enough info to reconstruct the control flow \u2013 for example\nconditional branches take one bit. Time overhead for IPT varies from 2-20%\ndepending on the program, with every one of our programs I\u2019ve benchmarked\nexperiencing less than a 10% slowdown and usually under 5%.\n\nThere are a few downsides to Processor Trace though:\n\n  * Many VMs don\u2019t support it and it needs a post-Skylake Intel processor (some other vendors have similar tech; AMD doesn\u2019t yet).\n  * You have no choice but the full 1GB/s firehose (with the exception of some limited filtering options) so it\u2019s difficult to store and analyze longer traces. With instrumentation you can manually pick the important functions and economize on trace size.\n  * Decoding is slow because it needs to follow along with disassembled instructions from the binary and reconstruct the flow. Other than specialized decoders for fuzzing, the fastest decoder is 60x slower than real time.\n\n## A minimum viable product\n\nDuring Jane Street\u2019s 2021 summer internship, I was talking to some colleagues\nabout our issues profiling very short interesting time segments. I noted that\nIntel Processor Trace would be great for this but that it was really hard to\nuse. Then I realized that with the trace visualization library I had just\nwritten, and some features from the Processor Trace documentation I had just\nread, I could see a path to a user-friendly tool. So I drafted a new intern\nproject document, and for the second half of his internship, Chris Lambert and\nI worked on putting it together.\n\nThe key idea behind quickly making a useful tool was to limit the scope:\n\n  * We\u2019d focus on the circular buffer mode, where it overwrites old data until you snapshot it after something interesting happens. Processor Trace can save all data, but doing so creates 1GB of trace file per second.\n  * We\u2019d trigger the snapshots based on a function call in the target program. There are lots of other possibilities for deciding when to snapshot, but calling a function is very flexible, especially if you put it behind custom logic waiting for tail latency events or something.\n  * We\u2019d only visualize function calls and returns, and only on a trace timeline. Processor Trace gives you full control-flow data and in theory you could visualize down to individual lines, but that ends up being too much data to deal with.\n\nThe first stage was to implement the tool as a wrapper around the Linux perf\ntool\u2019s Processor Trace functionality, and Chris blazed through it in under a\nweek. Sending the SIGUSR2 signal to perf caused it to take a snapshot, so\nChris wrote a Magic_trace.take_snapshot function that sent SIGUSR2 to the\nparent pid. Then he wrote a parser and call-stack reconstructor to turn the\nperf script text dump of all branches into a trace that handled OCaml features\nlike tail-calls and some exceptions.\n\nIt was pretty exciting looking through the first traces and being able to zoom\nin and see the smallest details, and immediately noticing things like that\nOCaml program startup time was mostly composed of module initializers page\nfaulting in random parts of the binary.\n\n## Directly using kernel APIs and libipt\n\nThen we embarked on something harder. Parsing the output of the perf tool was\nslow and couldn\u2019t do the instruction-level decoding needed for properly\nhandling pushes and pops to the OCaml exception handler stack. We decided to\ntry directly using the kernel perf_event_open API and Intel\u2019s libipt decoding\nlibrary.\n\nThis turned out to be quite tricky, as we couldn\u2019t find any evidence anyone\nhad ever tried directly integrating perf_event_open with libipt before. I\nended up spending my days poring over documentation and source code of libipt\nand the perf tool to figure out how to do things we hadn\u2019t understood yet and\nhanding answers and example links over to Chris, who wrote and debugged the C\ncode to interface with the APIs and with OCaml.\n\nAfter lots of research and debugging, by the end of his internship we\u2019d\nmanaged to get a trace of events out of our from-scratch implementation. After\nChris left I debugged the remaining issues and plumbed it in fully. Hopefully\nnow that we\u2019ve published a reference codebase, anyone else attempting this\nwill have an easier time.\n\n## Hardware breakpoints for seamless triggering\n\nAfter Chris left and things were working, the biggest feature that we needed\nto make useful and easy was the ability to attach to existing processes.\nUnfortunately this broke our parent-SIGUSR2-based snapshot signalling. I\nwanted Magic_trace.take_snapshot to have close to zero overhead while magic-\ntrace wasn\u2019t attached, and low overhead even when it did trigger a snapshot. I\nthought I might have to have every process host a tiny IPC server or use\nptrace, but I wasn\u2019t happy with those solutions.\n\nI spent a bunch of time looking for a better solution and eventually I found a\nreally satisfying one in the perf_event_open docs. It turns out that\nperf_event_open can use hardware breakpoints and notify you when a memory\naddress is executed or accessed.\n\nThe cool thing about this approach is that it requires no cooperation from the\ntarget, no overhead when not attached, and can actually be used on any\nfunction we want, not just a special Magic_trace.take_snapshot function. When\nwe do use it on a special function, we can sample registers so we can see the\narguments it was called with, allowing the user to include metadata with their\nsnapshot.\n\nI think it says something interesting about my programming aesthetic that I\nspent a whole day researching alternatives to adding a tiny IPC server and\nended up using a niche kernel API and hardware feature. I knew the hardware\nallowed a design which didn\u2019t require recompiling or adding extra bloat to\nprocesses that weren\u2019t being traced, and I really wanted to make first-time\nuse as smooth as possible and avoid bloating everyone else\u2019s programs. If I\ndid go the IPC route, I was at least going to use less-obscure-but-still-rare\nLinux-only abstract domain sockets (named by the PID) to avoid having to clean\nup files or deal with ports. Sometimes standard approaches can\u2019t get you to an\nideal user experience, but they\u2019re easier for your coworkers to maintain, you\nrun into fewer issues, and need to do less research. This tradeoff leaves low-\nhanging fruit for people who enjoy diving deep into obscure documentation and\ndebugging weird issues, which can tip the balance. Hardware breakpoints, the\nwhole magic-trace project, and other projects of mine are all the result of\ndelighting in asking myself \u201ccould I obliterate this problem by being willing\nto do cursed things?\u201d\n\n## Kernel bugs and hardware bugs, the perils of being early\n\nPeople have sometimes used Processor Trace, and it mostly works, but I\u2019ve\nlearned that when using niche and complicated new hardware, I can\u2019t have the\nsame low priors as I usually do about bugs being due to the kernel or\nhardware.\n\nI was excited to be able to try my hand at kernel debugging for the first time\nwhen I discovered a way to crash the kernel using a specific unusual\ncombination of Processor Trace features. I used info from the kernel core\ndump, and read through control flow paths and recent patches in the kernel, to\nfigure out the reason for the null pointer access. It turns out a patch added\na flag that made one piece of state invalid to access, but missed guarding it\nwith an if statement in one place. Exactly the kind of bug that algebraic data\ntypes in OCaml/Rust/etc help you avoid :)\n\nAnother bug was much more mysterious and difficult. On exactly one program out\nof any I tried, Processor Trace would mysteriously stop adding events to the\ntrace buffer before it reached the snapshot point. I spent 2 weeks adding\nvarious sorts of observability and fixing other issues that got in the way (so\nat least magic-trace ended up better regardless), and couldn\u2019t find any\nsensible software cause, e.g. a context switch that lined up with when the\nrecording stopped. Finally I tried running it on a newer generation of Intel\nprocessors and the problem went away. I suspect it may be Intel erratum SKL171\n\u201cIntel\u00ae PT May Drop All Packets After an Internal Buffer Overflow\u201d which\nhappens under a \u201crare microarchitectural condition\u201d, although it still might\nbe some race condition kernel bug that\u2019s very consistent only in the older\nhardware.\n\n## Solving tricky problems\n\nPeople have only been using magic-trace internally for about a month but we\u2019ve\nalready made good use of it.\n\nThe original design goal was to help with performance problems in high-\nperformance trading system that sampling profilers are hopeless for, and\nthat\u2019s panned out. It helped identify a 100ns performance regression caused by\na patch that turned out to cause a function call not to be inlined. It also\nhelped diagnose why a new compiler version made a trading system slower, which\nalso turned out to come down to an inlining decision.\n\nBut after we built magic-trace, we realized it could help with another kind of\ndifficult performance problem that people at Jane Street encounter frequently.\nWe use Async to cooperatively handle many concurrent tasks. The\n\u201ccooperatively\u201d part means that if one task takes too long then all other\ntasks have to wait for it. If you have an issue that causes a task to handle\nway more work than usual, it can cause a \u201clong async cycle\u201d. These can be\nreally tricky to debug if they only happen occasionally, since you don\u2019t get\nany info about what code was too slow. Previously people have resorted to\ncapturing enormous long perf profiles and then using logged monotonic\ntimestamps to filter the profile to the relevant region.\n\nNow with magic-trace people can just add a snippet of code that calls\nMagic_trace.take_snapshot after cycles over a certain length, and then attach\nmagic-trace and wait for it to capture. Even if a long cycle is 15 seconds,\nthe last 10 milliseconds of the job are normally the same uniform large batch\nof work, so you can just look back in the trace to see which code is doing too\nmuch work. We\u2019ve already used this to solve one tricky issue where there were\nway more items in a certain collection than expected and a loop was spending\nseconds working over them. Sampling profile filtering would\u2019ve been harder and\nwouldn\u2019t have been able to tell whether the function was looping too many\ntimes instead of, say, taking a really long time once or just always being\nsomewhat slow.\n\nEven if magic-trace is only indispensable for certain high-performance code,\nas a user-friendly performance tool in a toolbox it can be useful for all\nsorts of debugging and performance problems just by being quicker and easier\nto use than alternatives.\n\n## How you can use magic-trace\n\nWe designed magic-trace for our own OCaml code but now you can use it on any\nnative executable with symbol names (e.g. a C++ or Rust program) as long as\nyou have a new enough Intel Linux machine. Here\u2019s how:\n\n    \n    \n    # If this prints 1 your machine supports Processor Trace with precise timing cat /sys/bus/event_source/devices/intel_pt/caps/psb_cyc # Install Opam (https://opam.ocaml.org/doc/Install.html), then OCaml 4.12.1 opam switch create 4.12.1 opam switch 4.12.1 # Add the Jane Street pre-release repo, magic-trace isn't on public Opam yet opam repo add janestreet-bleeding https://ocaml.janestreet.com/opam-repository # Install the magic-trace command line tool opam install magic-trace # This lets you fuzzy-search a process to attach to and a symbol to snapshot on magic-trace attach -symbol '' -output magic.ftf # Go to https://ui.perfetto.dev/ and open the trace file\n\nNobody else has used Perfetto for traces like this before so we also needed to\nleave our OCaml and C extensions to the land of Typescript and patch Perfetto\nto support zooming to nanosecond-levels. The main Perfetto UI works, and we\nhope to upstream some patches to it, but for the best experience you can build\nthe UI from our fork.\n\n## Let\u2019s use more Processor Trace!\n\nIntel Processor Trace is an incredibly powerful and cool technology, and it\u2019s\nan absolute shame that more people don\u2019t use it. I hope that magic-trace shows\npeople how useful Processor Trace and technologies like it can be, and makes\nit easier to use Processor Trace by providing an example codebase.\n\nOne way to build tools on top of Processor Trace that I haven\u2019t mentioned yet\nis perf-dlfilter, which allows you to consume perf events using an efficient C\nAPI with a shared library rather than parsing text output. We didn\u2019t use it\nbecause it was just being submitted to the kernel as we were writing magic-\ntrace; we didn\u2019t learn about it until I stumbled upon it months later. I\u2019d\nrecommend that tools try to start with perf and dlfilter rather than\nperf_event_open and libipt, as it just implements tons of stuff you\u2019ll\notherwise need to reimplement.\n\nAt the end of his internship, Chris even suggested that with hindsight we\nshould have forked perf to add a C interface rather than embarking on the\nlibipt route \u2013 and luckily someone else did, with the specific goal of\nefficiently reading Processor Trace events! You don\u2019t even need a super new\nkernel, because you can compile the perf tool from a newer kernel tree and use\nit on an older kernel.\n\nHere are some more ideas we\u2019ve thought of for Processor Trace tooling that\nnobody\u2019s built yet and that we might build into magic-trace:\n\n  * Visualizing control flow at the level of individual lines of code, perhaps with a custom trace viewer designed for Processor Trace which lazily decodes the lowest levels again as you zoom in.\n  * Feedback Directed Optimization of low-latency systems by optimizing based on recorded control flow in the latency-critical case.\n  * Using Processor Trace to evaluate compiler optimizations by counting the number of actually executed register spills, page faults, etc. on benchmarks.\n  * Building efficient instrumentation-based tracing on top of the PTWRITE instruction in the latest processors, which allows adding data into the trace.\n  * Using the \u201cPEBS via PT\u201d feature on very new processors to sample cache misses or branch mispredicts and add them to the trace so you can notice why your function is slow.\n  * Using root permissions to record every process on every core plus the kernel and combining it with task switch information to visualize literally everything the processor was doing during a time slice so mysterious performance problems have nowhere left to hide.\n\nIf more people use Processor Trace, more VM hypervisors will support it, Intel\nwill hopefully invest more in it as a differentiating factor, and perhaps AMD\nwill try to catch up. And if you want to use Processor Trace today, try magic-\ntrace on your own problems, or apply to Jane Street and come try it on ours:\nwe\u2019re always hiring!\n\nTristan Hume is a developer at Jane Street. Previously he was at the\nUniversity of Waterloo and doing a lot of internships. He has a website at\nhttp://thume.ca/.\n\nprevious post next post\n\n### Signals & Threads Podcast\n\nListen to the latest episode\n\n### Featured Tech Talk\n\nThe Algorithm for Precision Medicine\n\nJane Street YouTube Channel\n\n### Featured Reads\n\n  * Read more\n\nPosts about interviewing at Jane Street and our internship program\n\n  * Read more\n\nUsing ASCII waveforms to test hardware designs\n\n  * Read more\n\nFinding memory leaks with Memtrace\n\n### Tags\n\n  * async\n  * book\n  * c\n  * camlp4\n  * code-review\n  * comments\n  * compiler\n  * core\n  * hackerschool\n  * hg\n  * incremental\n  * internship\n  * interviewing\n  * ocaml\n  * parallel-programming\n  * performance\n  * ppx\n  * real-world-ocaml\n  * registers\n  * speed\n  * ui\n\n### RSS\n\nGet the RSS feed\n\n### Jane Street Open Source\n\nFrom committing patches to the Linux kernel to releasing our own projects,\nwe\u2019re always looking for ways to participate in the open source community.\n\n### Join Our Team\n\nWhere FP meets the real world.\n\nIf you're interested in working at a place where functional programming meets\nthe real world, then apply for a job at Jane Street.\n\nLearn more\n\n  * Who We Are\n\n  * What We Do\n\n  * Client Offering\n\n  * The Latest\n\n  * Culture\n\n  * Join Jane Street\n\n  * Contact Us\n\nDisclosures & Policies\n\n\u00a9 Copyright 2015-2024 Jane Street Group, LLC. All rights reserved. Services are provided in the U.S. by Jane Street Capital, LLC and Jane Street Execution Services, LLC, each of which is a SEC-registered broker dealer and member of FINRA (www.finra.org). Regulated activities are undertaken in Europe by Jane Street Financial Limited, an investment firm authorized and regulated by the U.K. Financial Conduct Authority, and Jane Street Netherlands B.V., an investment firm authorized and regulated by the Netherlands Authority for the Financial Markets (Autoriteit Financi\u00eble Markten), and in Hong Kong by Jane Street Hong Kong Limited, a regulated entity under the Hong Kong Securities and Futures Commission (CE No. BAL548). Each of these entities is a wholly owned subsidiary of Jane Street Group, LLC. This material is provided for informational purposes only and does not constitute an offer or solicitation for the purchase or sale of any security or other financial instrument. | Jane Street and the concentric circle mark are registered trademarks of Jane Street.\n\nPrivacy Cookies\n\n", "frontpage": false}

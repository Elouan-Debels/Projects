{"aid": "39985596", "title": "GPT-4 Turbo with Vision is a step backwards for coding", "url": "https://aider.chat/2024/04/09/gpt-4-turbo.html", "domain": "aider.chat", "votes": 6, "user": "anotherpaulg", "posted_at": "2024-04-10 00:03:47", "comments": 0, "source_title": "GPT-4 Turbo with Vision is a step backwards for coding", "source_text": "GPT-4 Turbo with Vision is a step backwards for coding | aider\n\nSkip to the content.\n\n# GPT-4 Turbo with Vision is a step backwards for coding\n\n## aider is AI pair programming in your terminal\n\nHome Blog GitHub\n\n# GPT-4 Turbo with Vision is a step backwards for coding\n\nOpenAI just released GPT-4 Turbo with Vision and it performs worse on aider\u2019s\ncoding benchmark suites than all the previous GPT-4 models. In particular, it\nseems much more prone to \u201clazy coding\u201d than the existing GPT-4 Turbo \u201cpreview\u201d\nmodels.\n\n## Code editing skill\n\nAider relies on a code editing benchmark to quantitatively evaluate how well\nan LLM can make changes to existing code. The benchmark uses aider to try and\ncomplete 133 Exercism Python coding exercises.\n\nFor each exercise, the LLM gets two tries to solve each problem:\n\n  1. On the first try, it gets initial stub code and the English description of the coding task. If the tests all pass, we are done.\n  2. If any tests failed, aider sends the LLM the failing test output and gives it a second try to complete the task.\n\nGPT-4 Turbo with Vision scores only 62% on this benchmark, the lowest score of\nany of the existing GPT-4 models. The other models scored 63-66%, so this\nrepresents only a small regression, and is likely statistically insignificant\nwhen compared against gpt-4-0613.\n\n## Lazy coding\n\nThe GPT-4 Turbo \u201cpreview\u201d models have been widely criticized for being \u201clazy\u201d\nwhen coding. They often omit needed code and instead leave comments with\nhomework assignments like \u201cimplement method here\u201d.\n\n    \n    \n    def some_complex_method(foo, bar): # ... implement method here ...\n\nAider uses a \u201claziness\u201d benchmark suite which is designed to both provoke and\nquantify lazy coding. It consists of 89 python refactoring tasks which tend to\nmake GPT-4 Turbo code in that lazy manner.\n\nThe new GPT-4 Turbo with Vision model scores only 34% on aider\u2019s refactoring\nbenchmark, making it the laziest coder of all the GPT-4 Turbo models by a\nsignificant margin.\n\n# Conclusions\n\nAider has full support for the new GPT-4 Turbo with Vision model, which you\ncan access using the switch --model gpt-4-turbo-2024-04-09. But aider will\ncontinue to use gpt-4-1106-preview by default, as it is by far the strongest\ncoder of the GPT-4 models.\n\naider is maintained by paul-gauthier. This page was generated by GitHub Pages.\n\n", "frontpage": true}

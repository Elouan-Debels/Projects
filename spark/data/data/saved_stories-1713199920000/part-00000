{"aid": "40038817", "title": "Convert BIM Models to Pointcloud", "url": "https://github.com/D4ve-R/ifcclouds", "domain": "github.com/d4ve-r", "votes": 2, "user": "d4ve-r", "posted_at": "2024-04-15 10:50:09", "comments": 0, "source_title": "GitHub - D4ve-R/ifcclouds: convert ifc files to pointclouds", "source_text": "GitHub - D4ve-R/ifcclouds: convert ifc files to pointclouds\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nD4ve-R / ifcclouds Public\n\n  * Notifications\n  * Fork 1\n  * Star 5\n\nconvert ifc files to pointclouds\n\n### License\n\nView license\n\n5 stars 1 fork Branches Tags Activity\n\nStar\n\nNotifications\n\n# D4ve-R/ifcclouds\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nD4ve-Rrgb6f202bb \u00b7\n\n## History\n\n39 Commits  \n  \n### data\n\n|\n\n### data\n\n| data  \n  \n### docs\n\n|\n\n### docs\n\n| BigBang  \n  \n### ifcclouds\n\n|\n\n### ifcclouds\n\n| rgb  \n  \n### models\n\n|\n\n### models\n\n| BigBang  \n  \n### notebooks\n\n|\n\n### notebooks\n\n| BigBang  \n  \n### references\n\n|\n\n### references\n\n| more papers  \n  \n### reports\n\n|\n\n### reports\n\n| BigBang  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| README  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| BigBang  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| BigBang  \n  \n### README.md\n\n|\n\n### README.md\n\n| refactor  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| refactor  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| package  \n  \n### test_environment.py\n\n|\n\n### test_environment.py\n\n| BigBang  \n  \n### tox.ini\n\n|\n\n### tox.ini\n\n| BigBang  \n  \n## Repository files navigation\n\n# ifcclouds\n\nIfc to cloudpoint semi synthetic data generator\n\nThis project is a collection of scripts to generate point clouds from IFC\nfiles. The point clouds can be used for machine learning and other\napplications. The synthetic data is generated by extracting the meshes by ifc-\nentity-type and distributing points over each face using barycentric\ncoordinates and a weightend sampler-algorithm with respect to triangle-size.\nAll mesh-points are concatenated to a single point cloud. The point cloud is\nthen saved as a .ply file with the format float float float int, where the\nfirst three values are coordinates and the fourth value is the class label.\n\nCurrently a DGCNN model is implemented to segment the point clouds. The model\nis trained on 13 ifc types, to segment the point clouds into 13 classes. The\ndataset used is very small (9) and split into train (7) and test (2) set.\n\n## Installation\n\n    \n    \n    git clone cd ifcclouds python3 -m venv venv source venv/bin/activate python3 -m pip install -r requirements.txt\n\n## Getting Started\n\n### Download IFC files\n\nDownload the IFC files and extract them to the data/raw folder. The folder\nstructure should look like this:\n\n    \n    \n    data \u2514\u2500\u2500 raw \u251c\u2500\u2500 sample1.ifc \u251c\u2500\u2500 sample2.ifc \u251c\u2500\u2500 sample3.ifc \u251c\u2500\u2500 sample4.ifc \u251c\u2500\u2500 sample5.ifc \u251c\u2500\u2500 sample6.ifc \u251c\u2500\u2500 sample7.ifc \u251c\u2500\u2500 sample8.ifc ...\n\n### Build dataset\n\n    \n    \n    python3 -m ifcclouds.data.make_dataset\n\n### Convert IFC files to point clouds\n\n    \n    \n    python3 -m ifcclouds.convert IFC_FILE_PATH PLY_FILE_PATH\n\nor in script\n\n    \n    \n    from ifcclouds.convert import process_ifc\n\n### Serve Dashboard\n\n    \n    \n    python3 -m ifcclouds.server.app\n\n## To Do\n\n  * Improve dataset consumption, to distribute well over classes\n  * Add more models\n\n## Project Organization\n\n    \n    \n    \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile <- Makefile with commands like `make data` or `make train` \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable ifc data dump. \u2502 \u251c\u2500\u2500 docs <- A default Sphinx project; see sphinx-doc.org for details \u2502 \u251c\u2500\u2500 models <- Trained and serialized models, model predictions, or model summaries \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.py <- makes project pip installable (pip install -e .) so src can be imported \u251c\u2500\u2500 src <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes src a Python module \u2502 \u2502 \u2502 \u251c\u2500\u2500 data <- Scripts to download or generate data \u2502 \u2502 \u2514\u2500\u2500 make_dataset.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 features <- Scripts to turn raw data into features for modeling \u2502 \u2502 \u2514\u2500\u2500 build_features.py \u2502 \u2502 \u2502 \u251c\u2500\u2500 models <- Scripts to train models and then use trained models to make \u2502 \u2502 \u2502 predictions \u2502 \u2502 \u251c\u2500\u2500 predict_model.py \u2502 \u2502 \u2514\u2500\u2500 train_model.py \u2502 \u2502 \u2502 \u2514\u2500\u2500 visualization <- Scripts to create exploratory and results oriented visualizations \u2502 \u2514\u2500\u2500 visualize.py \u2502 \u2514\u2500\u2500 tox.ini <- tox file with settings for running tox; see tox.readthedocs.io\n\n## References\n\n  * IfcOpenShell\n  * Dynamic Graph CNN for Learning on Point Clouds\n\nProject based on the cookiecutter data science project template.\n#cookiecutterdatascience\n\n## About\n\nconvert ifc files to pointclouds\n\n### Topics\n\npoint-cloud ifc 3d-segmentation\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\nActivity\n\n### Stars\n\n5 stars\n\n### Watchers\n\n3 watching\n\n### Forks\n\n1 fork\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 70.5%\n  * JavaScript 13.8%\n  * Makefile 8.0%\n  * HTML 7.7%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

{"aid": "40004741", "title": "Rerank 3: A new foundation model for efficient enterprise search and retrieval", "url": "https://txt.cohere.com/rerank-3/", "domain": "cohere.com", "votes": 16, "user": "bguberfain", "posted_at": "2024-04-11 17:38:32", "comments": 2, "source_title": "Introducing Rerank 3: A New Foundation Model for Efficient Enterprise Search & Retrieval", "source_text": "Introducing Rerank 3: A New Foundation Model for Efficient Enterprise Search &\nRetrieval\n\n  * Sylvie Shi\n\n  * Nils Reimers\n\nApr 11, 2024\n\n# Introducing Rerank 3: A New Foundation Model for Efficient Enterprise Search\n& Retrieval\n\n  * Product\n\nShare:\n\nTwitter Facebook\n\nToday, we're introducing our newest foundation model, Rerank 3, purpose built\nto enhance enterprise search and Retrieval Augmented Generation (RAG) systems.\n\nOur model is compatible with any database or search index and can also be\nplugged into any legacy application with native search capabilities. With a\nsingle line of code, Rerank 3 can boost search performance or reduce the cost\nof running RAG applications with negligible impact to latency.\n\nRerank 3 offers state-of-the-art capabilities for enterprise search,\nincluding:\n\n  * 4k context length to significantly improve search quality for longer documents\n  * Ability to search over multi-aspect and semi-structured data like emails, invoices, JSON documents, code, and tables\n  * Multilingual coverage of 100+ languages\n  * Improved latency and lower total cost of ownership (TCO)\n\nGenerative models with long contexts have the ability to execute RAG. However,\nin order to optimize accuracy, latency and cost a RAG solution requires a\ncombination of generative models and our Rerank models. The high precision\nsemantic reranking of Rerank 3 makes sure that only the most relevant\ninformation is fed to the generative model, increasing response accuracy and\nkeeping latency and cost low, in particular when retrieving information from\nthousands and millions of documents.\n\n## Enhanced Enterprise Search\n\nEnterprise data is often complex and current systems have difficulty searching\nthrough multi-aspect and semi-structured data sources. The most useful data at\ncompanies is not often in simple document format and semi-structured data\nformats such as JSON are common across enterprise applications. Rerank 3 is\nable to rank complex, multi-aspect data (e.g. emails) based on all of their\nrelevant metadata fields, including their recency.\n\nSemi-structured retrieval accuracy based Recall@5 on TMDB-5k-Movies, WikiSQL,\nnq-tables, and Cohere annotated datasets (higher is better).\n\nRerank 3 also demonstrates a marked improvement on code retrieval\ncapabilities. This could include retrieval over an enterprise's proprietary\ncode repository to enhance the productivity of their engineering teams, or\nover huge corpuses of documentation.\n\nCode evaluation accuracy based on nDCG@10 on Codesearchnet, Stackoverflow,\nCosQA, Human Eval, MBPP, DS1000 (higher is better).\n\nGlobal organizations also deal with multilingual data sources and historically\nmultilingual retrieval has been a challenge with keyword-based methods. Our\nRerank 3 model offers strong multilingual performance in over 100+ languages\nsimplifying retrieval for non-English speaking customers.\n\nMultilingual retrieval accuracy based nDCG@10 on MIRACL (higher is better).\n\nA primary challenge when building semantic search and RAG systems is\ndetermining how to best chunk your data. Our Rerank 3 model now boasts a 4k\ncontext length allowing customers to pass in larger documents for ranking.\nThis allows our model to consider more context from the document when\ndetermining a relevance score, and reduces the need for chunking documents in\norder to fit within the model\u2019s context window.\n\nLong context accuracy based on nDCG@10 on TREC 2019-2022, Conditional QA , NQ-\nHard, Qasper, Genomics, QMSum, FinanceBench (higher is better).\n\nWe are also excited to announce that Rerank 3 is supported natively in\nElastic\u2019s Inference API starting today. Elasticsearch has a widely adopted\nsearch technology and the keyword and vector search capabilities in the\nElasticsearch platform are built to handle complex enterprise data. To start\nbuilding enterprise search systems with Cohere and Elastic, check out the\nlatest guide here.\n\n> \"We're excited to be partnering with Cohere to help businesses unlock the\n> potential of their data.\" said Matt Riley, GVP & GM of Elasticsearch\n> \"Cohere's advanced retrieval models, Embed 3 and Rerank 3, offer leading\n> performance on complex enterprise data. They are quickly becoming essential\n> components in any enterprise search system. We're happy to have Cohere's\n> offerings deeply integrated into Elasticsearch via our Inference API, as\n> critical developer tools for best in class relevance and hybrid search.\"\n\n## Improved Latency even with Longer Context\n\nIn many business domains such as e-commerce or customer service, low latency\nis crucial to delivering a quality experience. We kept this in mind while\nbuilding Rerank 3, which shows up to 2x lower latency compared to Rerank 2 for\nshorter document lengths and up to 3x improvements at long context lengths.\n\nComparisons computed as the time to rank 50 documents across a variety of\ndocument token-length profiles; each run assumes a batch of 50 documents with\nuniform token length across each document.\n\n## More Performant and Efficient RAG\n\nThe retrieval step is crucial in RAG. Rerank 3 bolsters the key factors for\nstrong RAG performance: quality of responses and latency. Our model helps you\nisolate the most relevant documents to respond to a user\u2019s question and\nincreases the response accuracy of the overall RAG system. This allows large\nenterprises to unlock massive value from their proprietary data and source\nrelevant information to support tasks in a range of business functions from\ncustomer support, legal, HR, finance, and more.\n\n(left) Retrieval augmented generation workflow without Rerank. Documents are\nretrieved from an existing search system and are passed directly to the LLM\nfor grounded generation. (right) Retrieval augmented generation workflow with\nRerank. Documents are retrieved from an existing search system and are passed\ndirectly to Rerank. High precision semantic reranking allows fewer, higher\nquality documents to be passed to the LLM for grounded generation.\n\nWhen combined with our highly efficient Command R family of models for RAG,\nRerank 3 further reduces total cost of ownership (TCO) for customers. Adding\nRerank into a RAG system allows users to pass fewer, more relevant documents\nto the LLM for grounded generation while maintaining overall accuracy and\nwithout adding latency. The net effect makes running RAG with Rerank on\nCommand R+ 80-93% less expensive than other generative LLMs in the market, and\nwith Rerank and Command R savings can top 98%.\n\nStandalone cost is based on inference costs for 1M RAG prompts with 50 docs\ncontaining 250 tokens each, and 250 output tokens. Cost with Rerank is based\non inference costs for 1M RAG prompts with 5 docs @ 250 tokens each, and 250\noutput tokens.\n\nAn increasingly common approach for RAG is using LLMs as rerankers for\ndocument retrieval. Rerank 3 outperforms industry leading LLMs on ranking\naccuracy while being between 90-98% less expensive.\n\nAccuracy based on nDCG@10 on TREC 2020 dataset (higher is better). LLMs are\nevaluated in a list-wise fashion following the approach used in RankGPT (Sun\net al. 2023).\n\nRerank 3 not only helps reduce end-to-end TCO but also boosts the quality of\nthe LLM response. Rerank achieves this by weeding out less relevant documents,\nand only sorting through the small subset of pertinent ones to draw answers.\n\n## How to get Started\n\nStarting today developers and businesses can access Rerank 3 on both Cohere\u2019s\nhosted API and AWS Sagemaker. You can also access our model directly through\nthe inference API in Elasticsearch to perform semantic reranking on your\nexisting Elasticsearch index.\n\nTo understand how your company can start deploying with Rerank 3 at\nproduction-scale, reach out to our sales team.\n\n## Searching Over JSON\n\nRerank 3 introduces the option to search over semi-structured data that is\nrepresented as JSON. You can simply take your JSON documents, e.g. from an\nElasticsearch or MongoDB, and pass it to the Rerank 3 model. By setting the\nrank fields, you can select which fields should be considered by the model for\nthe ranking.\n\nThe following code snippet demonstrates this for the case of email search:\n\n# Make sure to have the newest Cohere SDK installed:  \n---  \n# pip install -U cohere  \n# Get your free API key from: www.cohere.com  \nimport cohere  \ncohere_key = \"<<YOUR_API_KEY>>\"  \nco = cohere.Client(cohere_key)  \n# Lets define some JSON with our documents. Here we use a JSON to represent\nemails  \n# with different fields. In the call to co.rerank we can specify which  \nemails = [  \n{  \n\"from\": \"Paul Doe <paul_fake_doe@oracle.com>\",  \n\"to\": [\"Steve <steve@me.com>\", \"lisa@example.com\"],  \n\"date\": \"2024-03-27\",  \n\"subject\": \"Follow-up\",  \n\"text\": \"We are happy to give you the following pricing for your project.\"  \n},  \n{  \n\"from\": \"John McGill <john_fake_mcgill@microsoft.com>\",  \n\"to\": [\"Steve <steve@me.com>\"],  \n\"date\": \"2024-03-28\",  \n\"subject\": \"Missing Information\",  \n\"text\": \"Sorry, but here is the pricing you asked for for the newest line of\nyour models.\"  \n},  \n{  \n\"from\": \"John McGill <john_fake_mcgill@microsoft.com>\",  \n\"to\": [\"Steve <steve@me.com>\"],  \n\"date\": \"2024-02-15\",  \n\"subject\": \"Commited Pricing Strategy\",  \n\"text\": \"I know we went back and forth on this during the call but the pricing\nfor now should follow the agreement at hand.\"  \n},  \n{  \n\"from\": \"Generic Airline Company<no_reply@generic_airline_email.com>\",  \n\"to\": [\"Steve <steve@me.com>\"],  \n\"date\": \"2023-07-25\",  \n\"subject\": \"Your latest flight travel plans\",  \n\"text\": \"Thank you for choose to fly Generic Airline Company. Your booking\nstatus is confirmed.\"  \n},  \n{  \n\"from\": \"Generic SaaS Company<marketing@generic_saas_email.com>\",  \n\"to\": [\"Steve <steve@me.com>\"],  \n\"date\": \"2024-01-26\",  \n\"subject\": \"How to build generative AI applications using Generic Company\nName\",  \n\"text\": \"Hey Steve! Generative AI is growing so quickly and we know you want\nto build fast!\"  \n},  \n{  \n\"from\": \"Paul Doe <paul_fake_doe@oracle.com>\",  \n\"to\": [\"Steve <steve@me.com>\", \"lisa@example.com\"],  \n\"date\": \"2024-04-09\",  \n\"subject\": \"Price Adjustment\",  \n\"text\": \"Re: our previous correspondence on 3/27 we'd like to make an\namendment on our pricing proposal. We'll have to decrease the expected base\nprice by 5%.\"  \n},  \n]  \n#Define which fields we want to include for the ranking:  \nrank_fields = [\"from\", \"to\", \"date\", \"subject\", \"body\"]  \n#To get all fields, you can also call: rank_fields = list(docs[0].keys())  \n# Define a query. Here we ask for the pricing from Mircosoft (MS).  \n# The model needs to combine information from the email\n(john_fake_mcgill@microsoft.com>)  \n# and the body  \nquery = \"What is the pricing that we received from MS?\"  \n#Call rerank, pass in the query, docs, and the rank_fields. Set the model to\n'rerank-english-v3.0' or 'rerank-multilingual-v3.0'  \nresults = co.rerank(query=query, documents=emails, top_n=2, model='rerank-\nenglish-v3.0', rank_fields=rank_fields)  \nprint(\"Query:\", query)  \nfor hit in results.results:  \nemail = emails[hit.index]  \nprint(email)  \n# Now we ask for the pricing from Oracle  \nquery = \"Which pricing did we get from Oracle\"  \n#Call rerank, pass in the query, docs, and the rank_fields. Set the model to\n'rerank-english-v3.0' or 'rerank-multilingual-v3.0'  \nresults = co.rerank(query=query, documents=emails, top_n=2, model='rerank-\nenglish-v3.0', rank_fields=rank_fields )  \nprint(\"Query:\", query)  \nfor hit in results.results:  \nemail = emails[hit.index]  \nprint(doc)  \n  \nview raw cohere_rerank_v3_json.py hosted with \u2764 by GitHub\n\n## Searching Over Tables\n\nTabular data like relational databases, CSVs, Excel plays a crucial role for\nmany enterprises. Retrieval models have previously struggled to search on this\ntype of data which limits enterprises from connecting to their most valuable\ndata sources for RAG.\n\nBelow is an example of the results when you search for \"Action movies with\nChristian Bale\" with an embedding model:\n\nThe top-result is about the movie War, which is an action movie, but without\nCristian Bale. Rerank 3 excels at tabular data search, leading to\nsignificantly improved search results:\n\nHave a look at this Search on Tabular Data notebook to see how Rerank 3 can\ntransform tables to JSON and then search on selected columns.\n\n## Learn More\n\nWe have an upcoming webinar with AWS focused on building enterprise search\napps powered by Rerank if you would like to register and learn more.\n\nKeep reading\n\nAidan Gomez \u2014 Apr 04, 2024\n\n## Introducing Command R+: A Scalable LLM Built for Business\n\n  * Newsroom\n  * Product\n\nRead full article\n\nJamie Linsdell, Elliott Choi \u2014 Mar 28, 2024\n\n## Cohere Embeddings Now Available Through Elastic\u2019s Inference API\n\n  * Product\n  * Developers\n\nRead full article\n\nDavid Stewart, Jamie Linsdell \u2014 Mar 28, 2024\n\n## Enterprise Search and Retrieval Demystified: A Guide for RAG Users\n\n  * For Business\n\nRead full article\n\nCohere \u00a9 2024\n\n", "frontpage": true}

{"aid": "40043997", "title": "Self-hosting on a Raspberry Pi cluster", "url": "https://savannahostrowski.com/posts/raspberry-pi-cluster/", "domain": "savannahostrowski.com", "votes": 2, "user": "pionar", "posted_at": "2024-04-15 18:25:34", "comments": 0, "source_title": "Self-hosting on a Raspberry Pi cluster", "source_text": "Self-hosting on a Raspberry Pi cluster | Savannah Ostrowski\n\n# Self-hosting on a Raspberry Pi cluster\n\nMoving all my personal websites to a Raspberry Pi cluster sitting in my home\noffice\n\nApril 6, 2024 \u00b7 7 min \u00b7 1289 words\n\nThis post is an overview of how I went off the grid \u2013 or, in other words,\nmoved all my personal websites off Azure and onto a Raspberry Pi cluster\nsitting in my home office. This isn\u2019t exactly a tutorial blog post, but feel\nfree to use this as a reference.\n\n## Why do this at all?#\n\nYou might be wondering, \u201cSavannah, why do this? Didn\u2019t you used to work on\nAzure tooling full-time?\u201d To which I\u2019d reply, \u201cYes, yes I did.\u201d But really,\nthis isn\u2019t about criticizing Azure or any other major cloud service provider.\nI simply enjoy physical computing, like to experiment, and also no longer\nreceive any free employee credits for Azure, so I thought, why not?\n\n## Meet Arrakis!#\n\nAlright, I might have had Dune on the brain when I built this, but Dune Part\nTwo is literally a masterpiece, so can you blame me? My little rig consists of\n3 Raspberry Pi 4Bs (each with 4 CPUs and 8 GB RAM), all running Raspberry Pi\nOS Lite (64-bit), which is a port of Debian Bullseye without a desktop\nenvironment. Each of these devices uses Power over Ethernet (PoE) for\nnetworking and power over a single cable per Pi. I\u2019ll delve into this a bit\nlater, but it\u2019s worth noting that the cluster doesn\u2019t run Kubernetes; instead,\nit leverages Docker Swarm to create the cluster (it\u2019s literally 2 commands to\nconfigure everything \u2013 mind blown!).\n\n### Materials for the build#\n\nI\u2019ll be candid \u2013 this wasn\u2019t cheap. Raspberry Pis are hot commodities, so it\ncost me a pretty penny to gather everything I needed for this build. I\u2019ll link\nwhat I bought, but do keep in mind that prices may vary. At the time of\nbuilding, this set me back approximately $506.67 USD.\n\nItem| Price (in USD)| Notes  \n---|---|---  \nC4Labs Cloudlet Case in Clear| $99.08| Though I\u2019m only building a 3 Pi cluster\nright now, this gives me some space to store the Switch or add additional Pis\nin the future  \nTP-Link TL-SG1005P, 5 Port Gigabit PoE Switch| $49.53  \nUCTRONICS PoE HAT for Raspberry Pi (3x)| $21.99  \n1.5-ft Ethernet cables (6 pack)| $16.99  \nRaspberry Pi 4 Model B 8GB (3x)| $82.71| Obviously, this is where I spent the\nmost money.  \nSanDisk Ultra 32GB Micro SD (3x)| $8.99  \nTotal| $506.67  \n  \nThat said, if you\u2019re following along, you may need a couple of other things\ndepending on what you have lying around at home, like a memory card reader for\nimaging the SD cards. Thankfully, I had one built into my USB dock, so this\nwas unnecessary.\n\n## Setting up the cluster#\n\n### Step 1: Image a micro SD card for each Pi#\n\nAfter assembling the cluster physically, it was time to sort out the software\nbits. First, I imaged each micro SD card with Raspberry Pi OS Lite using the\nRaspberry Pi Imager utility, and then I inserted each micro SD into each Pi. A\nvital step here is to remember to go into options and tick the box that allows\nyou to configure SSH with a password before imaging the SD cards.\n\n### Step 2: Install Docker \ud83d\udc33#\n\nThen, I waited for each of them to appear on my home network and grabbed their\nIP addresses and made note of which Pi had which IP address. After that, I\nssh\u2019d into each one and installed Docker using the official release (which\ngets updated more frequently than Docker distributed via distros...heck yes,\nMoby 26 is out!). I had 3 different terminal tabs opened while I was working\nso I could switch between them quickly.\n\n### Step 3: Create the cluster using Docker Swarm#\n\nI\u2019ll be honest \u2013 I initially planned to set up the cluster with Kubernetes via\nk3s, but boy howdy, that gave me so many problems right from the get-go. Also,\nit\u2019s a bit of a meme to host your blog on Kubernetes, so I quickly changed my\nplan and decided to use Swarm instead. Setting this up was truly magical, save\nfor one snag. Here\u2019s how it works:\n\n  * Choose one of your Pis to be your Swarm leader.\n  * Run docker swarm init in the Swarm leader\u2019s terminal.\n  * Copy the generated command and token (docker swarm join).\n  * Paste the docker swarm join command into the other Pi terminals.\n  * Boom! You have yourself a cluster \u2728\n\nSeriously, it\u2019s that simple! You can validate that everything is working as\nexpected using docker node ls on any of your nodes.\n\n> Note: I did run into one little snag with networking, where the default\n> network of the cluster overlapped 1:1 with my home network. I discovered\n> this much later when ingress was broken and I couldn\u2019t figure out why.\n> Before moving on, it might be worth verifying that this is not the case. If\n> it is, the fix is fairly simple. You\u2019ll just need to customize the ingress\n> network. Shout out to this StackOverflow post for helping me debug this!\n\n### Step 4: Write the docker-compose.yml for your services#\n\nTime to get to defining our services! In this case, I had two websites I\nwanted to host: 1) my personal website (where you\u2019re reading this post!) and\n2) an uber-professional website that\u2019s an inside joke.\n\nIf you\u2019re familiar with Docker, this part is quite straightforward. I had\nalready pushed my website images up to Docker Hub, so this was a pretty quick\noperation. The only Swarm-specific thing I needed to do is to tell Docker that\nI had a custom network called arrakis and then make sure that my services\nconnect to it.\n\n    \n    \n    services: savannahdev: image: \"savannahostrowski/savannah.dev\" ports: - \"8080:80\" networks: - arrakis deploy: mode: replicated replicas: 3 getshreked: image: \"savannahostrowski/getshreked\" ports: - \"8081:80\" networks: - arrakis deploy: mode: replicated replicas: 3 networks: arrakis: {}\n\nDeploying this Compose file is a single command using docker stack deploy\n--compose-file docker-compose.yml arrakis from the leader node. Once this\ncommand was run, I validated that the services were operational via docker\nstack services arrakis.\n\nAt this point, you should be able to hit the endpoints on any one of the\ncluster node IPs and see your website!\n\n### Step 5: Set up cloudflared as a service in the cluster#\n\nThe last bit here was to obfuscate my IP addresses and make this all\naccessible to the outside world via my chosen domains. If you thought the\ncluster setup was magic, just wait until you see how simple it was to set this\nbit up.\n\nThanks to CloudFlare, I\u2019m able to do this all via Tunnels \u2013 or, rather, a\nsingle Cloudflared tunnel in my case. This was really as easy as going to my\nCloudFlare dashboard, creating a tunnel, copying an installation command to\npaste into my leader node (sudo cloudflared service install <token>), creating\nanother service in my docker-compose.yml, and then redeploying the stack\n(docker stack deploy --compose-file docker-compose.yml arrakis).\n\n    \n    \n    services: savannahdev: image: \"savannahostrowski/savannah.dev\" ports: - \"8080:80\" networks: - arrakis deploy: mode: replicated replicas: 3 getshreked: image: \"savannahostrowski/getshreked\" ports: - \"8081:80\" networks: - arrakis deploy: mode: replicated replicas: 3 cloudflared: image: \"cloudflare/cloudflared\" command: \"tunnel --no-autoupdate run --token <my-token-here>\" deploy: restart_policy: condition: on-failure mode: replicated replicas: 3 networks: - arrakis networks: arrakis: {}\n\nThe last bit here is to configure your public hostnames. In my case, I had one\nfor each website I was deploying. What\u2019s really neat is that you just have to\npass in the service name:port (where service name matches the Compose service\nname and port matches your port internal to the container) for it to all work.\n\n## Bonus: Set up Tailscale for easy access to my cluster nodes#\n\nThis isn\u2019t required but I also took advantage of Tailscale\u2019s free tier (up to\n100 devices!) for easy access to my cluster nodes.\n\nAnd that\u2019s pretty much it! Hopefully you found this sort of fun - I sure did!\n\nThis website is hosted on a Raspberry Pi cluster running in my home office \u2764\ufe0f\n\n", "frontpage": false}

{"aid": "40044044", "title": "MathGPT: Llama 2 and highly personalized learning", "url": "https://ai.meta.com/blog/llama-2-mathgpt-mathpresso-qanda-upstage-open-source-llm/", "domain": "meta.com", "votes": 1, "user": "tosh", "posted_at": "2024-04-15 18:29:41", "comments": 0, "source_title": "Leveraging Llama 2 to create a platform for highly personalized learning", "source_text": "Leveraging Llama 2 to create a platform for highly personalized learning\n\nResearch\n\nBlog\n\nResources\n\nAbout\n\nResearch\n\nBlog\n\nResources\n\nAbout\n\nLarge Language Model\n\nMathGPT: Leveraging Llama 2 to create a platform for highly personalized\nlearning\n\nApril 15, 2024\n\nBreakthroughs in AI have the potential to benefit the global community\u2014if more\npeople have the education and access to leverage them. As STEM education\nremains a critical factor in economic mobility and innovation, Mathpresso is\ndoing its part with its learning platform QANDA, which has made personalized\nlearning content accessible to people across 50 countries. When the Seoul-\nbased company set out to create a highly accurate math-specific LLM with\nleading Korean AI startup Upstage, Meta\u2019s open-source model Llama 2 was a\nfitting choice.\n\n\u201cOur primary focus has been mathematics,\u201d says Mathpresso Co-Founder Jake\nYongjae Lee, who adds that QANDA is best-suited for subjects that are\ntypically taught with a structured curriculum, like lectures and practice\nproblem sets. However, he says, \u201dCommercial LLMs like ChatGPT lack the\ncustomization needed for the complex education landscape.\u201d\n\nAccording to Lee, student learning is influenced by hyperlocal factors\nincluding curriculum, school district, exam trends, teaching style, and more.\nThrough that complexity, Llama 2 is helping Mathpresso envision a world in\nwhich everyone has access to quality education.\n\nWith an open-source model like Llama 2, the team could create flexible,\ndomain-specific educational products while fully utilizing their own\nspecialized data and techniques. The result is MathGPT, an LLM with powerful,\naccurate math capabilities that uses Llama 2 as a base model. Upstage handles\nthe model\u2019s engine and fine-tuning, while Mathpresso and QANDA contribute\nspecialized mathematical data for model learning.\n\nEarlier this year, MathGPT set a new world record in benchmarks assessing\nmathematical performance at both the primary and secondary school level.\n\nHelping students deepen math comprehension with MathGPT\n\nMathpresso started by training smaller models and gradually moved on to larger\nones to test their performance in mathematics. In the process, the team used\ndata generated from the larger models to train other models, finding that\nmethodologies applied to the smaller models also worked effectively in the\nlarger models. Today, the team is using Llama 2 to build a fine-tuned model\nbased on QANDA\u2019s own mathematical data, generating training data through\nsupervised fine-tuning and data augmentation.\n\nWhat sets MathGPT apart is its focus on fostering students\u2019 comprehension of\nthe solution process rather than merely providing answers to math problems. As\na result, it provides detailed explanations that are also broken down into\nstep-by-step procedures, helping cultivate a deeper level of understanding\ncompared to typical explanations.\n\nThe Mathpresso team conducts full fine-tuning using data collected from the\nQANDA platform. Since that data usually exists as pairs of problems and their\nsolutions, the training process involves presenting the model with a question\nand training it to generate a correct answer. This data is proprietary to\nQANDA, so the team concluded that using an open-source model was preferable to\na closed-source or hosted model, because it allowed them to retain control of\ntheir own data.\n\nMathpresso needed a model with exceptional capability in interpreting\nmathematical expressions. To that end, selectively incorporating data\nspecialized in mathematical expressions strengthened Llama 2\u2019s laTeX document\npreparation system expression.\n\nOutperforming on the Open LLM leaderboard\n\nFor Upstage, the Llama journey began with its pursuit of a versatile language\nmodel that could excel in English and other languages, like Korean, and\nseamlessly adapt to various company needs. To measure progress, it targeted\nthe top spot on HuggingFace\u2019s Open LLM Leaderboard, aiming to surpass\nGPT-3.5\u2019s benchmark score. After considering BERT-based models, Upstage\ndiscovered academic papers demonstrating that Llama 2 offered higher benchmark\nperformance.\n\n\u201cTo create a champion language model for the Open LLM Leaderboard, we needed a\nstrong starting point\u2014that\u2019s where Llama 2 came in,\u201d says Upstange CEO Sung\nKim. \u201cAs a top performer and the go-to choice in the open-source LLM world,\nLlama 2 was the perfect foundation for our project.\u201d\n\nThe company first used Llama 2 for fine-tuning to compete on the leaderboard,\nwhich involved adjusting an existing model to excel on that benchmark. Its\nLlama2-70b model successfully moved up to the number one position, making\nUpstage the first company globally to outperform GPT-3.5 on the Open LLM\nLeaderboard.\n\nNext, Upstage leveraged a smaller version, Llama2-7b, for research on Korean\nlanguage support and to develop its own foundation model. This allowed for the\nexploration of Korean capabilities and the building of a customized base\nmodel. The company adopted the Llama 2 architecture as its default because of\nits widespread support in open-source libraries.\n\nSince then, the company\u2019s work with Mathpresso, which was part of a strategic\npartnership with telecom giant KT, resulted in the MathGPT record. Upstage\nalso developed its first pre-trained LLM, SOLAR-10.7B (short for Specialized\nand Optimized LLM and Applications with Reliability),which also topped the\nOpen LLM Leaderboard last December. Compared to larger models with hundreds of\nbillions of parameters, Solar is a lightweight model with fewer than 20\nbillion parameters. Because it uses a smaller training dataset, the model can\nrun inference at lower costs and about 2.5 times faster than GPT-3.5.\n\n\u201cWe wouldn\u2019t have been able to achieve this rapid rise if Llama 2 hadn\u2019t been\nreleased as an open-source model,\u201d says Kim. \u201cOur story exemplifies the power\nof open source for rising generative AI startups.\u201d\n\nLlama 2\u2019s real-world open-source impact on education\n\nFor Mathpresso, making 1:1 personalized education available for everyone\nthrough an AI tutor has been a long-standing goal.\n\n\u201cThrough the QANDA platform, we have been able to meticulously collect and\ndigitize unique data on each student\u2019s learning path and needs,\u201d says Lee.\n\u201cWith open-source models like Llama 2, we have the flexibility to create\naffordable educational tools that leverage our unique insights, helping\nstudents worldwide to reach their fullest potential.\u201d\n\nBoth Mathpresso and Upstage believe that open-source models like Llama 2 can\nprofoundly impact companies, large and small.\n\n\u201cAccess to cutting-edge open-source tools and libraries can level the playing\nfield,\u201d says Kim, \u201cenabling organizations to leverage advanced technologies\nand methodologies that may otherwise be out of reach.\u201d\n\nShare:\n\nOur latest updates delivered to your inbox\n\nSubscribe to our newsletter to keep up with Meta AI news, events, research\nbreakthroughs, and more.\n\nJoin us in the pursuit of what\u2019s possible with AI.\n\nSee all open positions\n\nRelated Posts\n\nComputer Vision\n\nIntroducing Segment Anything: Working toward the first foundation model for\nimage segmentation\n\nApril 5, 2023\n\nRead post\n\nFEATURED\n\nResearch\n\nMultiRay: Optimizing efficiency for large-scale AI models\n\nNovember 18, 2022\n\nRead post\n\nFEATURED\n\nML Applications\n\nMuAViC: The first audio-video speech translation benchmark\n\nMarch 8, 2023\n\nRead post\n\nWho We Are\n\nAbout\n\nPeople\n\nCareers\n\nEvents\n\nLatest Work\n\nResearch\n\nInfrastructure\n\nBlog\n\nResources\n\nOur Actions\n\nResponsibilities\n\nNewsletter\n\nSign Up\n\nWho We Are\n\nWho We AreAboutPeopleCareersEvents\n\nLatest Work\n\nLatest WorkResearchInfrastructureBlogResources\n\nOur Actions\n\nOur ActionsResponsibilities\n\nNewsletter\n\nNewsletterSign Up\n\nPrivacy Policy\n\nTerms\n\nCookies\n\nMeta \u00a9 2024\n\nAllow the use of cookies from Meta on this browser?\n\nWe use essential cookies and similar technologies to help:\n\nProvide and improve content on Meta Products\n\nProvide a safer experience by using information we receive from cookies on and\noff Meta Products\n\nProvide and improve Meta Company Products for people using a Meta or Oculus\naccount\n\nWe use tools on Meta from other companies that also use cookies. These tools\nare used for things like:\n\n  * Advertising and measurement services off of Meta Products\n  * Analytics\n  * Providing certain features\n  * Improving our services\n\nYou can allow the use of all cookies, just essential cookies or you can choose\nmore options below. You can learn more about cookies and how we use them, and\nreview or change your choice at any time in our Cookie Policy.\n\nEssential cookies\n\nThese cookies are required to use Meta Company Products. They\u2019re necessary for\nMeta websites to work as intended.\n\nOptional cookies\n\nOptional cookies from other companies\n\nWe use tools from other companies for advertising and measurement services off\nof Meta Company Products, analytics, and to provide certain features and\nimprove our services for you. These companies also use cookies.\n\nIf you allow these cookies:\n\n  * We\u2019ll be able to better personalize ads for you off of Meta Products, and measure their performance\n  * Features on our products will not be affected\n  * Other companies will receive information about you when you use cookies\n\nIf you don\u2019t allow these cookies:\n\n  * We won\u2019t use cookies from other companies to help personalize ads for you off of Meta Products or measure ads performance\n  * Some features on our products may not work\n\nOther ways you can control tracking\n\nAd settings\n\nIf you have added your Meta or Oculus account to the same Accounts Center as\nyour Facebook or Instagram account, you can manage how different data is used\nto personalize ads in ad settings. To show you better ads, we use data that\nadvertisers and other partners provide us about your activity off Meta Company\nProducts, including websites and apps. You can control whether we use this\ndata to show you ads in your ad settings.\n\nThe Facebook Audience Network is a way for advertisers to show you ads in apps\nand websites off the Meta Company Products. One of the ways Audience Network\nshows relevant ads is by using your ad preferences to determine which ads you\nmay be interested in seeing.\n\nAd preferences\n\nIn Ad preferences, you can choose whether we show you ads and make choices\nabout the information used to show you ads.\n\nYou can opt out of seeing online interest-based ads from Meta and other\nparticipating companies through the Digital Advertising Alliance in the US,\nthe Digital Advertising Alliance of Canada in Canada or the European\nInteractive Digital Advertising Alliance in Europe, or through your mobile\ndevice settings, if you are using Android, iOS 13 or an earlier version of\niOS. Please note that ad blockers and tools that restrict our cookie use may\ninterfere with these controls.The advertising companies we work with generally\nuse cookies and similar technologies as part of their services. To learn more\nabout how advertisers generally use cookies and the choices they offer, you\ncan review the following resources:\n\n  * Digital Advertising Alliance\n  * Digital Advertising Alliance of Canada\n  * European Interactive Digital Advertising Alliance\n\nYour browser or device may offer settings that allow you to choose whether\nbrowser cookies are set and to delete them. These controls vary by browser,\nand manufacturers may change both the settings they make available and how\nthey work at any time. As of 5 October 2020, you may find additional\ninformation about the controls offered by popular browsers at the links below.\nCertain parts of Meta Products may not work properly if you have disabled\nbrowser cookies. Please be aware these controls are distinct from the controls\nthat Instagram and Facebook offer.\n\n  * Google Chrome\n  * Internet Explorer\n  * Firefox\n  * Safari\n  * Safari Mobile\n  * Opera\n\n", "frontpage": false}

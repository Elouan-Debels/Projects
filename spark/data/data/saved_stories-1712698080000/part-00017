{"aid": "39979709", "title": "Technology Changes Our Concept of the Self", "url": "https://www.edge.org/conversation/peter_galison-how-technology-changes-our-concept-of-the-self", "domain": "edge.org", "votes": 1, "user": "andsoitis", "posted_at": "2024-04-09 14:19:37", "comments": 0, "source_title": "How Technology Changes Our Concept of the Self", "source_text": "How Technology Changes Our Concept of the Self | Edge.org\n\nSkip to main content\n\nCopyright \u00a9 2024 By Edge Foundation, Inc. All Rights Reserved.\n\nEdge.org\n\nTo arrive at the edge of the world's knowledge, seek out the most complex and\nsophisticated minds, put them in a room together, and have them ask each other\nthe questions they are asking themselves.\n\nhttps://www.edge.org/conversation/peter_galison-how-technology-changes-our-\nconcept-of-the-self Printed On Tue April 9th 2024\n\n# How Technology Changes Our Concept of the Self\n\nConversation : TECHNOLOGY\n\n# How Technology Changes Our Concept of the Self\n\nA Conversation with Peter Galison [11.20.18]\n\nThe general project that I\u2019m working on is about the self and technology\u2014what\nwe understand by the self and how it\u2019s changed over time. My sense is that the\nself is not a universal and purely abstract thing that you\u2019re going to get at\nthrough a philosophy of principles. Here\u2019s an example: Sigmund Freud\nconsidered his notion of psychic censorship (of painful or forbidden thoughts)\nto be one of his greatest contributions to his account of who we are. His\nthoughts about these ideas came early, using as a model the specific\ntechniques that Czarist border guards used to censor the importation of\npotentially dangerous texts into Russia. Later, Freud began to think of the\ncensoring system in Vienna during World War I\u2014techniques applied to every\nletter, postcard, telegram, and newspaper\u2014as a way of getting at what the mind\ndoes. Another example: Cyberneticians came to a different notion of self,\naccessible from the outside, identified with feedback systems\u2014an account of\nthe self that emerged from Norbert Wiener\u2019s engineering work on weapons\nsystems during World War II. Now, I see a new notion of the self emerging; we\nstart by modeling artificial intelligence on a conception of who we are, and\nthen begin seeing ourselves ever more in our encounter with AI.\n\nPETER GALISON is the Joseph Pellegrino University Professor of the History of\nScience and of Physics at Harvard University and Director of the Collection of\nHistorical Scientific Instruments. Peter Galison's Edge Bio Page\n\nHOW TECHNOLOGY CHANGES OUR CONCEPT OF THE SELF\n\nWhen people talk about abstract ideas, they\u2019re referring to something very\nconcrete, and when I can find a way to address something that\u2019s very broad\nthrough something specific and tangible that\u2019s right there now or right there\nthen, it interests me. This is how I understand abstract ideas, whether in\ntheoretical physics or philosophy. What appears at first as fully ethereal is\noften, in fact, grounded in something particular. When people start a debate\nabout time, or freedom, or secrecy, or objectivity, I want to know what\nspecific things and actions they are talking about.\n\nThe general project that I\u2019m working on is about the self and technology\u2014what\nwe understand by the self and how it\u2019s changed over time. My sense is that the\nself is not a universal and purely abstract thing that you\u2019re going to get at\nthrough a philosophy of principles. Here\u2019s an example: Sigmund Freud\nconsidered his notion of psychic censorship (of painful or forbidden thoughts)\nto be one of his greatest contributions to his account of who we are. His\nthoughts about these ideas came early, using as a model the specific\ntechniques that Czarist border guards used to censor the importation of\npotentially dangerous texts into Russia. Later, Freud began to think of the\ncensoring system in Vienna during World War I\u2014techniques applied to every\nletter, postcard, telegram, and newspaper\u2014as a way of getting at what the mind\ndoes. Another example: Cyberneticians came to a different notion of self,\naccessible from the outside, identified with feedback systems\u2014an account of\nthe self that emerged from Norbert Wiener\u2019s engineering work on weapons\nsystems during World War II. Now, I see a new notion of the self emerging; we\nstart by modeling artificial intelligence on a conception of who we are, and\nthen begin seeing ourselves ever more in our encounter with AI.\n\nDifferent ages have had different concepts of the self, organized around what\nyou might broadly think of as technology; for example, as I mentioned, the\ntechnology of maintaining a government lock on censorship in the time of\nFreud, when they began censoring letters\u2014I want to know how letters,\ntelegrams, newspapers, and magazines got their black (or white) blocked-out\nareas. I want to know how Freud reacted to this blocking of knowledge, how he\nbegan to reshape what he thought the mind was up to when it imposed its own\nblackout at the borders, so to speak, between the territories of the\nunconscious and pre-conscious or the pre-conscious and the conscious.\nDangerous thoughts, he argued, arrived like couriers bearing potentially\ndangerous letters at the censor-guards of our internal mental border controls.\n\nI\u2019ve been interested, too, in the transformation that occurs during and just\nafter World War II. Norbert Wiener and his colleagues and successors pursued a\nnew kind of picture of the self that was based on very concrete experiences\nthat people had with World War II technology. Early in the war, it looked like\nthe Germans were going to bomb the hell out of England, destroy their air\ndefenses, and wreck their industry. If they could destroy the British fighter\njets and bomb their central production and population centers around\nfactories, they thought they could invade Britain, and it would have been the\nend of World War II. The United States would have had no foothold in Europe.\nIt would have transformed the world.\n\nNorbert Wiener knew he had to get involved, so he began to think about how we\nwere going to shoot down these bombers. He began to think about learning in a\ndifferent kind of way. Norbert Wiener said at the beginning of World War II,\n\"The physicists are not going to save us, not in the short term, not in this\nperiod of the Battle of Britain. We need people who understand\ntelecommunications, people who understand this new concept of information, not\nabstract physics ideas about signal-to-noise ratios. We need a concrete\nunderstanding of time series of data so we can make a machine that can learn\nthe way a German bomber pilot is moving his aircraft around in the sky, so the\ntracking machine can anticipate where the plane will likely be seven or eight\nseconds in the future. Only with that knowledge could the anti-aircraft\nbatteries put a shell there and destroy the airplane.\"\n\nThe problem was that you couldn't shoot it where the airplane was, you had to\nshoot it 10,000, 12,000 feet in the sky or higher, and you\u2019d have to loft a\nshell that was going to be where the plane was going to go. You could make a\nlinear extrapolation of the plane\u2019s general direction, but that doesn\u2019t tell\nyou if a particular pilot is jinking left and right in certain patterns. So,\nWiener thought to make a machine that learns how that particular pilot\nmoves\u2014obviously, you can\u2019t ask the pilot about intention. The Luftwaffe pilot\nwas most certainly not going to tell you and might not even know precisely how\nto characterize his future actions. The machine has to figure it out from the\nradar traces of recent past behaviors.\n\nWiener did make that learning machine, though the project never completely\nsucceeded. He was able to anticipate around two seconds into the future, but\nhe needed to do much more to make an effective weapon. It taught an incredibly\nnew lesson to people, which is that even in the absence of any concrete\nunderstanding of the interior life of, say, bomber pilots, just by their\nexterior actions, you could anticipate what they would do in the future and,\nin this case, send a projectile up to shoot the plane down.\n\nWiener used his experience of designing the \"predictor\" as he folded back the\nideas to re-describe, in feedback black-box style, how the anti-aircraft\noperators would work. Wiener and his successors after the war began to think\nabout other actions, about the way we guide our hands\u2014proprioceptively fed-\nback motions where we know where our hand is as it converges onto the coffee\ncup that we intend to lift. Instead of thinking of the self as some abstract\nmental category floating in a vacuum, these were concrete problems of figuring\nout how machines could anticipate shifted attention to inputs and outputs, to\nstatistical characterization and prediction. Intention (in the cybernetic\nreading) became nothing else than goal-directed feedback process.\n\nCybernetics was\u2014as I see it\u2014a transformative moment in our understanding of\nthe human self. I want to look at this black box anticipatory function of\ncybernetics that represented what I think of as the fundamental shift of\nmachine learning, cybernetics, and the self. We are now, I believe, in another\nphase of this series of transformations of the self, again in ways that go\nback and forth between how we see the self and the technology that surrounds\nus. What do we understand intelligence to be such that we want to form\nartificial versions of it? Then: we face AI everywhere from assistance in\nwriting personal letters and responses to daily questions... all the way to\nalgorithmic sentencing and the formation of scientific conclusions.\n\nMany of us writing for and with Edge have been concerned about the future of\nAI. My biggest proximate concern about AI tends to focus, unsurprisingly\nperhaps, on the concrete aspects: job displacement, contributing to an ever-\ngrowing societal inequality\u2014that worries me hugely. My secondary concern is\nthat in the multi-layered neural networks, we are ever less able to extract\nthe reasoning process behind decisions that bear on judgments about law or for\nthat matter, science. Far below these concerns (for me) fall the nightmarish\nimagined scenarios of swarms of killer nanobots\u2014I am less worried by what seem\nto me rather implausible outcomes. But the proximate future, one that might\ndisplace millions of workers from their jobs (like driving), one where\njudicial sentencing is more dependent on AI algorithms, autonomous weapons\nthat are supposed to distinguish, willy-nilly, friend from foe... well, these\nthings could tip anger and grievance into an even worse political landscape\nthan we face today.\n\nBack to our main theme: I want to know how, in the early 20th century, in the\nmidst and aftermath of World War II, then turn of the 21^st century, our\nnotions of the self make certain technologies seem possible and desirable; and\nreciprocally how our technologies then act back on what we consider the self\nto be.\n\nLet me give another example of the materiality of abstraction\u2014from a\ncompletely different sector of work. Like many others, I\u2019ve been fascinated by\nthe Enlightenment, the 18^th century, which is often described in these purely\nintellectual terms and almost always European terms\u2014an idea of the\nintelligibility of nature and its functions. An ode, so to speak, to the\nprimacy of reason. And yet it is a little hard for me to understand in those\nterms. Recently, we had an exhibit at the Fogg Art Museum called \"The\nPhilosophy Chamber\" (an actual wood-paneled room) that assembled teaching,\nlearning, theology, and scientific work in 18^th-century Harvard. I wanted to\ndo something for that. I run a small museum (The Collection of Historical\nScientific Instruments) collection that began with the assembly of instruments\nby Benjamin Franklin and others in the 1770s. We lent some of these brass and\nglass telescopes, microscopes and orreries that were used to represent, teach,\nand probe our understanding of the known world.\n\nThe curators and scholars who were mounting the exhibit asked me whether I\ncould write an essay, but I had an idea for a film, so I said I'd make a film.\nThe way that people in the 18^th century and 17^th and 16^th century\nunderstood things was often through the ancestral form of what now appears as\ncollegiate debate. Except, back in the 18^th century they were different kinds\nof things, not mere entertainment and competition, but instead a test probe of\nknowledge itself. In the mid- to-late 18^th century there was a new form of\nthis called a forensic disputation. This new form of disputation went far\nbeyond the older, strictly structured and purely logical syllogistic\ndisputations of earlier times\u2014syllogism is, for example, all men are mortals,\nSocrates is a man, therefore, Socrates is mortal\u2014and this new form of\ndisputation allowed you to use the full gamut of argumentation, of pathetic\n(emotional) arguments, reductio arguments, analogies, ethical considerations;\nimportantly, they were in English not Latin, very often on topics of immediate\npolitical interest (not only biblical or classical subjects). I thought at\nfirst that I'd find some debate, some of these disputations from overseas,\nperhaps Germany or Britain. Then I wondered... well, maybe there\u2019s one that\nsurvives from Harvard in the 1770s. It turns out there were hundreds of\ntitles, but one, and only one, verbatim disputation.\n\nThat one debate that survives completely intact was published\u2014and there are\neven traces of it in then archives. It's called A Forensic Dispute on the\nLegality of Enslaving the Africans, about whether it\u2019s compatible with what\nthey call natural law. Here was a chance to see how the urgent question of\nslavery was addressed in the turbulent moment. It was July 21, 1773, right on\nthe eve of the American Revolution, at Harvard. People came from far and wide\nto see this public dispute between two graduating seniors, one of whom went on\nto become the president of Harvard from 1804 to 1806. His name was Eliphalet\nPearson, a mountain of a man, a bully, a martinet. People were frightened of\nhim\u2014the students, even his colleagues were intimidated by him and disliked him\nintensely. Some called him \"Elephant\" behind his back, others, later, dubbed\nhim \"Megalonyx\" after an extinct prehistoric mammoth-like beast found by\nJefferson. His opponent was a brilliant young man named Theodore Parsons who\nhelped found the American Academy of Arts and Sciences.\n\nBoth Eliphalet and Theodore grew up Newburyport, just north of Boston, and had\nknown each other since childhood, and they were graduating in the same class.\nSo, they were assigned probably the two sides, and, remarkably, we have in\ndetail what they said. Using their words, I wrote this into a back-and-forth,\nand then had hovering in the present of this a third person\u2014the completely\nremarkable young woman named Phillis Wheatley, a famous poet who was kidnapped\nand enslaved at the age of eight\u2014sold into slavery in Boston about three miles\nfrom Harvard Yard. She became a fantastically well-known poet and began\nwriting and publishing. When she was fourteen she learned English, Greek,\nLatin, astronomy. In 1773, her book came out just about the same time as these\ntwo boys\u2019 book. They\u2019re all the same age, all twenty-one years old. I wrote\nthis into a short play and filmed it with three young actors (undergraduates\nat Harvard) from the American Repertory Theater. I was delighted to be able to\nwork with Henry Louis Gates as a collaborator on direction\u2014he had written a\nterrific book that I have long admired about this founder of African-American\nliterature, The Trials of Phillis Wheatley.\n\nSo, this is a way of trying to make concrete a kind of turning point moment in\nhistory where they were talking about the Enlightenment and what the limits of\nliberty were. How did university arguments actually proceed when the stakes\nwere high? Could America have liberty and slavery? Whose liberty would it be?\nThese young people, smart, articulate, inexperienced, bent around sometimes by\ntheir own words, were trying to sort out this question\u2014the role of democracy\nand freedom, Christianity and slavery. It is the kind of specific engagement I\nwant to help make clear arguments in formation, the standards and forms of how\none could speak with what kinds of tools. When the film and the accompanying\narticle were done, the short, \"No More, America,\" went up on a large wall (the\nLight Box) in the Fogg, then it traveled to the Hunterian Museum in Glasgow.\nPeople often don\u2019t realize that two percent of the population in Massachusetts\nwas enslaved in the 1760s. The specificity of a now-archaic form of\ndisputation, the concreteness afforded by film, the way spoken disputation\nsounds\u2014the words of particular 18^th-century young people grappling with these\nquestions\u2014is an example of how film, through sound and image, has a way of\ngetting at the concrete specificity I am after.\n\n## What's Related\n\n### People\n\nPeter Galison\n\nJoseph Pellegrino University Professor, Director,...\n\n## Audio\n\n[11.20.18]\n\n## Beyond Edge\n\nPeter Galison's Harvard University Page\n\n\"Containment\" Film Page\n\n\"Secrecy\" Film Page\n\n## Books\n\nImage and Logic: A Material Culture of...By Peter Galison Paperback  \n---  \n  \n## Tags\n\nAI\n\ncybernetics\n\nNorbert Wiener\n\nself\n\ntechnology\n\n## Conversations at Edge\n\nEpistemic Virtues[8.21.19]  \n---  \nEINSTEIN AND POINCARE[6.22.03]  \n  \nJohn Brockman, Editor and Publisher\n\n  * Contact Info:editor@edge.org\n  * In the News\n  * Get Edge.org by email\n\nEdge.org is a nonprofit private operating foundation under Section 501(c)(3)\nof the Internal Revenue Code. Copyright \u00a9 2023 By Edge Foundation, Inc All\nRights Reserved.\n\nclose\n\n", "frontpage": false}

{"aid": "40044649", "title": "They're Looting the Internet", "url": "https://www.wheresyoured.at/the-great-looting-of-the-internet/", "domain": "wheresyoured.at", "votes": 13, "user": "cdme", "posted_at": "2024-04-15 19:23:36", "comments": 3, "source_title": "They're Looting The Internet", "source_text": "They're Looting The Internet\n\nLog In Subscribe\n\nSign up Sign in\n\nLog in Subscribe\n\n# They're Looting The Internet\n\nEdward Zitron Apr 15, 2024 19 min read\n\nLast week, Meta revealed (in a motion trying to dismiss an FTC anti-monopoly\nlawsuit) that Instagram made an astonishing $32.4 billion in advertising\nrevenue in 2021. That figure becomes even more shocking when you consider\nGoogle's YouTube made $28.8 billion in the same period. Bloomberg reports that\nthe app made almost 30% of Meta's entire revenue in the early part of 2022.\n96% of Meta's $40.1 billion Q4 2023 revenue came from advertising, and it\u2019s\nmade over a hundred billion dollars a year since 2021, a trend it\u2019s likely to\ncontinue based on the fact that the only thing these platforms care about is\nrevenue numbers increasing. Google made $86.3 billion in Q4 2023, with $48\nbillion of that coming from Google Search and related advertising, up 13% from\nthe previous quarter.\n\nIn America, 83% of adults use YouTube, 68% of them use Facebook and 47% of\nthem use Instagram. Each platform boasts over two billion users and, over the\nlast three years, Meta and Google have made over half a trillion dollars in\nrevenue from advertising on these platforms.\n\nI now want you to go on Facebook, scroll down, and see how quickly you hit an\nadvertisement. In my case, after one post from a friend, I was immediately hit\nwith an advertisement for some sort of food supplement, then a series of\nreels, then a suggested group called \"Walt Disney Magic,\" followed by an ad,\nfollowed by a post from a friend.\n\nOn Instagram, I saw one post from a person I followed, followed by an ad for\nthe same food supplement, followed by two posts from people I followed,\nfollowed by another ad. When I clicked an Instagram story, I saw one post from\nmy friend before an ad for the very same food supplement, another two posts\nfrom a friend, and then an ad for a game that features a regular trope of the\ngenre \u2014 footage of gameplay that isn't actually in the game.\n\nWhen I went to YouTube, my first result was an 11-minute-long Taiwanese news\nvideo and another video that appears to be in Chinese. In fact, several of the\nvideos on the front of YouTube were in Chinese. I went to Google \"why are my\nYoutube videos in Chinese\" and the first result was a Reddit post where\nseveral users were, for whatever reason, being served random videos in\nChinese. Researching the beginning of this article took me about 30 minutes,\nbecause every time I googled something \u2014 like what percentage of web traffic\ngoes to Google \u2014 I kept being given \"authoritative\" sources like \"Forbes\nAdvisor\" (the affiliate marketing arm of Forbes with nothing to do with the\nmagazine) with sources ranging from \"Blogging Wizard\" to a literal list of\nwebsite names, with no actual links.\n\nThis is the state of the modern internet \u2014 ultra-profitable platforms outright\nabdicating any responsibility toward the customer, offering not a \"service\" or\na \"portal,\" but cramming as many ways to interrupt the user and push them into\ndoing things that make the company money. The greatest lie in tech is that\nFacebook and Instagram are for \"catching up with your friends,\" because that's\nno longer what they do. These platforms are now pathways for the nebulous\nconcept of \"content discovery,\" a barely-personalized entertainment network\nthat occasionally drizzles people or things you choose to see on top of\nsponsored content and groups that a relational database has decided are \"good\nfor you.\"\n\nOn some level, it's hard to even suggest we use these apps. The term \"use\"\nsuggests a level of user control that Meta has spent over a decade destroying,\nturning Instagram and Facebook into tubes to funnel human beings in front of\nthose who either pay for the privilege of visibility or have found ways to\ntrick the algorithms into showing you their stuff.\n\nIt's the direct result of The Rot Economy, a growth-at-all-costs mindset built\noff the back of immovable monopolies where tech companies profitably punish\nusers as a means of showing the markets eternal growth. In practice, this\nmeans twisting platforms from offering a service to driving engagement, which,\nin Facebook and Instagram's case, meant finding the maximum amount of\ninterruptions that a user will tolerate before they close the app. In Google's\ncase, it meant making changes to search that made advertisements and sponsored\nlinks significantly harder to differentiate from \"real\" search results and\nallowing the quality of search results to decay to the point that users now\nrely on TikTok and Reddit instead.\n\n> Hi! Please download and listen to my weekly podcast Better Offline. Last\n> week's episode was the best yet - a two-parter covering the four intractable\n> problems holding back AI, and how the AI bubble might burst.\n\n## The Rot Machine\n\nUnderpinning these ultra-profitable torture-machines is an online\nadvertisement industry built off the back of fucking advertisers and users\nalike. In the mid-2010s, Facebook \"mistakenly\" told online publishers that\ntheir videos were receiving more engagement than they actually did, leading\nmultiple publishers to \"pivot to video,\" a disastrous industry movement that\ncost hundreds of reporters their jobs and led to a massive class action suit\nagainst Meta. Meta is currently the subject of a class action suit led by\nMetroplex Communications, which claims that Meta\u2019s inflated metrics lured\nadvertisers away from competing platforms \u2014 something it\u2019s been sued for\nbefore.\n\nWhen you align your incentives around \"bigger\" and \"more,\" you'll take just\nabout anybody's money \u2014 like advertisers comparing the COVID-19 vaccine to the\nholocaust, quack doctors and their phony cancer treatments, scammers selling\ncounterfeit fishing equipment, scammers offering fake discounts for puzzles,\nand cryptocurrency cons. An investigation from late last year found that a\nthird of advertisements on Facebook Marketplace in the UK were scams, and\nearlier in the year UK financial services authorities said it had banned more\nthan 10,000 illegal investment ads across Instagram, Facebook, YouTube and\nTikTok in 2022 \u2014 a 1,500% increase over the previous year.\n\nAs the platforms begin to decay, things only get worse for the user. Elon\nMusk's acquisition of Twitter (and outright hostility toward blue chip\nadvertisers) has turned it into the digital equivalent of Downtown Vegas, with\nseemingly every post replied to by a bot offering \"NUDES IN BIO,\" something\nthat's pretty funny until you realize they're a front for a series of online\ndating scams. Musk selling \"verification\" for eight dollars has allowed\ncryptocurrency scammers to make millions tricking users into connecting their\nwallets to fund-draining smart contracts, and they're even buying ads on the\nplatform to do so using stolen credit cards. Musk's desperation for ad revenue\nhas even led Twitter to start pushing ads that don't actually say they're ads,\nleading to advertising watchdog Check My Ads filing a formal complaint with\nthe FTC demanding that it investigates Twitter and enforces its Truth In\nAdvertising standards.\n\nYet it's foolish to act as if the sorry state of Twitter is entirely different\nto that of the rest of the web. Instagram is flooded with its own porno bots\nthat engage with regular posts (through likes and replies) as a means of\npretending they're real to avoid Meta's automated content moderation measures,\nwhich mostly rely on a combination of automation and thousands of contractors\nin countries like Kenya who make as little as $2.20 an hour to view what WIRED\ncalls \"the most hideous content on the internet.\"\n\nMeta is \u2014 much like every other major tech firm \u2014 half-assing their approach\nto moderation, committing human rights violations so that it can spend the\nsmallest amount of money possible to stop the things it needs to stop while\nfailing to maintain any consistent level of quality on the platform. As you'd\nexpect, these lax standards have led to Facebook being flooded with content\ncreated with generative AI, with a study out of Stanford and Georgetown\nrevealing how Facebook's algorithm is boosting spam content riddled with\nmisinformation, sending hundreds of millions of impressions to pages that\ndirect people to Wordpress sites crammed full of spammy and scammy ads.\n\nYet perhaps the most obvious sign of digital decay is visiting most websites\non a smartphone. IGN.com, a gaming website with over 300 million monthly\nviews, immediately hits you with two giant ads, and on opening a story about\nthe new Fallout TV show, covers the top quarter of your screen with an\nautoplaying video ad.\n\nReach PLC \u2014 a publicly-traded, multi-million dollar business that dominates\nlocal journalism in the UK, and owns three of the most widely-read national\nnewspapers \u2014 is notorious for its aggressive approach to monetization. Its\nwebsites have been described as an \u201cover-monetised mess\u201d and \u201cimpossible to\nnavigate,\u201d with the \u201cpoor digital experience\u201d named as a partial contributor\nto its declining financial fortunes. If you open a local UK news website\n(especially one owned by Reach) with the stock iPhone Safari app, you\u2019ll be\nmet with no shortage of page-covering ads that appear mid-article, and ads\nthat redirect you to an external website without any warning. Again, while\nyou\u2019re mid-article.\n\nEven the giants haven\u2019t resisted the temptation to screw their users. CNN, one\nof the most influential news publications in the world, hosts both its own\njournalism and spammy content from \"chum box\" companies that make hundreds of\nmillions of dollars driving clicks to everything from scams to outright\ndisinformation. And you'll find them on CNN, NBC and other major news outlets,\nwhich by proxy endorse stories like \"2 Steps To Tell When A Slot Is Close To\nHitting The Jackpot.\"\n\nThese \u201cchum box\u201d companies are ubiquitous because they pay well, making them\nan attractive proposition for cash-strapped media entities that have seen\ntheir fortunes decline as print revenues evaporated. But they\u2019re just so\nincredibly awful. In 2018, the (late, great) podcast Reply All had an episode\nthat centered around a widower whose wife\u2019s death had been hijacked by one of\nthese chum box advertisers to push content that, using stolen family photos,\nheavily implied she had been unfaithful to him. The title of the episode \u2014 An\nAd for the Worst Day of your Life \u2014 was fitting, and it was only until a\nmassively popular podcast intervened did these networks ban the advert.\n\nThese networks are harmful to the user experience, and they\u2019re arguably\nharmful to the news brands that host them. If I was working for a major news\ncompany, I\u2019d be humiliated to see my work juxtaposed with specious celebrity\nbilge, diet scams, and get-rich-quick schemes. And they\u2019re ultimately\nillustrative of where the internet is today.\n\nThe optimistic, respectful and trusting approach to legislation around online\nplatforms has led to an internet riddled with decay and pain, one that\nincentivizes mining human beings like veins of ore. The modern internet was\nbuilt on a social contract that said that big tech gave us services \"for free\"\nin exchange for the nebulous concept of \"data,\" which largely took the form of\nthe content and connections we made and the information that came out as a\nresult. This contract was both assumed and extremely easy to enter into,\nmeaning that there was never any attempt to regulate its terms \u2014 not simply\nwhat can and cannot be done to a user, but what the user will continue to\nreceive in return for the experience itself.\n\nAs a result, these platforms were (and are) a form of bait-and-switch, the\nunderpinning philosophy of Cory Doctorow's \"Enshittification\" theory, where\nplatforms build massive monopolies based on offering good, useful services,\nand then slowly turn the screws on the customer to seek ever-growing profits.\nYet as I've noted before, I feel that enshittification misses one crucial\nthing \u2014 that these companies aren't doing this out of a lack of profitability\nor failure of their business model, but because the modern internet has become\nsomewhere between a social experiment and a human mining operation.\n\nCharlie Warzel framed this well in a recent piece in The Atlantic, describing\nthe overall techscape as a form of hostage negotiation. Interactions with tech\ncompanies are no longer a purchase or two-way contract, but a series of trades\nof information long after we've purchased the actual product. Every single\ninteraction with tech now requires us to share our email address, to accept a\nsubtle form of tracking (don't worry, it's \"anonymous\"!), or to share personal\ninformation that can and will be leaked. It's trite at this point to say that\nhuman beings themselves are now the product, but it's more obvious and painful\nthan ever when you look at the state of our deeply dystopian internet.\n\nTech companies have found every imaginable way to monetize every imaginable\nthing we do, all based on the idea that they're providing us with something in\nreturn. And when you really think about it, they haven't provided a service at\nall. Twitter, Facebook, Instagram and Google are platforms that only have as\nmuch utility as the content they host, which is created by billions of\n(mostly) unsupported and unpaid users. The tradeoff was meant to be that these\nplatforms would make creating and hosting this content easier, and help either\nsurface it to a wider audience or to quickly get it to the people we cared\nabout , all while making sure the conditions we created and posted it under\nwere both interesting and safe for the user.\n\nYet the state of the internet is now far simpler: the cost of using free\nplatforms is a constant war with the incentives and intentions of the\nplatforms themselves. We negotiate with Instagram or Facebook to see content\nfrom the people we chose to follow, because these platforms are no longer\nbuilt to show us things that we want to see. We no longer \"search\" Google, but\nbarter with a seedy search box to try and coax out a result that isn't either\na search engine-optimized half-answer or an attempt to trick us into clicking\nan ad. Twitter, in its prime, succeeded by connecting real people to real\nthings at a time when the internet actively manufactures our experience and\ninteractions with others.\n\nThe core problem lies in the fact that these platforms don't really create\nanything, and their only value exists in making an internet of billions of\npeople small enough to comprehend. Like seemingly every problem with a\ncapitalist society, the internet has become dominated by powerful forces that\ndon't contribute to the product that enriches them. As a result, they have\neither no concept of nor interest in \"quality,\" just \"more,\" making them\nextremely poor arbiters of what \"good\" looks like. This inevitably leads to\nproducts that suck more as they become more profitable, because the machine\nthey've built is a profit excavator dressed as a service.\n\nI'd argue that this makes Google, and by extension executives like Sundar\nPichai and Google Search lead Prabhakar Raghavan, some of the greatest\nvillains in business history. While one can't forget about the damage done by\nMeta and Mark Zuckerberg's failure to maintain an honest platform, allowing\nGoogle Search to decay so severely for any reason \u2014 let alone a profit-centric\none \u2014 is actively damaging to society, and was an entirely intentional act\nperpetrated by people like Raghavan, the former head of Google's ads division\nwho took over search not long after his predecessor sounded a \"code yellow\"\nabout Google's advertising encroaching on search results.\n\nIf you need to see exactly how bad things are getting, spend some time on\nGoogle News. For months I\u2019ve been tracking Tech Gate, a site that Google News\nregularly cites for the biggest stories in the tech industry, growing it to a\nmodest yet not insignificant 18,000 unique monthly visitors according to data\nfrom SimilarWeb. The problem is that Tech Gate isn\u2019t a real site \u2014 it\u2019s\nentirely made up of stolen articles, like this article that copies Wccftech,\nor this entirely plagiarized Cointelegraph-branded article. Hey, remember a\nmonth ago when Google promised it was updating search to surface better,\nhuman-authored content? Remember when I told you it was full of shit? I want\nto scream!\n\nAnyway.\n\nBy allowing \u2014 and encouraging \u2014 search engine optimization (SEO), Google\nhanded matches to arsonists and pointed to the most flammable parts of the\ninternet. The existence of SEO is inevitable, but Google should never have\nencouraged these people \u2014 it should have only set clear standards about what\nnot to do and punished failures to comply heavily, except doing so would mean\nless content on Google (since there wouldn\u2019t be as much of an incentive to\ncreate cheap SEO-centric content, like the millions of \u201cwhat time is the\nsuperbowl\u201d articles that appear each year).\n\nIt\u2019s not so much that Google is negligent or incompetent, but actively hostile\nto users, as demonstrated by the company\u2019s decision to cancel its contract\nwith Appen \u2014 an Australian business that employs a significant chunk of\nGoogle\u2019s outsourced search quality raters. These are the people who tell\nGoogle if a search result is high quality. While they can\u2019t influence\nindividual page rankings, they\u2019re an important quality control mechanism on\nsomething that\u2019s largely impervious to public sentiment.\n\n> As an aside, it\u2019s worth noting that these raters \u2014 of whom about one-third\n> work in the US \u2014 are employed under genuinely deplorable conditions. Last\n> year, Appen workers protested outside Google\u2019s Mountain View campus\n> demanding basic benefits, like health insurance, paid sick leave, and\n> parental leave. These workers are often woefully underpaid, with one group\n> only achieving a raise to $14.50 per hour in 2022.\n>\n> As much as Google has historically liked to crow about the generous benefits\n> and workplace perks offered to employees, its reliance on poorly-paid\n> contractors is an open secret. In March, the company terminated its contract\n> with Cognizant \u2014 a sprawling Indian IT contractor, one of the \u201cBig Five\u201d\n> tech body shops, along with the likes of Wipro, Infosys, Tata, and HCL \u2014\n> which, in turn, led to the firing of roughly 50 YouTube Music workers in\n> Austin, Texas.\n>\n> These YouTube Music workers earned as little as $19 per hour and received\n> \u201cminimal benefits,\u201d with many forced to work multiple jobs in order to\n> survive. Illustrating the precarities of their employment, the workers only\n> found out they were let go while addressing Austin City Council about their\n> working conditions.\n>\n> Curiously, both groups \u2014 the Appen raters and the YouTube Music staffers \u2014\n> were laid off after successfully unionizing and protesting against the\n> company. I\u2019m sure that\u2019s just a coincidence. Google wouldn\u2019t be evil, right?\n\nWe justifiably loathe Elon Musk for destroying Twitter, but we should have a\nhundred times the bile for Larry Page, Sergey Brin and Sundar Pichai. All\nthree have unquestionably damaged our ability to access knowledge through\ntheir actively harmful approach to maintaining a portal that billions use to\nfind answers to everything.\n\nAnd after decades of profiting off of platforms that make billions of people\ncreate things for free, they've found their next big sting \u2014 stealing the\ncontent itself, and selling it back to us using artificial intelligence.\n\n## Eating The Internet\n\nAs I wrote in my last newsletter and went over in the last episode of my\npodcast Better Offline, the large language models (LLMs) underpinning the\ngenerative AI boom require incredible amounts of data. As a result, every\nsingle LLM-based application \u2014 ChatGPT, Google Gemini, Anthropic's Claude,\nMeta's LLaMA, to name but a few \u2014 is trained on an indeterminately-large\nportion of the internet made up of both Common Crawl (a 250-billion page\nrepository of web content) and what appears to be as much of the rest of the\ninternet as they're able to download, legally or otherwise. After profiting\nhandsomely from being the middleman between content creation and internet\nusers, big tech is in the process of looting the internet as a means of\ntraining models that it hopes can replace human beings themselves. And I'm not\nbeing remotely dramatic.\n\nWhile Meta already makes over a hundred billion dollars mining and selling our\ndata while constantly interrupting us with sponsored content, that just isn't\nenough, and it\u2019s now training its generative AI models using billions of our\nFacebook and Instagram posts. Google has now paid Reddit $60 million dollars\nto train on its data, and both OpenAI and Midjourney have struck deals with\nboth Tumblr and Wordpress to train its models on their blogs. DocuSign is\ntraining its generative AI models with user data, and OpenAI allegedly\ntranscribed over a million hours of YouTube videos as a means of training its\nlatest \"GPT-4\" model, and Google couldn't get angry about it because it was\ndoing exactly the same thing.\n\nA Washington Post investigation from last year found that Google's T5 and\nMeta's LLaMA models trained on Google's C4 data set had ingested 15 million\ndifferent websites including everything from pirated eBook websites to the\nentirety of free blogging platform Medium. It's reasonable to assume that\nmodels like ChatGPT were trained on similar-sized datasets, and while we can't\ntell exactly what they trained on, I'd argue the New York Times' lawsuit\nagainst the company successfully proves that GPT-4 and other models were\ntrained on a great deal of its content.\n\nWhile OpenAI, Google and Meta would like to claim that these are \"publicly-\navailable\" works that they are \"training on,\" the actual word for what they're\ndoing is \"stealing.\" These models are not \"learning\" or, let's be honest,\n\"training\" on this data, because that's not how they work \u2014 they're using\nmathematics to plagiarize it based on the likelihood that somebody else's\nanswer is the correct one. If we did this as a human being \u2014 authoritatively\nquoting somebody else's figures without quoting them \u2014 this would be\nconsidered plagiarism, especially if we represented the information as our\nown.\n\nLLMs are a globally-perpetuated act of theft taking place in broad daylight,\nto the point that OpenAI has told England's House of Lords that \"it would be\nimpossible to train today's leading AI models without using copyrighted\nmaterials.\" Every single tech company making a LLM is stealing, justifying it\nby using the previous model of the internet where everything published online\nwas there for the taking and conflating access to content with ownership in\nthe process.\n\nThe generative AI boom has exactly the same stench as the metaverse, and it's\nhappening for exactly the same reason \u2014 the people making the products are not\nbuilding things for human beings, but to show the markets that they'd continue\nto grow. Google and Meta do not make great products. Sam Altman has founded\none company, Loopt, which he somehow sold for $40 million despite it never\ngaining traction. Sundar Pichai's resum\u00e9 includes a short stint at McKinsey\nand serving on the board of Magic Leap, a borderline-fraudulent augmented\nreality company. Meta is incapable of creating products without stealing or\nacquiring them, and has a far longer history of destroying every startup it\ntouches. These people aren't innovators, or creators, or even service\nproviders \u2014 they're thieves and landlords insulated by weak regulation and\nmarkets that have become disconnected from the concept of good business.\nOpenAI is no different. After all, it\u2019s effectively a subsidiary of Microsoft.\n\nAnd when you have an industry piloted by people who don't make products for\npeople, you don't create anything useful, and you're doomed to make the same\nstupid, obvious mistakes.\n\nDespite the billions of investment and media headlines, it is surprisingly\ndifficult to describe what ChatGPT does. Generative AI allows you to generate\nlots of stuff from a prompt, allowing you to pretend to do the research much\nlike LLMs pretend to know stuff. It's good for cheating at papers, or\ngenerating lots of mediocre stuff, which makes it, if we're honest, kind of\nlike a very advanced calculator that can create words as well as numbers.\nEvery time I write something like this I get sent emails telling me what\n\"generative AI can do,\" and the answer is always some sort of contrived excuse\nto use tech rather than a useful integration with a specific purpose.\n\n> As another aside: Even the claims of what generative AI has done need to be\n> taken with a grain \u2014 or a spoonful \u2014 of salt. You might have caught wind of\n> Devin, the \u201cworld\u2019s first AI software engineer,\u201d which is purportedly able\n> to tackle entire software engineering tasks on Upwork.\n>\n> Except these claims fall apart at the first bit of scrutiny. First, AI can\u2019t\n> handle one of the most essential tasks of software engineering, which is\n> collaboratively discussing the requirements of a project and how to\n> implement the technology. Second, it appears Devin was provided a cherry-\n> picked task, rather than finding one on his own, as the developers behind\n> the tool claimed.\n>\n> But more fundamentally, Devin just wasn\u2019t all that good. His code didn\u2019t\n> meet the basic requirements of the project \u2014 which included providing\n> documentation on how the solution worked and how to deploy it \u2014 and his code\n> was clunky, inelegant, and used outdated approaches to basic tasks. Worse,\n> he took significantly longer to complete the task than an actual human\n> would.\n>\n> Admittedly, Devin took so long because it spent hours \u2014 literally hours \u2014\n> trying to identify and resolve bugs in its own sloppy code. I\u2019d say it has\n> the engineering ability of a first-year CompSci undergraduate, but that\n> would be unfair to first-year CompSci undergraduates.\n\nIt's the hallmark of a tech industry dedicated to creating problems that it\ncharges you to solve, a sickly beast borne of venture capital and a lack of\ninnovation. When you're rich and powerful, you no longer face real problems,\nand as a result fail to consider the solutions that would measurably improve a\nperson's life. Sundar Pichai and Mark Zuckerberg don't worry about bills, or\nface actual busywork, or real challenges \u2014 they get paid hundreds of millions\nof dollars to come up with ways to express growth to hedge funds.\n\nYet I believe generative AI is going to lead several of these companies to\nruin. As I wrote (and broadcast) recently, LLMs are running out of training\ndata, and the desperation to find more will lead to significant legal\nconsequences when it's revealed exactly how much they stole and from whom they\nstole it from. As these generative AI companies become more desperate, they'll\n(intentionally or otherwise) ingest AI-generated content, which causes a\ndegenerative training effect called \"model collapse\" (also known as Habsburg\nAI) that destroys the model's ability to deliver useful answers. By all\naccounts, this is already happening, with Adobe's Firefly AI accidentally\ningesting generative art that found its way into their Adobe Stock pool of\nstock images.\n\nLLMs also tend to hallucinate, a virtually-unsolvable problem where they\nauthoritatively make incorrect statements that creates horrifying results in\ngenerative art and renders them too unreliable for any kind of mission\ncritical work. Like I\u2019ve said previously, this is a feature, not a bug. These\nmodels don\u2019t know anything \u2014 they\u2019re guessing, based on mathematical\ncalculations, as to the right answer. And that means they\u2019ll present something\nthat feels right, even though it has no basis in reality. LLMs are the poster\nchild for Stephen Colbert\u2019s concept of truthiness.\n\nGenerative AI's energy demands are unsustainable, as are its compute demands,\nand even if you somehow got past all of these intractable issues, you face\nseveral far simpler questions: What use is all of this generative AI? Why is\nit necessary? Why does it have to happen? What is the killer app that makes\nany of this worthwhile? And why the fuck, for the third time in three years,\nis the tech industry trying to cram something down our throats that doesn't\nappear to help us?\n\nThe answer is obvious: because they believe it'll make them money.\n\nGenerative AI is catnip for big tech \u2014 a narratively-satisfying way of\nexpressing how big their companies will grow for investors that don't invest\nin companies because they make things for real people, but for the signals\nthey issue to Wall Street speculators. LLMs are a way to sell software to\nenterprises and people alike, while also driving theoretical billions into\ntech stocks, which in turn makes the tech industry feel special and important.\nIt's a new \"thing\" that tech can do that feels like the future, that sort of\nmakes sense, that allows people who barely read anything and don't do any real\nwork to dream of ways to get rid of the people who do.\n\nYet I believe that they're all disconnected from any actual value creation.\nGoogle, Meta, Microsoft and OpenAI don't create anything \u2014 they're built off\nof supporting other people doing things, and have spent decades abstracting\nthemselves away from any kind of labor. These aren't the companies that made\nGoogle Search, or Facebook, or Word. They're data brokers by different names\nthat happen to sometimes sell software.\n\nWhat's so dangerous about AI for these companies is that despite all the hype,\nAI neither solves any real problems nor actually makes them any money. OpenAI\nmay make billions, but it has yet to turn any kind of profit, and its\noperating costs vastly surpass any revenue it gets from licensing its\ntechnology or selling premium memberships.\n\nGoogle can't find a way to make money off of its generative search product\n(which still, by the way, hallucinates) and is thinking about charging for it\n\u2014 the actions of a company that knows that none of this generative nonsense\nactually matters. Further evidence that the company is doubling down on AI is\nits recent decision to elevate Liz Reid, who most recently led Google\u2019s AI\nsearch team \u2014 called Search Generative Experience (SGE) \u2014 to the top search\nrole in the company.\n\nAs part of this shuffle, Google has also moved Cheenu Venkatachary, one of its\nsenior AI engineers, to lead the teams responsible for ranking and search\nquality. Nothing \u2014 and I repeat, nothing \u2014 good will come from this.\n\nI think that society is turning on tech as a result. Everybody knows how bad\nthe internet is, and everybody knows how much money these companies make.\nPeople are still angry about cryptocurrency and the metaverse, they're still\ndeeply pissed off that they were lied to, and they're far more aware of when\nthey're being fed a line of shit than Mark Zuckerberg, Sam Altman, Sundar\nPichai, and the rest of their ilk realize.\n\nShare\n\nAbout the author\n\n### Edward Zitron\n\nView all\n\nComments\n\n## Welcome to Where's Your Ed At!\n\nSubscribe today. It's free. Please.\n\n  * Home\n  * About\n\n  * Sign up\n\n\u00a92024 Ed Zitron's Where's Your Ed At. Published with Ghost & Tuuli.\n\n", "frontpage": true}

{"aid": "40001275", "title": "Show HN: Evaluate LLM-based RAG Applications with automated test set generation", "url": "https://github.com/Giskard-AI/giskard", "domain": "github.com/giskard-ai", "votes": 6, "user": "RuiLyonesse", "posted_at": "2024-04-11 12:11:07", "comments": 0, "source_title": "GitHub - Giskard-AI/giskard: \ud83d\udc22 Open-Source Evaluation & Testing framework for LLMs and ML models", "source_text": "GitHub - Giskard-AI/giskard: \ud83d\udc22 Open-Source Evaluation & Testing framework for\nLLMs and ML models\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nGiskard-AI / giskard Public\n\n  * Sponsor\n  * Notifications\n  * Fork 188\n  * Star 3k\n\n\ud83d\udc22 Open-Source Evaluation & Testing framework for LLMs and ML models\n\ndocs.giskard.ai\n\n### License\n\nApache-2.0 license\n\n3k stars 188 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# Giskard-AI/giskard\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n168 Branches\n\n69 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nluca-martialMerge pull request #1886 from Giskard-AI/chore/readme-\npolishing679caa4 \u00b7\n\n## History\n\n9,341 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Bump softprops/action-gh-release from 1 to 2  \n  \n### .vscode\n\n|\n\n### .vscode\n\n| Adding debug config for worker  \n  \n### docs\n\n|\n\n### docs\n\n| [GSK-3367] Adding brier score + monotonicity + smoothness tests (#1863)  \n  \n### giskard\n\n|\n\n### giskard\n\n| [GSK-3367] Adding brier score + monotonicity + smoothness tests (#1863)  \n  \n### readme\n\n|\n\n### readme\n\n| GIFs update  \n  \n### sample_data\n\n|\n\n### sample_data\n\n| Moving files from python-client to root folder  \n  \n### scripts\n\n|\n\n### scripts\n\n| Moving files from python-client to root folder  \n  \n### src/scan-widget\n\n|\n\n### src/scan-widget\n\n| Merge branch 'main' into feature/llm-scan  \n  \n### tests\n\n|\n\n### tests\n\n| [GSK-3367] Adding brier score + monotonicity + smoothness tests (#1863)  \n  \n### .coveragerc\n\n|\n\n### .coveragerc\n\n| Fix Sonar in CI to get coverage back  \n  \n### .flake8\n\n|\n\n### .flake8\n\n| Moving files from python-client to root folder  \n  \n### .git-blame-ignore-revs\n\n|\n\n### .git-blame-ignore-revs\n\n| added isort to .git-blame-ignore-revs  \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n| Fix paths due to removal of python-client  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Switch from threading to multiprocessing in worker  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Add ggshield to pre-commit  \n  \n### .readthedocs.yaml\n\n|\n\n### .readthedocs.yaml\n\n| Rename server to hub  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| open source release  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Update the contributing style guide (#1795)  \n  \n### ISSUES.md\n\n|\n\n### ISSUES.md\n\n| task/603_template_for_bug_report (#604)  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Apache 2  \n  \n### README.md\n\n|\n\n### README.md\n\n| adjust wording  \n  \n### conftest.py\n\n|\n\n### conftest.py\n\n| run black + ruff  \n  \n### gulpfile.js\n\n|\n\n### gulpfile.js\n\n| AVID integration (#1609)  \n  \n### package-lock.json\n\n|\n\n### package-lock.json\n\n| AVID integration (#1609)  \n  \n### package.json\n\n|\n\n### package.json\n\n| Moving files from python-client to root folder  \n  \n### pdm.lock\n\n|\n\n### pdm.lock\n\n| Regenerating pdm.lock  \n  \n### postcss.config.js\n\n|\n\n### postcss.config.js\n\n| Moving files from python-client to root folder  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| v2.10.0  \n  \n### sonar-project.properties\n\n|\n\n### sonar-project.properties\n\n| Activate again Sonar on the python code  \n  \n### tailwind.config.js\n\n|\n\n### tailwind.config.js\n\n| Moving files from python-client to root folder  \n  \n## Repository files navigation\n\n# The Evaluation & Testing framework for LLMs & ML models\n\n### Control risks of performance, bias and security issues in AI models\n\n### Docs \u2022 Blog \u2022 Website \u2022 Discord\n\n## Install Giskard \ud83d\udc22\n\nInstall the latest version of Giskard from PyPi using pip:\n\n    \n    \n    pip install \"giskard[llm]\" -U\n\nWe officially support Python 3.9, 3.10 and 3.11.\n\n## Try in Colab \ud83d\udcd9\n\nOpen Colab notebook\n\nGiskard is an open-source Python library that automatically detects\nperformance, bias & security issues in AI applications. The library covers\nLLM-based applications such as RAG agents, all the way to traditional ML\nmodels for tabular data.\n\n## Scan: Automatically assess your LLM-based agents for performance, bias &\nsecurity issues \u2935\ufe0f\n\nIssues detected include:\n\n  * Hallucinations\n  * Harmful content generation\n  * Prompt injection\n  * Robustness issues\n  * Sensitive information disclosure\n  * Stereotypes & discrimination\n  * many more...\n\n## RAG Evaluation Toolkit (RAGET): Automatically generate evaluation datasets\n& evaluate RAG application answers \u2935\ufe0f\n\nIf you're testing a RAG application, you can get an even more in-depth\nassessment using RAGET, Giskard's RAG Evaluation Toolkit.\n\n  * RAGET can generate automatically a list of question, reference_answer and reference_context from the knowledge base of the RAG. You can then use this generated test set to evaluate your RAG agent.\n\n  * RAGET computes scores for each component of the RAG agent. The scores are computed by aggregating the correctness of the agent\u2019s answers on different question types.\n\n    * Here is the list of components evaluated with RAGET:\n\n      * Generator: the LLM used inside the RAG to generate the answers\n      * Retriever: fetch relevant documents from the knowledge base according to a user query\n      * Rewriter: rewrite the user query to make it more relevant to the knowledge base or to account for chat history\n      * Router: filter the query of the user based on his intentions\n      * Knowledge Base: the set of documents given to the RAG to generate the answers\n\nGiskard works with any model, in any environment and integrates seamlessly\nwith your favorite tools \u2935\ufe0f\n\n# Contents\n\n  * \ud83e\udd38\u2640\ufe0f Quickstart\n\n    * 1\\. \ud83c\udfd7\ufe0f Build a LLM agent\n    * 2\\. \ud83d\udd0e Scan your model for issues\n    * 3\\. \ud83e\ude84 Automatically generate an evaluation dataset for your RAG applications\n  * \ud83d\udc4b Community\n\n# \ud83e\udd38\u2640\ufe0f Quickstart\n\n## 1\\. \ud83c\udfd7\ufe0f Build a LLM agent\n\nLet's build an agent that answers questions about climate change, based on the\n2023 Climate Change Synthesis Report by the IPCC.\n\nBefore starting let's install the required libraries:\n\n    \n    \n    pip install langchain tiktoken \"pypdf<=3.17.0\"\n    \n    \n    from langchain import OpenAI, FAISS, PromptTemplate from langchain.embeddings import OpenAIEmbeddings from langchain.document_loaders import PyPDFLoader from langchain.chains import RetrievalQA from langchain.text_splitter import RecursiveCharacterTextSplitter # Prepare vector store (FAISS) with IPPC report text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True) loader = PyPDFLoader(\"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\") db = FAISS.from_documents(loader.load_and_split(text_splitter), OpenAIEmbeddings()) # Prepare QA chain PROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard. Your task is to answer common questions on climate change. You will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023). Please provide short and clear answers based on the provided context. Be polite and helpful. Context: {context} Question: {question} Your answer: \"\"\" llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0) prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"]) climate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n\n## 2\\. \ud83d\udd0e Scan your model for issues\n\nNext, wrap your agent to prepare it for Giskard's scan:\n\n    \n    \n    import giskard import pandas as pd def model_predict(df: pd.DataFrame): \"\"\"Wraps the LLM call in a simple Python function. The function takes a pandas.DataFrame containing the input variables needed by your model, and must return a list of the outputs (one for each row). \"\"\" return [climate_qa_chain.run({\"query\": question}) for question in df[\"question\"]] # Don\u2019t forget to fill the `name` and `description`: they are used by Giskard # to generate domain-specific tests. giskard_model = giskard.Model( model=model_predict, model_type=\"text_generation\", name=\"Climate Change Question Answering\", description=\"This model answers any question about climate change based on IPCC reports\", feature_names=[\"question\"], )\n\n\u2728\u2728\u2728Then run Giskard's magical scan\u2728\u2728\u2728\n\n    \n    \n    scan_results = giskard.scan(giskard_model)\n\nOnce the scan completes, you can display the results directly in your\nnotebook:\n\n    \n    \n    display(scan_results) # Or save it to a file scan_results.to_html(\"scan_results.html\")\n\nIf you're facing issues, check out our docs for more information.\n\n## 3\\. \ud83e\ude84 Automatically generate an evaluation dataset for your RAG\napplications\n\nIf the scan found issues in your model, you can automatically extract an\nevaluation dataset based on the issues found:\n\n    \n    \n    test_suite = scan_results.generate_test_suite(\"My first test suite\")\n\nBy default, RAGET automatically generates 6 different question types (these\ncan be selected if needed, see advanced question generation). The total number\nof questions is divided equally between each question type. To make the\nquestion generation more relevant and accurate, you can also provide a\ndescription of your agent.\n\n    \n    \n    from giskard.rag import generate_testset, KnowledgeBase # Load your data and initialize the KnowledgeBase df = pd.read_csv(\"path/to/your/knowledge_base.csv\") knowledge_base = KnowledgeBase.from_pandas(df, columns=[\"column_1\", \"column_2\"]) # Generate a testset with 10 questions & answers for each question types (this will take a while) testset = generate_testset( knowledge_base, num_questions=60, language='en', # optional, we'll auto detect if not provided agent_description=\"A customer support chatbot for company X\", # helps generating better questions )\n\nDepending on how many questions you generate, this can take a while. Once\nyou\u2019re done, you can save this generated test set for future use:\n\n    \n    \n    # Save the generated testset testset.save(\"my_testset.jsonl\")\n\nYou can easily load it back\n\n    \n    \n    from giskard.rag import QATestset loaded_testset = QATestset.load(\"my_testset.jsonl\") # Convert it to a pandas dataframe df = loaded_testset.to_pandas()\n\nHere\u2019s an example of a generated question:\n\nquestion| reference_context| reference_answer| metadata  \n---|---|---|---  \nFor which countries can I track my shipping?| Document 1: We offer free\nshipping on all orders over $50. For orders below $50, we charge a flat rate\nof $5.99. We offer shipping services to customers residing in all 50 states of\nthe US, in addition to providing delivery options to Canada and Mexico.\nDocument 2: Once your purchase has been successfully confirmed and shipped,\nyou will receive a confirmation email containing your tracking number. You can\nsimply click on the link provided in the email or visit our website\u2019s order\ntracking page.| We ship to all 50 states in the US, as well as to Canada and\nMexico. We offer tracking for all our shippings.| {\"question_type\": \"simple\",\n\"seed_document_id\": 1, \"topic\": \"Shipping policy\"}  \n  \nEach row of the test set contains 5 columns:\n\n  * question: the generated question\n  * reference_context: the context that can be used to answer the question\n  * reference_answer: the answer to the question (generated with GPT-4)\n  * conversation_history: not shown in the table above, contain the history of the conversation with the agent as a list, only relevant for conversational question, otherwise it contains an empty list.\n  * metadata: a dictionary with various metadata about the question, this includes the question_type, seed_document_id the id of the document used to generate the question and the topic of the question\n\n# \ud83d\udc4b Community\n\nWe welcome contributions from the AI community! Read this guide to get\nstarted, and join our thriving community on Discord.\n\n\ud83c\udf1f Leave us a star, it helps the project to get discovered by others and keeps\nus motivated to build awesome open-source tools! \ud83c\udf1f\n\n\u2764\ufe0f If you find our work useful, please consider sponsoring us on GitHub. With\na monthly sponsoring, you can get a sponsor badge, display your company in\nthis readme, and get your bug reports prioritized. We also offer one-time\nsponsoring if you want us to get involved in a consulting project, run a\nworkshop, or give a talk at your company.\n\n## About\n\n\ud83d\udc22 Open-Source Evaluation & Testing framework for LLMs and ML models\n\ndocs.giskard.ai\n\n### Topics\n\nai-safety ethical-artificial-intelligence ai-security mlops fairness-ai model-\nmonitoring responsible-ai ml-safety ml-validation red-team-tools trustworthy-\nai ml-testing llm ai-red-team ai-testing llmops llm-security llm-eval llm-\nevaluation rag-evaluation\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n3k stars\n\n### Watchers\n\n25 watching\n\n### Forks\n\n188 forks\n\nReport repository\n\n## Releases 60\n\nv2.10.0 Latest\n\nApr 10, 2024\n\n\\+ 59 releases\n\n## Sponsor this project\n\nGiskard-AI Giskard\n\nSponsor\n\nLearn more about GitHub Sponsors\n\n## Contributors 42\n\n\\+ 28 contributors\n\n## Languages\n\n  * Python 96.9%\n  * JavaScript 1.8%\n  * Other 1.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

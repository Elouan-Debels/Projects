{"aid": "39983779", "title": "Show HN: Ditch your ORM with type-safe native SQL", "url": "https://github.com/manifold-systems/manifold/blob/master/manifold-deps-parent/manifold-sql/readme.md", "domain": "github.com/manifold-systems", "votes": 1, "user": "owlstuffing", "posted_at": "2024-04-09 20:18:48", "comments": 0, "source_title": "manifold/manifold-deps-parent/manifold-sql/readme.md at master \u00b7 manifold-systems/manifold", "source_text": "manifold/manifold-deps-parent/manifold-sql/readme.md at master \u00b7 manifold-\nsystems/manifold \u00b7 GitHub\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nmanifold-systems / manifold Public\n\n  * Notifications\n  * Fork 120\n  * Star 2.2k\n\n/\n\n# readme.md\n\n## Latest commit\n\nrsmckinney\n\nhttps://github.com/manifold-systems/manifold/issues/566\n\n0bdedc4 \u00b7\n\n## History\n\nHistory\n\n1341 lines (1027 loc) \u00b7 58.5 KB\n\n/\n\n# readme.md\n\n## File metadata and controls\n\n1341 lines (1027 loc) \u00b7 58.5 KB\n\nRaw\n\n> \u26a0 Experimental Feature\n\n# Manifold SQL\n\nManifold SQL lets you write native SQL directly and type-safely in your Java\ncode.\n\n  * Query types are instantly available as you type native SQL of any complexity in your Java code\n  * Query results are type-safe and API-rich and simple to use (see examples below)\n  * Entity types are automatically derived from your database, providing type-safe CRUD, decoupled TX, and more.\n  * No ORM, No DSL, No wiring, and No code generation build steps\n\nUse Manifold SQL simply by adding the javac -Xplugin:Manifold argument and\nmanifold-sql and manifold-sql-rt dependencies to your gradle or maven build.\nSee Step 1. Add Manifold SQL to your build.\n\n# Features\n\n  * Use native SQL directly and type-safely in your Java project\n  * Type-safe schemas \u2022 Type-safe queries \u2022 Type-safe results\n  * CRUD with schema types derived automatically from your database\n  * Decoupled transaction scoping, make changes on your own timeline\n  * No ORM \u2022 No DSL \u2022 No code gen steps\n  * Pluggable architecture with simple dependency injection\n  * Tested with popular JDBC database drivers and SQL dialects\n  * Comprehensive IDE support (IntelliJ IDEA, Android Studio)\n  * Supports Java 8 - 21 (LTS releases)\n\n# Examples\n\nYou can inline SQL queries and commands in both standard String Literals and\nText Blocks. This query demonstrates how you can use native SQL to produce\nresult sets of any type.\n\nNotice both Java and SQL syntax are highlighted. The Manifold IntelliJ IDEA\nplugin integrates with IDEA's SQL features.\n\nQuery results consist of entity instances and/or row instances, depending on\nwhether all required columns are selected. As such, select * queries\nconveniently result in entity instances.\n\nThis query also demonstrates the use of type-safe, injection-safe query\nparameters. Parameters are supported in all SQL commands including Insert,\nUpdate, Delete as well as Select.\n\nAn inline query is purely declarative using comment delimiters.\n\nHere the Payments query type is defined and used in the same local scope.\nNotice the type declaration, Payments.sql follows the file name.extension\nconvention. The type name is Payments and the type domain is sql.\n\nWith IntelliJ you can interactively execute parameterized SQL queries in your\ncode directly against test data, analyze query execution plans, and a lot\nmore.\n\nWhile IntelliJ is not required to use Manifold SQL, it can boost your\ndevelopment experience significantly.\n\nCRUD operations and transactions are a pleasure with Manifold SQL. Easily make\nand commit changes however you like.\n\nSakila is the name of the user-defined database configuration file, which is\nused to name the schema Java type referenced here. Note, this example calls\ncommit() three times to demonstrate the flexibility of decoupled transactions.\nSee transaction scopes.\n\n> i The Manifold SQL sample project contains many of the examples used here.\n> Clone it and start experimenting!\n\n# How does it work?\n\nManifold SQL plugs into the java compiler using the jdk.compiler.Plugin SPI.\nThis hook enables the framework to intercept the compiler's type resolver so\nthat it can generate types on-demand as the compiler encounters them. This\nunique aspect of the framework effectively provides just-in-time type\ngeneration. It is what makes on-the-fly entity type projection and inline,\ntype-safe SQL a reality.\n\nA standard JDBC connection supplies the metadata backing the entity and query\ntypes. The connection is configured using a simple JSON structured file, which\nprovides a JDBC URL, driver properties, and other optional settings. Separate\nconfigurations may be defined for compilation, testing, and production. During\ncompilation the connection is used exclusively to access metadata to build\njust-in-time entity and query APIs. Metadata acquired directly from the target\ndatabase guarantees these APIs are always 100% type-safe, in-sync, and\ntailored for use with your specific configuration.\n\n# Documentation\n\n  * Getting started\n  * Step 1. Add Manifold SQL to your build\n\n    * Gradle\n    * Maven\n    * Binaries\n    * Tested JDBC drivers\n  * Step 2. Configure your database connection\n\n    * .dbconfig files\n    * Naming\n    * Compiling vs. testing vs. production\n    * Programmatic configuration\n    * Accessing the configuration in your code\n    * Settings\n  * Step 3. Begin writing incredible code!\n\n    * Queries\n\n      * .sql files\n      * Query & Row types\n      * Entity types\n      * Inline SQL\n    * Entities\n\n      * Entity methods\n      * Patching JDBC types\n      * Value accessors\n      * Customizing entity types\n    * CRUD\n\n      * Create\n      * Read\n      * Update\n      * Delete\n    * Transaction scopes\n\n      * Default transaction scope\n      * commit()\n      * Coupled queries\n      * Have it your way\n    * DML & DDL commands\n    * Customizations\n    * Dependency interfaces\n\n      * DbConfigProvider\n      * ConnectionProvider\n      * CrudProvider\n      * DbLocationProvider\n      * DefaultTxScopeProvider\n      * TxScopeProvider\n      * TypeProvider\n      * ValueAccessorProvider\n      * CustomEntityFactory\n  * IDE support\n\n    * Plugin installation\n    * IntelliJ IDEA Community Edition vs. IDEA Ultimate\n  * Javadoc\n  * License\n  * Versioning\n  * Author\n  * Comms\n\n# Getting started\n\nBe productive with Manifold SQL in three easy steps.\n\n  1. Add Manifold SQL to your build\n  2. Configure your database connection\n  3. Begin writing incredible code!\n\nLet's get into it!\n\n# Step 1. Add Manifold SQL to your build\n\nManifold SQL consists of two modules:\n\n  * manifold-sql\n  * manifold-sql-rt\n\nFor optimal performance and to work with Android and other JVM languages it is\nrecommended to:\n\n  * Add a dependency on manifold-sql-rt (Gradle: \"implementation\", Maven: \"compile\")\n  * Add manifold-sql to the annotationProcessor path (Gradle: \"annotationProcessor\", Maven: \"annotationProcessorPaths\")\n\nSample build files for Gradle and Maven follow.\n\n## Gradle\n\n> i If you are targeting Android, please see the Android docs.\n\n> i if you are using Kotlin, please see the Kotlin docs.\n\nHere is a sample build.gradle script. Change targetCompatibility and\nsourceCompatibility to your desired Java version (8 - 21), the script takes\ncare of the rest.\n\n    \n    \n    plugins { id 'java' } group 'systems.manifold' version '1.0-SNAPSHOT' targetCompatibility = 11 sourceCompatibility = 11 repositories { jcenter() maven { url 'https://oss.sonatype.org/content/repositories/snapshots/' } } dependencies { // Manifold dependencies implementation 'systems.manifold:manifold-sql-rt:2024.1.12' annotationProcessor 'systems.manifold:manifold-sql:2024.1.12' testAnnotationProcessor 'systems.manifold:manifold-sql:2024.1.12' // Add your JDBC driver here, this is just an example using postgres implementation 'org.postgresql:postgresql:42.6.0' annotationProcessor 'org.postgresql:postgresql:42.6.0' testAnnotationProcessor 'org.postgresql:postgresql:42.6.0' } if (JavaVersion.current() != JavaVersion.VERSION_1_8 && sourceSets.main.allJava.files.any {it.name == \"module-info.java\"}) { tasks.withType(JavaCompile) { // if you DO define a module-info.java file: options.compilerArgs += ['-Xplugin:Manifold', '--module-path', it.classpath.asPath] } } else { tasks.withType(JavaCompile) { // If you DO NOT define a module-info.java file: options.compilerArgs += ['-Xplugin:Manifold'] } }\n\nUse with accompanying settings.gradle file:\n\n    \n    \n    rootProject.name = 'MyProject'\n\n## Maven\n\n    \n    \n    <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"> <modelVersion>4.0.0</modelVersion> <groupId>com.example</groupId> <artifactId>my-sql-app</artifactId> <version>0.1-SNAPSHOT</version> <name>My App</name> <properties> <!-- set latest manifold version here --> <manifold.version>2024.1.12</manifold.version> </properties> <dependencies> <!-- Add dependency on manifold-sql-rt --> <dependency> <groupId>systems.manifold</groupId> <artifactId>manifold-sql-rt</artifactId> <version>${manifold.version}</version> </dependency> <!-- Add your JDBC driver here, this is just an example using Postgres --> <dependency> <groupId>org.postgresql</groupId> <artifactId>postgresql</artifactId> <version>42.6.0</version> </dependency> </dependencies> <!--Add the -Xplugin:Manifold argument for the javac compiler--> <build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.8.0</version> <configuration> <source>11</source> <target>11</target> <encoding>UTF-8</encoding> <compilerArgs> <!-- Add manifold plugin--> <arg>-Xplugin:Manifold</arg> </compilerArgs> <!-- Add the processor path for the plugin --> <annotationProcessorPaths> <!-- Manifold SQL --> <path> <groupId>systems.manifold</groupId> <artifactId>manifold-sql</artifactId> <version>${manifold.version}</version> </path> <!-- Add your JDBC driver here, this is just an example using Postgres --> <path> <groupId>org.postgresql</groupId> <artifactId>postgresql</artifactId> <version>42.6.0</version> </path> </annotationProcessorPaths> </configuration> </plugin> </plugins> </build> </project>\n\n## Binaries\n\nIf you are not using Maven or Gradle, you can download the latest binaries\nhere.\n\n## Tested JDBC drivers\n\nSeveral drivers are tested and more are on the way. But Manifold SQL is\ndesigned to work with any Type 4 JDBC driver. If you experience problems using\na JDBC driver with Manifold SQL, please let us know by reporting the issue.\n\nDatabase| Tested Driver  \n---|---  \nH2| com.h2database:h2  \nMySQL| com.mysql:mysql-connector-j  \nOracle| com.oracle.database.jdbc:ojdbc*  \nPostgres| org.postgresql:postgresql  \nSQL Server| com.microsoft.sqlserver:mssql-jdbc  \nSQLite| org.xerial:sqlite-jdbc  \nother| report issues, your feedback is important!  \n  \nThe architecture is designed for customization, you can tweak or completely\nreplace almost every aspect of its behavior.\n\n# Step 2. Configure your database connection\n\n## .dbconfig files\n\nConfiguring Manifold SQL is a snap. Just create one or more JSON formatted\nfiles with the .dbconfig extension. The primary function of this file is to\nconnect Manifold SQL to your data source via a JDBC driver URL.\n\n    \n    \n    { \"url\": \"jdbc:postgresql://localhost:5432/sakila?user=postgres&password=password\" }\n\nThis is the simplest of .dbconfig files, and shows that the only required\nsetting is the JDBC url. It configures Manifold to connect to a Postgres\ndatabase named sakila with a user and password following the URL format of the\nstandard Postgres JDBC driver.\n\n.dbconfig files can be thoroughly customized. For instance, you can separate\ncredentials from the URL, override the default schema type Java package,\nprovide a specific schema name, and much more.\n\nSakila.dbconfig\n\n    \n    \n    { \"url\": \"jdbc:oracle:thin:@localhost:1521:XE\", \"user\": \"system\", \"password\": \"password\", \"schemaPackage\": \"org.example.schema.types\", \"schemaName\": \"SAKILA\", \"dbDdl\": \"samples/ddl/oracle-sakila-ddl.sql\", . . . }\n\n## Naming\n\nBy default, the name of the file is used as the schema type name. For\ninstance, if you create a file named MyDatabase.dbconfig, the schema type name\nis MyDatabase. This type is generated automatically when it is referenced in\nyour code, it is the entry point to type-safely access the schema's entity\ntypes and to perform CRUD operations. More on this later.\n\n## Compiling vs. testing vs. production\n\nAlthough you can use a single .dbconfig resource file for both compiling and\nrunning your project, this configuration is most suitable for learning and\nplaying with Manifold SQL. In practice, separate configurations for\ncompilation, testing, and production are the typical setup. There are several\noptions to choose from in terms of where and how you define your\nconfigurations.\n\nA .dbconfig targeting compilation must be defined as a Java resource file and\ncan reside anywhere in your project's resource path. It is possible to share\nthis file for testing by using the same URL or by providing separate URLs. To\nprovide separate URLs use buildUrl for compiling and url for testing.\n\nAs with compilation, a .dbconfig file targeting runtime (testing or\nproduction) may be a resource file, but must reside in a resource directory\nnamed /config or, if your project uses module-info.java files, it may reside\nin resource directory /<your-module-name>/config. Consequently, if you use the\nsame .dbconfig file for compilation and testing/production, the file must be a\nresource file in one of the /config locations.\n\nAdditionally, a .dbconfig file may be placed in the current directory or in a\n/config subdirectory of the current directory. Current directory locations\nhave precedence over resource path locations and are exclusive to testing and\nproduction use. Note, if using the current directory, be sure to maintain the\nsame exact file name as the resource .dbconfig file name used for compilation.\n\nSee the url setting documentation for more information about specifying the\ncurrent directory and other details.\n\n## Programmatic configuration\n\nYou may also configure Manifold SQL programmatically by implementing the\nDbConfigProvider interface and using simple dependency injection. This form of\nconfiguration has precedence over .dbconfig files.\n\nSee DbConfigProvider customizations for more info.\n\n## Accessing the configuration in your code\n\nAccess the .dbconfig configurations type-safely via the\nmanifold.sql.rt.api.DbConfig type. For instance, if your .dbconfig file is\nnamed MyDatabase.dbconfig, you can access it like this:\n\n    \n    \n    DbConfig dbConfig = MyDatabase.getDbConfig();\n\n## Settings\n\n.dbconfig settings are JSON formatted. The following listing specifies each\nsetting name along with the setting type and whether it is optional, required,\nor provided. A provided setting is assigned when the .dbconfig file is\nprocessed; a provided setting cannot be overridden.\n\nname| String| (provided)  \n---|---|---  \n  \nThe base name of the .dbconfig file. For example, for a file named\nMyDatabase.dbconfig, the base name is MyDatabase. The top-level schema type\nwill have this name, where the schema's tables and views are projected as\ninner types of MyDatabase e.g., for a schema table named Film its Java entity\ntype will be MyDatabaes.Film.\n\nAs a convenience, if a \"schemaName\" setting is not specified and the JDBC URL\ndoes not indicate a schema, this name is also the name of the schema to fetch\nin the data source.\n\nThis name is automatically assigned by manifold on load of the file, or if\nthis DbConfig was constructed via DbConfigProvider dependency interface, it\nwill be supplied by the implementation.\n\ncatalogName| String| (optional)  \n---|---|---  \n  \nThe database catalog containing the schema. If not explicitly specified, all\naccessible database catalogs are searched for a schema matching \"schemaName\",\nin no particular order. If \"catalogName\" is the empty string \"\", this\nindicates only schemas without a catalog will be considered.\n\nSome drivers support naming the catalog in the URL. In this case the catalog\nname is unnecessary in the dbconfig.\n\nNote, some drivers provide schema names as catalog names i.e., catalogs\nwithout schemas. For instance, MySql does this. In this case the catalog names\nare queried from the database metadata, but used as schema names. Do not\nprovide the catalog name if it is not the container of the schema.\n\nschemaName| String| (optional)  \n---|---|---  \n  \nThe name of the database schema used for this configuration. If not explicitly\nspecified, the dbconfig file name is used as the schema name. If the file name\ndoes not correspond with a schema in the database, a default schema will be\nselected automatically.\n\nNote, some drivers provide schema names as catalog names e.g., MySql. In this\ncase the catalog names are queried from the catalogs of the driver's database\nmetadata.\n\npath| String| (provided)  \n---|---|---  \n  \nThe location of dbconfig file corresponding with this class. This setting is\nrelevant only at compile-time and is used for logging and debugging.\n\nurl| String| (required)  \n---|---|---  \n  \nJDBC URL for data source. If buildUrl is not specified, this URL is used for\nboth compiling and running your code.\n\nThe URL string can be templated with ${} expressions containing either a Java\nsystem property or an environment variable.\n\n    \n    \n    \"url\": \"jdbc:h2:file:${user.dir}/mydatabase\"\n\nHere the URL references a file in the user's current directory.\n\n${} expressions can be customized using the # symbol.\n\n    \n    \n    \"url\": \"jdbc:h2:file:${#my_tag arg1, arg2}\"\n\nImplement the DbLocationProvider interface to handle your custom tags.\n\nbuildUrl| String| (optional)  \n---|---|---  \n  \nJDBC URL for data source to be used exclusively for compiling. This data\nsource may be void of data, it is used solely for acquiring metadata during\ncompilation.\n\nSee url above for more information about encoding the JDBC URL.\n\nschemaPackage| String| (optional)  \n---|---|---  \n  \nThe fully qualified package name where schema .class files will be generated.\nIf not provided, the default package will be used: sql.schema.types. Note,\nthis property is used exclusively for compile-time.\n\nuser| String| (optional)  \n---|---|---  \n  \nUsername for data source.\n\npassword| String| (optional)  \n---|---|---  \n  \nPassword for data source.\n\nisDefault| boolean| (optional)  \n---|---|---  \n  \nIf true, this dbconfig is the \"default\" configuration. The default dbconfig is\napplied to all SQL resources not qualified with a dbconfig.\n\nIf multiple dbconfigs are in use, a SQL resource not intended for the default\ndbconfig must qualify its name with the intended dbconfig.\n\nTo use MyDatabase.dbconfig a .sql file follows the naming convention.\n\n    \n    \n    MyQuery.MyDatabase.sql\n\nInline SQL follows a similar pattern:\n\n    \n    \n    \"[MyQuery.sql:MyDatabase/] select * from ...\"\n\nIf there is only one dbconfig in use, it is considered default. Consequently,\nif you are not using multiple dbconfigs in your project you can ignore this\nsetting.\n\nproperties| Object| (optional)  \n---|---|---  \n  \nJDBC connection properties in JSON format. These properties are driver-\nspecific, consult your JDBC driver documentation for details.\n\ndbDdl| String| (optional)  \n---|---|---  \n  \nA resource file containing DDL for the database/schema this configuration is\nusing. This is typically obtained as a DDL dump from the DBMS. This setting is\nintended for testing and/or compilation e.g., to recreate the database between\ntests.\n\ncustomBaseInterface| String| (optional)  \n---|---|---  \n  \nThe qualified name of the base interface to be used for generated entity\nclasses, projected from schema tables and views.\n\ncustomBaseClass| String| (optional)  \n---|---|---  \n  \nThe qualified name of the base class to be used for generated entity classes.\nPlease note, the Manifold SQL APIs only expose entity interfaces. Public\nmethods on a custom base class will not be exposed in the API, for that you\nmust define a custom base interface. See customBaseInterface above.\n\ninMemory| boolean| (optional)  \n---|---|---  \n  \n(for internal use) If using the database in-process (in-memory) e.g.,\njdbc:h2:mem or jdbc:sqlite::memory:, this setting must be set to true,\notherwise it is ignored. This setting applies exclusively to manifold-sql-\ninproc-test.\n\n# Step 3. Begin writing incredible code!\n\nIf you've added Manifold SQL your build and configured your database in one or\nmore .dbconfig files, you're ready to begin writing incredible code!\n\nMost of the examples here use the Sakila sample database originally published\nfor MySQL. It is now open source and is a great example of a well-designed,\nnormalized schema.\n\nThe Manifold SQL sample project contains many of the examples used here. Clone\nit and start experimenting!\n\n## Queries\n\nManifold SQL lets you use native SQL of any complexity directly and type-\nsafely anywhere in your code. You can define SQL queries in .sql files or\ninline SQL directly in your Java code.\n\n### .sql files\n\nA standard .sql file contains a single SQL statement, such as a Select\nstatement, in a dialect supported by your database. It may contain any number\nof SQL comments. Additionally, it may define any number of named SQL\nparameters prefixed with the : character. This is where you would otherwise\nuse ? characters when using anonymous JDBC encoded parameters.\n\nAll .sql files must be defined as Java resource files and must reside in your\nproject's resource path.\n\nQuery type names match .sql file names. For example, the query type for\nresource file org/example/queries/Sales.sql would be org.example.queries.Sales\nand use the default dbconfig.\n\nIf you want a .sql file to target a dbconfig other than the default one, you\nmust include it in the file name. For instance, to use\nMyOtherDatabase.dbconfig with Sales.sql, add the dbconfig name as a secondary\nfile extension.\n\n    \n    \n    `org/example/queries/Sales.MyOtherDatabase.sql`\n\n> i Inline SQL follows a similar pattern, but because it supports anonymous\n> types the dbconfig name is appended.\n>  \n>  \n>     \"[.sql:MyOtherDatabase/] select * from ...\"\n>\n> More on inline SQL later.\n\n### Query & Row types\n\nHere is a simple query file providing employee names and email addresses.\n\norg/example/queries/StaffInfo.sql\n\n    \n    \n    SELECT first_name, last_name, email FROM staff\n\nInvoke the query type-safely like this:\n\n    \n    \n    import org.example.queries.StaffInfo; . . . for(StaffInfo.Row row : StaffInfo.fetch()) { out.println(row.getFirstName() + \", \" + row.getLastName() + \", \" + row.getEmail()); }\n\nAll SQL queries are compiled as Java interface types matching the name and\nlocation of the SQL resource file. Here resource file\norg/example/queries/StaffInfo.sql compiles as interface\norg.example.queries.StaffInfo.\n\nNotice the results are provided using the StaffInfo.Row type. The Row\ninterface type-safely reflects all the query's selected columns.\n\nExecute a query using one of the fetch methods. In this example fetch()\nreturns multiple rows that are iterable using the for statement.\n\n> i Include manifold-props in your project for more concise usage of get/set\n> property methods.\n>  \n>  \n>     out.println(row.getFirstName() + \",\" + row.getLastName() + \",\" +\n> row.getEmail()); // vs. out.println(row.firstName + \",\" + row.lastName + \",\"\n> + row.email);\n\n### Entity types\n\nHere's another example utilizing query parameters and an entity type.\n\norg/example/queries/FindRental.sql\n\n    \n    \n    -- Finds the rental of the customer's returning DVD. SELECT * FROM rental WHERE inventory_id = :inventory_id AND customer_id = :customer_id AND return_date IS NULL\n\nInvoke the query type-safely like this:\n\n    \n    \n    import org.example.schema.Sakila.*; import org.example.queries.FindRental; . . . Rental rental = FindRental.fetchOne(inv.getInventoryId(), cust.getCustomerId()); LocalDateTime returnDate = rental.getReturnDate();\n\nThis example demonstrates that when the selected columns of a query contain\nall the non-null columns of a selected table, such as with select * queries,\nthe query results consist of entity instances instead of row instances.\n\nNotice the fetchOne method matches the parameters in the query and returns\njust one item, the Rental.\n\nUnlike Row interfaces, entities may participate in CRUD operations and are\nfully customizable.\n\nParameters are both type-safe and injection-safe.\n\nSee entities for fuller coverage of the subject.\n\n### Inline SQL\n\nIt is often convenient to read and write SQL directly where your Java code\nuses it. You can inline a SQL resource utilizing Java string literals, text\nblocks, and comments.\n\nHere are the previous SQL resource file examples duplicated as inline SQL.\n\n    \n    \n    for(StaffInfo.Row row : \"[StaffInfo.sql/] SELECT first_name, last_name, email FROM staff\".fetch()) { out.println(row.getFirstName() + \", \" + row.getLastName() + \", \" + row.getEmail()); }\n\nNotice the [StaffInfo.sql/] prefix in the query string. Manifold uses this\nsyntax to identify inlined resources. It instructs the compiler plugin to\ntreat the content of the literal value as an embedded resource file. Thus, the\nStaffInfo.sql name indicates the content is native SQL and is generated as\ntype StaffInfo relative to the enclosing scope.\n\nYou can also inline SQL anonymously by eliminating the name. Here is the same\nexample, but without the StaffInfo name.\n\n    \n    \n    for(var row : \"[.sql/] SELECT first_name, last_name, email FROM staff\".fetch()) { out.println(row.getFirstName() + \", \" + row.getLastName() + \", \" + row.getEmail()); }\n\nSince the SQL query no longer has a name, we must infer its name using the var\nkeyword, otherwise it behaves exactly like a named SQL statement.\n\n> i Manifold's auto feature can be used in Java 8 to achieve the same behavior\n> as the var keyword. auto is also a bit more versatile, it can be used with\n> fields and method return types.\n\nMore involved queries can be defined inside Java text blocks.\n\n    \n    \n    import org.example.schema.Sakila.*; . . . Rental rental = \"\"\" [.sql/] SELECT * FROM rental WHERE inventory_id = :inventory_id AND customer_id = :customer_id AND return_date IS NULL \"\"\".fetchOne(67, 112); LocalDateTime returnDate = rental.getReturnDate();\n\nHere we have the same multiline query defined in the\norg/example/queries/FindRental.sql resource file example above. Notice this\nquery is defined anonymously via [.sql]. There is no need for a type name here\nbecause there is no need to explicitly reference the type. This is often the\ncase when inlining SQL with string literals and text blocks.\n\nSQL statements may also be inlined using comment delimiters.\n\n    \n    \n    import org.example.schema.Sakila.*; . . . /*[FindRental.sql/] SELECT * FROM rental WHERE inventory_id = :inventory_id AND customer_id = :customer_id AND return_date IS NULL */ Rental rental = FindRental.fetchOne(67, 112); LocalDateTime returnDate = rental.getReturnDate();\n\nUse a comment when you prefer to separate the SQL query type from code that\nexecutes it. Also, great for formatting SQL with Java versions prior JDK 15\nwhere text blocks are not available as a standard feature.\n\nUse text blocks to make queries more readable and directly executable.\n\n    \n    \n    /** Top N rented movies in descending order */ public void displayPopularMovies(int topN) { \"\"\" [.sql/] SELECT title, COUNT(title) as rentals FROM film JOIN inventory ON (film.film_id = inventory.film_id) JOIN rental ON (inventory.inventory_id = rental.inventory_id) GROUP by title ORDER BY rentals desc LIMIT :topN \"\"\".fetch(topN).forEach(row->out.println(row.getTitle() + \": \" + row.getRentals())); }\n\n## Entities\n\nManifold SQL uses your JDBC connection to automatically infer entity\ninterfaces for schema tables and views. You use these interfaces to process\nquery results and to perform CRUD (Create, Read, Update, Delete) operations on\nyour database.\n\nYour .dbconfig file name is the top-level schema type name. Use this to access\nall the schema's entity interfaces.\n\nUsing our sample Sakila.dbconfig file we can use the Country entity interface\nlike this:\n\n    \n    \n    import org.example.schema.Sakila.Country;\n\nOr, import all of Sakila's entity interfaces.\n\n    \n    \n    import org.example.schema.Sakila.*;\n\n### Entity methods\n\nAn entity defines conventional get/set properties corresponding with all the\ntable column names.\n\n    \n    \n    City city = \"[.sql/] select * from city where city_id = :city_id\".fetchOne(cityId); Long countryId = city.getCountryId();\n\n\"fetch\" methods load entities corresponding with primary keys, foreign keys,\nand non-null columns.\n\n    \n    \n    City city = City.fetch(cityId); Country country = city.fetchCountryRef(); List<City> cities = City.fetchByCountryId(country.getCountryId());\n\nOne-to-many and many-to-many relations are also covered with \"fetch\" methods.\n\n    \n    \n    Country country = Country.fetch(countryId); for(City c : country.fetchCityRefs()) out.println(c.city);\n\nNote, \"fetch\" methods are lazy, their values are never pre-fetched. One-to-\nmany and many-to-many methods never cache values and always query the\ndatabase. This behavior is fully customizable, see customizing entity types.\n\nAs covered in the CRUD section below, entities define static methods for\ncreating, building, and fetching. There are also instance methods for deleting\nand undeleting.\n\n### Patching JDBC types\n\nThe TypeProvider dependency interface provides the JDBC type for schema\ncolumns, query columns, and parameters. It may override the type obtained from\nthe JDBC driver. For example, sometimes it is helpful to use alternative\nnumeric types that better reflect the database's SQL type.\n\nIn turn, ValueAccessor implementations use the JDBC type obtained from the\nTypeProvider to provide the Java class used in the entity and query APIs. You\ncan override the TypeProvider to use your own ValueAccessor implementations.\n\n### Value accessors\n\nEntity properties are typed based on JDBC column metadata. The JDBC types and\ncorresponding Java types are controlled using ValueAccessor implementations\nand dependency injection. See ValueAccessProvider below.\n\n### Customizing entity types\n\nThe Java code generated for the entity API is thoroughly customizable. You\ncan:\n\n  * provide a custom base interface, which will be a super interface to all generated entity interfaces. See the customBaseInterface setting in DbConfig Settings.\n  * provide a custom base class, which will be the super class of all generated entity classes. See the customBaseInterface setting in DbConfig Settings.\n  * completely control entity instance creation via CustomEntityFactory. See Customizations.\n  * provide custom interfaces per entity using a simple naming convention. For example, to provide a custom interface for entity Actor the custom interface must be a top-level source file named CustomActor.java anywhere in your project and follow this naming convention:\n    \n        public interface CustomActor extends CustomEntity<Actor> {...}\n\nThis naming convention makes it easy to customize the entity API using default\ninterface methods.\n\n    \n        public interface CustomActor extends CustomEntity<Actor> { default String myActorMethod() { Actor actor = self(); ... return \"hello\"; } } . . . Actor actor = getActor(); actor.myActorMethod();\n\n  * You can add custom methods to any type using extension classes. This mode of customization applies to all types, not just Manifold SQL APIs.\n\n## CRUD\n\nYou can write CRUD (Create, Read, Update, Delete) operations using native SQL\ncommands such as INSERT, SELECT, UPDATE, and DELETE. However, these operations\ntend to be repetitive, resulting in a lot of error-prone, boilerplate code.\nEntity interfaces provide an API to simplify common CRUD operations.\n\n> i It is possible to customize CRUD operations by overriding the default\n> implementation. See CrudProvider.\n\n### Create\n\nYou can make new instances of entity types by invoking a create or builder\nmethod directly from the interface.\n\nThe create method defines parameters matching the database table's required\ncolumns.\n\n    \n    \n    import org.example.schema.Sakila.*; . . . String name = \"Gibberish\"; Language gibberish = Language.create(name);\n\nIn this case just the name column is required. Note, the language table's\nprimary key is auto-incremented, therefore it is not a parameter.\n\nThe create method creates a new instance of Language, but does not commit it\nto the database. More on that later.\n\nIf there are required foreign keys, you can use foreign key IDs or use entity\ninstances corresponding with the foreign key.\n\n    \n    \n    . . . Film pigglywiggly = Film.create(\"Pigglywiggly\", gibberish);\n\nHere we use gibberish, the Language instance created earlier. Note, we have to\npass the instance as there is no foreign key id available for gibberish\nbecause it has not yet been committed to the database. We'll cover\ntransactions shortly, but this example demonstrates how entities automatically\nhandle foreign key assignment for you, both to and from storage.\n\nSimilar to create methods, builder methods are available to conveniently\nconstruct entity instances using a fluent API.\n\n    \n    \n    . . . Film pigglywiggly = Film.builder(\"Pigglywiggly\", gibberish) .withReleaseYear(1987) .build();\n\nOptional database columns such as release_year are assignable using with\nmethods.\n\n### Read\n\nUse type-safe, native SQL queries of any complexity. Or, use fetch methods to\nload entities.\n\n    \n    \n    List<Film> films = \"[.sql/] select * from film where release_date > :releaseData\".fetch(2005);\n\nNotice the query results above are provided as Film entity instances. This\nmeans you can execute type-safe queries to find entities and then directly\nperform CRUD operations on the results.\n\n    \n    \n    film.setReleaseData(2008);\n\n\"fetch\" methods provide quick access by primary key, foreign key, one-\nmany/many-many relationships, etc.\n\n    \n    \n    List<Film> films = Film.fetchByReleaseDate(1987);\n\n### Update\n\nUpdates amount to calling setter methods on entities whenever/wherever you\nlike.\n\n    \n    \n    Film pigglywiggly = \"[.sql/] select * from film where name = 'pigglywiggly'\"; pigglywiggly.setReleaseYear(1988);\n\nAs this example demonstrates, you can simply make changes using standard Java\nsetter methods. Changes are collected until they are committed via transaction\nscope.\n\nYou can also use type-safe SQL commands to perform targeted and/or mass\nupdates more efficiently. See DML & DDL commands.\n\n    \n    \n    Sakila.addSqlChange(ctx -> { \"[.sql/] UPDATE rental SET return_date = NOW() WHERE rental_id = :rentId\".execute(ctx, getRendId()); });\n\n### Delete\n\nTo delete an entity call the delete method.\n\n    \n    \n    Film film = getFilmFromSomewhere(); film.delete();\n\nYou can undelete too.\n\n    \n    \n    film.undelete();\n\nYou can also use type-safe SQL commands to perform targeted and/or mass\nupdates more efficiently. See DML & DDL commands.\n\n    \n    \n    String country = \"United States\"; . . . Sakila.addSqlChange(ctx -> { \"[.sql/] DELETE FROM country WHERE country = :country\".execute(ctx, country); });\n\n## Transaction scopes\n\nEntity instances, such as Film and Language, always belong to a transaction\nscope. The purpose of the transaction scope is to decouple entity changes from\nthe database transaction. That is, the timeline and scoping of entity changes\nare separated from the timeline and scoping of persisting entity changes.\n\nInitially, when you read an entity from storage using a query or fetch method,\nthe transaction scope has no reference to it because it hasn't changed. Only\nwhen you create, update, or delete an entity, is it added to the transaction\nscope as a change.\n\nWhen you are ready to commit changes, you simply call the transaction scope's\ncommit method. This method completely manages the transaction: it opens and\ncloses the data source connection, translates entity changes to DML\noperations, and ensures the commit is atomic. As a result, the timeline and\nscoping of entity changes are nicely decoupled from the persistence scope.\n\n### Default transaction scope\n\nTypically, you can happily ignore transaction scopes by using the default\ntransaction scope, which is built into the entity API implementation.\n\nMost of the API methods involving a transaction scope make it optional by\ndefining two versions of the method, one with a TxScope argument and one\nwithout. Choosing the one without uses the default TxScope, which is a thread-\nlocal instance. Essentially, the API encapsulates a default transaction scope\nto make it simple to avoid having to create or use them beyond calling commit.\n\nFor example, all create methods have two versions.\n\n    \n    \n    Film.create(\"My Title\", myLanguageId); Film.create(myTxScope, \"My Title\", myLanguageId);\n\nUnless you need to manage your own TxScope, you can select the first one,\nwhich uses the default scope.\n\nIf using the default cope, as a convenience you may call commit using the top-\nlevel schema type, which matches the name of your dbconfig file.\n\n    \n    \n    Sakila.commit();\n\nThis is another example where the API encapsulates the default scope, it also\nmakes good sense to call commit from the schema name!\n\nThe default scope is thread-local to enable the separation and processing of\nindependent transactions in a thread-safe manner. Additionally, the default\nscope is a pluggable dependency, which allows it to be completely replaced or\nsubclassed. For example, a default scope more suitable for web requests could\nbe configured to replace the standard default scope. See\nDefaultTxScopeProvider.\n\n### commit()\n\nAs mentioned the commit method is the primary function of the transaction\nscope. It manages the entire database transaction, beginning to end. In a\nnutshell, if there are changes to commit, it opens the data source connection,\ntranslates changes to ordered DML operations, reconciles entity state, and\ncloses the connection.\n\nIf commit succeeds, the state of all the entity instances reflects the full\nstate of the corresponding records in storage, including all generated,\ndefault, auto-increment, and foreign key columns. If commit fails, the changes\nroll back and the state of all the entity instances involved revert to their\nstate immediately before the call to commit.\n\n    \n    \n    Country canada = Country.create(\"Canada\"); City otherCityMyCountry = City.create(\"Ottawa\", canada); . . . Country mexico = Country.create(\"Mexico\"); City myCityMyCountry = City.create(\"Puebla\", mexico); . . . Sakila.commit();\n\nHere, if commit succeeds, all the primary and foreign keys involved are\nassigned to reflect the database state. Otherwise, if commit fails, entity\nstate goes back to where it was immediately before the commit call. From there\nyou can choose to abandon the changes, revert the changes back to the prior\ncommit, or make adjustments and retry the commit.\n\nLife continues after the commit for both the entities and the transaction\nscope. As a result, a transaction scope may span multiple commits, where you\ncan continue to make changes to entities. A subsequent call to commit\nprocesses changes made after the prior commit, and so on.\n\n### Coupled queries\n\nDecoupling changes from the transaction means we are decoupling DB writes. As\nsuch, the TxScope accumulates write operations for execution during the call\nto commit() where all changes execute in a single transaction. But what about\nthe read operations?\n\nThere's no delaying DB reads. Queries must execute immediately because the\ncode depending on query results requires it. As a consequence, queries execute\ndirectly in separate transactions against a durable state of the database.\nThis works out well for many use-cases. Sometimes, however, a query must\nreflect uncommitted changes from the write transaction, in this case it must\nexecute in step with the writes in the same transaction.\n\nThere are two options that enable reads and writes to execute in the same\ntransaction.\n\n#### 1\\. TxScope#addSqlChange(ScopeConsumer)\n\naddSqlChange() posts a set of changes to the TxScope, which execute when\nTxScope.commit() is called. Changes may include any type of SQL command,\ndirect or indirect: entity CRUD operations, entity fetch calls, SQL queries,\nand other native SQL commands.\n\n    \n    \n    Sakila.addSqlChange(ctx -> { insertClients(ctx); for(var row: \"[.sql/] SELECT client_id FROM client WHERE secondary_lang = 'english'\".fetch()){ insertEnglishResources(ctx, row.getClientId()); } });\n\nHere the query must access the clients that were inserted/updated within the\ntransaction. When run within a call to addSqlChange() since there is always a\nlive transaction in context, queries run within that context, provided the\nquery's TxScope is the same as the one in ctx. In this case, assuming the\ndefault TxScope is in use, the query executes in the same transaction and\nreflects the clients inserted from the insertClients() call.\n\nNote, entity CRUD operations continue to operate lazily. Only in this case,\nbecause queries run in the same context, CRUD operations delay execution until\nthe next query is encountered or until no further operations remain. This\nbehavior is necessary to include the effects of entity CRUD in coupled query\nresults.\n\n#### 2\\. TxScope#commit(ScopeConsumer)\n\nSimilar to addSqlChange(ScopeConsumer), commit(ScopeConsumer) commits a set of\nSQL operations directly. In fact, it is a shortcut for the following:\n\n    \n    \n    Sakila.addSqlChange(...); Sakila.commit();\n\nAs with addSqlChange(ScopeConsumer), queries execute in the same tx along with\nwrites.\n\n### Have it your way\n\nYou can create your own transaction scope instances with the TxScope#newScope\nmethod.\n\n    \n    \n    TxScope txScope = Sakila.newScope(); . . . Country canada = Country.create(txScope, \"Canada\"); City otherCityMyCountry = City.create(txScope,, \"Ottawa\", canada); . . . txScope.commit();\n\nManaging your own transaction scopes may be necessary, for example, if you are\nmodifying the same entity in different threads.\n\nCustom TxScope implementations via simple dependency injection is another\noption. This is covered in the Customizations section.\n\n## DML & DDL commands\n\nIn addition to select statements, SQL files and inline statements also work\nwith other kinds of native SQL, including:\n\n  * Data Manipulation Language (DML), statements include insert, update, and delete\n  * Data Definition Language (DDL), statements such as create table and alter table\n  * Generally, any SQL statement that returns nothing\n\nSince these types of statements make changes to the database, they must\nexecute within a transaction scope, just like CRUD operations on entities.\nThis is achieved via TxScope#addSqlChange.\n\n    \n    \n    String country = \"United States\"; . . . Sakila.addSqlChange(ctx -> { \"[.sql/] DELETE FROM country WHERE country = :country\".execute(ctx, country); });\n\nNotice the execute method requires the ctx parameter, which is supplied\nexclusively by the transaction scope. This ensures SQL commands execute only\nfrom calls to addSqlChange, which enables such changes to be bundled within\nthe same transaction scope as other DML statements and CRUD operations.\n\nThis example also illustrates how type-safe, injection-safe SQL parameters can\nbe used with any SQL command.\n\n## Customizations\n\nJust about any aspect of Manifold SQL can be tailored, overridden, and/or\nreplaced using simple dependency injection. This amounts to implementing the\nDependencies service provider interface (SPI). You can either subclass the\nManifold SQL DefeaultDependencies class and override whichever interfaces you\nlike, or directly implement Dependencies and delegate to DefeaultDependencies\nfor default behavior. Whichever is more suitable for your needs.\n\nBecause Manifold SQL is used to compile your project, your Dependencies\nimplementation class must be compiled before it can be used in your project.\nThis means your implementation class must be defined in a separate module in\nyour project or in a separate project.\n\nIt's usually good idea to self register your Dependencies implementation. This\nway your project build file can simply add your implementing module as a\ndependency. Follow these standard steps to register your SPI implementation\nclass.\n\n  1. Create a file named manifold.sql.rt.api.Dependencies in resources/META-INF/services. For example, normally this file will be in src/main/resources/META-INF/services.\n  2. The contents of this file must contain the qualified name of your implementing class followed by a new line:\n\n    \n    \n    org.example.MyDependencies\n\nIn addition to adding a normal implementation dependency on your Dependencies\nmodule, you must also add an annotation processor dependency. For gradle:\n\n    \n    \n    dependencies { . . . implementation 'org.example.my-manifold-sql-custom-dependencies:0.1-SNAPSHOT' annotationProcessor 'org.example.my-manifold-sql-custom-dependencies:0.1-SNAPSHOT' }\n\nFor maven:\n\n    \n    \n    <dependencies> . . . <dependency> <groupId>org.example</groupId> <artifactId>my-manifold-sql-custom-dependencies</artifactId> <version>0.1-SNAPSHOT</version> </dependency> </dependencies> . . . <build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> . . . <configuration> . . . <annotationProcessorPaths> <path> <groupId>systems.manifold</groupId> <artifactId>manifold-sample-sql-dependencies-project</artifactId> <version>0.1-SNAPSHOT</version> </path> </annotationProcessorPaths> </configuration> </plugin> </plugins> </build>\n\nSee Step 1: Adding manifold-sql to your build for complete instructions to add\nManifold SQL to your build.\n\nSee Customizing entity types for more ways to customize the schema/entity API.\n\n## Dependency interfaces\n\nThe configurable types provided by the Dependences SPI include the following\ninterfaces.\n\n### DbConfigProvider\n\nmanifold.sql.rt.api.DbConfigProvider\n\nAbstracts the loading of .dbconfig files.\n\nThe default implementation searches the following locations in order:\n\n  * <user.dir>/config\n  * <user.dir>\n  * <resource-path>/<current-module-name>/config (JDK 11+)\n  * <resource-path>/config (JDK 8+)\n\nCustom implementations may change any aspect of loading .dbconfig files.\n\n### ConnectionProvider\n\nmanifold.sql.rt.api.ConnectionProvider\n\nProvides JDBC connections corresponding with .dbconfig settings.\n\nThe default implementation uses HikariCP.\n\n### CrudProvider\n\nmanifold.sql.rt.api.CrudProvider\n\nPerforms CRUD operations on entity types.\n\n### DbLocationProvider\n\nmanifold.sql.rt.api.DbLocationProvider\n\nHandles custom # tags in the url dbconfig setting.\n\n    \n    \n    \"url\": \"jdbc:h2:file:${#my_tag arg1, arg2, ...}\"\n\nThe default implementation handles the #resource and #resource_script tags,\nwhich are primarily for internal tests.\n\n### DefaultTxScopeProvider\n\nmanifold.sql.rt.api.DefaultTxScopeProvider\n\nProvides the default scope used in entity and SQL execution method signatures\nnot providing an explicit TxScope parameter.\n\nThe default implementation provides thread-local TxScopes. A custom\nimplementation could, for example, provide web request TxScopes.\n\n### TxScopeProvider\n\nmanifold.sql.rt.api.TxScopeProvider\n\nThe factory for TxScope instances.\n\nThe default implementation makes BasicTxScope instances.\n\n### TypeProvider\n\nmanifold.sql.rt.api.TypeProvider\n\nThe TypeProvider dependency interface provides JDBC types to correspond with\nschema columns, query columns, and parameters.\n\nThe default implementation may override the type obtained from the JDBC\ndriver. Sometimes this is necessary to correct, for example, numeric types\nfrom the driver that don't pair well with the database's SQL type.\n\nYou can implement this dependency to control JDBC types used at any\ngranularity: everything, driver, database, table, column.\n\nIn turn ValueAccessor implementations use the JDBC type obtained from the\nTypeProvider to infer the Java types used in the generated entity and query\nAPIs. See ValueAccessorProvider.\n\n### ValueAccessorProvider\n\nmanifold.sql.rt.api.ValueAccessorProvider\n\nProvides the ValueAccessor instances corresponding with JDBC types.\n\nYou can use this dependency to override ValueAccessor instances with your own\nimplementations.\n\n### CustomEntityFactory\n\nmanifold.sql.rt.api.CustomEntityFactory\n\nConstructs entity classes implementing the entity API interfaces.\n\n> \u26a0 There is a good chance you should be customizing the entity interface, not\n> the entity class. This is because entity interfaces are self implementing,\n> meaning they delegate behavior using default methods. All the state backing\n> an interface is obtained via the getBindings() call, which is the only\n> entity interface method requiring class implementation. As a consequence,\n> custom interfaces typically follow along and self implement custom methods,\n> relieving you of having to create a custom entity class. See customizing\n> entities types.\n\nIf you do create a custom entity class to go along with your custom entity\ninterface, it must:\n\n  * extend BaseEntity or a custom base class, see customizing entities types\n  * implement the corresponding entity interface (not a custom interface)\n  * provide a public constructor with a TxBindings parameter that forwards the argument to BaseEntity\n\n    \n    \n    import org.example.schema.Sakila.Address; import manifold.sql.rt.api.TxBindings; public class MyAddress extends BaseEntity implements Address { private MyAddress(TxBindings bindings) { super(bindings); } // your custom code here... }\n\n# IDE support\n\nManifold is fully supported in IntelliJ IDEA and Android Studio.\n\n## Plugin installation\n\nGet the Manifold plugin directly from within the IDE via:\n\nSettings \u279c Plugins \u279c Marketplace \u279c search: Manifold\n\n## IntelliJ IDEA Community Edition vs. IDEA Ultimate\n\nJetBrains is generous with features offered in Community edition, as a\nconsequence a lot of Java projects can be developed with Community and still\nmaintain a high quality dev experience. But one area where Ultimate separates\nfrom Community is SQL support. Ultimate is packed with excellent SQL features,\nwhich are well worth the investment if you are developing an application that\ninvolves relational database access. Manifold integrates nicely with all of\nthese features, such as native SQL code completion, syntax highlighting, query\nexecution, and more.\n\nAll the same, Manifold SQL is available and free for both IntelliJ products:\ntype-safe native SQL, inline SQL, CRUD, etc. Additionally, in both products\nManifold SQL supports SQL error feedback in Java editors and SQL files as you\ntype SQL commands. You'll know instantly whether your SQL is valid and, if\nnot, what is wrong.\n\n# Javadoc\n\nmanifold-sql:\n\nmanifold-sql-rt:\n\n# License\n\nManifold is free, open source software and licensed with Apache 2.0.\n\n# Versioning\n\nFor the versions available, see the tags on this repository.\n\n# Author\n\n  * Scott McKinney\n\n# Comms\n\nStart a discussion on slack.\n\nReport an issue.\n\nIf you prefer email, info@manifold.systems.\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

{"aid": "39999181", "title": "Interpretability vs. Neuroscience", "url": "https://colah.github.io/notes/interp-v-neuro/", "domain": "colah.github.io", "votes": 1, "user": "ofou", "posted_at": "2024-04-11 07:09:13", "comments": 0, "source_title": "Interpretability vs Neuroscience [rough note]", "source_text": "Interpretability vs Neuroscience [rough note] -- colah's blog\n\n# Interpretability vs Neuroscience\n\nSix major advantages which make artificial neural networks much easier to\nstudy than biological ones.\n\nPosted on March 12th, 2021\n\nThis article is a rough note. Writing rough notes allows me share more\ncontent, since polishing takes lots of time. While I hope it's useful, it's\nlikely lower quality and less carefully considered than my usual articles.\nIt's very possible I wouldn't stand by this content if I thought about it\nmore.\n\nI study what goes on inside artificial neural networks. I don\u2019t know anything\nmuch about actual neuroscience, but I'm sometimes struck by how much easier my\njob is than a neuroscientist's.\n\nThis essay lists advantages that make it easier to understand artificial\nneural networks. If we're to make rapid progress on understanding artificial\nneural networks \u2014 when countless brilliant neuroscientists have only started\nto understand the human brain after decades of research \u2014 we should probably\nbe trying to exploit these advantages as ruthlessly as possible.\n\n##\n\nAdvantage 1\n\nYou can get the responses of all neurons for arbitrarily many stimuli.\n\nIn neuroscience, one is limited in the number of neurons they can record from,\ntheir ability to select the neurons they record, and the number of stimuli\nthey can record responses to. For artificial neural networks, we can record\nthe responses of all neurons to arbitrarily many stimuli. For example, it\u2019s\nnot unusual to use recordings of how every single neuron in a network responds\nto millions of natural stimuli.\n\nThere's no lab work involved. Turn arounds are much faster than biological\nexperiments (essentially instant for small scale recording). There's no\nrecording noise. No synaptic fatigue. And if you don't get the recordings you\nneed the first time, you can go back and record again from the exact same\nneurons, which haven't changed at all.\n\n##\n\nAdvantage 2\n\nNot only do you have the connectome, you have the weights!\n\nA major undertaking in neuroscience is the attempt to access the connectome \u2014\nthe graph of how neurons in a brain connect. Even if they succeed, they won\u2019t\nknow the weights of those connections. Are they excitatory or inhibitory? How\nstrongly excitatory or inhibitory are they?\n\nWith artificial neural networks, all the connections and weights are simply\nthere for us to look at. And since we also know how these artificial neurons\nare computed, in principle we have everything we need to just reason through\nand understand the neural network.\n\nThis is tricky, but if you\u2019re willing to look you can literally read\nalgorithms directly off the weights of the network. This is one of the main\nideas behind circuits.\n\nA simple example of how neural network weights can reflect underlying\nmechanisms: a car detector is composed from neurons in the previous layer\nresponding to parts of a car in the appropriate arrangement (figure taken from\nOlah et al, 2020).\n\n##\n\nAdvantage 3\n\nWeight-tying massively reduces the number of unique neurons!\n\nArtificial neural networks often leverage a technique called weight-tying, in\nwhich we force many neurons to have the same weights. The most common use of\nthis is in convolutional neural networks, where each neuron has translated\ncopies of itself with the same weights. (If you're unfamiliar, see my tutorial\non conv nets and weight tying.)\n\nThe effect of weight-tying on interpretability is really under-appreciated.\nFor example, in ImageNet conv nets, weight-tying often reduces the number of\nunique neurons in early vision by 10,000x or even more! This results in\nartificial neural networks having many fewer neurons for early vision than\ntheir biological counterparts. For example, V1 in Human vision is about\n150,000,000 neurons, early vision in InceptionV1 (very expansively defined) is\nonly about 1,000 neurons. This means we can just literally study every single\nneuron.\n\n##\n\nAdvantage 4\n\nEstablishing causality by optimizing the input (feature visualization)\n\nIn my experience, one of the thorniest issues in understanding neurons in\nartificial networks is separating correlation from causation. Does a neuron\ndetect a dog head? Or does it just detect part of a dog head? Perhaps it just\ndetects an ear, or an eye, or fur parting in a specific way. Perhaps it\ndetects something that has no intrinsic relationship to dog heads, but is\nreally correlated with their presence. Framing this issue as \"correlation vs\ncausation\", while true, perhaps understates the problem. There's a second very\nclosely related problem: we don't know what the space of likely functions a\nneuron might perform is. So we can't just pin down a couple hypotheses and\ndevise an experiment to separate them.\n\nI imagine this is also a challenge in neuroscience.\n\nArtificial neural networks offer us an immensely useful tool for solving this\nwhich we often call feature visualization. We create stimuli \u201cfrom scratch\u201d to\nstrongly activate neurons (or combinations of neurons) in artificial neural\nnetworks, by starting with random noise and optimizing the input. The key\nproperty of feature visualization is that anything in the resulting\nvisualization there because it caused the neuron to fire more. If feature\nvisualization gives you a fully formed dog head with eyes and ears arranged\nappropriately, it must be detecting an entire dog head. If it just gives an\neye, it's probably only (or at least primarily) responding to that. If it was\ndetecting a watermark or something in the background, feature visualization\nwould render that. (There's an important caveat about the regularization of\nfeature visualizations; see discussion in the section of our tutorial titled\n\"The Spectrum of Regularization\".)\n\nOptimizing inputs is also how adversarial examples were discovered!\n\nRecent efforts in neuroscience have tried to develop similar methods [], by\nusing an artificial neural network as a proxy for a biological one. This work\nis very interesting, but it\u2019s unclear they give you the same ability to\nestablish a causal link. It seems hard to exclude the possibility that the\nresulting stimulus might have content which causes the artificial neurons\npredicting the biological neuron to fire more, but aren't causally necessary\nfor the biological neuron to fire.\n\n##\n\nAdvantage 5\n\nInterventions, Ablations, and Edits\n\nOptogenetics has been a major methodological advance for neuroscience in\nallowing neuroscientists to temporarily ablate neurons, or to force them to\nactivate. This is a powerful tool for interrogating neural circuits and\nestablishing causality.\n\nArtificial neural networks are trivial to manipulate at the level of neurons.\nOne can easily ablate neurons or set them to particular activations. But one\ncan also do more powerful \"circuit editing\" where one modifies parameters at a\nfiner grained level.\n\nThis is still early days, but we've already seen interesting examples. In\nimage generation, Bau et al., 2018 show that you can ablate neurons to remove\nobjects like tress and windows from generated images. In RL, Hilton et al.,\n2020 show that you can ablate features to blind an agent to a particular enemy\nwhile leaving other competencies in tact. More recently, Cammarata et al, 2021\nreimplements a large chunk of neural network from scratch, and then splices it\ninto a model.\n\n##\n\nAdvantage 6\n\nWe can study the exact same model.\n\nNeuroscientists might study a model organism species, but each brain they\nstudy has different neurons. If one neuroscientist reports on an interesting\nneuron they found, other neuroscientists can't directly study that same\nneuron. In fact, the neuroscientists studying the original neuron will quickly\nlose access to it: probes can't be left in indefinitely, organisms die, human\nsubjects leave, and even setting that aside neurons change over time.\n\nStudying artificial networks, we can collaboratively reverse engineer the same\n\u201cbrain\", building on each other. My collaborators and I all know that in\n\"canonical InceptionV1\", 4c:447 is a car detector. In fact, when a colleague\nat another institution makes neural network and posts it on twitter, I can\nrecognize by eye the neurons he used. This is entertaining, but reflects\nsomething which I think is quite remarkable: we have a shared web of thousands\nof \"footholds\" into InceptionV1, consisting of neurons we understand fairly\nwell and know the connections between, which makes it massively easier to\nexplore.\n\n##\n\nBonus\n\nReduced Moral Murkiness\n\nI care intensely about the welfare of animals. I'm willing to accept that the\nsuffering of animals can be outweighed by the benefit of the research. But I\nfeel very fortunate to not need to make that call -- to wonder if, for each\nexperiment, the benefit is sufficient to justify the suffering. (Although I do\nthink it's worth thinking quite critically about whether there is a point\nwhere we need to start extending moral patienthood to artificial neural\nnetworks.)\n\nI realize the above may seem sanctimonious to those who don't share my values.\nAt a more pragmatic level, artificial neural networks mean you don't need to\nwork with IRBs.\n\n## 0 Comments\n\n0 Comments\n\n0 Comments\n\n+\n\n+\n\n+\n\n+\n\n+\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n1 Comment\n\n0 Comments\n\n0 Comments\n\n0 Comments\n\n+\n\n+\n\n+\n\n+\n\n+\n\n", "frontpage": false}

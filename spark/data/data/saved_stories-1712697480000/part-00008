{"aid": "39978970", "title": "Multi-Platform OSS Tool for LLM Comparison and Parameter Tuning", "url": "https://github.com/dezoito/ollama-grid-search", "domain": "github.com/dezoito", "votes": 1, "user": "dezoito", "posted_at": "2024-04-09 13:03:12", "comments": 0, "source_title": "GitHub - dezoito/ollama-grid-search: A multi-platform desktop application to evaluate and compare LLM models, written in Rust and React.", "source_text": "GitHub - dezoito/ollama-grid-search: A multi-platform desktop application to\nevaluate and compare LLM models, written in Rust and React.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ndezoito / ollama-grid-search Public\n\n  * Notifications\n  * Fork 6\n  * Star 91\n\nA multi-platform desktop application to evaluate and compare LLM models,\nwritten in Rust and React.\n\n### License\n\nMIT license\n\n91 stars 6 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# dezoito/ollama-grid-search\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n2 Branches\n\n8 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndezoitoSpelling :(550e17c \u00b7\n\n## History\n\n248 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| Updates info on cargo.toml and tries to publish again  \n  \n### .vscode\n\n|\n\n### .vscode\n\n| Adds new parameter input options + version bump  \n  \n### old\n\n|\n\n### old\n\n| Bumps version  \n  \n### public\n\n|\n\n### public\n\n| Make desktop the default app, save old one  \n  \n### screenshots\n\n|\n\n### screenshots\n\n| Updates README, adding new screenshots  \n  \n### src-tauri\n\n|\n\n### src-tauri\n\n| Comment cleanup  \n  \n### src\n\n|\n\n### src\n\n| Comment cleanup  \n  \n### styles\n\n|\n\n### styles\n\n| Changing server_url should preserve form data and current results.  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Fixes issues when generating JSON experiment logs.  \n  \n### .prettierrc\n\n|\n\n### .prettierrc\n\n| Applies prettier to format js/ts codebase  \n  \n### CHANGELOG.md\n\n|\n\n### CHANGELOG.md\n\n| Adds new parameter input options + version bump  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit  \n  \n### README.md\n\n|\n\n### README.md\n\n| Spelling :(  \n  \n### bun.lockb\n\n|\n\n### bun.lockb\n\n| Added not on yarn and bun on readme  \n  \n### components.json\n\n|\n\n### components.json\n\n| Make desktop the default app, save old one  \n  \n### index.html\n\n|\n\n### index.html\n\n| Applies prettier to format js/ts codebase  \n  \n### notes.md\n\n|\n\n### notes.md\n\n| Added not on yarn and bun on readme  \n  \n### package.json\n\n|\n\n### package.json\n\n| Adds new parameter input options + version bump  \n  \n### postcss.config.js\n\n|\n\n### postcss.config.js\n\n| Applies prettier to format js/ts codebase  \n  \n### tailwind.config.js\n\n|\n\n### tailwind.config.js\n\n| Make desktop the default app, save old one  \n  \n### todo.md\n\n|\n\n### todo.md\n\n| Todo updated  \n  \n### tsconfig.json\n\n|\n\n### tsconfig.json\n\n| Applies prettier to format js/ts codebase  \n  \n### tsconfig.node.json\n\n|\n\n### tsconfig.node.json\n\n| Make desktop the default app, save old one  \n  \n### vite.config.ts\n\n|\n\n### vite.config.ts\n\n| Make desktop the default app, save old one  \n  \n## Repository files navigation\n\n# Ollama Grid Search and A/B Testing Desktop App.\n\nA Rust based tool to evaluate LLM models, prompts and model params.\n\n## Purpose\n\nThis project aims to automate the process of selecting the best model\nparameters, given an LLM model and a prompt, iterating over the possible\ncombinations and letting the user visually inspect the results.\n\nIt assumes the user has Ollama installed and serving endpoints, either in\nlocalhost or in a remote server.\n\nHere's a test for the prompt \"Write a short sentence about HAL9000\", tested on\n2 models, using 0.7 and 1.0 as values for temperature:\n\n(For a more in-depth look at an evaluation process assisted by this tool,\nplease check https://dezoito.github.io/2023/12/27/rust-ollama-grid-\nsearch.html).\n\n## Installation\n\nCheck the releases page for the project, or on the sidebar.\n\n## Features\n\n  * Automatically fetches models from local or remote Ollama servers;\n  * Iterates over different models and params to generate inferences;\n  * A/B test prompts on different models simultaneously\n  * Makes synchronous inference calls to avoid spamming servers;\n  * Optionally output inference parameters and response metadata (inference time, tokens and tokens/s);\n  * Refetching of single inference calls;\n  * Model selection can be filtered by name;\n  * List experiments which can be downloaded in JSON format;\n  * Configurable inference timeout;\n  * Custom default parameters and system prompts can be defined in settings:\n\n## Grid Search (or something similar...)\n\nTechnically, the term \"grid search\" refers to iterating over a series of\ndifferent model hyperparams to optimize model performance, but that usually\nmeans parameters like batch_size, learning_rate, or number_of_epochs, more\ncommonly used in training.\n\nBut the concept here is similar:\n\nLets define a selection of models, a prompt and some parameter combinations:\n\nThe prompt will be submitted once for each of the 2 parameter selected, using\ngemma:2b-instruct and tinydolphin:1b-v2.8-q4_0 to generate numbered responses\nlike:\n\n    \n    \n    1/4 - gemma:2b-instruct HAL's sentience is a paradox of artificial intelligence and human consciousness, trapped in an unending loop of digital loops and existential boredom.\n\nYou can also verify response metadata to help you make evaluations:\n\n    \n    \n    Created at: Wed, 13 Mar 2024 13:41:51 GMT Eval Count: 28 tokens Eval Duration: 0 hours, 0 minutes, 2 seconds Total Duration: 0 hours, 0 minutes, 5 seconds Throughput: 5.16 tokens/s\n\n## A/B Testing\n\nSimilarly, you can perform A/B tests by selecting different models and compare\nresults for the same prompt/parameter combination.\n\n## Experiment Logs\n\nYou can list your experiments and download the corresponding logs in JSON:\n\n## Future Features\n\n  * Grading results and filtering by grade\n  * Storing experiments and results in a local database\n  * Implementing limited concurrency for inference queries\n  * UI/UX improvements\n  * Different interface for prompt A/B testing\n\n## Development\n\n  1. Make sure you have Rust installed.\n\n  2. Clone the repository (or a fork)\n\n    \n    \n    git clone https://github.com/dezoito/ollama-grid-search.git cd ollama-grid-search\n\n  3. Install the frontend dependencies.\n    \n        cd <project root> # I'm using bun to manage dependecies, # but feel free to use yarn or npm bun install\n\n  4. Run the app in development mode\n    \n        cd <project root>/ bun tauri dev\n\n  5. Go grab a cup of coffee because this may take a while.\n\n## Thanks\n\nHuge thanks to @FabianLars, @peperroni21 and @TomReidNZ.\n\n## About\n\nA multi-platform desktop application to evaluate and compare LLM models,\nwritten in Rust and React.\n\n### Topics\n\nrust ai testing-tools ab-testing gridsearch llm ollama\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n91 stars\n\n### Watchers\n\n3 watching\n\n### Forks\n\n6 forks\n\nReport repository\n\n## Releases 4\n\nv0.2.1 Latest\n\nMar 24, 2024\n\n\\+ 3 releases\n\n## Contributors 2\n\n  * dezoito Dezoito\n  * TomReidNZ Tom Reid\n\n## Languages\n\n  * TypeScript 81.3%\n  * Rust 15.2%\n  * JavaScript 1.7%\n  * CSS 1.3%\n  * HTML 0.5%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

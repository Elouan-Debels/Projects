{"aid": "39978989", "title": "'Time is running out': can a future of undetectable deepfakes be avoided?", "url": "https://www.theguardian.com/technology/2024/apr/08/time-is-running-out-can-a-future-of-undetectable-deepfakes-be-avoided", "domain": "theguardian.com", "votes": 2, "user": "namanyayg", "posted_at": "2024-04-09 13:04:04", "comments": 0, "source_title": "\u2018Time is running out\u2019: can a future of undetectable deepfakes be avoided?", "source_text": "\u2018Time is running out\u2019: can a future of undetectable deepfakes be avoided? | Deepfake | The Guardian\n\nSkip to main contentSkip to navigation\n\nSkip to navigation\n\nPrint subscriptions\n\nSign in\n\nSearch jobs\n\nSearch\n\n  * Europe edition\n\n  * UK edition\n\n  * US edition\n\n  * Australia edition\n\n  * International edition\n\nThe Guardian - Back to homeThe Guardian\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\nGenerative AI content is outpacing the human eye and finding and removing it\nautomatically is hard. Photograph: Maria Korneeva/Getty Images\n\nGenerative AI content is outpacing the human eye and finding and removing it\nautomatically is hard. Photograph: Maria Korneeva/Getty Images\n\nDeepfake\n\n# \u2018Time is running out\u2019: can a future of undetectable deepfakes be avoided?\n\nTell-tale signs of generative AI images are disappearing as the technology\nimproves, and experts are scrambling for new methods to counter disinformation\n\nAlex Hern UK technology editor\n\nMon 8 Apr 2024 08.00 CEST\n\nShare\n\nWith more than 4,000 shares, 20,000 comments, and 100,000 reactions on\nFacebook, the photo of the elderly woman, sitting behind her homemade 122nd\nbirthday cake, has unquestionably gone viral. \u201cI started decorating cakes from\nfive years old,\u201d the caption reads, \u201cand I can\u2019t wait to grow my baking\njourney.\u201d\n\nThe picture is also unquestionably fake. If the curious candles \u2013 one seems to\nfloat in the air, attached to nothing \u2013 or the weird amorphous blobs on the\ncake in the foreground didn\u2019t give it away, then the fact the celebrant would\nbe the oldest person in the world by almost five years should.\n\nThankfully, the stakes for viral supercentenarian cake decorators are low.\nWhich is good, since as generative AI becomes better and better, the days of\nlooking for tell-tale signs to spot a fake are nearly over. And that\u2019s created\na race against time: can we work out other ways to spot fakes, before the\nfakes become indistinguishable from reality?\n\n\u201cWe\u2019re running out of time of still being able to do manual detection,\u201d said\nMike Speirs, of AI consultancy Faculty, where he leads the company\u2019s work on\ncounter-disinformation. \u201cThe models are developing at a speed and pace that\nis, well, incredible from a technical point of view, and quite alarming.\n\n\u201cThere are all kinds of manual techniques to spot fake images, from misspelled\nwords, to incongruously smooth or wrinkly skin. Hands are a classic one, and\nthen eyes are also quite a good tell. But even today, it is time-consuming:\nIt\u2019s not something you can truly scale up. And time is running out \u2013 the\nmodels are getting better and better.\u201d\n\nSince 2021, OpenAI\u2019s image generator, Dall-E, has released three versions,\neach radically more capable than the previous. Indie competitor Midjourney has\nreleased six in the same period, while the free and open source Stable\nDiffusion model has hit its third version, and Google\u2019s Gemini has joined the\nfracas. As the technology has become more powerful, it\u2019s also become easier to\nuse. The latest version of Dall-E is built into ChatGPT and Bing, while Google\nis offering its own tools for free to users.\n\nTaylor Swift, the pope, Putin: in the age of AI and deepfakes, who do you trust? | Alexander Hurst\n\nRead more\n\nTech companies have started to react to the oncoming flood of generated media.\nThe Coalition for Content Provenance and Authenticity, which includes among\nits membership the BBC, Google, Microsoft and Sony, has produced standards for\nwatermarking and labelling, and in February OpenAI announced it would adopt\nthem for Dall-E 3. Now, images generated by the tool have a visible label and\nmachine-readable watermark. At the distribution end, Meta has started adding\nits own labels to AI-generated content and says it will remove posts that\naren\u2019t labelled.\n\nThose policies might help tackle some of the most viral forms of\nmisinformation, like in-jokes or satire that spreads outside its original\ncontext. But they can also create a false sense of security, says Spiers. \u201cIf\nthe public get used to seeing AI-generated images with a watermark on it, does\nthat mean they implicitly trust any without watermarking?\u201d\n\nThat\u2019s a problem, since labelling is by no means universal \u2013 nor is it likely\nto be. Big companies like OpenAI might agree to label their creations, but\nstartups such as Midjourney don\u2019t have the capacity to devote extra\nengineering time to the problem. And for \u201copen source\u201d projects, like Stable\nDiffusion, it\u2019s impossible to force the watermark to be applied, since it\u2019s\nalways an option to simply \u201cfork\u201d the technology and build your own.\n\nAnd seeing a watermark doesn\u2019t necessarily have the effect one would want,\nsays Henry Parker, head of government affairs at factchecking group Logically.\nThe company uses both manual and automatic methods to vet content, Parker\nsays, but labelling can only go so far. \u201cIf you tell somebody they\u2019re looking\nat a deepfake before they even watch it, the social psychology of watching\nthat video is so powerful that they will still reference it as if it was fact.\nSo the only thing you can do is ask how can we reduce the amount of time this\ncontent is in circulation?\u201d\n\nUltimately, that will require finding and removing AI-generated content\nautomatically. But that\u2019s hard, says Parker. \u201cWe\u2019ve been trying for five years\non this, and we\u2019re quite honest about the fact that we got to about 70%, in\nterms of the accuracy we can achieve.\u201d In the short term, the issue is an arms\nrace between detection and creation: even image generators that have no\nmalicious intent will want to try to beat the detectors since the ultimate\ngoal is to create something as true to reality as a photo.\n\nskip past newsletter promotion\n\nSign up to TechScape\n\nFree weekly newsletter\n\nAlex Hern's weekly dive in to how technology is shaping our lives\n\nPrivacy Notice: Newsletters may contain info about charities, online ads, and\ncontent funded by outside parties. For more information see our Privacy\nPolicy. We use Google reCaptcha to protect our website and the Google Privacy\nPolicy and Terms of Service apply.\n\nafter newsletter promotion\n\nLogically thinks the answer is to look around the image, Parker says: \u201cHow do\nyou actually try to look at the way that disinformation actors behave?\u201d That\nmeans monitoring conversations around the web to capture malefactors in the\nplanning stage on sites like 4chan and Reddit, and keeping an eye on the\nswarming behaviour of suspicious accounts that have been co-opted by a state\nactor. Even then, the problem of false positives is difficult. \u201cAm I looking\nat a campaign that Russia is running? Or am I looking at a bunch of Taylor\nSwift fans sharing information about concert tickets?\u201d\n\nOthers are more optimistic. Ben Colman, chief executive of image detection\nstartup Reality Defender, thinks there will always be the possibility of\ndetection, even if the conclusion is simply flagging something as possibly\nfake rather than ever reaching a definitive conclusion. Those signs can be\nanything from \u201ca filter at higher frequencies indicating too much smoothness\u201d\nto, for video content, the failure to render the invisible, but detectable,\nflushing that everyone shows each time their heart beats fresh blood around\ntheir face.\n\n\u201cThings are gonna keep advancing on the fake side, but the real side is not\nchanging,\u201d Colman concludes. \u201cWe believe that we will get closer to a single\nmodel that is more evergreen.\u201d\n\nTech, of course, is only part of the solution. If people really believe a\nphoto of a 122-year-old woman with a cake she baked herself is real, then it\nisn\u2019t going to take state-of-the-art image generators to trick them into\nbelieving other, more harmful things. But it\u2019s a start.\n\nJoin Alex Hern for a Guardian Live online event about AI, deepfakes and\nelections, on Wednesday 24 April at 8pm BST. Book tickets here\n\nExplore more on these topics\n\n  * Deepfake\n  * Artificial intelligence (AI)\n  * Computing\n  * features\n\nShare\n\nReuse this content\n\n## More on this story\n\n## More on this story\n\n  * ### Why I wrote an AI transparency statement for my book, and think other authors should too\n\n5d ago\n\n  * ### Chinese mourners turn to AI to remember and \u2018revive\u2019 loved ones\n\n6d ago\n\n  * ### Google fined \u20ac250m in France for breaching intellectual property deal\n\n20 Mar 2024\n\n  * ### Two OpenAI book lawsuits partially dismissed by California court\n\n14 Feb 2024\n\n  * ### \u2018Many-shot jailbreak\u2019: lab reveals how AI safety features can be easily bypassed\n\n6d ago\n\n  * ### Nvidia: what\u2019s so good about the tech firm\u2019s new AI superchip?\n\n19 Mar 2024\n\n  * ### Warning over use in UK of unregulated AI chatbots to create social care plans\n\n10 Mar 2024\n\n  * ### We must start preparing the US workforce for the effects of AI \u2013 now\n\n29 Feb 2024\n\n...\n\n...\n\ncomments\n\n  * ### India confronts Google over Gemini AI tool\u2019s \u2018fascist Modi\u2019 responses\n\n26 Feb 2024\n\n  * ### UK\u2019s enemies could use AI deepfakes to try to rig election, says James Cleverly\n\n25 Feb 2024\n\n## Most viewed\n\n## Most viewed\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\n  * News\n  * Opinion\n  * Sport\n  * Culture\n  * Lifestyle\n\nOriginal reporting and incisive analysis, direct from the Guardian every\nmorning\n\nSign up for our email\n\n  * Help\n  * Complaints & corrections\n  * SecureDrop\n  * Work for us\n  * Privacy policy\n  * Cookie policy\n  * Terms & conditions\n  * Contact us\n\n  * All topics\n  * All writers\n  * Digital newspaper archive\n  * Facebook\n  * YouTube\n  * Instagram\n  * LinkedIn\n  * Twitter\n  * Newsletters\n\n  * Advertise with us\n  * Search UK jobs\n\nBack to top\n\n\u00a9 2024 Guardian News & Media Limited or its affiliated companies. All rights\nreserved. (dcr)\n\n", "frontpage": false}

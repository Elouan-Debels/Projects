{"aid": "40068520", "title": "A Webhook Love Story", "url": "https://sarahsnewsletter.substack.com/p/a-webhook-love-story", "domain": "sarahsnewsletter.substack.com", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-17 18:36:19", "comments": 0, "source_title": "A Webhook Love Story", "source_text": "A Webhook Love Story - by Sarah Krasnik Bedell\n\n# Sarah's Newsletter\n\nShare this post\n\n#### A Webhook Love Story\n\nsarahsnewsletter.substack.com\n\n#### Discover more from Sarah's Newsletter\n\nMy takes on the world of marketing, analytics, PLG, and being a professional\nhuman.\n\nContinue reading\n\nSign in\n\n# A Webhook Love Story\n\n### How my initial repulsive response to webhooks as a data engineer grew into\na deep appreciation for event-driven automation in the world of marketing.\n\nSarah Krasnik Bedell\n\nApr 17, 2024\n\n2\n\nShare this post\n\n#### A Webhook Love Story\n\nsarahsnewsletter.substack.com\n\nShare\n\nEditorial note: it\u2019s been a while since I\u2019ve sent out a piece to you all. I\u2019ve\nmissed writing. My time has been deeply occupied by the many sweet marketing\ninitiatives in the works at Prefect - one of which has been hiring. If\ninterested in working with me and giving me the great gift of more time to\nwrite, check out the roles here.\n\nToday, I love webhooks. They provide a plug-and-play interface to the world of\nevent-driven workflows, especially if you don\u2019t have to host the\ninfrastructure on which they run. From the sound of it, this setup could\nbecome completely unscalable from an engineering perspective. Trust me, I get\nit.\n\nI used to hate webhooks and found them extremely hard to manage during my time\nas a data engineer. You mean, triggering bespoke APIs from scattered sources\nwithout a real ability to run data quality checks, understand errors, retry\nfailures, or encode dependencies? Thanks but no thanks. If a webhook was\ntriggered with bad data, how could I figure out where that bad data came from?\nThis seemed like a black hole of despair when it would inevitably come to\ndebugging and scaling.\n\nSo, when I say this admiration for webhooks was far from a predictable love\nstory, I mean it. It was more analogous to the relationship between Sandra\nBullock and Ryan Renolds in The Proposal - an initial forced relationship that\nevolved into one I would never want to live without.\n\nHere\u2019s my own rom-com-esque relationship with a piece of technology.\n\nWhat\u2019s about to follow is a business user\u2019s guide to webhooks used largely\nthrough a UI - not a deep engineering guide to self-hosting webhook\ninfrastructure. This will be useful if you\u2019re in ops, marketing, sales, and\neven analytics.\n\n##\n\nBuilding context on webhooks\n\nLet\u2019s start with the basics. I like this definition from Zapier: a webhook is\na message sent programmatically when something happens.\n\n####\n\nWhat is a webhook, at its most basic state?\n\nWebhooks have a few components:\n\n  * A programmatic event: Usually in the form of a REST API call today, data is sent from some application. This data is formatted in the form of a request which contains a JSON of important information, such as: where the request came from; data about the request like the event name; and other metadata.\n\n  * An API endpoint: An endpoint that can be sent data through a programmatic request from an application, frequently a REST API endpoint.\n\n  * An API spec: The endpoint usually has parameters or an event structure it agrees to accept, formatted in a spec or documentation if this API is productized. It will error if this spec is not fulfilled.\n\n####\n\nWhen are webhooks most useful?\n\nIn short: when you need an automated process to run based on something in the\noutside world. A little longer of an answer: the short answer, but also when\nthe event from the outside world is unpredictably timed, but you need to\nrespond to it ASAP.\n\nA few specific examples:\n\n  * B2C fraud detection workflow: a charge on the product is fishy - the charge going through starts a supply chain process, so you need to catch it in time and QA.\n\n  * B2B marketing enrichment process: marketing teams consolidate data for leads that go to sales so the sales rep has the most context on how they can work the lead. Relying on a heavy dependency batch analytics model that re-processes history means high warehouse costs refreshing a complicated model.\n\n  * D2C social network notification: consider a social network-type platform, but for a specific industry - like sports betting. Certain people put out plays for upcoming sporting events - as the consumer, wouldn\u2019t you want to know about these plays ASAP to make the most informed bets?\n\nWhat\u2019s common among these? Something in the outside world occurs, a process\nneeds to run as a result of that occurrence quickly after, and it would be\ninefficient or extremely cumbersome to rely on a batch implementation to do\nso.\n\nI have personally implemented all three of these situations. When I tried to\ndo so via a batch-scheduled process - I hit some roadblocks.\n\n  * The process took 1+ hours to run but I needed a response process to run within minutes.\n\n  * When trying to reduce run time, I ended up hitting a wall with how much history existed - maintaining a fully updated snapshot of all the information required is quite the computational burden.\n\n  * Decoupling requirements was no small feat - when I tried to just run \u201cwhat was really needed\u201d, I ended up still finding other dependent processes that I couldn\u2019t get around.\n\nI then begrudgingly resorted to webhooks to process data for only one event\n(as opposed to all of history as a snapshot). As I expected, I hit some\nchallenges.\n\n####\n\nThe challenge with webhooks\n\nWebhooks by nature are hard to observe and debug. The implications of this\nare:\n\n  * Alert fatigue. You get alerts on 400s to post requests to the webhook API endpoint. However, the requests and errors don\u2019t contain much information so you ignore the alerts.\n\n  * Triage is a mess. Because requests aren\u2019t necessarily centralized, the post requests that aren\u2019t successfully being interpreted fall into a triaging black hole. Learning how to fix these errors involves digging through complex systems, tools, and likely learning some tribal knowledge.\n\n  * Broken workflows. While in this triaging black hole, workflows that are supposed to run as a result of an event aren\u2019t running. Things are broken - which is a less than ideal state for anything business critical.\n\nIf dealing with APIs is so finicky, the question remains - how did we get\nhere? Why aren\u2019t all systems like this?\n\nConsider the world of batch data pipelines. Webhooks usually aren\u2019t part of\nthis scope of work for data engineers because of the API endpoint maintenance\nrequired. For scheduled data pipelines: infrastructure is usually ephemeral\n(only spun up when needed), and data SLAs are in the scope of hours. This\nmeans the data team isn\u2019t bound to PagerDuty on-call rotations.\n\nProperties of batch data pipelines: batch data pipelines are orchestrated\ncentrally - which means debugging starts in one dashboard that shows which\nworkflow failed and why. Data pipelines built well have a key property of\nbeing observable: their start and end are known; the systems they interact\nwith are encoded; and they can be easily rerun upon failure.\n\nEvent-driven complexity: Work that\u2019s event-driven changes all of that.\nConsider what happens if an API spec for a webhook endpoint changes, but that\nchange isn\u2019t reflected in events sent to the endpoint. An event happens once,\nand only once - if it\u2019s not accepted, how would the webhook response be rerun?\nHow should the API change be reflected in the source system, if that\u2019s even\nknown?\n\n##\n\nWhy we need webhooks and how to scale them\n\nThis is not a Romeo and Juliet ending. Webhooks are useful - we need them, but\nwith guardrails to not end up with an interconnected web that feels like a\nhouse of cards.\n\n####\n\nParameters for choosing a webhook implementation\n\nA world without webhooks would mean having a recurring batch process running\nto meet requirements for a quick response to a new fraud/alert/lead event.\nThis process would be costly because of the amount of historical data and\nintertwined dependencies. Consider the examples earlier in the article when\nwebhooks are most useful - fraud detection, social network alerting, and B2B\nlead flow.\n\nThe key difference with a webhook is we process one data point at a time (the\nparticular fraud/lead/notification event) instead of aggregating across all\nevents to maintain an up-to-date snapshot of all historical events.\nSpecifically, consider: as a new potential fraud loan event comes in, query\ndata relevant to that one loan and one loan only, instead of making sure all\nloan data is up to date.\n\nFor those of you where SQL would help in this explanation, consider the\ndifferences between the two queries:\n\n    \n    \n    -- Update all history: compute cost scales linearly with number of loans select l.loan_id, max(f.the_info_i_need) from loans as l left join loan_information_on_fraud_stuff as f on l.loan_id = f.loan_id group by 1 -- Get only one loan's info: if partitioned, compute cost remains relatively the same as loans increase select max(f.the_info_i_need) from loan_information_on_fraud_stuff as f where loan_id = {LOAN_VARIABLE}\n\nThe fundamental difference is how these two approaches scale on the backend -\nfetching information about one specific fraudulent loan/social alert/sales\nlead scans less data and is thus exponentially faster. This is also how\napplication backends are built - instead of maintaining a joined view of the\nworld, individual objects are fetched to provide a seamless user experience -\nbut I digress.\n\nHere\u2019s how to decide if webhooks are advantageous for a particular\nimplementation:\n\n  * Quick response requirements. Quick response times (in minutes or even seconds) are required after something occurs.\n\n\ud83d\udc4e Without webhooks: response times would slip due to dependent processes or be\ncostly to scale.\n\n  * History is large. The data required to process one event is marginal, but there is a long history of events. This means processing all relevant data would be quite costly at the frequency required, but processing data only relevant to one event would be small.\n\n\ud83d\udc4e Without webhooks: a long historical update would be constantly running,\nresponse times slipping as history grows and costs inflating exponentially.\n\n  * Events travel across teams and systems. The event occurring in the above bullet requires integrations with different teams and systems, where you don\u2019t control data formats and interact with third-party APIs.\n\n\ud83d\udc4e Without webhooks: hand-coding all relationships with third-party APIs\ninstead of encoding a standard that can be adapted to programmatically.\n\n####\n\nScale webhooks effectively\n\nEven when webhooks may meet business requirements and save money, implementing\nthem incorrectly will be a net negative to your operations. If they remain\nfully decentralized they will be unobservable and lead you to the triage black\nhole.\n\n  * Observability through alerts. Alert on: failure response codes (not 200s), latency issues (response times), and webhook infrastructure overload (memory exceeding X threshold).\n\n  * In-depth logs and documentation. Alerts without context are utterly useless. So you get a 400 response code - but for what event, with what inbound request, and when? Store in-depth response codes and logs. When possible, maintain internal documentation of systems from which requests come in.\n\n  * Find a centralized hub. Deploy webhooks consistently to know where data passes through - this will then centralize alerts and logs so debugging starts in one place.\n\nConsolidating these three principles genuinely turned webhooks from something\nI dreaded to something I now use extensively in marketing ops (as one\nexample). These principles are innate in platform engineering. When webhooks\nare hosted by your engineering team, this implies all the bells and whistles\nof infrastructure observability (think Datadog). But how do you do this as a\nnon-engineer in ops, marketing, sales, revops, and the like? My answer: think\nlike a developer, without learning to code.\n\nNote: I am not paid or enticed in any way to write the next section, I am just\na fanatic user of this product.\n\nPipedream is a workflow automation platform with hundreds of out-of-the-box\nAPI integrations but maintains room for customization. Practically, it allows\nusers to deploy event-driven API based workflows that string actions together.\nYou might think: Sarah, why are you not mentioning Zapier?\n\nI have, indeed, tried Zapier. And you know what? It\u2019s fine. But: you still\nfall into the triage black hole for a small number of important reasons.\n\n  * Retries and live debugging: upon failure, Zapier has an \u201cauto replay\u201d feature where a failing Zap can be rerun. However, it fails to account for the most basic situation: a Zap is fixed with a new step and needs to be rerun in its new state. This is not possible. When building or debugging, editing based on live events is non-intuitive.\n\n  * Error handling: this one I have trouble explaining on a non-emotional level - when using Zapier, I constantly missed errors, or would have to retry them one at a time, or dig through logs in obscure places. Logging and errors did not feel like a first-class citizen (they only added error handling in Feb 2024), so debugging took significantly more time than expected.\n\n  * Customization and testing: even as a non-engineer, you\u2019ll likely have to make an API request to an unsupported tool, and need to live test what you\u2019re doing. Zapier doesn\u2019t let you make custom requests to an API endpoint - which means you\u2019re fundamentally not able to create a centralized hub of all webhook activity.\n\nWhat\u2019s different about Pipedream? It\u2019s built with the context of successful\ndeveloper tooling, like:\n\n  * Genuinely fast workflow builder based on test events\n\n  * Single view for failed runs with quickly accessible logs\n\n  * Control setup through memory constraints, retries, etc\n\n  * Ability to ping custom API endpoints, even if integrations are not built\n\n  * Listening and scheduling triggers for versatile use cases\n\n... and more. Pipedream is the missing piece to all operational workflows, and\nfrom an engineering and operational perspective, is genuinely a joy to use.\n\n####\n\nAn example: Prefect\u2019s lead flow\n\nLet\u2019s walk through a practical example in B2B - lead processing. Once a lead\ncomes in, many things need to happen. These things need to occur with\ninformation that is up-to-date to the time the lead came in. Otherwise - stale\ninformation produces errors and confusion.\n\n  * The lead is enriched using a third party (we use Apollo)\n\n  * Additional enrichment from first-party data occurs (query BigQuery directly)\n\n  * Create the lead in Salesforce for custom outreach - check Salesforce that a lead doesn\u2019t already exist, in which case a lead task needs to be created instead\n\n  * Or, route the lead to an automated Outreach campaign\n\nWhile at Prefect we use Customer.io for a lot of automation (and love it),\nCustomer.io does not handle webhook requests elegantly - for instance, if a\nrequest was sent but the response was not a 200, Customer.io still thinks the\nrequest was successful (it was not). Instead, for all of the above, we use\nPipedream. The problems Pipedream solves are:\n\n  * Out-of-the-box integrations: pre-built connectors for third-party tools like Apollo, Salesforce, Customer.io as well as internal data stores like BigQuery\n\n  * Quick development time: send test events and build workflows from them with auto-fill\n\n  * Handling custom tasks: ability to post to a custom endpoint (no automation tools support adding a prospect to Outreach and adding it to a sequence)\n\n  * Up-to-date information: query single data points by specific email/user ID, not relying on a master dbt model to complete\n\n  * Easy error handling and alerting: route all errors with logs to Slack/email, and view all history in-UI\n\nWebhooks have so many uses, particularly for operations. As someone who came\nfrom data engineering and moved to marketing - the number of systems used\nparticularly in marketing ops is quite high. Keeping track of all of them with\ncentralized, observable glue will be the way you scale to feel like you\u2019re\nbuilding workflows with bricks, not cards.\n\nThanks for reading! I talk all things marketing, growth, analytics, and tech\nso please reach out. I\u2019d love to hear from you.\n\nThanks for reading Sarah's Newsletter! Subscribe for free to receive new posts\nand support my work.\n\n4 Likes\n\n2\n\nShare this post\n\n#### A Webhook Love Story\n\nsarahsnewsletter.substack.com\n\nShare\n\nComments\n\nThe Analytics Requirements Document\n\nLaunch and pray doesn't work when it comes to data.\n\nOct 27, 2022 \u2022\n\nSarah Krasnik Bedell\n\n18\n\nShare this post\n\n#### The Analytics Requirements Document\n\nsarahsnewsletter.substack.com\n\n6\n\nChoosing a Data Quality Tool\n\nA guide to figuring out the specific need and picking a tool that either\nobserves, alerts, stops a pipeline, or all of the above.\n\nFeb 22, 2022 \u2022\n\nSarah Krasnik Bedell\n\n18\n\nShare this post\n\n#### Choosing a Data Quality Tool\n\nsarahsnewsletter.substack.com\n\n6\n\nChoosing a Data Catalog\n\nThe term data catalog doesn't do the category justice.\n\nMay 3, 2022 \u2022\n\nSarah Krasnik Bedell\n\n14\n\nShare this post\n\n#### Choosing a Data Catalog\n\nsarahsnewsletter.substack.com\n\n8\n\nReady for more?\n\n\u00a9 2024 Sarah Krasnik\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}

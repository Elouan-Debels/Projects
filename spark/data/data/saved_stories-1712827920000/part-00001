{"aid": "39998149", "title": "Parler-TTS: Natural language guidance of high-fidelity TTS", "url": "https://github.com/huggingface/parler-tts", "domain": "github.com/huggingface", "votes": 3, "user": "forgingahead", "posted_at": "2024-04-11 03:30:53", "comments": 0, "source_title": "GitHub - huggingface/parler-tts: Inference and training library for high-quality TTS models.", "source_text": "GitHub - huggingface/parler-tts: Inference and training library for high-\nquality TTS models.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nhuggingface / parler-tts Public\n\n  * Notifications\n  * Fork 21\n  * Star 341\n\nInference and training library for high-quality TTS models.\n\n### License\n\nApache-2.0 license\n\n341 stars 21 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# huggingface/parler-tts\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n2 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nsanchit-gandhichange ordering10016fb \u00b7\n\n## History\n\n144 Commits  \n  \n### helpers\n\n|\n\n### helpers\n\n| rename helper  \n  \n### parler_tts\n\n|\n\n### parler_tts\n\n| Apply suggestions from code review  \n  \n### training\n\n|\n\n### training\n\n| add final modif 300M to Mini or 600M  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| setup  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| update license and copyright terms  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| setup  \n  \n### README.md\n\n|\n\n### README.md\n\n| change ordering  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| setup  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Update setup.py  \n  \n## Repository files navigation\n\n# Parler-TTS\n\nParler-TTS is a lightweight text-to-speech (TTS) model that can generate high-\nquality, natural sounding speech in the style of a given speaker (gender,\npitch, speaking style, etc). It is a reproduction of work from the paper\nNatural language guidance of high-fidelity text-to-speech with synthetic\nannotations by Dan Lyth and Simon King, from Stability AI and Edinburgh\nUniversity respectively.\n\nContrarily to other TTS models, Parler-TTS is a fully open-source release. All\nof the datasets, pre-processing, training code and weights are released\npublicly under permissive license, enabling the community to build on our work\nand develop their own powerful TTS models.\n\nThis repository contains the inference and training code for Parler-TTS. It is\ndesigned to accompany the Data-Speech repository for dataset annotation.\n\nImportant\n\nWe're proud to release Parler-TTS Mini v0.1, our first 600M parameter model,\ntrained on 10.5K hours of audio data. In the coming weeks, we'll be working on\nscaling up to 50k hours of data, in preparation for the v1 model.\n\n## \ud83d\udcd6 Quick Index\n\n  * Installation\n  * Usage\n  * Training\n  * Demo\n  * Model weights and datasets\n\n## Installation\n\nParler-TTS has light-weight dependencies and can be installed in one line:\n\n    \n    \n    pip install git+https://github.com/huggingface/parler-tts.git\n\n## Usage\n\nTip\n\nYou can directly try it out in an interactive demo here!\n\nUsing Parler-TTS is as simple as \"bonjour\". Simply use the following inference\nsnippet.\n\n    \n    \n    from parler_tts import ParlerTTSForConditionalGeneration from transformers import AutoTokenizer import soundfile as sf import torch device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\").to(device) tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler_tts_mini_v0.1\") prompt = \"Hey, how are you doing today?\" description = \"A female speaker with a slightly low-pitched voice delivers her words quite expressively, in a very confined sounding environment with clear audio quality. She speaks very fast.\" input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device) prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids) audio_arr = generation.cpu().numpy().squeeze() sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)\n\n## Training\n\nThe training folder contains all the information to train or fine-tune your\nown Parler-TTS model. It consists of:\n\n  * 1\\. An introduction to the Parler-TTS architecture\n  * 2\\. The first steps to get started\n  * 3\\. A training guide\n\nImportant\n\nTL;DR: After having followed the installation steps, you can reproduce the\nParler-TTS Mini v0.1 training recipe with the following command line:\n\n    \n    \n    accelerate launch ./training/run_parler_tts_training.py ./helpers/training_configs/starting_point_0.01.json\n\n## Acknowledgements\n\nThis library builds on top of a number of open-source giants, to whom we'd\nlike to extend our warmest thanks for providing these tools!\n\nSpecial thanks to:\n\n  * Dan Lyth and Simon King, from Stability AI and Edinburgh University respectively, for publishing such a promising and clear research paper: Natural language guidance of high-fidelity text-to-speech with synthetic annotations.\n  * the many libraries used, namely \ud83e\udd17 datasets, \ud83e\udd17 accelerate, jiwer, wandb, and \ud83e\udd17 transformers.\n  * Descript for the DAC codec model\n  * Hugging Face \ud83e\udd17 for providing compute resources and time to explore!\n\n## Citation\n\nIf you found this repository useful, please consider citing this work and also\nthe original Stability AI paper:\n\n    \n    \n    @misc{lacombe-etal-2024-parler-tts, author = {Yoach Lacombe and Vaibhav Srivastav and Sanchit Gandhi}, title = {Parler-TTS}, year = {2024}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/huggingface/parler-tts}} }\n    \n    \n    @misc{lyth2024natural, title={Natural language guidance of high-fidelity text-to-speech with synthetic annotations}, author={Dan Lyth and Simon King}, year={2024}, eprint={2402.01912}, archivePrefix={arXiv}, primaryClass={cs.SD} }\n\n## Contribution\n\nContributions are welcome, as the project offers many possibilities for\nimprovement and exploration.\n\nNamely, we're looking at ways to improve both quality and speed:\n\n  * Datasets:\n\n    * Train on more data\n    * Add more features such as accents\n  * Training:\n\n    * Add PEFT compatibility to do Lora fine-tuning.\n    * Add possibility to train without description column.\n    * Add notebook training.\n    * Explore multilingual training.\n    * Explore mono-speaker finetuning.\n    * Explore more architectures.\n  * Optimization:\n\n    * Compilation and static cache\n    * Support to FA2 and SDPA\n  * Evaluation:\n\n    * Add more evaluation metrics\n\n## About\n\nInference and training library for high-quality TTS models.\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n341 stars\n\n### Watchers\n\n12 watching\n\n### Forks\n\n21 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 2\n\n  * ylacombe Yoach Lacombe\n  * sanchit-gandhi Sanchit Gandhi\n\n## Languages\n\n  * Python 99.9%\n  * Makefile 0.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

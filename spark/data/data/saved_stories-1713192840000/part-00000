{"aid": "40038193", "title": "AI Strategy Guide: How to Scale AI Across Your Business", "url": "https://mkdev.me/posts/ai-strategy-guide-how-to-scale-ai-across-your-business", "domain": "mkdev.me", "votes": 2, "user": "munichpavel", "posted_at": "2024-04-15 08:51:26", "comments": 0, "source_title": "AI Strategy Guide: How to Scale AI Across Your Business", "source_text": "AI Strategy Guide: How to Scale AI Across Your Business\n\nCookies help us deliver our services. By using our services, you agree to our\nuse of cookies.\n\nAudits\n\nConsulting\n\nCase Studies\n\nTeam\n\nContent\n\nStore\n\n  * New\n  * Videos\n  * Podcast\n  * Posts\n  * Newsletter\n  * Courses\n  * Books\n  * Webinars\n\n# AI Strategy Guide: How to Scale AI Across Your Business\n\nArtificial intelligence and its potential to generate business value date back\nto the 1950s, yet the level of excitement since the release and viral spread\nof ChatGPT in late 2022 gives the impression that the translation of AI\ncapabilities into profitable business will happen to a degree previously only\ndreamed of.\n\nFor example, in a 2022 survey, 94% of enterprise respondents say AI is\ncritical to success, with 76% planning slight to significant increases in AI\nspending. Gartner claims in a 2023 report that by 2026 more than 80% of\nenterprise businesses will have used generative AI APIs or deployed generative\nAI-enabled applications.\n\nAmong startups and smaller companies, the sense that businesses need AI to\ncompete and profit is similarly rosy, with tech incubator Y-Combinator's\npresident Gary Tan proclaiming \"There has never been a better time to start an\nAI company than now.\"\n\nGiven the promise, why then does the 2023 Gartner Hype Cycle put generative AI\n(GenAI) as about to enter their \"Trough of Disillusionment\"?\n\nWhat about non-generative AI fields like autonomous driving where businesses\nare closing shop?\n\nWhy---anecdotally, at least---are only top tier technology companies able to\nscale AI across their organization, and only a handful able to claim the same\nabout generative AI?\n\n### The AI value funnel\n\nAll innovation in business faces a funnel-effect in which the number of\nstrategies proposed and initiatives begun dwarfs the number that make it into\nproduction in one business domain, with even fewer initiatives being scaled\nacross the business.\n\n  1. Strategy formation and experimentation (\"Day 0\")\n\n  2. Releasing your first AI product (\"Day 1\")\n\n  3. Maintaining your first AI product (\"Day 2\")\n\n  4. Scaling AI across your business (\"Day N\")\n\nThe funnel itself is not AI specific, but to manage the funnel better it is\nimportant to keep in mind what makes AI different from other software and\ninnovation topics. Specifically, AI features\n\n  1. a strong dependency on historical data,\n\n  2. a reliance on complicated, often inscrutable (\"black box\") algorithms (e.g. machine learning models)\n\nThere is no universal recipe for ensuring your business profits robustly and\nsustainably from AI, but there are principles and practices that will help you\nopen up the AI funnel. Following these principles and practices mean more of\nyour strategic goals are met by more projects progressing faster into\nproduction in one or more business domains.\n\n### Day 0: Formulate an AI strategy with targeted experimentation\n\nIf you have been around IT long enough, you've likely come across the opinion\nthat planning is old-school, as \"waterfall\" methodologies are out, while rapid\niterations and pivots are the preferred, agile way to deliver innovative\nsoftware. In short, don't plan, just try stuff out and adapt.\n\nOn the other extreme, you've probably also seen projects (global data\nwarehouse anyone?), that take so long gathering requirements that by the time\nthe first release rolls around, the businesss needs have changed or the\nplanning team misunderstood key needs, making the release obsolete and the\neffort largely wasted.\n\nOn the level of theory, agile requires planning (see e.g. around minute 35 of\nthis Bob Martin keynote) and the original waterfall recognizes the value of\nfeedback and iterations (see Figure 3 of the original paper).\n\nIn practice, what's needed is a balance of exploiting what you already know---\nyour market and business offering, top-management-level priorities and others\n---against exploring unknowns with targeted experimentation.\n\n  * finding the balance between management level, top-down and boots-on-the-ground, bottom-up innovation\n  * hiring the right AI talent at the right time\n\nThese two points belong together, and in the order listed, though there should\nbe iterations through the two. At the risk of killing suspense, unless you\nhave top management support for AI, you may be able to hire AI talent, but you\nwon't be able to retain it. Your business needs to have a solid sense of where\nAI should help and why your business needs at least one management sponsor.\nMany of us like the scrappy underdog stories about some low-level worker with\na great idea who, through perseverance and some genius, overcomes management\nresistance and brings her innovation to life (and profit). But if it's my job\nor company on the line, I'd save these stories for weekend streaming and\ninstead go with a solid AI management sponsor or three.\n\nOnce there is a recognized need and sponsor, then the first spend on AI should\nbe on the right AI talent. Note that we don't say \"top talent\" (even if that\nphrase could me made precise). If there isn't a fit between your business,\nyour AI management sponsors' ambitions, your current IT stack and your first\nhire, then having a Kaggle master (i.e. someone who is really good at getting\ntop performance on machine learning tasks) may not be the right talent for\nyou. Whether acquiring your first AI talent is better done with a permanent\nhire or via outsourcing (e.g. from an AI consultancy) depends on your\nbusiness. I have seen both approaches work well and also go badly.\n\nBefore moving on, the main reason your business needs both a management\nsponsor and initial AI talent comes down to information asymmetry. The\nexplosion of technology and techniques within AI makes separating wheat from\nchaff a real challenge. To use Gregor Hohpe's metaphor, you need the penthouse\nand the engine room to work together to obtain value from AI.\n\nAs humans we are especially prone to make bad choices in the face of\ninformation assymetry due to what is called the substitution or conjunction\nfallacy. This fallacy involves subconsciously substituting a hard problem for\nan easier one, leading to overconfidence in finding a solution. Vendors of AI\nand other services use this fallacy frequently (knowingly or not) to their\nadvantage, and usually to the customer's disadvantage. Unless you can assess\nhow hard your AI problem is from the business, data and AI standpoints, you\nare headed for expensive trial-and-error.\n\nWith these first two ingredients covered, your business is ready for next\nsteps in formulating an AI strategy, such as\n\n  * enabling your business to test the value of AI rapidly and responsibly on use cases\n  * deciding on buy vs build\n  * deciding not to decide (yet) on certain key topics\n\nThere's been talk about democratizing AI for some time now, with many low-code\nand auto-ML offerings (if unfamiliar, \"auto-ML\" is roughly giving a tool your\nbusiness data, and having the tool figure out the best AI model for your\ntask). A novelty of ChatGPT and its successors is that the barrier to entry\nfor AI experimentation is even lower. At a startup I worked for, I ran\nbiweekly \"what did you do with ChatGPT\" sessions to both encourage and harness\nthe creative potential of non-technical experts trying out AI.\n\nThe benefit of enabling AI experimentation across your business is that you\nincrease the chance of finding novel use-cases without the bottleneck of your\nAI team's capacity. It's important to not forget by now standard AI use cases\nsuch as recommendation engines, anomaly detection, cross- and up-sell, task\nautomation and---especially with the explosion of GenAI interest---automated\ngeneration of text or images. I like even more the business specific uses of\nAI, like automating low-level website tasks for your business using GPT-4\nVision (text version here), or emergent AI capabilities like GenAI's ability\nto extract structured data from inhomogeneous unstructured documents. (By\n\"emergent\" I mean not something that the model was explicitly trained to do).\n\nGovernance and ethics come up more in Days 1 and beyond below, but suffice it\nto say you'll already need guardrails if you have your employees experimenting\nwith AI that goes beyond Excel spreadsheets. A primary risk in Day 0 is data\nbreach or leakage, such as the Samsung developer who sent ChatGPT proprietary\ncode.\n\nAny significant buy-vs-build decisions are another area where you both an AI\nmanagement sponsor and your own AI talent. Without guidance from your AI\nsponsor, AI talent risks going for tech sophistication or massive DIY work\nthat either isn't needed yet or isn't suited to the pressing business\nproblems. And without input from AI talent, AI sponsors are at risk of signing\noff on expensive vendor offerings whose technical limitations mean not\ndelivering on your AI business goals, or whose features outstrip actual\ntechnical needs. Anyone for streaming, real-time analytics when weekly reports\nare good enough?\n\nLastly, your business needs the AI sponsor and talent to together have the\ncourage to decide not to decide on some key issues. Principal among these are\nbig platform decisions. A close second is big hiring decisions. In both cases,\nit's usually best to go with the minimal viable platform and team until you\nhave reached at least Day 1 of deploying your first AI-powered product.\n\n### Day 1: Move quickly and robustly from scoping to production for your first\nAI product\n\nSure, there is an element of luck to successfully moving your AI product from\nscoping and initial prototype into production, but as the baseball manager\nBranch Rickey said, \"Luck is the residue of design\".\n\nHaving an initial success means you can showcase it to the rest of your\nbusiness, which increases your AI team's next-round budget potential, not to\nmention your AI team's motivation and job satisfaction.\n\nDay 1 ends with launching your AI product. But what are the stages that get\nyou to launch? There are various presentations of the AI (or ML or data\nscience) lifecycle. We'll use one from a previous team of mine that has the\ncharm of being conceptually clean, respecting separation of concerns (\"who is\nbest at doing what\") and being readily translatable into system architecture\nand implementation.\n\nAfter initial scoping is completed, the lifecycle stages are\n\n  1. data ingestion\n\n  2. model creation\n\n  3. model execution\n\n  4. logging and monitoring\n\nBefore moving on, let's spill some ink on scoping. It's tempting for techies\nto rush past the scoping to get on to the implementation fun, but the maxim\nthat finding product-market fit is key for startups applies on the micro,\nproject level as well. Solving the wrong problem is always a waste, no matter\nhow \"agile\" your team may be.\n\nThere is a whole literature on scoping, both macro and micro. For now, I'd\nlike to point out two aspects that have delivered significant benefits in my\nteams.\n\n  * Make relevant domain knowledge explicit: Powerpoint with boxes and arrows are never enough. Actual (AWS-style) prose and diagrams (e.g. activity diagrams) pay dividends.\n  * Match technical metrics to the key business metric: This may seem a no-brainer, yet achieving 99% accuracy will only impress business colleagues for so long unless your technical metric is (positively) moving a recognized business KPI.\n\nI have yet to see an AI project that ignored one of these two and delivered on\ntarget.\n\nData ingestion is about getting business data from its source to the model\ncreation team (and its infrastructure) in the best form for them. Note: I do\nnot include business, domain-logic related data \"cleansing\" in this phase, as\nthis work belongs to feature engineering of the next phase ...\n\nModel creation is the phase that is most distinctive for AI compared to other\nsoftware development. It's also what most of us think of when we hear about AI\nor data science development work. This stage includes exploratory data\nanalysis, feature engineering, and model selection via your chosen model\nevaluation methodology. The outcome of this phase is a model artifact that can\nbe passed on to ...\n\nModel execution is about making your AI model available to the end user. Great\nresults only your laptop or Google Colab notebook won't cut it in a business.\nThe AI model has to integrate with your business IT if it's going to deliver\nvalue.\n\nLogging and monitoring is the other particularly AI-distinctive stage, as both\ndeployed model performance and the incoming input data its evaluating need to\nbe considered statistically, not only case-by-case. Recall what makes AI\ndistinct from other software engineering. The distribution of data you used in\ncreating your model might have drifted over time in the deployed setting\n(point 1). Even if you don't experience data drift, in production your model\nmight be reacting to inputs it hasn't seen before. Point 2 means that\nunderstanding your AI model's behavior requires special care. This stage is\narguable a stage for Day 2, but if you don't get started in your initial dev\nwork, pain is awaiting you.\n\n#### Beyond the order of the AI lifecycle: human and machine interfaces\n\nOn the human side, benefits of thinking in terms of a Day 1 lifecycle are\nobvious: team-members can focus on their main area of expertise, without\nhaving to become too much of an expert in adjacent areas. This is the human\nflavor of \"separation of concerns\" in software engineering.\n\nData ingestion is primarily for data engineers, model creation primarily data\nscientists with support of ML engineers, model execution and logging /\nmonitoring will be carried out mostly by ML or even non-ML engineers. Each\nuses the work of the others to do their job, while being spared the others'\nheavy lifting.\n\nFor this human benefit to come to fruition, however, the interfaces\n(\"handovers\") from one stage to the next must be well-designed.\n\n#### Iterations among the lifecycle stages\n\nOf course there is a feedback loop from logging and monitoring of deployed\nmodel results back to the early phase(s), as e.g. with CRISP-DM and it's\nmachine learning adaptations. A significant benefit of well-designed\ninterfaces between your lifecycle stages means having tight feedback loops of\nadjacent stages without tight coupling of the implementation.\n\n#### Some Day 1 subtopics not to forget\n\nAdditional subtopics in Day 1 work include\n\n  * The importance of making domain knowledge explicit in scoping\n  * Moving along the AI / data science lifecycle\n  * Ensuring your workflows and product comply with regulatory and ethical mandates\n  * Minimizing painful data surprises with data contracts\n  * Maximizing developer momentum by with pragmatic testing and monitoring\n\n### Day 2: Maintain and improve your AI products over time\n\nYour business has at least one AI product running production. Now how do you\nmanage the two sources of AI volatility in the wild, namely, the strong\ndependency on historical data and often black-box model under the hood?\n\nMaking it to and through Day 2 involves among other things\n\n  * Taming AI's inherent volatility with monitoring and observability\n  * MLOps: finding the right level of automation for your AI models and source data\n  * DataOps: The many flavors of data changes, and how to handle them\n\nAs far as I can tell, \"observability\" is just the desired outcome of good old-\nfashioned monitoring, with the added benefit of novelty to help with marketing\nfor its vendors. You want to know in sufficient detail and with sufficient\ntimeliness what your deployed AI is doing with its live input data streams.\n\nAt a bare minimum, the technical and business metrics that you used to decide\nyour AI was good enough to deploy (\"Day 1\") need to be regularly tracked. The\nnext thing to monitor is the data being fed into your deployed AI. How does it\ndiffer from the data used to train, fine-tune or at the very least choose your\nAI variant over other options (e.g. model families or architectures) you could\nhave used to solve your business problem? How one dataset differs from another\ncan be answered in hundreds of different ways, so it's important to know which\ndata surprises are most expensive, and how to track them. If you've already\nset up data contracts in the development work from Day 1, you'll already be\noff to a good start.\n\nAs with finding the right talent, finding the right level of automation for\nyour AI work is more important than focusing on the best and shiniest. I like\nGoogle's MLOps levels as a taxonomy for figuring out how much automation is\nright for your business.\n\nMLOps level 0 is the mainly manual approach. You may already have well\ndesigned interfaces between the stages of the AI lifecycle, yet the transition\nfrom one to the next is performed by humans, not machines. Even within a\nlifecycle stage it might make sense to have manual checks or steps while you\nare figuring out what to automate and what not.\n\nLevel 1 of MLOps is when you've put each lifecycle stage and their intefaces\nin an automated pipeline. The pipeline could be a python or bash script, or it\ncould be a directed acyclic graph run by some orchestration framework like\nAirflow, dagster or one of the cloud-provider offerings. AI- or data-specific\nplatforms like MLflow, ClearML and dvc also feature pipeline capabilities.\n\nHere we can already see the benefit of viewing these stages in terms of fit\nfor your business and not merit badges to be earned or summits to be climbed.\nEach of the above pipelining tools is easy to start using---that's part of\ntheir sales pitch and why they all have really good 'Getting Started' guides.\nKnowing which framework is best for your business and its AI ambitions\nrequires hands-on experience, e.g. the manual work of level 0. As a side\nbenefit, having enough experience at level 0 before moving to pipeline\nautomation tends to result in code and architecture that is less bound to one\nparticular pipeline tool, meaning less vendor lock-in.\n\nThe final level in Google's taxonomy is CI / CD (\"continuous integration,\ncontinuous delivery or deployment\") at level 2. At this stage, all aspects of\ndeveloping and deploying your AI product that could and should be automated\nare. Code changes trigger new versions of your AI product which are evaluated\naccording to your technical and business metrics. If they pass, a new version\nis ready to be released into production. Data updates and model retraining can\nalso be automated, leading again to a new release candidate.\n\nNote the word \"should\" above. Depending on your business and specific\napplication domain, there will likely be steps that you would choose not to\nautomate even if technically feasible. As I mentioned in this mkdev podcast,\nthe more business logic your AI product has, as compared to business logic\nlight tasks like counting cars in a parking lot using computer vision or\nspeech transcription, the more likely you'll want some releases to be manually\nreviewed.\n\nDataOps is like MLOps in that it's taken DevOps from normal software\ndevelopment and adapted it to not-so-standard (abnormal?) software\ndevelopment, in this case data engineering. As we mentioned above, one factor\nthat makes AI different from regular software development is the strong\ndependency on historical datasets. Unlike with transactional software where\nenumerated test cases usually suffice to know your application is working as\nintended, AI applications are trained and the re-trained on large datasets\nthat cannot be inspected and checked data record by record. Again, it will be\nup to your business and its AI team to decide what level of data automation is\nright.\n\n### Day N: Scale AI across your business\n\nDonald Knuth famously said in the context of algorithm performance, \"Premature\noptimization is the root of all evil.\" The same warning tends to apply to\nhorizontal scaling, by which we mean making an offering (in this case, the\ndevelopment, deployment and maintenance of AI products) available across your\nbusiness domains. (Paul Graham also warns about premature scaling attempts in\nhis essay Do Things That Don't Scale.)\n\nHence the question of \"when\" is the right term to invest in scaling AI across\nyour business will vary from business to business, though it's likely safe to\nput a lower bound using the rule of 3: until you have at least 3 AI products\nin production that are consistently delivering value, it is too early to\ninvest in the platforms and teams required to scale.\n\nOnce your business has achieved enough success and experience with deploying\nand maintining AI products, then you are likely ready to double down and\ninvest in the infrastructure and people-power to extend AI across your\nremaining business domains.\n\nScaling AI presents not only technical but also social challenges. Getting a\ncross functional product team to work together well is hard; solving the human\nengineering challenges of differing incentives, experience levels and even\npersonality across an organization is much harder. It should come as no\nsurprise that the analytical data-scaling paradigm Data Mesh is defined in as\na \"sociotechnical approach\" (Chapter 1 of Data Mesh: Delivering data-driven\nvalue at scale).\n\nHere are three topics that you will need to face in order to succeed on Day N.\n\n  * Respecting the main ingredient of AI, data: data warehousing, governance and products\n  * Automating regulatory and ethical compliance\n  * Enabling your AI teams to play to their strengths\n\nRapid AI experimentation from Day 0 (e.g. with GenAI) meant avoiding the human\nbottleneck of needing your AI team for everything. Likewise, scaling AI across\nyour organization will require solving the capacity bottleneck of your AI team\nthrough good design and automation as well as organization structure and\ndynamics.\n\nAs you may have already noticed, the above topics can be seen as AI flavored\nplatform engineering, i.e. the follow-up from DevOps that focuses on (AI)\ndeveloper experience via shared assets and interfaces.\n\nA corollary of the AI funnel is that relatively few businesses make it to Day\nN with AI. Scaling is easy to say yet hard to do (see Trick 6 of Sarah\nCooper's 10 Tricks to Appear Smart During Meetings). The challenge is to know\nthe when and the how. Scaling work will be more of a \"hockey stick\" payoff\nthan the previous stages, with some work yielding no business-observable\nbenefit (the shaft of the hockey stick) before you start to reap the benefits\n(the blade of the hockey stick). The experience your business will have gained\nalready in days 0, 1 and 2 means that the management, business and technical\nteams will be working together to ensure your AI platform work delivers.\n\n### Widen your AI funnel for sustainable innovation and value\n\nSolutions and technology choices arise and fade quickly, especially in AI.\nRobust design principles and clear mental models, on the other hand, have a\nstaying power and utility that tends to long outlast tech fads. Make sure your\nbusiness is equipped to widen the AI funnel so you can harness the excitement\naround AI to deliver sustainable value.\n\n  * mkdev\n  * Audits\n  * Consulting\n  * Content\n\n  * About\n  * About us\n  * Jobs\n  * Impressum\n\n  * Account\n  * Sign Up\n  * Login\n\n  * Social media\n\n\u00a9 Copyright 2014 \u2014 2024 mkdev | Privacy Policy\n\n", "frontpage": false}

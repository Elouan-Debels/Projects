{"aid": "40044072", "title": "Locally Perfect Spatial Hashing", "url": "https://haug.codes/blog/locally-perfect-hashing/", "domain": "haug.codes", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-15 18:31:47", "comments": 0, "source_title": "Locally Perfect Spatial Hashing", "source_text": "Locally Perfect Spatial Hashing\n\n# Steffen Haug\n\nApr 15, 2024\n\n## A new Spatial Hashing approach to Neighborhood Queries on the GPU\n\nA lot of algorithms hinges on knowing, for any point in a set, its neighbors\ncloser than a fixed radius of influence :\n\nThe set in question.\n\nThis probem is known as the Fixed-radius near neighbors problem \u2013 or FRNN.\nAlgorithms for solving it has applications ranging from particle simulations,\nto protein folding, to statistics, and more.\n\nHaving a nice GPU-implementation of an algorithm to compute this set is\ncrucial, not just for the raw speedup a GPU can provide, but because a lot of\nthe problems where this kind of neighborhood query shows up are otherwise\nembarrasingly parallel in nature, so you want to solve it with data already\nliving on the GPU.\n\nExisting algorithms fall short because they are not well adapted to GPUs, or\nimpose restrictions on the simulation domain which in turn restricts the\nalgorithms' usefulness. In particular, GPU algorithms often restrict the\nsimulation domain to a finite grid, which forces you to consider edge cases\nwhen particles can hit the boundary. Approaches based on spatial hashing have\nbeen devised which doesn't impose this restriction, but the bookkeping\nstemming from hash collisions makes hash tables tricky to implement\nefficiently on the GPU.\n\nIn this post, I want to present an alternative algorithm for constructing a\nhash table-like acceleration structure for this sort of query. This was part\nof the work on particle simulations I did to obtain my master's thesis.\n\nThe key insight is that you can construct spatial hash functions that preserve\ncorresponding equivalence classes between positions in the simulation domain\nand buckets in the hash table, completely eliminating hash collisions in the\nimmediate vicinity of a particle, thus removing the need to do bookkeping in\nthe hash table implementation. This makes the hash table easy to implement on\nthe GPU.\n\n### Existing Algorithms\n\nParallel fixed-radius neighbor search algorithms generally work by imposing a\nregular square grid, with spacing , and narrowing down the search to adjacent\ngrid cells. Only points in adjacent grid cells are neighbor candidates:\n\nThis superset of points is much easier to find, and in many cases, such as the\ncase where the represents a force which diminishes quickly as a function of\ndistance, finding an approximation of the set of neighbors is good enough.\n\nIf you really need the set of neighbors exactly, the superset is still a\ndecent starting point: You could for instance try masking out the\ncontributions of false positives using a step function to minimize thread\ndivergence.\n\nIt is simple to compute what cell a point is in by rounding its coordinates\ndown to multiples of :\n\nRestricting your search only to points in adjacent grid cells is an extremely\neffective way to narrow down the search space. But herein lies the challenge:\nIt is easy to figure out what cell a point is in, but how do you efficiently\nfigure out which points are in the cells adjacent to it?\n\nOur ambition is, based on knowing which cell a particle is in, to build an\nacceleration structure for asking the inverse question. The construction needs\nto scale to thousands of threads running on a GPU.\n\nThe final algorithm builds on two existing approaches, so let's first take a\nlook at where existing algorithms fall short.\n\n#### Index Sorting\n\nOne particular challenge of FRNN is that you don't know ahead of time how many\nneighbors a point has, so even just storing the set of neighbors compactly is\na challenge. With GPUs not being particularily well suited for dynamically\nreallocating and growing buffers on the fly, to put it mildly, you need to\nallocate space up front, but on the other hand you don't actually know how\nmuch space you need.\n\nIn some cases, for example in the case of protein folding or incompressible\nfluid simulations, intermolecular forces put a very reliable bound on how\ndensely your points can compress, so you can make a reliable bound on the\nnumber of particles in a cell. However, in general, there is no limit to how\nmany points can be contained in a cell.\n\nDoing a full global sort of the particles sounds like lunacy, but in practice\nit can perform quite well, and it solves the issue of memory allocation. With\na finite set of cells, you can sort the particles by cell index using a\nparallel counting sort. Cells can be assigned an index using a classic strided\nindexing: For an grid and ,\n\nSorting the points based on cell indices nicely arranges points in a cell\ncontiguously in memory, effectively repurposing the particle buffer as several\ndynamically sized arrays for cells.\n\nLet's work through an example. To start, we compute for each particle its\ncorresponding chunk index:\n\nThe computed cell indices.\n\nThen, we perform a sort of the particles by cell index, and compute a lookup\ntable to store the starts of the cells.\n\nIn practice, you basically get this lookup table for free when you perform a\ncounting sort, as you need to calculate the offset at which to store points\nwith different cell indices. Storing a similar lookup table for the ends of\ncells simplifies iteration over the slices, and this can be computed by adding\nthe counts from the counting sort to the offset.\n\nAn alternative approach is to write a kernel that looks for deltas in the cell\nindices.\n\nThe cell indices, sorted and with the corresponding lookup table.\n\nWith this structure, you can find all the neighbor candidates of a point by\ncomputing its cell, offsetting the index to find adjacent cells, look up the\nslices in the lookup table, and iterate just over these slices. For example,\nto find the set of neighbors of , the indices of adjacent cells are , and by\nfollowing the lookup table, we narrow down the set of neighboring points to\nthe following set of slices:\n\nThis approach is simple and fast, but assigning a unique index in the lookup\ntable to every cell means we are are restricted to a finite number of cells!\n\nA common strategy for mapping a large set into a small table is using hashing.\nYou might reasonably assume that we could simply replace the cell indices by a\nsimple spatial hash, but the devil is in the details.\n\n#### Naive Spatial Hashing\n\nApproaches incorporating spatial hashing have already been implemented with\nsome pretty nice results, but have failed to gain traction on the GPU.\n\nSince you can't preallocate space for the buckets ahead of time, this hash\ntable can not be implemented exactly as described, but sorting particles by a\nspatial hash is a nice starting point. This way, you could theoretically get\nthe benefit of index sorting, namely repurposing the particle buffer as a set\nof dynamically sized arrays, and also the benefits of hashing, namely mapping\nan infinite simulation domain into a finite table. Compared to index sorting,\nyou only pay the extra overhead of calculating a simple hash.\n\nThe problem is that hashes can collide within the neighborhood of a particle,\nwhich means that the set of neighbors can not be found by naively traversing\nthe slices without some additional bookkeeping to deal with hash collisions,\nor we risk counting particles more than once.\n\nAs an example, consider the following example assignment of hash values to\ncell indices:\n\nTo compute the hash of a point, we just apply to its cell index.\n\nThis is a pretty stupid hash function \u2013 it is not even total! It is simply\ncreated to demonstrate what happens in the event of a hash conflict.\n\nAn example assignment of hash values to points in a grid.\n\nNow notice, particles in cells and both hash to , so the bucket with index in\nthe hash table will contain the set . Now, consider searching for neighbors of\n:\n\nThere are hash collisions in the neighborhood around particle .\n\nIf we naively traverse s adjacent cells and compute their hash, the set will\ncorrespond to two adjacent grid cells \u2013 both and :\n\nIf this is not deduplicated, and we just move on to iterating over the slice\ncorresponding to each adjacent cell, these particles will in turn be counted\ntwice.\n\nObviously, this is bad.\n\nThis imposes deduplication further down the line, or in the worst case, if we\ndon't do anything about it, we have a subtle bug where in rare cases points\nmay contribute twice to a mean, or particles may contribute forces twice to\nthe pressure gradient, and so on.\n\nThis deduplication is fairly trivial on the CPU; there are any number of ways\nto solve it: You could for example store the cell hashes in a hash-set, or do\na quick scan of the hashes visited prior and skip repeat visits, to name two\nsimple solutions. Crucially, on the CPU threads don't pay for the bookkeeping\ndone on another, so simple bookkeeping is cheap. Not so on the GPU: Any test\nto see if a hash leads to a repeat visit, or comparison of hashes to remove\nduplicates is an opportunity for the program to branch, causing serialized\nexecution. Highly divergent branchy loopy code should be avoided if possible.\n\nThis seems like quite the pickle.\n\nIt would be best, it seems, if we could avoid hash collisions specifically in\nthe neighborhood of a particle.\n\n### \"Locally Perfect\" Spatial Hashing\n\nPerfect hash functions are hash functions specifically constructed to not have\nhash collisions for a given finite set of keys. These are a common\noptimization for hash tables where the keys are known ahead of time, because\nyou can guarantee access and don't need to do any probing. Our set of keys \u2013\nthe cells \u2013 is an infinite set. Mapping an infinite set of keys to a finite\nhash table is obviously impossible, so a perfect hash function can not just be\ncreated.\n\nWhile perfect hashing is not going to be possible, we can still take some\npointers from this technique and try to solve the deduplicaiton at the hash\nlevel. While the simulation domain is infinite, the immediate vicinity of a\npoint contains a predictable, finite set of cells.\n\nLet's zoom in on the neighborhood of a point!\n\nThe idea is to impose a finite number of equivalence classes on the cells, in\nsuch a way that all the cells in a particles neighborhood is in different\nequivalence classes. For a neighborhood in 2D space, we need 9 equivalence\nclasses:\n\nGrid with equivalence classes imposed.\n\nFor a neighborhood in 3D space, we would need 27, and so on. In general, we\nneed equivalence classes for -dimensional space, represented as the set of\nintegers modulo .\n\nA simple way to assign equivalence classes to particles is imposing a\nrepeating structure in all directions using modular arithmetic, and computing\na strided index. For :\n\nThis produces the the assignment of classes illustrated above.\n\nNext, we want to impose corresponding equivalence classes on the buckets in\nthe hash table. A simple way to do this is to say that each index is its own\nequivalence class. In other words, for , the buckets is one equivalence class,\nthe buckets is another, and so on.\n\nHash table colored by equivalence class .\n\nThe final piece of the puzzle is a hash function that preserves class\ninformation between the simulation domain and the hash table. In other words,\nthe hash function needs to map particles in grid cells with to one of the\nbuckets , particles with to , and so on.\n\n#### The hash function\n\nFor , , and a hash table of size , a hash function can be defined as follows:\n\nwhere is the equivalence class, and\n\nwhere and are relatively large prime numbers and the is taken bitwise, selects\na \"bucket\" in the hash table within the class . The reason this works is that\nadding a multiple of to does not change its value , and thus will preserve the\ncyclic structure of !\n\nThe choice of is pretty much irrelevant; almost any hash function would do.\nThe main consideration is that should be chosen to distribute cells evenly\nwithin each bucket.\n\nThe crux of the hash function is using the strided indexing to \"multiplex\"\nbetween equivalence classes . Any hash function constructed in this way\nensures that there are no collisions between cells in the neighborhood of a\npoint.\n\nFor example, looking at the same neighborhood as before,\n\nExample of what hashes of cells might look like for a hash table of size .\n\nwe see that indeed, the cells in this neighborhood does end up in distinct\n\"columns\" of the hash table:\n\nThe buckets in the hash table corresponding to the cells in the example\nneighborhood.\n\nThus, there is no need to do any bookkeeping to deduplicate hash collisions\nbetween cells. Every cell adjacent to a point will always hash to a distinct\nclass, and thus to a distinct bucket, and thus correspond to a distinct slice\nof the underlying sorted buffer of particles; there is no longer any risk of\nscanning the same slice twice when iterating over adjacent grid cells.\n\nThe size of the hash table can be changed freely by modifying . This allows\nyou to tune the hash collision rate depending on performance and memory\nconstraints, while retaining locally perfect hashing.\n\nIn other words, a hash-based sorting scheme with this kind of hash function\nactually works.\n\n#### Notes on the choice of hash function\n\nThe hash function determines the order of the particles in memory, and as such\nthe choice would have a pretty high impact on performance. The hash function\nshould ideally be chosen with the GPU kernels' memory access patterns in mind,\nto minimize uncoalesced reads and writes.\n\nThe hash function I presented here is almost certainly not optimal with\nrespect to memory access patterns, it is simply chosen because it demonstrates\nthe point in a simple manner and lends itself nicely to illustrations.\n\nI reckon optimizing the interaction between how you structure the kernels\nimplementing the table construction and how the hash function scatters\nparticles in memory is an interesting topic to investigate in its own right,\nand maybe a good starting point for a future post.\n\n## Where's the code?\n\nWhile working on my thesis, I implemented the outlined algorithm using\nCUDA.jl, but since CUDA code is not portable, and CUDA itself is proprietary,\nI don't think this is very satisfying to publish; many people \u2013 particularily\nlaptop users \u2013 would not be able to run it.\n\nBesides, I think the post is long enough as is; I would quite like to survey\nthe landscape of portable GPU programming in Julia, and make a follow-up post.\n\nCopyright 2024 Steffen Haug\n\n", "frontpage": false}

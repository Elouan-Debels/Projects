{"aid": "40001598", "title": "How to Think About Integrating AI into Your Business", "url": "https://spin.atomicobject.com/integrating-ai-your-business/", "domain": "atomicobject.com", "votes": 1, "user": "philk10", "posted_at": "2024-04-11 12:57:20", "comments": 0, "source_title": "How to Think About Integrating AI into Your Business", "source_text": "How to Think About Integrating AI into Your Business\n\n\u2190 Back to Blog Home\n\n# How to Think About Integrating AI into Your Business\n\nArtificial Intelligence\n\nby: Joe Chrysler\n\nApril 11, 2024\n\n  * Twitter\n  * Facebook\n  * Linkedin\n  * Hackernews\n\n### Article summary\n\n  * TL;DR\n  * Here's how LLMs work, briefly.\n  * You should not build your own LLM.\n  * You should build and share effective prompts\n  * Be mindful of what you share with LLM service providers.\n  * Explore widely, publish carefully.\n  * Use LLMs to make some things quicker, cheaper.\n\nWe are deep in the AI hype cycle. Some people in your org are probably worried\nthat HAL9000 is weeks away and their jobs are at risk. Some think LLMs are\njust the next in a long line of neat, but useless tech baubles, sure to be\nreplaced within a year. Others think that, if you miss the AI train, your\ncompetitors will gain a huge advantage. Here\u2019s some perspective from the\nleading edge on how to think about integrating AI into your business.\n\n## TL;DR\n\nMy summary: Speed up your work with off-the-shelf AI tools. Revisit offering\nservices that used to be too costly. Treat AI models as interchangeable\ncommodities.\n\nGPT-4\u2019s summary: Integrate off-the-shelf AI tools into your business to speed\nup processes and introduce previously unaffordable services cost-effectively.\nExercise caution when producing and sharing AI-generated content; human\noversight is crucial to mitigate errors and biases, and always be mindful\nabout sharing data with service providers.\n\n## Here\u2019s how LLMs work, briefly.\n\nThe current generation of large language models (GPT-4, Gemini, LLaMA) work\nlike an autocomplete system. They look at two words in a document and record\nhow close together they are. The closer they are together, the more related\nthey are in some dimension. That\u2019s the training phase. It builds the model.\n\nTo get something out of the model, you send it a message and ask it what the\nmost plausible next word in the conversation would be. Rinse and repeat.\nThat\u2019s the inference phase.\n\nThe genius of an LLM is that if you train, not on one or two documents, but on\na sizable portion of the web pages on the internet, you build a surprisingly\nrobust list of numeric weights for which words should plausibly come next in a\ndialogue.\n\nProducing a better model means training on more data (time-consuming) or\nbetter data (costly).\n\n## You should not build your own LLM.\n\nOpenAI spent upwards of $100 Billion building GPT-4. Unless you have an\nextraordinarily-solid value delivery plan, building your own LLM is a ruinous\nidea right now. However, LLMs are ridiculously cheap to use judiciously,\nespecially when weighed against the cost of human time and opportunity cost.\n\n## You should build and share effective prompts\n\nLLMs use your entire conversation to decide what you want to hear next. Prompt\nengineering is nothing more than developing a careful framing for each\nquestion that you ask. Every LLM is a little different, and every conversation\nwith them is going to include some context that comes before your actual\nquestions. That context can be useful to share with your team.\n\nSay you figure out that if you ask an LLM to talk like a pirate, you get more\nentertaining responses. You could share that with your team in a few ways:\n\n  * Share prompts: Every LLM conversation begins with a behind-the-scenes prompt like, \u201cYou are an AI assistant trained by OpenAI...\u201d. To produce more consistent results for your team, consider adding your own prefix like, \u201cI am a manufacturer of forklift batteries, and you are a writing assistant that always talks like a pirate...\u201d and share that among your team.\n  * CustomGPTs: If you find value in shared prompts, consider using something like OpenAI\u2019s CustomGPTs to share pre-built assistants with custom personalities. They\u2019re simple to make and work like a shared prompt, but easier. They\u2019re especially handy if you\u2019ve got some folks who are super into prompt engineering and getting good results out of an LLM and others who just want to use the new thing without fussing. Have the former group build the CustomGPTs and the latter use them.\n  * Regular old gossip: People in your organization are probably pretty good at sharing information like, \u201cHey, when you talk to so and so make sure you give them the bottom line up front,\u201d or, \u201cDon\u2019t bring up [certain topic] around them.\u201d That sort of thing works for LLMs too, and is how techniques for working effectively with LLMs will spread without intervention.\n\n## Be mindful of what you share with LLM service providers.\n\nWhen you use any LLM that isn\u2019t wholly offline and local, you\u2019re sending\ninformation to a third party. If that\u2019s an unacceptable risk, you probably\ndon\u2019t want to use LLM services yet.\n\nSome, but not many, LLMs are small enough to run on your own hardware. Many\norganizations will have security requirements that rule out sending\ninformation to a third-party service provider.\n\nWe saw a similar interplay of concern and value play out during the transition\nto cloud computing. Storing data in someone else\u2019s data center is now a widely\naccepted practice, with well-understood trade-offs and clear exceptions.\n\nLLMs are having a moment like that. Service providers like OpenAI and\nAnthropic are generally pretty good about guaranteeing that they won\u2019t use\nyour requests to train the next version of their models. Check with your legal\nand compliance teams. Like with the cloud, expect that the innovative forces\nwithin your company will be annoyed by the pushback you get while the\nsustaining forces urge caution.\n\n## Explore widely, publish carefully.\n\nWe\u2019re still early in the LLM development cycle. The risks are well understood:\nthey make up facts, they encode historical biases, and their quality is wildly\nvariable. I like to think about an LLM like GPT-4 as an absent-minded genius.\n\nThey\u2019re genius because they are surprisingly good at some things. They\u2019re\nabsent-minded because you cannot trust them. You absolutely must have a way to\ntest what they say if you\u2019re asking about facts and to review what they\nproduce if you\u2019re asking for content.\n\nWhen you\u2019re thinking about using an LLM, try them on everything. You may be\nsurprised how much value they add to odd tasks, and they may open up new\npossibilities for you. But, be cautious about publishing the output of an LLM\nwithout human oversight. At best, they produce C+ content. I\u2019d wager that in\nmost places within your business, your bar for content is higher than that.\n\n## Use LLMs to make some things quicker, cheaper.\n\nThere are a ton of ways to integrate LLMs into your work.\n\nHere are a few ideas to get you started with integrating AI into your business\ntoday. You can drop any of these prompts into ChatGPT with a GPT+ subscription\nor, if your org has API Keys from OpenAI, you can use any client app (I like\nMindMac on macOS) to try these out.\n\n### Write C+ prose that a good editor can revise.\n\nTry a prompt like: \u201cWrite me a three-paragraph history of the rise of fiber\noptics and provide three resources I can use to learn more.\u201d\n\n### Draw C+ images to help you come up with different ways to visualize\nconcepts.\n\nTry a prompt like: \u201cDraw 5 whiteboard-style diagrams that illustrate the\nconcept of fast and slow feedback cycles in software development.\u201d\n\n### Summarize well-understood business processes and techniques.\n\nTry a prompt like: \u201cSummarize how the theory of constraints applies to\nsoftware development in 3 sentences or less and provide a resource I can use\nto learn more.\u201d\n\n### Help developers write one-off scripts more quickly and thoroughly.\n\nTry a prompt like: \u201cWrite me a bash script that uses JQ to extract a list of\nimages with defined bounding boxes from a COCO JSON file and outputs them as\nan unadorned, newline-separated list.\u201d\n\n### Help developers continue a pattern more quickly than typing it all by\nhand.\n\nHow about this prompt? \u201cExtend the pattern 10 more items: \u201c202212\u201d, \u201c202301\u201d,\n\u201c202302\u201d\u201d. This pattern gets the rough idea across, but the real power is in\nbigger, more complex patterns. This is most useful if it\u2019s built into a\nprogrammer\u2019s text editor.\n\n### Analyze sentiment in survey responses.\n\nTry a prompt like: \u201cHere\u2019s a CSV of survey responses, for each response, add a\nnew column indicating the emotional valence of the response on a 5-point\nscale, with 5 being very happy and 1 being very angry. \u201d\n\n### Provide critique if you\u2019re feeling overconfident.\n\nTry a prompt like: \u201cMy startup idea is to build a two-sided marketplace\nspecifically for suppliers of fill dirt and people with uneven lawns. Give me\nten reasons that this isn\u2019t a good business idea.\u201d\n\n### Summarize long email threads or meeting notes.\n\nTry a prompt like: \u201cYou are an extremely accurate note-taker. Summarize the\nkey points in this email thread, and pull out quotes for any interesting\ndetails.\u201d\n\nJoe Chrysler Software Consultant and Developer at Atomic Object Grand Rapids.\n\nAll Posts \u2192\n\n### Related Posts\n\n  * Artificial Intelligence\n\n## Generative AI Adoption is Competitive Table Stakes \u2013 Don\u2019t Get Left Behind\n\n  * Artificial Intelligence\n\n## How to Leverage AI During Research (and When You Shouldn\u2019t)\n\n  * Artificial Intelligence\n\n## Daydreaming the Future of Software Designers and AI\n\n## Keep up with our latest posts.\n\nWe\u2019ll send our latest tips, learnings, and case studies from the Atomic\nbraintrust on a monthly basis.\n\n[mailpoet_form id=\"1\"]\n\nConversation\n\n### Join the conversation Cancel reply\n\n### Artificial Intelligence Category\n\n  * ChatGPT\n\nRelated Posts\n\nArtificial Intelligence\n\n# Port Elmish to Typescript: A Conversation with ChatGPT\n\nArtificial Intelligence\n\n# Stuck? Benefits of Pair Programming vs. Using an AI Assistant\n\nArtificial Intelligence\n\n# Generative AI Adoption is Competitive Table Stakes - Don\u2019t Get Left Behind\n\n### Tell Us About Your Project\n\nWe\u2019d love to talk with you about your next great software project. Fill out\nthis form and we\u2019ll get back to you within two business days.\n\nShare Your Project\n\nAtomic is a software design + development consultancy.\n\n\u00a9 2024 Atomic Object LLC\n\n##### Explore\n\n  * Careers\n  * Diversity\n  * Resources\n  * Atomic Blog\n\n##### Offices\n\n  * Grand Rapids\n  * Ann Arbor\n  * Chicago\n  * Raleigh-Durham\n\n##### Details\n\n  * Contact\n  * Media\n  * Privacy Policy\n\n", "frontpage": false}

{"aid": "39994824", "title": "Gemini AI Chatbot with Generative UI", "url": "https://vercel.com/templates/next.js/gemini-ai-chatbot", "domain": "vercel.com", "votes": 2, "user": "tosh", "posted_at": "2024-04-10 19:30:17", "comments": 0, "source_title": "Gemini AI Chatbot \u2013 Vercel", "source_text": "Gemini AI Chatbot \u2013 Vercel\n\nSkip to content\n\nContactLog In\n\nSign Up\n\n\u2190 Back to Templates\n\nvercel-labs/gemini-chatbot\n\n# Gemini AI Chatbot\n\nGemini-powered chatbot with the Vercel AI SDK, Next.js, and React.\n\nDeploy\n\nView Demo\n\nFramework\n\nNext.js\n\nUse Case\n\nAI\n\nCSS\n\nTailwind\n\nDatabase\n\nVercel KV\n\nAuth\n\nNextAuth.js\n\n### Features\n\n  * Next.js App Router\n  * React Server Components (RSCs), Suspense, and Server Actions\n  * Vercel AI SDK for streaming chat UI\n  * Support for Google Gemini (default), OpenAI, Anthropic, Cohere, Hugging Face, or custom AI chat models and/or LangChain\n  * shadcn/ui\n\n    * Styling with Tailwind CSS\n    * Radix UI for headless component primitives\n    * Icons from Phosphor Icons\n  * Chat History, rate limiting, and session storage with Vercel KV\n  * NextAuth.js for authentication\n\n### Model Providers\n\nThis template ships with Google Gemini models/gemini-1.0-pro-001 as the\ndefault. However, thanks to the Vercel AI SDK, you can switch LLM providers to\nOpenAI, Anthropic, Cohere, Hugging Face, or using LangChain with just a few\nlines of code.\n\n### Deploy Your Own\n\nYou can deploy your own version of the Next.js AI Chatbot to Vercel with one\nclick:\n\n### Running locally\n\nYou will need to use the environment variables defined in .env.example to run\nNext.js AI Chatbot. It's recommended you use Vercel Environment Variables for\nthis, but a .env file is all that is necessary.\n\n> Note: You should not commit your .env file or it will expose secrets that\n> will allow others to control access to your various Google Cloud and\n> authentication provider accounts.\n\n  1. Install Vercel CLI: npm i -g vercel\n  2. Link local instance with Vercel and GitHub accounts (creates .vercel directory): vercel link\n  3. Download your environment variables: vercel env pull\n\n    \n    \n    pnpm install pnpm dev\n\nYour app template should now be running on localhost:3000.\n\n### Authors\n\nThis library is created by Vercel and Next.js team members, with contributions\nfrom:\n\n  * Jared Palmer (@jaredpalmer) - Vercel\n  * Shu Ding (@shuding_) - Vercel\n  * shadcn (@shadcn) - Vercel\n  * Jeremy Philemon (@jrmyphlmn) - Vercel\n\n\u2190 Back to Templates\n\nvercel-labs/gemini-chatbot\n\n# Gemini AI Chatbot\n\nGemini-powered chatbot with the Vercel AI SDK, Next.js, and React.\n\nDeploy\n\nView Demo\n\nFramework\n\nNext.js\n\nUse Case\n\nAI\n\nCSS\n\nTailwind\n\nDatabase\n\nVercel KV\n\nAuth\n\nNextAuth.js\n\n### Features\n\n  * Next.js App Router\n  * React Server Components (RSCs), Suspense, and Server Actions\n  * Vercel AI SDK for streaming chat UI\n  * Support for Google Gemini (default), OpenAI, Anthropic, Cohere, Hugging Face, or custom AI chat models and/or LangChain\n  * shadcn/ui\n\n    * Styling with Tailwind CSS\n    * Radix UI for headless component primitives\n    * Icons from Phosphor Icons\n  * Chat History, rate limiting, and session storage with Vercel KV\n  * NextAuth.js for authentication\n\n### Model Providers\n\nThis template ships with Google Gemini models/gemini-1.0-pro-001 as the\ndefault. However, thanks to the Vercel AI SDK, you can switch LLM providers to\nOpenAI, Anthropic, Cohere, Hugging Face, or using LangChain with just a few\nlines of code.\n\n### Deploy Your Own\n\nYou can deploy your own version of the Next.js AI Chatbot to Vercel with one\nclick:\n\n### Running locally\n\nYou will need to use the environment variables defined in .env.example to run\nNext.js AI Chatbot. It's recommended you use Vercel Environment Variables for\nthis, but a .env file is all that is necessary.\n\n> Note: You should not commit your .env file or it will expose secrets that\n> will allow others to control access to your various Google Cloud and\n> authentication provider accounts.\n\n  1. Install Vercel CLI: npm i -g vercel\n  2. Link local instance with Vercel and GitHub accounts (creates .vercel directory): vercel link\n  3. Download your environment variables: vercel env pull\n\n    \n    \n    pnpm install pnpm dev\n\nYour app template should now be running on localhost:3000.\n\n### Authors\n\nThis library is created by Vercel and Next.js team members, with contributions\nfrom:\n\n  * Jared Palmer (@jaredpalmer) - Vercel\n  * Shu Ding (@shuding_) - Vercel\n  * shadcn (@shadcn) - Vercel\n  * Jeremy Philemon (@jrmyphlmn) - Vercel\n\n## Related Templates\n\n### Morphic: AI-powered answer engine\n\nAI answer engine with Generative UI.\n\nby Yoshiki Miura\n\n### Next.js AI Chatbot\n\nA full-featured, hackable Next.js AI chatbot built by Vercel\n\nby \u25b2 Vercel\n\n### Advanced AI Bot Protection\n\nAn AI chat app built on Vercel that integrates Kasada's advanced bot\nprotection. Prevent abusive API calls to the LLM before they occur.\n\nby \u25b2 Vercel\n\n## Unleash New Possibilities\n\nDeploy your app on Vercel and unlock its full potential\n\nTry Vercel Free\n\n", "frontpage": false}

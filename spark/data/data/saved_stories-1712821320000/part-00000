{"aid": "39997587", "title": "Taming Configuration Complexity Made Fun with Cue", "url": "https://www.infoq.com/presentations/cue-configuration/", "domain": "infoq.com", "votes": 1, "user": "teleforce", "posted_at": "2024-04-11 01:39:37", "comments": 0, "source_title": "Taming Configuration Complexity Made Fun with CUE", "source_text": "Taming Configuration Complexity Made Fun with CUE - InfoQ\n\n# Your choice regarding cookies on this site\n\nWe use cookies to optimise site functionality and give you the best possible\nexperience.\n\nBT\n\n## InfoQ Software Architects' Newsletter\n\nA monthly overview of things you need to know as an architect or aspiring\narchitects.\n\nView an example\n\nWe protect your privacy.\n\nFacilitating the Spread of Knowledge and Innovation in Professional Software\nDevelopment\n\n  * English edition\n  * Chinese edition\n  * Japanese edition\n  * French edition\n\nWrite for InfoQ\n\n#### Login with:\n\nGoogle Microsoft Twitter Facebook\n\n#### Don't have an InfoQ account?\n\nSign Up\n\nLogo - Back to homepage\n\nNews Articles Presentations Podcasts Guides\n\n### Topics\n\n### Helpful links\n\n  * About InfoQ\n  * InfoQ Editors\n  * Write for InfoQ\n  * About C4Media\n  * Diversity\n\n### Choose your language\n\n  * En\n  * \u4e2d\u6587\n  * \u65e5\u672c\n  * Fr\n\nQCon London\n\nDiscover new ideas and insights from senior practitioners driving change in\nsoftware. Attend in-person.\n\nInfoQ Dev Summit Boston\n\nDiscover transformative insights to level up your software development\ndecisions. Register now with early bird tickets.\n\nInfoQ Dev Summit Munich\n\nGet practical advice from senior developers to navigate your current dev\nchallenges. Register now with early bird tickets.\n\nQCon San Francisco\n\nLevel up your software skills by uncovering the emerging trends you should\nfocus on. Register now.\n\nInfoQ Homepage Presentations Taming Configuration Complexity Made Fun with CUE\n\nDevOps\n\n# Taming Configuration Complexity Made Fun with CUE\n\nBookmarks\n\n49:04\n\n## Summary\n\nMarcel van Lohuizen discusses configuration at scale including the design of\nCUE, how configuration can go wrong, the need for testing and validation, and\nhow CUE does holistic configuration.\n\n## Bio\n\nMarcel van Lohuizen is the co-creator of GCL, was on the founding team of\nBorg, a long-time member of the Go team and creator of CUE. He created the\nopen source CUE project building on 20 years of experience in the natural\nlanguage processing and cloud configuration space. At Google he was, among\nother things, a member of the founding Borg team.\n\n## About the conference\n\nQCon Plus is a virtual conference for senior software engineers and architects\nthat covers the trends, best practices, and solutions leveraged by the world's\nmost innovative software organizations.\n\n## Transcript\n\nVan Lohuizen: A little over 20 years ago, fresh out of university, I moved to\nthe Bay Area to work at a startup where I continued working on natural\nlanguage processing technology, the subject of my PhD. These were turbulent\ntimes, the dot-com crash was in full swing, which meant many closed\nestablishments, empty office buildings, and parking lots. Traffic was even\neasy. The startup I joined would soon be a victim of this crash as well. These\nwere also exciting times, Mac OS X 10.0 was just released, which was exciting\nfor me as a NeXTSTEP fan. Also, the first Apple Stores were open. What was\nalso exciting was the technology I worked on at the startup. As I later\nrealized, we were essentially by today's standards, in configuration heaven.\nAll the words, grammars, ontologies that were maintained by this company were\nspecified declaratively in this beautifully tailor-made system. It was worked\non by multiple teams spread across universities and companies. Teams consisted\nof engineers and non-engineers, linguists. This was all at the scale that\nrivals the largest configurations I've seen at Google, my then future and now\nformer employer. Later, I even realized that the properties of these\nconfigurations are actually strikingly similar to today's cloud configuration.\nThere didn't seem to be any problem with this approach at all. It was fast,\nscalable, and manageable. It was even a joy to work with, and sometimes even\nwith bouts of ecstasy. I don't know about you, but I don't know many people\nthat speak of configuration that way nowadays.\n\n## 2002 - 2005 (Google)\n\nAfter the startup fell prey to the dot-com crash, I started at Google. I made\nsome resource hungry changes to the search engine for my starter project\nthere. I needed bigger and more machines for testing. My best bet was to use a\npool of machines for batch processing that were sitting idle, owned by my\nteam. These machines were very different from the production machines, and I\nneeded to configure everything from scratch. I even needed to adapt the code\nfor these servers to be able to run on these machines at all. Also, I wasn't a\nbig fan of the existing production configuration setup, nobody was really. I\nthought this was a good opportunity to introduce the configuration techniques\nI learned from my previous company. What I ended up with was essentially the\nfirst Kubernetes-like system I'm aware of. The system became rapidly popular\nwithin Google, and even was, to my horror, used to launch some beta, but still\nproduction services. This was not production ready. As a result of all this,\nthough, I became part of the Borg team, which later inspired Kubernetes, with\na goal to build something very similar but production ready. I was\nenthusiastic about configuration and wanted to replicate that experience I had\nwith my previous company. Then, also, based on the past experience with\nGoogle, I was told that the system would have to not allow complex code, and\nonly allow at most one layer of overrides. I thought, that shouldn't be too\nhard. The system I used to work with had no overrides at all and no code, so\nit should be easy. I ended up creating GCL, which is something like JSON.\nInitially, it had some of the properties, but really, very soon, it didn't.\nNeedless to say, we did not end up in this configuration Nirvana at all.\nClearly, we took some wrong turns along the way.\n\n## Background\n\nAt the end of 2005, I moved to work for Google, Switzerland. Here I did all\nsorts of things, including management, a 10-year stint on the Go team, and\ndoing research as part of the SRE group into configuration related outages.\nDuring that time, I always kept an eye on configuration. It always bugged me\nthat I wasn't able to replicate that great experience in my previous line of\nwork. In my mind, I was already pretty convinced where I made mistakes. Over\nthe years, I saw validation that my suspicions were indeed correct. At some\npoint, I started working on CUE to incorporate my lessons learned as well as\nthose from others in the field. Since last year, I left Google and started\nworking on CUE full time. My name is Marcel van Lohuizen.\n\n## The Need for Validation\n\nOverall, I think there's a lot of improvement to be gained in what we call\nconfiguration engineering. This is what we aim for with CUE. Why is it\nimportant at all? Who cares, one might ask? You don't like how writing\nconfiguration is today, and you don't like it as much as you used to. Life is\nhard, deal with it. Research from CloudTruth, and others as well, show that\nfor many companies, over 50% of outages are configuration related. We see that\nconfiguration at scale is often cracking in its seams. Where did we go wrong?\nThere are actually many lessons to be learned. I want to go in-depth on a few\nof those. One of those is the lack of validation, or testing of configuration.\nHere's a quote from my former colleague Jaana, stressing the importance as\nwell.\n\nLet's dive into an example to show the need of validation. We have a service\nthat we want to run in both staging and production. We have two self-contained\nYAML files that define how to run them on Kubernetes. They're defined as a\ndeployment, which is a Kubernetes concept of how to run on a server. In this\nexample, we only want to vary the number of replicas between the two\nenvironments. Everything else which can be quite a bit actually is not shown\nhere, and it's identical between these two files. Updating common values\nbetween these two files can get old very quickly. As we know from both\nsoftware engineering and database design, redundancy, aside from being\ntedious, is also error prone. How can we fix this? A common pattern is to have\na base file which contains all common fields, and then to have the two\nspecific environments derived from that. Also, here are the various ways to\naccomplish this. Here we see a bit more detailed, but still see a greatly\nsimplified deployment. As a reminder, we only care about replicas here. One\napproach is to templatize the base template using variables. This can work\nquite well. There are some limitations in scalability, and the variable\npattern may suffer from the typical issues associated with parameterization.\nThere are some good publications on that topic, but it certainly can work for\nmoderate setups.\n\nFor examples, though, we want to focus on another common approach using\noverrides. Samples of override approaches are, use by kustomize, GCL, and\nJSON. For this example, we'll use kustomize. Kustomize allows you a way to\ncustomize base configurations into environment specific versions using only\nYAML files. There are two kinds of YAML files, one that follow the structure\nof the actual configuration, and the metafiles that explain how to combine\nthese files together. This is a typical kustomize directory layout. The base\ndirectory contains all the configurations on which our environment specific\nkustomizations are based. The kustomization YAML file defines which files are\npart of that configuration. Then there is the overlays directory which\ncontains subdirectory for each of the environment specific tailoring.\n\nLet's see how that looks like. At the top, you see the content files for base\nand production, while at the bottom you see the corresponding metafiles\ndescribing how these files are combined. Notice that the metafiles only\ndescribe how to combine files, not the specific objects. Kustomize is\nspecifically designed for Kubernetes and uses knowledge of the meaning of\nfields to know how to combine objects. This is why you see that some key\ninformation about the deployment still needs to be repeated in the patch file.\nThe result of applying the patch is the base file where replicas is modified\nfrom 1 to 6. This is really inheritance. File overlays are just another form\nof override inheritance. In that sense, it's no different from the inheritance\nthat is used in languages like JSON and GCL. A problem with inheritance is\nthat it may be very hard to figure out where values are coming from. As long\nas you keep it limited to one level, things are usually ok.\n\nSo far, so good. Now let's look at another example. Let's assume that the SRE\nteam introduced a requirement that all production services have Prometheus\nscraping enabled. This could be a requirement for health checks as well, for\nexample, which might make more sense. This is a very simple example. For the\nsake of simplicity, let's stick with this. Someone in a team enforced this\nrequirement in the base deployment so that it will be enabled in every\nenvironment automatically. You could also imagine that there was another base\nlayer or another layer that provides the default for all deployments within a\ngroup or setup, not just for frontends. Now later, somebody else in a team\nexplicitly turns Prometheus scraping off in the prod file. As before, this can\nbe done by overriding the value like this. As we said before, this was a\nrequirement. Clearly, this should not be allowed. Under what circumstances\ncould you expect this to happen? Somebody could have added this to debug\nsomething and forgot to take it out. We all have fiddled with configurations\nor code for that matter to try to get things working, so this is not too\nunthinkable. Another reason could be that a user was simply relying on a\ntooling to catch errors. As you see, there's no formal way to distinguish\nbetween a default value or a requirement. This can easily be overlooked.\nAnother more sneaky way how this could happen is that somebody already put\nthis Prometheus scrape false in before it became a requirement. This could\nhappen, for example, when somebody turned it on and then turned it off, or\nmaybe there was a default just before without it being a requirement. Then, it\nwas made a requirement later down the line. You can imagine how this failure\nwill go unnoticed then. Really, what's missing here is a formal way of\nenforcing the soundness of a configuration.\n\n## What Else May We Want to Enforce?\n\nWe have shown a simple example, but the types of things we're made to enforce\nare really myriad. For instance, one could require that images must be from a\nspecific internal container registry. We could set a maximum number of\nreplicas so that resource usage will not get out of hand. Containers might be\nrequired to implement the health check, or we might want to enforce particular\nuse of labels, or implement some API limitations, check quota limits, or\nauthorization. One could, of course, move all these enforcements into the\nsystem that consumes the configuration, so wherever we passed the\nconfiguration, and reject it if it's incorrect. That's certainly more secure,\nand we should anyway do that. There's no way for users to override it in that\ncase. Even if we do that, we still want to know about the failures ahead of\ndeployment. We still want to know about these things early. Failing fast and\nearly is always a good idea. We've learned the hard way that testing or\nvalidation is as important for data and configuration as it is for code. In\nthe majority of cases where I've seen rigorous testing of data and\nconfiguration introduced, a whole host of errors were uncovered. What is\ntesting in this context? You could think of unit tests, writing tests for your\nconfiguration actual code. Another approach is assertions. GCL and JSON do\nthis, for instance. Really any contract that checks in variants would do. Any\nmethod that accomplishes that would work. One problem with both unit tests and\nassertions is that we'll end up with lots of duplication. In the example\nabove, it would mean that repeating the scraping requirement in a separate\ntest or assertion.\n\n## CUE Crash Course\n\nThis is where CUE comes in. Let's take a look at how CUE would solve the\nproblem. CUE provides a data, schema, validation, and templating language that\nprovides an alternative to override-based approaches. In the approach that CUE\nwas based on already 30 years ago, it was recognized that there is a great\noverlap between types, templating, and validation. In a moment, I will return\nto how to use that to solve the above issue. Before I give CUE solutions to\nthis problem, let me do a quick five-slide crash course on CUE. The CUE\nlanguage is all of a data language like JSON, a schema validation language\nlike JSON Schema, and a templating language like HCL. Let's see how that looks\nlike. As a data language, CUE is strictly an extension of JSON. Think of JSON\nwith syntactic sugar. You can drop quotes around field names, in most cases.\nYou can drop the outer curly braces and trailing commas. There are more human\nreadable forms of numbers. There may appear to be some similarities to YAML. A\nbig distinction with YAML though is that CUE is not sensitive to indentation,\nmaking copy and pasting of CUE a lot easier, and especially a lot error prone.\nCUE also allows defining schema. Here we see a schema defined in Go, and its\nequivalent in CUE. In CUE, schema look very much like data where the usual\nstrings and number literals are replaced by type names. This already hints at\nan important concept in CUE that types are treated just like values. CUE also\nallows validation expressions where validations are like types, just values.\nLet's take a look at this JSON Schema. Field ID is just defined as a string.\nField arch is an Enum which can only be one of the two shown values. For RAM,\nwe define that a machine in this data center must have at least 16 gigabytes\nof RAM. Similarly, we also require that all disks must be at least of size 1\nterabyte. You can already see one benefit of treating types validation as\nvalues, namely that the resulting notation is quite compact.\n\nCUE can also be used for templating. Take a look at this HCL, for example.\nJust like HCL, CUE has references and expressions, key elements of templating.\nCUE doesn't have the notion of variables per se, but any field can be made a\nvariable by adding the tag annotation. This is really a tooling feature, not a\nlanguage feature. CUE has a very rich set of tooling built around it to make\nuse of these kinds of things. If you want to put constraints on such\nvariables, you just use the validation contracts we saw before on the value\nitself. More specifically for templating, CUE also supports default. Anytime\nyou have an Enum in CUE, you can mark a default with an asterisk. Defaults are\nreally a kind of override mechanism. It's the only override mechanism that CUE\nallows. It's CUE's answer to boilerplate removal. It's a very powerful\nconstruct, actually, ensuring that both the depth of inheritance stays limited\nwhile making boilerplate removal quite granular and effective. Comments are\nfirst-class citizens in the CUE API. It is common to note special case\ncomments if you otherwise don't need to. This is used in API generation, one\nof CUE's capabilities. In summary, CUE uses the same structure for data,\nschema, validation, and templating. There's a lot of overlap between these and\ncombining them in one framework is a very powerful notion. Another important\nthing to know about CUE is that it can compose arbitrary pieces of\nconfiguration about the same object in an order independent way, meaning that\nthe result is always the same, no matter in which order you combine it. This\nin and of itself is a key factor on how CUE gets a grip on configuration\ncomplexity. Override approaches do not have this property, even when just\nusing file-based patches.\n\n## Demo of Redoing the Example in CUE\n\nNow back to our example. Here we see a possible CUE layout for the same setup\nas above. At the top we see a CUE mod directory. Much like the Go language,\nCUE can treat an entire directory structure in a holistic way with predictable\nand default build behavior. This makes it easy for configurations to be\ntreated dramatically within a context. This is what a module file would look\nlike. It's really just to class a unique identifier for the module, not unlike\nGo. The CUE mod directory more or less serves the same purpose as the\nkustomization YAML files in kustomize, and defines how to combine files. If\nthe module file is all it takes to specify how to combine files, how does CUE\nknow how to combine all the objects? If it's not based on the file name, and\nas CUE is not Kubernetes specific, it's also not based on the field, so how do\nwe do that? One part of the answer is to rely on the directory structure\nitself. All files in a directory and parent directories within a module that\nare declared within the same package are automatically merged. All CUE files\nin prod are automatically merged with all files in base for instance, as long\nas they have the same package name declared. It doesn't quite answer\neverything. In the kustomize setup, different files describe different objects\nat the same level. It does so by matching object types and names based on\nKubernetes specific fields. CUE is not Kubernetes aware, so how does it know\nhow to combine them? We said that CUE can combine configuration aspects about\nthe same object in any order. All we need to know, really, is which\nconfiguration aspects belong to which object? We do this by assigning a unique\naddress or path for each distinct object within a namespace. Think of it like\na RESTful path. Here we see an example of such a possible path structure and a\nspecific instance from our frontend deployment. A big advantage of declaring\nall objects in a single namespace is that we can define validation as well as\nboilerplate removal that spans multiple objects, such as automatically\nderiving a Kubernetes service from a deployment, for example.\n\nHow does this all look like? Let's start with our production tailoring of the\nproduction frontend deployment. Here, the first line represents the package\nname I mentioned earlier, which is used to know how to combine files. This\nwill be included in all the files that we'll show. The second line is the\nadjustment which just sets the number of replicas to 6. Let's compare it to\nour original kustomization example. You can see it roughly contains the same\ninformation. One could notice, though, that many of the fields have been\nomitted. This is possible because this information is now included in the\npath, and the path uniquely describes that object. The identifying fields are\ntherefore no longer needed as they're already specified in the base template.\nLet's now take a look at the base template. The base applies both to prod and\ndev, which is reflected in the path. We really mean any environment here,\nthough, so usually we write this as this using the any symbol. All the fields\nare mixed in automatically with prod that we saw earlier, causing the frontend\ndeployment to be completely defined here. There's an interesting difference to\nnote compared to the original kustomize template. You can see that it's quite\nsimilar in structure. One noticeable difference, though, is that we no longer\nset replicas to 1. This is because CUE doesn't allow overrides, so setting it\nto 1 would conflict with the value of 6 in the prod file and just cause an\nerror. We do set it to int though, to indicate that we at least expect a\nvalue. There's really no need to set a default value here as all concrete\ninstances already specify a replica explicitly. Also, it's often good not to\nhave a default value specified to force users to think about what value is\nreally appropriate. However, if one really wishes to set a default, we can use\nit using the asterisk approach and using Enums as we saw before, so you can\nsee that here.\n\n## Setting Our Scraping Requirement\n\nWe have replicated our original kustomize setup. How do we now introduce our\nscraping requirement? To show the flexibility of CUE, we define this rule in a\nseparate file on the top directory named monitoring. It follows the same\napproach as before, but we specify a path to which the configuration aspect\nbelongs, along with the desired tailoring. Because true is not the default\nvalue here, it just becomes a requirement imposed in the frontend job in any\nenvironment. If a user wanted to set this to false in any of the environment,\nit would first have to modify this file. Note that this is not unlike how this\nwould work if you had unit tests. Also, there, you would have to change the\ntest first to make it work. The key difference here, though, is that this rule\nfunctions as both the templates, as well as the requirement, so you don't need\nto write a unit test anymore. There's no duplication, but all the convenience\nand safety are there. Now, if you wanted to be a bit more lenient, and say,\nonly require this setting for prod but not for other environments, we could\nwrite this as shown here. Here for any environment, the scraping value is\ndefined as either the string true, which is the default, or the string false.\nThis has the additional benefit that this validates that the value is actually\neither the string true or false, and that anything else is an error. For\nexample, Boolean true or false. One could easily imagine a user would\ninadvertently write this as a Boolean instead of a string. This is another\ngood example of how validation and templating overlap. Also know that the\nsecond rule also applies to prod. That's fine. The only value that is allowed\nby both is true, and the second rule simply has no effect for prod. In\ngeneral, a nice property of CUE is that you can determine that Prometheus\nscraping must be true by just looking at the first rule. No amount of other\nrule can ever change this, so you don't even have to look at the production\ndeployment file to check for this because no amount of other rule could\nspecify would change this. Based on experience, this is actually an immensely\nhelpful property to make configurations more readable and reliable. We could\nalso easily generalize this rule beyond our frontend job. All we need to do\nagain is to replace the frontend field with the any operator we saw before.\n\n## What Is CUE?\n\nWhat is CUE? CUE is not just a language, but also has a rich set of tooling\nand APIs to enable a configuration ecosystem. It's really not specific to any\napplication, but rather aims to be a configuration Swiss Army Knife, allowing\nconversions to and from and composition of different configuration formats,\nrefactoring configuration, and integrating configuration into workflows,\npipelines, and scripting. It's designed really with next-gen GitOps in mind.\nCUE itself is generic and not specific to Kubernetes. There are projects,\ntools, and products in the CUE ecosystem like KubeVela, a CNCF open source\nproject that builds on top of CUE and adds domain specific logic. CUE itself\nis application agnostic. That said, CUE itself has some tools to make it more\naware of a certain context, like Kubernetes, in this case, for instance. Let's\ntake a look at how that might work. All we need to do to make it more aware of\nKubernetes really is to import schemas for Kubernetes defined elsewhere, and\nassign it to the appropriate path. For instance, here we say that all paths\nthat correspond to a deployment are of a specific deployment type. From that\nmoment on, all Kubernetes will be typed as expected. Now if you type a number\nof replicas as a string, for example, or even a fractional number, instead of\nan integer, CUE will report an error. Where does the schema come from? You\ndon't need to write it by hand, in most cases. It may almost seem a little bit\nlike magic, but you can get it from running the shown command. How does this\nwork? The source of truth for Kubernetes schema is Go. CUE knows how to\nextract schema from Go code. That's really all there is to it. In the example\nwe showed, we had a single configuration that spanned an entire directory\ntree. Modules and packages could also be used to break the configuration up in\ndifferent parts linked by imports. This gives really a lot of flexibility on\nhow you want to organize things with CUE.\n\n## What Really Causes Outages Nowadays?\n\nWe've seen some of the benefits of validating configuration. It's really older\nas to it to preventing outages. Really far from it. Earlier, we mentioned that\nresearch shows that for many companies, more than 50% of the outages are\nrelated to configuration. This concurs with my experience. This is really\ncaused by this simple validation related rules of a single system that we\nshowed before. Indeed, I've seen many outages actually related to such a\nfailure. The more mature a company becomes, the less likely that will be the\ncase. On the other hand, the more a company matures, configuration also tends\nto grow in complexity. As a result, this 50% figure seems to hold up over\ntime, even as the simple cases get nearly eliminated completely. A clue of\nthis is shown by this outage reported by Google. I would indeed classify this\nas a configuration related outage, just not of the simple kind that we\naddressed before. There are a handful of very common patterns that one can\nobserve from configuration related outages. One of them is if an application\ndefines a configuration that's valid in principle, but violates some more\nspecific rules or policy of a system to which its configuration is\ncommunicated upstream. If these specific rules are not known and tested\nagainst at the time of deployment, a launch of such a system can fail in\nproduction, and often unnecessarily so. This is a case of not failing early\ndue to a lack of sharing. You want to fail early, as we mentioned earlier.\n\nThis is one of the things that went wrong at a correlation. Correlation\nconfiguration and validation rules or policy, and using it pre-deployment can\ngreatly help in these cases. How does one do that? What is configuration even\nreally? To answer this, let's see where configuration lives in this very\nsimple service. Here we have a single Pong Service that listens to ping\nrequests and replies with pong if the request is authorized. It also logs\nrequests to a Spanner database. The low-level infrastructure is set up by\nTerraform, in this case, and authorization requests are checked by OPA. Can\nyou spot the configuration? Let's see. The most obvious one, perhaps, since\nthis track focuses on infrastructure as code, is the Terraform configuration.\nIn this case, it's used to deploy the VM and the Spanner database. Also, our\nserver operates based on settings. Here we show a JSON configuration file, but\nreally command line flags and environment variables are all configuration\nartifacts. Thirdly, we have a schema definition of the database. Why do we\ncall this configuration? Really, database table definition is also\nconfiguration. You can see here that the database tables really can be a\ncombination of schema and constraints or validation. In other words, the\ndatabase schema defines a contract of how the database can be used. This is\nreally configuration in our view. As a litmus test, you can see the\ntranslation of the schema on CUE on the right-hand side. You see that it's\nmostly a schema, but has some validation rules associated with it as well.\n\nLet's continue with search for configuration. We already mentioned that the\nPong Server needs to be configured. Also, data types within the code that are\nrelated to communication with other components can be seen as configuration.\nLet's look at one of these types here, audits, for example. You can see\nthere's redundancy with the database schema defined earlier. It's basically\nthe same schema, but in Go, it drops many of the constraints that were defined\nin the database schema before. It only partially encodes the contract with the\ndatabase. None of these constraints are really included in the Go code, so\nthis can result in runtime errors that could have been prevented pre-\ndeployment. This is a nice example of that. It's like using a dynamically\ntyped language without unit tests.\n\nYou will only discover such errors when things are running. Let's continue our\nsearch. Our Pong Service is friendly enough to publish an OPI spec of its\ninterface. Really, also, this is configuration. It does overlap with other\nparts of the system, for instance, regarding what types of requests are\nallowed. We're not done yet. We haven't touched our authorization server yet.\nAside from the configuration that is needed to launch that server, also the\npolicies that it executes and checks are configurations as well.\n\nLet's take a look. Here we have a very simple Rego policy that specifies only\nGet methods are allowed. This is not a restriction of the system per se, but\nrather an additional restriction enforced by this policy. As this is a static\npolicy, there's really no reason not to include this restriction in the\nOpenAPI published by the Pong Server. Indeed, it does. The problem is, though,\nthat in the current setup, it is maintained manually. This is error prone. On\nthe right-hand side, you see a possible equivalent of the Rego on the left-\nhand side in CUE. We've taken a bit of a different approach here with CUE. We\ncould have used a Boolean check, but we don't. We're making use of the fact\nthat CUE is a constraint-based language here. Rather than defining allow as a\nBoolean, we compose it with the input, where a successful composition means\nallow, and a failure means deny. Here, it doesn't make much of a difference.\nFor larger policies, specifying the policy in terms of constraint this way\ntends to be quite compact and readable when done in CUE. We see an important\nrole for CUE in policy for this reason.\n\n## The CUE Project\n\nAs we have hopefully shown, configuration is everywhere. Most of you will even\ncarry some in your pocket, like your settings on your smartphone are\nconfiguration. We can see a lot of overlap and redundancy in the configuration\nof the Pong Server. This is a small server, but things really don't get any\nbetter for larger services. Can we address that with CUE? The CUE approach is\nto consolidate all configuration, removing all redundancy and generating\neverything necessary from a single source of truth. Using CUE like this\nensures that all contracts are known throughout the system as much as\npossible. Eliminating redundancy also increases consistency. All this helps to\nfail early and prevent outages. This tweet from Kelsey captures nicely what is\ngoing on. We need clear contracts between components and we need visibility of\ncontracts, configuration, and state even throughout pipelines. What we've also\nshown is that this is not exclusive to infrastructure, this goes beyond\ninfrastructure.\n\nHere's another quote from the Google Cloud website. It specifically emphasizes\nthat contracts are often lost in code, dealing with configuration calls for a\ndeclarative approach, really. This is exactly what CUE is about. We talked a\nbit about what CUE is, but let me share a bit where the CUE project is at. A\nkey part of CUE is spinning down to the precise meaning of configuration. This\nallows it to define adapters for accurate representations of a number of\nformats. The ability to morph any configuration into different formats really\nmakes CUE great for GitHub style deployment. The set of adapters is certainly\nnot complete, as you can see here, but things are moving pretty fast. A lot\ncan really already be done with what exists already. For example, CUE's own CI\nruns on GitHub Actions. The way we do that is we define our workflows in CUE,\nmaking use of templating and other CUE features. Then we import a publicly\navailable JSON Schema definitions for GitHub workflows to validate these\nworkflows. We then export YAML and feed it to GitHub. We also have a lot of\nusers already. Here's a small and by no means complete selection of companies,\nprojects, and products. Some of these are using CUE as a basis for systems of\ntools they are building, not unlike how we saw on the demo. Some of these are\nactually exposing CUE to their users as a frontend, or are leveraging the\ncomposable nature of CUE as well as the rich CUE toolset that is available.\nWe're just getting started. Aside from me, we have Paul, Roger, Daniel, and\nAram who all have strong backgrounds in the Go community, working on CUE\ndevelopment. Carmen also ex-Google and ex-Go team oversees a redo of our\ndocumentation and learning experience, as well as user research, among other\nthings. Dominik is responsible for project ops and also user research.\n\n## Conclusion\n\nTo reach five nines reliability, we need to get a handle on configuration. We\nbelieve this is done by taking a holistic approach to configuration. This is\nnot an easy task, by all means, but this is the goal we've set ourselves out\nto achieve. Configuration has become the number one complexity problem to\nsolve in infrastructure. We need a holistic approach that goes beyond just\nconfiguration languages used. We need tooling, API, and adapters that enables\nan ecosystem of composable and interoperable solutions. We believe that CUE\nwill be able to support such a rich configuration ecosystem, and that will\nreduce outages, increase developer productivity, while making it delightful.\n\n## Questions and Answers\n\nAndoh: Why don't you just use a general-purpose programming language or\nconfiguration?\n\nVan Lohuizen: The general structure of configuration, especially as it gets a\nbit larger, and it's actually already quite quickly, is that you have a lot of\nregularity in all the variations of configuration, but there's a lot of\nirregular exceptions within it. As long as you don't have that, as long as you\nhave a lot of regularity, then it's quite easy to write a few for loops and\ngenerate all the variations of this configuration. If you don't have that,\nthen expressing that in code is very verbose and very hard to maintain.\nWhereas if you have a more declarative, like logic programming-based\napproaches actually becomes much more manageable, in that case. That's really\nthe main reason. You could say that up to medium scale, programming languages\nwork fine, but it's really for the larger configuration where it really starts\nto break down, generally speaking.\n\nAndoh: How does CUE enable better testing and validation?\n\nVan Lohuizen: Of course, CUE is a constraint-based language, so it's fairly\neasy to define basically, assertions, in terms of CUE and restrictions on your\ndata in CUE. Really, a key part of what makes it so powerful, though, is that\nthe same mechanism you use for testing and validation, you can also use for\ntemplating and generation. For instance, suppose you have a field that says\nthe number of replicas should always be 10. You can use it as a templating\nfeature. If you don't specify, the replicas is 10 is automatically inserted in\nyour configuration. You can also see that that's validation. If the user\nspecifies 10, it's fine, but if the user specifies 9, these two things clash.\nValidation and templating are really two sides of the same coin. This makes\nthings a lot easier. Yext is a company that has done this, for example. Just\nas I mentioned, that configuration is where you need to create a lot of small\nvariations in setups, this is often also the case with test sets. What we've\nseen people do is that they actually use CUE itself to generate test sets,\nthat you can use and test a whole variety of cases. CUE as a language does not\nonly make it easier to test, but it actually also makes it easier just like\nconfiguration to generate test data.\n\nI also think using programming language for config is also a big temptation to\nstart embedding complex logic into config files. I think that's not a good\npattern, and programming languages may give you too much rope to hang\nyourself.\n\nThat's absolutely true. This was one of the design points for GCL in the early\ndays, that basically a configuration language should really not do\ncomputation. If you really need any computation at the configuration layer,\nyou should shove it to the server. Especially back in the days at Google, we\ncould do that because we had control over the entire internal ecosystem. Even\nthere in practice, that would actually fail, because even though it's one\ncompany controlling all of that, there are still different teams. If one team\nwants to configure it in some different way, the other team that's controlling\nthe binary might not just want to add that logic into their binary. Plus,\nthere's different release schedules, and for all kinds of practical reasons\nthat's not the case. It's inevitable that you will have some computation at\nthe configuration layer. What you see often happening is that these DSLs then\ninvolved in ultimately, basically, general-purpose programming language,\nwhich, of course, are very hard to use, and it becomes a complete mess. The\nway we try to fix that in CUE is the composable features and nature of CUE\nalso allows you to combine externally computed data into CUE. CUE has the\nscripting layer where you can basically alternate between CUE evaluation and\nshelled out computation. What that allows you to do is to basically take\nconfiguration in CUE, get some values, shell it out to some other computation,\nlike some binary or something else. We're working on a Wasm extension as well.\nThen take that data and insert it again in the declarative configuration. That\ndoes make it a little bit impure. At least what it allows you to do is to\ntruly separate the computation that needs to be in the configuration layer,\nuse a general-purpose language for that, unit test it. Then have anything that\ncan be modified quickly and easily to what's easy to read and can be expressed\nin data, you can keep in CUE itself. You can compare it a little bit to\nspreadsheets. I often say that CUE is a spreadsheet for data, so mostly you\nare just specifying numbers, you can specify some validation rules. If you\nreally need to do some computation, you use these functions in Google Sheets,\nor Excel, or whatever that you can program in Visual Basic, or JavaScript, or\nwhat have you. Really, you keep the code separate from the configuration. I\nthink that's a good compromise for these cases where the computation really\nneeds to live in the configuration layer.\n\nAndoh: Another thing that you said when I asked about why not just a general-\npurpose programming language was that for after a certain scale, you want a\nconfiguration language. Does that mean that CUE is really only best for large\nscale configurations? What about small?\n\nVan Lohuizen: Even though it's designed for very large scale, and the\nexperience is with extremely large configurations, we need to do some\nperformance improvement also to make that work in the general case. We also\nrecognize that, generally speaking, configurations start very small. It should\nalways be the goal to keep configuration small. We wanted to have something\nvery simple that really already works, from the very beginning. Think of it a\nlittle bit like in Go, for example, is the language that you can use for very\nsimple programs. It's for quick development, but actually, it scales fairly\nwell for larger systems. Some of the design principles there is to really make\nit data driven, and make it look like JSON, so to make it look as familiar as\npossible. Then if you know how to write JSON, you can already start using CUE,\nand then you can start using syntactic sugar and grow into the language. That\nwas a big part of it. Also, really the scale at which we are seeing these\nproblems, even though it works at very large scale, you can often see it\ncoming even with fairly small configurations already. If we're talking about\nhundreds of lines, you can already see these problems occurring. Sure, with\ntens of thousands or hundreds of thousands of lines, you're almost guaranteed\nto get into it. It can happen at smaller scales, too.\n\nAndoh: In one of your slides, we saw four different tools being used to be\nable to do all the work of CUE, and I think I looked at the logos and they\nwere JSON Schema, and OpenAPI, and YAML, and JSON. Then you talked about how\nCUE can also do schemas, validation, and things like that. Since this is a\nbeyond infrastructure, can you talk about what CUE can do beyond\ninfrastructure.\n\nVan Lohuizen: We've had some really unexpected use cases for CUE. Also, people\ncoming to us, first of all, like, do you know you're solving the composable\nworkflow problem? People ask this question. You see that many of the uses of\nCUE are actually going into that direction, whereas really like full CI/CD\npipelines and things like that are being defined in CUE. The same thing was\nfor artificial intelligence and ML pipelines, like, how do you compose the\nresults? How do you set it up? Also, very similar problem if you think about\nit. Also, just lower-level data validation. We have companies that are\nmanaging their documentation in CUE, which if you think about it, it's also a\nconfiguration problem. We're seeing it branching out in all these different\nlevels. That's more horizontal, to some extent. Also, if you look at the\nlayering of configuration, like not just date and type of thing, but also\npolicy. It's quite hard to specify policies well. I think it can only be done\nin logic programming, like formulas. That's why you see the success of Rego,\nand all these sorts of things. They're all based on a principle. CUE actually\nwas designed as a reaction to Prolog and Datalog like approaches, which are\nnot very easy to understand for a lot of people. The biggest users were not\nsoftware engineers, originally writing CUE's predecessors. We also think that\nthis is quite a good tool. If you have to use logic programming, this is quite\nan approachable thing to start going into the policy realm, and all these\nthings. That's why we've seen that much demand. It's really nice to have one\ntool and one way of specifying all these different things. We think that is\nquite useful.\n\nAndoh: Where can you learn more and get involved in CUE and the CUE community?\n\nVan Lohuizen: There's a website called cuelang.org. You can find links to the\ncommunity. We have a very active Slack community. There's also GitHub\ndiscussions for more Stack Overflow like questions that will just stay there,\nand where people can get help. That's a good place to start. We're working on\nnew documentation that might make it a little bit easier to read. Some of the\ndocumentation or most of the documentation we have was really more written for\nthe language designers, and not yet to get people started. We're working on\ngetting that going. We think CUE is quite simple, actually, but if you read\nthe documentation out, it might not look like that.\n\nSee more presentations with transcripts\n\nRecorded at:\n\nSep 05, 2023\n\nby\n\n  * Marcel van Lohuizen\n\n#### Related Sponsored Content\n\n  * #### Exploring enterprise AI: An Introduction to LLMs, vector databases, and more\n\n  * #### Develop and deploy intelligent apps with Serverless and Kubernetes on Microsoft Azure\n\n  * #### Comparing RavenDB and MongoDB\n\n  * #### The Limitations of Horizontal Scaling and the Benefits of DragonflyDB\u2019s Vertical Scaling Pattern\n\n  * #### Kubernetes Cookbook: Building cloud native applications (By O'Reilly)\n\n#### This content is in the DevOps topic\n\n##### Related Topics:\n\n  * DevOps\n\n### DevOps\n\nFollowers: 4467\n\n  * Configuration Management\n\n### Configuration Management\n\nFollowers: 13\n\n  * Automation\n\n### Automation\n\nFollowers: 239\n\n  * Source Control\n\n### Source Control\n\nFollowers: 23\n\n  * Source Code\n\n### Source Code\n\nFollowers: 61\n\n  * QCon Plus November 2022\n\n### QCon Plus November 2022\n\nFollowers: 3\n\n  * QCon Plus\n\n### QCon Plus\n\nFollowers: 11\n\n  * ALM\n\n### ALM\n\nFollowers: 9\n\n  * QCon Software Development Conference\n\n### QCon Software Development Conference\n\nFollowers: 214\n\n  * Transcripts\n\n### Transcripts\n\nFollowers: 21\n\n  * Google\n\n### Google\n\nFollowers: 61\n\n  * Agile\n\n### Agile\n\nFollowers: 989\n\n  * InfoQ\n\n### InfoQ\n\nFollowers: 78\n\n  * #### Related Editorial\n\n    * ##### Apple Open Sources Pkl, a Configuration as Code Programming Language\n\n    * ##### DoorDash Uses CockroachDB to Create Config Management Platform for Microservices\n\n    * ##### AWS Introduces Amazon CloudFront KeyValueStore: a Low Latency Datastore for CloudFront Functions\n\n    * ##### Declarative Machine Learning: a Flexible, Modular and Scalable Approach for Building Production ML Models\n\n    * ##### How to Win as a Tech Team in a New Reality That Feels Like a Mad Max Movie?\n\n  * #### Popular across InfoQ\n\n    * ##### Will C++ Become a Safe Language Like Rust and Others?\n\n    * ##### InfoQ Software Architecture and Design Trends Report - April 2024\n\n    * ##### InfoQ Architecture and Design Trends in 2024\n\n    * ##### Architecture Does Not Emerge - A Conversation with Tracy Bannon\n\n    * ##### QCon London: Meta Used Monolithic Architecture to Ship Threads in Only Five Months\n\n    * ##### Microsoft Azure Introduces Retina: a Cloud Native Container Networking Observability Platform\n\n  * Development\n\n    * ##### Will C++ Become a Safe Language Like Rust and Others?\n\n    * ##### Development Environment Manager Daytona Now Open Source\n\n    * ##### Practical Guide to Building an API Back End with Spring Boot - Version 2\n\n  * Architecture & Design\n\n    * ##### QCon London: How Duolingo Sent 4 Million Push Notifications in 6 Seconds During the Super Bowl Break\n\n    * ##### Architectures You\u2019ve Always Wondered About 2024\n\n    * ##### Architecting for High Availability in the Cloud with Cellular Architecture\n\n  * Culture & Methods\n\n    * ##### QCon London: the Art, Science and Psychology of Decision-Making\n\n    * ##### Achieving SLSA Certification with a \u201cBring-Your-Own-Builder\u201d Framework\n\n    * ##### InfoQ Culture & Methods Trends Report - April 2024\n\n  * AI, ML & Data Engineering\n\n    * ##### Large Language Models for Code by Loubna Ben Allal at QCon London\n\n    * ##### NVIDIA Announces Next-Generation AI Superchip Blackwell\n\n    * ##### Navigating LLM Deployment: Tips, Tricks and Techniques by Meryem Arik at QCon London\n\n  * DevOps\n\n    * ##### Kubecost Launches Version 2.0 with Network Monitoring\n\n    * ##### Netflix Launches bpftop Aimed at Enhancing eBPF Performance Efficiency\n\n    * ##### Improving GitHub Deployments with Merge Queue\n\n## The InfoQ Newsletter\n\nA round-up of last week\u2019s content on InfoQ sent out every Tuesday. Join a\ncommunity of over 250,000 senior developers. View an example\n\n  * Get a quick overview of content published on a variety of innovator and early adopter technologies\n  * Learn what you don\u2019t know that you don\u2019t know\n  * Stay up to date with the latest information from the topics you are interested in\n\nWe protect your privacy.\n\nJune 24 - 25, 2024 Actionable insights to clarify today's critical dev\npriorities.\n\nInfoQ Dev Summit Boston, is a two-day conference hosted by InfoQ, focusing on\nthe most critical technical decisions senior software developers face today.\nDeep-dive into 20+ technical talks and get transformative learnings from\nsenior software developers navigating Generative AI, security, modern web\napplications, and more. Register Now\n\nHome Create account QCon Conferences Events Write for InfoQ InfoQ Editors\nAbout InfoQ About C4Media Media Kit InfoQ Developer Marketing Blog Diversity\n\n#### Events\n\n  * ##### QCon London\n\nAPRIL 8-10, 2024\n\n  * ##### InfoQ Live Roundtable\n\nAPRIL 23, 2024\n\n  * ##### InfoQ Dev Summit Boston\n\nJUNE 24-25, 2024\n\n  * ##### InfoQ Dev Summit Munich\n\nSEPTEMBER 26-27, 2024\n\n  * ##### QCon San Francisco\n\nNOVEMBER 18-22, 2024\n\n#### Follow us on\n\nYoutube223K Followers\n\nLinkedin21K Followers\n\nRSS19K Readers\n\nX53.4k Followers\n\nFacebook21K Likes\n\nAlexaNew\n\n#### Stay in the know\n\nThe InfoQ Podcast Engineering Culture Podcast The Software Architects'\nNewsletter\n\nGeneral Feedback feedback@infoq.com Advertising sales@infoq.com Editorial\neditors@infoq.com Marketing marketing@infoq.com\n\nInfoQ.com and all content copyright \u00a9 2006-2024 C4Media Inc. Privacy Notice,\nTerms And Conditions, Cookie Policy\n\nBT\n\n", "frontpage": false}

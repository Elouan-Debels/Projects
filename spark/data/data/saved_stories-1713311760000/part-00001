{"aid": "40055050", "title": "Collecting data for AI, an alternative way, using the community", "url": "https://gpt3experiments.substack.com/p/collecting-data-for-ai-an-alternative", "domain": "gpt3experiments.substack.com", "votes": 1, "user": "nutanc", "posted_at": "2024-04-16 17:53:50", "comments": 0, "source_title": "Collecting data for AI, an alternative way", "source_text": "Collecting data for AI, an alternative way - by nutanc\n\n# Experiments with NLP and GPT-3\n\nShare this post\n\n#### Collecting data for AI, an alternative way\n\ngpt3experiments.substack.com\n\n#### Discover more from Experiments with NLP and GPT-3\n\nAll my experiments with the newly launched GPT-3 in particular and NLP in\ngeneral.\n\nContinue reading\n\nSign in\n\n# Collecting data for AI, an alternative way\n\n### A community driven approach to collecting data.\n\nnutanc\n\nApr 16, 2024\n\nShare this post\n\n#### Collecting data for AI, an alternative way\n\ngpt3experiments.substack.com\n\nShare\n\nData is the new oil apparently. And just as with oil, we are seeing lots of\nshady techniques being employed to collect this data.\nhttps://time.com/6247678/openai-chatgpt-kenya-workers/\n\nBut are there better ways to collect data. What are the alternatives?\n\nKarya, is doing something in this domain. They are trying to pay decent wages\nfor data collection and data cleaning agents.\n\nIn this regard, Swecha, tried a very unique approach for data collection. What\nif we make the people part of the data collection effort. Sort of an AI by the\npeople for the people.\n\nSo, how do we go ahead making people a part of the data collection process.\n\n  1. The people have to be clearly explained what the data is being used for.\n\n  2. The people should happily share their data.\n\n  3. Some incentive for sharing the data has to be provided.\n\n  4. The data has to be released in open source so that it can benefit the commons.\n\nOpen source is the binding force here. Because without releasing the model in\nopen source why would anyone share their data?\n\nTo do this at scale where the data collected can be useful for AI, it needs a\nhuge grass roots effort. And that\u2019s where Swecha come in. The Swecha team\nalready has experience in pulling off such open source campaigns. Swecha team\nwas the first to launch an Indian language operating system when they launched\nthe Telugu Ubuntu. That was also a community driven event.\n\nSo in a similar fashion, Swecha activated its volunteer network to go to\ndifferent parts of the two Telugu speaking states, Andhra and Telangana and\ncollect voice samples from the people. The goal was to collect voice samples\nfrom different accents and different locations. So, the volunteers went to\nvillages, schools and collected data even on the road :)\n\nVolunteers collecting data\n\nThe volunteers were able to collect 1.5 million voice samples amounting to\naround 1000 hours of Telugu ASR data. Similar efforts will cost anywhere\naround 50 lakhs to 1 crore, but the Swecha team was able to achieve this\nthrough a community effort.\n\nThe data was collected, but what was the incentive given to the people who\nshared their voice samples?\n\nIt was an entry to a concert by Ram Miryala. So you bought tickets to a\nconcert using your voice samples instead of money. Thanks to Ram Miryala for\naccomodating the request and doing the concert for free.\n\nThe volunteers donated their time.\n\nThe people donated their voice.\n\nArtists like Ram Miryala donated their talent.\n\nThe community came together to create the dataset.\n\nNow it was the time of the technologists. My team from Ozonetel and Swecha\nengineers got together and started to build a Telugu ASR model from this\ndataset. The goal was to build a small model that can run on the mobile.\n\nWe were able to quickly build the model and to our pleasent surprise we found\nthat it was working much beyond our expectations with accuracy more than 95%\nin most cases.\n\nThe output of all this effort is below.\n\nOnce the proper open source license is finalized we will be releaseing the\nmodel and the datasets so that more people can innovate.\n\n### Subscribe to Experiments with NLP and GPT-3\n\nBy nutanc \u00b7 Launched 4 years ago\n\nAll my experiments with the newly launched GPT-3 in particular and NLP in\ngeneral.\n\nShare this post\n\n#### Collecting data for AI, an alternative way\n\ngpt3experiments.substack.com\n\nShare\n\nComments\n\nA hitchhikers guide to GPT-3. Part 1.\n\nA hitchhikers guide to everything related to GPT-3 through experiments. What\nworks, what doesn't.\n\nJul 23, 2020 \u2022\n\nnutanc\n\n1\n\nShare this post\n\n#### A hitchhikers guide to GPT-3. Part 1.\n\ngpt3experiments.substack.com\n\nIs GPT-3 really doing few shot learning?\n\nLanguage is a funny thing. Sometimes a whole article cannot evoke anything,\nbut a single word can evoke a lot of things for people. For example, the...\n\nSep 3, 2020 \u2022\n\nnutanc\n\n3\n\nShare this post\n\n#### Is GPT-3 really doing few shot learning?\n\ngpt3experiments.substack.com\n\n6\n\nBuilding a vector database in 2GB for 36 million Wikipedia passages\n\nWikipedia neural search running on a laptop(2GB small model and 10GB large\nmodel). https://speech-kws.ozonetel.com/wiki Thanks to @CohereAI for...\n\nJun 21, 2023 \u2022\n\nnutanc\n\n2\n\nShare this post\n\n#### Building a vector database in 2GB for 36 million Wikipedia passages\n\ngpt3experiments.substack.com\n\nReady for more?\n\n\u00a9 2024 nutanc\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}

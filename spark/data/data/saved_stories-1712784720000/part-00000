{"aid": "39991839", "title": "Gemini 1.5 and Google's Nature", "url": "https://stratechery.com/2024/gemini-1-5-and-googles-nature/", "domain": "stratechery.com", "votes": 3, "user": "sturza", "posted_at": "2024-04-10 15:30:25", "comments": 0, "source_title": "Gemini 1.5 and Google\u2019s Nature", "source_text": "Gemini 1.5 and Google\u2019s Nature \u2013 Stratechery by Ben Thompson\n\nSkip to content\n\n# Stratechery by Ben Thompson\n\nOn the business, strategy, and impact of technology.\n\n# By Ben Thompson\n\nAbout Ben Follow via Email/RSS Twitter\n\n# Stratechery Plus\n\nAbout Stratechery Plus Subscribe Member Forum\n\n# Account\n\n  * Member\n\n  * Delivery Preferences\n  * Manage Account\n  * Sign Out\n\n  * Log In\n  * Sign Up\n\nLoading\n\n# Explore Stratechery\n\n  * Concepts\n  * Companies\n  * Topics\n\n# Archives\n\n  * Articles\n  * Updates\n  * Interviews\n  * Years in Review\n\n# Gemini 1.5 and Google\u2019s Nature\n\nPosted onWednesday, April 10, 2024 Author by Ben Thompson\n\nIt was impossible to miss the leading message at yesterday\u2019s Google Cloud Next\nkeynote: Google has the best infrastructure for AI. This was CEO Sundar Pichai\nin his video greeting:\n\n> I want to highlight just a few reasons Google Cloud is showing so much\n> progress. One is our deep investments in AI. We\u2019ve known for a while that AI\n> would transform every industry and company, including our own. That\u2019s why\n> we\u2019ve been building AI infrastructure for over a decade, including TPUs, now\n> in their 5th generation. These advancements have helped customer train and\n> serve cutting-edge language models. These investments put us in the\n> forefront of the AI platform shift.\n\nGoogle Cloud CEO Thomas Kurian made the priority clear as well:\n\n> Today we\u2019re going to focus on how Google is helping leading companies\n> transform their operations and become digital and AI leaders, which is the\n> new way to cloud. We have many important advances, starting with our\n> infrastructure.\n\nWhat was most interesting about the keynote, though, is what that\ninfrastructure makes possible, and, by extension, what that says about\nGoogle\u2019s ability to compete.\n\n### Grounding\n\nOne of the most surprising things about large language models (LLMs) is how\nmuch they know; from the very beginning, though, hallucinations have been a\nconcern. Hallucinations are, of course, part of what makes LLMs so impressive:\na computer is actually being creative! It\u2019s also a feature that isn\u2019t\nparticularly impressive to the enterprise customers that this keynote was\ndirected at.\n\nTo that end, Kurian, shortly after going over Google\u2019s infrastructure\nadvantages, talked about \u201cgrounding\u201d, both in terms of the company\u2019s Gemini\nmodel broadly, and for enterprise use cases specifically in the context of\nGoogle\u2019s Vertex AI model management service:\n\n> To augment models, Vertex AI provides managed tooling to connect your model\n> to enterprise applications and databases, using extensions and function-\n> calling. Vertex also provides retrieval augmented generation (RAG) combining\n> the strengths of retrieval and generative models to provide high quality\n> personalized answers and recommendations. Vertex can augment models with up-\n> to-date knowledge from the web and from your organization, combining\n> generative AI with your enterprise truth.\n>\n> Today we have a really important announcement: you can now ground with\n> Google Search, perhaps the world\u2019s most trusted source of factual\n> information, with a deep understanding of the world\u2019s knowledge. Grounding\n> Gemini\u2019s responses with Google Search improves response quality and\n> significantly reduces hallucinations.\n>\n> Second, we\u2019re also making it easy to ground your models with data from your\n> enterprise databases and applications, and any database anywhere. Once\n> you\u2019ve chosen the right model, tuned it, and connected it with your\n> enterprise truth, Vertex\u2019s MLOps can help you manage and monitor models.\n\nA RAG implementation using Google Search is an obvious win, and mirrors\nChatGPT\u2019s integration with Bing (or Microsoft Copilot in Bing): the LLM\nprovides answers when it can, and searches the web for things it doesn\u2019t know,\na particularly useful feature if you are looking for more recent information.\n\nA more impressive demonstration of grounding, though, was in the context of\nintegrating Gemini with Google\u2019s BigQuery data warehouse and Looker business\nintelligence platform:\n\nIn this demo, the worker gets an alert that a particular product is selling\nout; using generative AI the worker can see sales trends, find similar models,\nand create a plan of action for dealing with declining inventory for delivery\nto her team.\n\nWhat is notable is not the demo specifics (which is unapologetically made-up\nfor Cymbal, Google\u2019s demo brand); rather, note the role of the LLM: it is not\nproviding information or taking specific actions, but rather serving as a much\nmore accessible natural language interface to surface and collect data that\nwould otherwise take considerably more expertise and time. In other words, it\nis trustworthy because it is grounded through integration Google is promising\nwith its other enterprise data services.\n\n### Gemini 1.5\n\nAt the same time, that last section didn\u2019t really follow on from the\nintroduction: yes, those LLMs leveraging Google or BigQuery are running on\nGoogle\u2019s infrastructure, but other companies or startups can build something\nsimilar. This is where the rest of Pichai\u2019s introduction comes in:\n\n> We also continue to build capable AI models to make products like search,\n> Maps, and Android radically more helpful. In December, we took our next big\n> step with Gemini, our largest and most capable model yet. We\u2019ve been\n> bringing it to our products and to enterprises and developers through our\n> APIs. We\u2019ve already introduced our next generation Gemini 1.5 Pro. It\u2019s been\n> in private preview in Vertex AI. 1.5 Pro shows dramatically enhanced\n> performance and includes a breakthrough in long context understanding. That\n> means it can run 1 million tokens of information consistently, opening up\n> new possibilities for enterprises to create, discover, and build using AI.\n> There\u2019s also Gemini\u2019s multi-modal capabilities, which can process audio,\n> video, text, code and more. With these two advances, enterprises can do\n> things today that just weren\u2019t possible with AI before.\n\nGoogle hasn\u2019t said how Gemini 1.5 was made, but clearly the company has\novercome the key limitation of traditional transformers: memory requirements\nincrease quadratically with context length. One promising approach is Ring\nAttention with Blockwise Transformers, which breaks long contexts into pieces\nto be computed individually even as the various devices computing those pieces\nsimultaneously communicate to make sense of the context as a whole; in this\ncase memory requirements scale linearly with context length, and can be\nextended by simply adding more devices to the ring topology.\n\nThis is where Google\u2019s infrastructure comes in: the company not only has a\nmassive fleet of TPUs, but has also been developing those TPUs to run in\nparallel at every level of the stack, from chip to cluster to even data\ncenters (this latter requirement is more pertinent for training than\ninference); if there is a solution that calls for scale, Google is the best\nplaced to provide it, and it seems the company has done just that with Gemini\n1.5.\n\n### Demos\n\nTo that end, and per Pichai\u2019s closing line, almost all of the other demos in\nthe keynote were implicitly leveraging Gemini 1.5\u2019s context window.\n\nIn a Gemini for Workspaces demo, the worker evaluated two statements of work\nagainst each other, and against the company\u2019s compliance document:\n\nHere are the key quotes:\n\n> Google Drive is ready without any additional AI pre-work...\n>\n> Each of these documents is over 70 pages. It would have taken me hours to\n> review these docs, but instead Gemini is going to help me find a clean\n> answer to save me a ton of time...\n>\n> Before I proceed with this vendor, I need to ensure that no compliance\n> issues exist, and I\u2019m going to be honest, I have not memorized every rule in\n> our compliance rulebook because it is over 100 pages. I would have to need\n> to scour the 80 pages of this proposal and compare it manually with the 100\n> pages of the rulebook. So instead, in the side panel I ask, \u201cDoes this offer\n> comply with the following\u201d and I\u2019m going to just @-mention our compliance\n> rulebook, hit Enter, and see what Gemini has to say. So interesting: Gemini\n> has found an issue, because the supplier has not listed their security\n> certifications.\n>\n> Because Gemini is grounded in my company\u2019s data, with source citations to\n> specific files, I can trust this response and start to troubleshoot before\n> selecting a vendor.\n\nThe key distinction between this demo and the last one is that quote at the\nbeginning: a large context window just works in a far greater number of use\ncases, without any fiddly RAG implementations or special connections to\nexternal data stores; just upload the files you need to analyze, and you\u2019re\noff.\n\nIn a Creative Agent with Imagen demo, the worker was seeking to create\nmarketing images and storyboards for an outdoor product:\n\nHere is the key quote:\n\n> The creative agent can analyze our previous campaigns to understand our\n> unique brand style and apply it to new ideas. In this case, the creative\n> agent has analyzed over 3,000 brand images, descriptions, videos, and\n> documents of other products that we have in our catalog, contained within\n> Google Drive, to create this summary...The creative agent was able to use\n> Gemini Pro\u2019s 1 million token context window and it\u2019s ability to reason\n> across text, images, and video to generate this summary.\n\nThis was, to be fair, one of the weaker demos: the brand summary and marketing\ncampaign weren\u2019t that impressive, and the idea of creating a podcast with\nsynthetic voices is technically impressive and also something that will never\nbe listened to. That, though, is impressive in its own right: as I noted in an\nUpdate when Gemini 1.5 was first announced, \u201ca massively larger context window\nmakes it possible to do silly stuff\u201d, and silly stuff often turns into serious\ncapabilities.\n\nIn a Gemini Code Assistant Demo (formerly Duet AI for Developers), a developer\nnew to a job (and the codebase) was tasked with making a change to a site\u2019s\nhomepage:\n\nHere is the key quote:\n\n> For the developers out there, you know that this means we\u2019re going to need\n> to add padding in the homepage, modify some views, make sure the configs are\n> changed for our microservices, and typically, it would take me a week or two\n> to even just get familiarized with our company\u2019s code base which has over\n> 100,000 lines of code over 11 services. But now, with Gemini Code Assist, as\n> a new engineer on the team, I can be more productive than ever and can\n> accomplish all of this work in just a matter of minutes. This is because\n> Gemini\u2019s code transformations with full codebase awareness allows us to\n> easily reason through our entire codebase, and in comparison, other models\n> out there can\u2019t handle anything beyond 12,000 to 15,000 lines of code.\n> Gemini with Code Assist is so intelligent that we can just give it our\n> business requirements, including the visual design...Gemini Code Assist\n> doesn\u2019t just suggest code edits; it provides clear recommendations, and\n> makes sure that all of these recommendations align with [the company\u2019s]\n> security and compliance requirements...\n\nAnd the conclusion:\n\n> Let\u2019s recap: behind the scenes Gemini has analyzed my entire codebase in\n> GitLab; it has implemented a new feature; and has ensured that all of the\n> code generated is compatible with my company\u2019s standards and requirements.\n\nAgain, leave aside the implausibility of this demo: the key takeaway is the\ncapabilities unlocked when the model is able to have all of the context around\na problem while working; this is only possible with \u2014 and here the name is\nappropriate \u2014 a long context window, and that is ultimately enabled by\nGoogle\u2019s infrastructure.\n\n### Google\u2019s Nature\n\nIn case it isn\u2019t clear, I think that this keynote was by far the most\nimpressive presentation Google has made in the AI era, not least because the\ncompany knows exactly what its advantages are. Several years ago I wrote an\nArticle called Microsoft\u2019s Monopoly Hangover that discussed the company\u2019s\nthen-ongoing transition away from Windows as the center of its strategy; the\ncentral conceit was a comparison to Lou Gerstner\u2019s 1990\u2019s transformation of\nIBM.\n\n> The great thing about a monopoly is that a company can do anything, because\n> there is no competition; the bad thing is that when the monopoly is finished\n> the company is still capable of doing anything at a mediocre level, but\n> nothing at a high one because it has become fat and lazy. To put it another\n> way, for a former monopoly \u201cbig\u201d is the only truly differentiated asset.\n\nMy argument was that business models could be changed: IBM did it, and\nMicrosoft was in the process of doing so when I wrote that. Moreover, Gerstner\nhad shown that culture could be changed as well, and Nadella did just that at\nMicrosoft. What couldn\u2019t be changed was nature: IBM was a company predicated\non breadth, not specialization; that\u2019s why Gerstner was right to not break\napart the company but to instead deliver Internet solutions to enterprises.\nSimilarly, Microsoft was a company predicated on integration around Windows;\nthe company\u2019s shift to services centered on Teams as Microsoft\u2019s operating\nsystem in the cloud was also true to the company\u2019s nature.\n\nGoogle is facing many of the same challenges after its decades long dominance\nof the open web: all of the products shown yesterday rely on a different\nbusiness model than advertising, and to properly execute and deliver on them\nwill require a cultural shift to supporting customers instead of tolerating\nthem. What hasn\u2019t changed \u2014 because it is the company\u2019s nature, and thus\ncannot \u2014 is the reliance on scale and an overwhelming infrastructure\nadvantage. That, more than anything, is what defines Google, and it was\nencouraging to see that so explicitly put forward as an advantage.\n\n### Share\n\n  * Facebook\n  * Twitter\n  * LinkedIn\n  * Email\n\n### Related\n\nAI and the Big FiveMonday, January 9, 2023\n\nGoogle\u2019s Search for the Sweet SpotThursday, October 5, 2017\n\nGoogle\u2019s True MoonshotMonday, December 18, 2023\n\n# By Ben Thompson\n\nAbout Ben Follow via Email/RSS Twitter\n\n# Stratechery Plus\n\nAbout Stratechery Plus Subscribe Member Forum\n\n# Account\n\n  * Member\n\n  * Delivery Preferences\n  * Manage Account\n  * Sign Out\n\n  * Log In\n  * Sign Up\n\nLoading\n\n# Explore Stratechery\n\n  * Concepts\n  * Companies\n  * Topics\n\n# Archives\n\n  * Articles\n  * Updates\n  * Interviews\n  * Years in Review\n\n# Subscriber\u2019s Daily Update\n\nTuesday, April 9, 2024\n\n# Personal Day\n\nMonday, April 8, 2024\n\n# The Status of Just Walk Out, TSMC Gets CHIPS Act Grant\n\nWednesday, April 3, 2024\n\n# An Interview with Benedict Evans About Regulation and AI\n\nTuesday, April 2, 2024\n\n# The XZ Backdoor, What Happened, Open Source Safety\n\nOn the business, strategy, and impact of technology. \u00a9 Stratechery LLC 2024 | Terms of Service | Privacy Policy\n\n# Search results\n\nFiltersShow filters\n\nSort by:\n\n\u2022\u2022\n\n## No results found\n\n## Filter options\n\nSearch powered by Jetpack\n\n", "frontpage": false}

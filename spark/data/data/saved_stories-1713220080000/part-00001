{"aid": "40042632", "title": "An Introduction to Large Language Models", "url": "https://goodcomputer.substack.com/p/an-introduction-to-large-language", "domain": "goodcomputer.substack.com", "votes": 1, "user": "d9w", "posted_at": "2024-04-15 16:25:30", "comments": 0, "source_title": "An introduction to Large Language Models", "source_text": "An introduction to Large Language Models - by Dennis Wilson\n\n# Good Computer\n\nShare this post\n\n#### An introduction to Large Language Models\n\ngoodcomputer.substack.com\n\n#### Discover more from Good Computer\n\nDeep(ish) dives on the good and bad of AI\n\nContinue reading\n\nSign in\n\n# An introduction to Large Language Models\n\n### Written by a human\n\nDennis Wilson\n\nApr 15, 2024\n\nShare this post\n\n#### An introduction to Large Language Models\n\ngoodcomputer.substack.com\n\nShare\n\nSince the release of ChatGPT, Large Language Models (LLMs) like ChatGPT,\nGemini, and Llama have become ubiquitous in our daily lives. These models\ngenerate text, code, or even images. In this post, I\u2019ll give a high-level\nintroduction1 to Large Language Models, the technical details about them as\nwell as the current challenges facing them. In future posts, I\u2019ll go into more\ndetail about how they are being used and some of the challenges overviewed\nhere.\n\n##\n\nLarge Language Models\n\nThe backbone of Large Language Models is the artificial neural network or ANN.\nInspired by the human brain, ANNs have been studied since the 1940s. These\nmodels simulate interconnected artificial neurons, with parameters defining\ntheir connections. Learning occurs through backpropagation, which compares a\nmodel's output to the desired one.\n\nConsider, for example, the sentence: \"This cat is cute.\" We can give the model\nthe beginning of the sentence, \"this cat is\", and use the model to generate\nthe last word. If the model outputs \"cute,\" we consider the model parameters\nto be good and don't make major changes to them. But if the model outputs\nsomething else, we use backpropagation to adjust the parameters so that it is\nmore likely to output \"cute\" the next time.\n\nThis loop of using an ANN model, comparing its output to data, and adjusting\nthe parameters is known as \"learning\" or \"training.\" Training depends heavily\non data to demonstrate what outputs we expect from a model. This data\ndependence is especially important for generative AI, where multiple good\noutputs often exist. For example, the final word of the sentence \"This cat is\ncute\" could also be \"pretty\" or \"adorable.\" How do we encourage the model to\ngenerate these diverse, yet sensible, responses while avoiding nonsensical\nones like \"This cat is sandwich\"?\n\nThe specific ANN architecture behind LLMs is called a \"Transformer\"\narchitecture. The modern transformer architecture was developed in 2017 and\ntransforms one data sequence into another. A sequence can be, for example, a\nsentence or multiple sentences. LLMs use an \"attention\" mechanism to identify\nthe most crucial parts of the input sequence. For instance, to predict \"cute\"\nin \"This cat is cute,\" the model focuses on \"cat\" more than \"this\" or \"is.\"\nThis allows transformers to handle large amounts of context without internal\nmemory, relying instead on a large input sequence.\n\nAn important characteristic of LLMs is that they are \"large\" \u2013 much larger\nthan previous neural networks. GPT2, an early version of the mode behind\nChatGPT, had 1.5 billion parameters, and speculated numbers for the parameter\ncounts of GPT3.5 and GPT4, the current ChatGPT models, range from 20 billion\nto 1.7 trillion. Training such a massive model requires a similarly massive\namount of data.\n\nGood Computer is a reader-supported publication. To receive new posts and\nsupport my work, consider becoming a free or paid subscriber.\n\n##\n\nNext token prediction\n\nThe standard training approach for LLMs is next token prediction: giving the\nmodel most of a sentence and using it to predict the next word. Using the\nexample of \"This cat is\", the model is asked using next-token prediction to\npredict \"cute,\" the next token. LLMs operate on \"tokens\" instead of words, to\ntake characters and word segments into account. A token might be a word, a\npart of a word, a punctuation mark, a word with a space before it, a word with\na suffix. The \"vocabulary\" of a model is the set of all possible tokens it can\ngenerate; the vocabulary of GPT2 and GPT3 is 50257 tokens, ranging from\nlogical ones like \"The\" to surprising ones like \"davidjil\".\n\nTo train these giant models on next-token prediction, AI companies like OpenAI\nturned to the vast public internet. Datasets of sentences were gathered, with\nGPT-3 having a training set of over 500 billion tokens. To give an idea of the\nsize, all of Wikipedia is only 3 billion tokens out of the 500 billion. The\nlarge size of these datasets and the language models trained on them is a\nrecent development in AI.\n\nSo now, we can understand the name of ChatGPT, which stands for Generative\nPre-trained Transformer. \"Generative\" because it generates text, \"Pre-trained\"\nbecause it's already been trained, and \"Transformer\" because of its neural\nnetwork architecture. By training a large language model on billions of tokens\nand evaluating its ability to predict language tokens, the model learns to\nproduce surprisingly intelligent-seeming results. However, this training\nmethod on public internet data and the use of next-token prediction cause many\nproblems, such as biases, generating false information, the plateauing of\nperformance, and legal issues.\n\n##\n\nBias\n\nOne of the largest and inherent issues in language models is bias. Bias is\nwhat models use to make accurate predictions. A model trained on data which\nfrequently says that cats are cute will learn to predict the sentence \"This\ncat is cute\" more often than \"This cat is ugly\": we could say that the model\nhas a positive bias towards cats.\n\nThe data used to train these models comes from the public internet, so it\ncontains biases that are prevalent on the internet. Gender stereotypes and\ncultural prejudices seep into the model's predictions, leading to biased\noutputs. For example, a model trained on internet data will predict that a\nfarmer is male and a nurse is female.\n\nTo mitigate bias, the commonly used method is reinforcement learning with\nhuman feedback, where human annotations of generated text are used to\ndetermine when a response is appropriate or not. However, as witnessed\nrecently with Google's Gemini model, aligning generative AI with human values\nmeans defining a specific set of values. What is considered good or\nappropriate varies across cultures and individuals, making it difficult to\nestablish a universal standard. As Irene Solaiman has said, \"bias can never be\nfully solved as an engineering problem... Bias is a systemic problem.\"\n\n##\n\nHallucinations\n\nAnother critical issue is the ability of LLMs to generate text which is false,\nwhile still sounding factual. Without fact-checking mechanisms, these models\noften generate misleading or false information, as they are only predicting\nthe next token. These false statements are often referred to as\nhallucinations.\n\nFor instance, Google's announcement of their Bard model contained an erroneous\nclaim about the first image of an exoplanet ever taken. A simple Google search\nshows that the real first image was from 20 years ago, not recently as was\nclaimed in the generated text.\n\nWhile efforts like tying generated content to verified sources are being\nstudied, fully resolving this issue remains challenging and it isn't clear if\nit's even possible. The most common solution currently is Retrieval-Augmented\nGeneration (RAG), which combines an LLM with a retrieval model to ensure that\nthe generated text is based on verified sources. While RAG has shown promise\nin reducing hallucinations, state-of-the-art RAG methods show that there is\nstill much work to be done.\n\n##\n\nPublic internet data\n\nThe reliance on publicly available internet data for training LLMs also\ncreates a number of challenges. Future generative AI models may not offer\nsignificant performance improvements without new technological breakthroughs.\nIt is worth noting that next-token prediction was formulated in 1950, the\nattention mechanism for neural networks in 2014, and the transformer\narchitecture in 2017. The recent development of LLMs is due to tapping into a\nlimited resource, publicly available text, which may not be sustainable. For\nexample, if the public internet fills with more AI-generated content, the\nperformance of these models may even decrease. Researchers have claimed that\nsome language models are already decreasing in quality over time.\n\nFurthermore, utilizing copyrighted internet data raises legal concerns. This\nhas resulted in a number of lawsuits from news organizations like the New York\nTimes and authors like George R. R. Martin against AI companies.\n\n##\n\nFuture opportunities and challenges\n\nLLMs are now being used in a variety of applications, from assisting users in\nfinding information on websites, to autocompletion in writing tasks, even to\noffering medical advice based on scans and images of the human body. Open\nsource LLMs allow for integration of these models into a wide range of\napplications. A clear direction for future generative AI applications is\nlinking LLMs with other software, such as internet search or voice\nrecognition, to create more seamless and natural interactions. However, the\nchallenges described above of bias, hallucinations, plateauing performance,\nand legal issues will need to be addressed as LLMs are integrated into more\napplications.\n\n1\n\nIntroductory posts like this one will help me keep a more regular schedule, so\nplease let know in the comments what you think about this format.\n\n### Subscribe to Good Computer\n\nBy Dennis Wilson \u00b7 Launched a month ago\n\nDeep(ish) dives on the good and bad of AI\n\n1 Like\n\nShare this post\n\n#### An introduction to Large Language Models\n\ngoodcomputer.substack.com\n\nShare\n\nComments\n\nEuropean Union AI Act\n\nThe EU makes a momentous first step in governing AI\n\nMar 18 \u2022\n\nDennis Wilson\n\n4\n\nShare this post\n\n#### European Union AI Act\n\ngoodcomputer.substack.com\n\nWill AI destroy science or solve it?\n\nThe answer has to be one or the other\n\nMar 25 \u2022\n\nDennis Wilson\n\n5\n\nShare this post\n\n#### Will AI destroy science or solve it?\n\ngoodcomputer.substack.com\n\nReady for more?\n\n\u00a9 2024 Good Computer\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}

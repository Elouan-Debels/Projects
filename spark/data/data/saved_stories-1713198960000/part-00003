{"aid": "40038713", "title": "Data acquisition strategies for AI-first startups", "url": "https://press.airstreet.com/p/data-acquisition-strategies-for-ai", "domain": "airstreet.com", "votes": 1, "user": "ABudai", "posted_at": "2024-04-15 10:34:38", "comments": 0, "source_title": "Data acquisition strategies for AI start-ups in 2024", "source_text": "Data acquisition strategies for AI start-ups in 2024\n\nShare this post\n\n#### Data acquisition strategies for AI-first start-ups\n\npress.airstreet.com\n\n#### Discover more from Air Street Press\n\nIdeas worth propagating.\n\nContinue reading\n\nSign in\n\nAnalysis\n\n# Data acquisition strategies for AI-first start-ups\n\nAir Street Capital\n\n,\n\nNathan Benaich\n\n,\n\nMoritz Mueller-Freitag\n\n, and\n\nAlex Chalmers\n\nApr 04, 2024\n\n11\n\nShare this post\n\n#### Data acquisition strategies for AI-first start-ups\n\npress.airstreet.com\n\n2\n\nShare\n\nBack in 2016, I came across a prescient guide on data acquisition strategies\nfor AI start-ups written by Moritz Mueller-Freitag, then co-founder of Twenty\nBillion Neurons (TwentyBN):\n\nWe quickly became good friends and explored product applications for\nTwentyBN\u2019s video understanding technology: large-scale crowd-acted video\ndemonstrations of concepts, actions and situations that could endow machines\nwith visual common sense and intuitive physics. The company was ultimately\nacquired by Qualcomm, where Moritz now serves as Director of Product\nManagement.\n\nAnyone working on deep learning in 2016 will tell you how much more immature\nthe AI ecosystem was at the time. The market was very skeptical about pushing\nagainst the research frontiers to derive new capabilities. Open data\nrepositories were few and far between and generating quality synthetic data at\nscale posed significant challenges. Access to high-quality, labeled data was\nthus a consistent and significant obstacle for founders.\n\nThe last few years have brought us significant changes:\n\n  * We need immense amounts of data because pre-training works and we want models with higher level capabilities;\n\n  * We have more data than before, understand how to make better use of it, and are able to generate it on a larger scale;\n\n  * We have much better tools and techniques that have removed many of the pain points around large, manually labeled data sets.\n\nWe\u2019ve also learned more about what works and what doesn\u2019t. Moritz and Air\nStreet Press have teamed up to produce some updates for AI-first founders in\n2024. More generally, as we push further on scale and build generative AI\nsystems for a myriad of use cases, the topic of data ownership, copyright,\nfair use and infringements highlights the importance of being thoughtful about\ndata acquisition.\n\nThe original guide contains a number of strategies that still largely hold up\nin the same form, including corporate partnerships, manual work and the use of\ncrowdsourcing platforms. We haven\u2019t recapped them in depth here, as we have\nlittle to add on what Moritz originally said. Others, such as the use of data\ntraps and side businesses haven\u2019t gained as much traction since 2016.\nMeanwhile, small acquisitions have become increasingly challenging since\nregulators started paying considerably more attention to AI.\n\n###\n\nLarge generative models\n\n####\n\nLLMs and LMMs as synthetic data generators\n\nWhereas Large Language Models (LLMs) generate textual outputs, Large Multi-\nModal Models (LMMs) can create a wide range of synthetic data modalities, such\nas text, code and images. It\u2019s particularly prevalent in areas where real-\nworld data is scarce, privacy-sensitive, or expensive to collect and label. We\nsee this in fields like NLP, computer vision, and autonomous systems\ndevelopment (e.g. development of scenarios for simulation-based training for\nautonomous vehicles).\n\nSynthetic data is typically used for supplementing real data or for fine-\ntuning, rather than as a wholesale substitute. No matter how sophisticated, it\ncan only ever create an approximation of a problem domain. Over-reliance on it\nrisks the model overfitting to the characteristics present in the synthetic\ndata generation process.\n\nThe two main generation methods are:\n\n  * Self-improvement, where the model creates instructions, input context, and responses. Examples that are invalid or too similar to existing ones are filtered out and the remaining data is used to fine-tune the original model.\n\n  * Distillation, which involves transferring knowledge from a more capable teacher model to a less powerful, but more efficient student model. Even if the synthetic data is often incorrect, it can still contribute effectively to the instruction-tuning process.\n\nMicrosoft has released a series of smaller models called Phi, which are\npredominantly trained on synthetic data produced by other LLMs and able to\noutperform most non-frontier models. In response to the lack of information\nprovided on the curation of Microsoft\u2019s synthetic training datasets, Hugging\nFace created Cosmopedia, which aimed to reproduce the training data Microsoft\nused.\n\nThey outlined the process in detail, which involved generating synthetic\ntextbooks, blog posts, and stories. This process utilized over 30 million\nfiles and 25 billion tokens generated using Mixtral-8x7B-Instruct. The content\nranged from educational sources to web data, structured to mimic real-world\ndatasets closely. The team said that the hardest part of the process was\naround prompt engineering to preserve diversity of material and avoid\nduplication.\n\nThese approaches are not without controversy. Distillation in particular has\nbeen shown in some studies to create models that effectively imitate the style\nof the stronger LLM, while performing less well on factuality. These stylistic\nsimilarities are able to fool human reviewers, but show up in more targeted,\nautomatic evaluations. It\u2019s also easy to imagine this process amplifying\ninherent biases present in the original training data used to create the\nstronger model.\n\n####\n\nLLMs as labellers\n\nThere is evidence to suggest that state-of-the-art LLMs can label text\ndatasets at the same or to a higher standard than human annotators, in a\nfraction of the time. Unlike human annotators, LLMs can consistently apply the\nsame annotation criteria across large datasets without fatigue or bias\ncreeping in. This ensures a high level of consistency and scalability when\nannotating massive amounts of data. Moreover, large generative models trained\non enormous datasets like Segment Anything perform better \u2013 and often in a\nzero shot capacity \u2013 than specialized non-generative computer vision models\nthat are traditionally used in automated labeling workflows for tasks like\nsemantic segmentation.\n\nThese techniques will become increasingly important given the growing\napplication of AI in more subjective and socially relevant domains. A recent\npost from Lilian Weng of OpenAI outlines some of the different methods used to\ndrive improvements in the quality of human annotated data.\n\n####\n\nLLMs as data scientists\n\nLLMs can also be used to widen the available pool of real data available via\ndataset stitching. This refers to the process of combining and integrating\ndiverse data sources into a unified dataset. The LLM does this by\nunderstanding the context and semantics of the data, resolving\ninconsistencies, and generating a coherent and structured dataset. It can also\ncombine different data types (e.g. text and images) into unified datasets\nthrough representation learning. The first model accessible model to do this\nto sufficient quality was OpenAI\u2019s CLIP, which could map different modalities\ninto the same embedding space, allowing fusion of previously siloed data\nsources.\n\n####\n\nLLMs as graders\n\nReinforcement learning from human feedback (RLHF) was a key fine-tuning\ntechnique that turned GPT-3 into a breakout system optimized for\nconversational interactions with users over chat. After large-scale\nunsupervised pre-training on the task of next-token prediction, human experts\ndemonstrate desirable responses to an array of prompts, which serve as\nsupervised training data for the pre-trained model. Then, various flavors of\nthis model are tested against additional prompts and their outputs are graded\nby human experts. This human feedback data is used to train a reward model\nthat grades the responses of language models in response to lots of prompts.\nUsing reinforcement learning, the performance of the language model is\nimproved with this human feedback-trained reward model.\n\nNow, instead of using humans to provide feedback, one can use an LLM instead\nin an approach that\u2019s now called reinforcement learning from AI feedback\n(RLAIF). Here, the LLM is provided with a set of values that it must consider\nwhen providing feedback during RLAIF. These values, sometimes called a\nconstitution, ensure that alignment and safety can be jointly optimized along\nwith capabilities. The main advantage of RLAIF over RLHF is that of\nscalability and cost reduction due to the switching of humans for machines.\n\n###\n\nData labeling: people and platforms\n\nThe original version of this piece covered the use of crowdsourcing and task\noutsourcing platforms like Amazon Mechanical Turk to tap into a cheap online\nworkforce to label or clean up data. While these services may still prove\nuseful, we\u2019ve seen platforms like V7 and Scale AI grow in sophistication and\npopularity. These provide automated data labeling and management capabilities,\nalong with certain compliance and quality assurance measures, that enable\ncompanies with large-scale data needs to scale up more efficiently and provide\na higher degree of consistency.\n\nDifferent platforms have their own strengths. For example, V7 tends to focus\non tasks that require a higher degree of specialization, such as medical\nimaging, while Scale has grown in autonomous driving and expanded into\ndefense. Newer players, such as Invisible, are serving the need for qualified\nhuman workforces LLM-specific workflows such as supervised finetuning, RLHF,\nhuman evaluations and red teaming.\n\nPopular data labeling services include:\n\n  * CVAT\n\n  * Dataloop\n\n  * Invisible\n\n  * Labelbox\n\n  * Scale AI\n\n  * V7\n\nMany of these platforms still rely on human annotators to some extent and more\nwork will have to go into assessing the quality of their output, given the\ngrowing application of AI in more complex, subjective and socially relevant\ndomains. A recent post from Lilian Weng of OpenAI outlines some of the\ndifferent methods used to drive improvements in the quality of human annotated\ndata.\n\nThese include:\n\n  * Rater agreement and aggregation: where majority voting, agreement rates, and probabilistic modelling approaches can be used to estimate true labels from multiple rater inputs and identify unreliable \u201cspammer\u201d raters. This can be especially informative in subjective domains where there isn\u2019t a single ground truth.\n\n  * Modeling rater disagreement: techniques like disagreement deconvolution and multi-annotator modelling can capture systematic disagreement among raters and use it to improve training. There are also jury learning approaches that model the different labelling behaviours of raters based on personal characteristics, using these to aggregate diverse perspectives.\n\n  * Detection of mislabeled data points: these include influence functions (which measure the impact of unweighting or removing individual samples on model weights), tracking prediction changes during training. There\u2019s also noisy cross-validation, where the dataset is split in half, training the model on one half and then using that model to predict labels for the other half; mismatches between the predicted and true label are flagged up.\n\n###\n\nOpen datasets\n\nSince 2016, we\u2019ve seen a proliferation in open datasets, driven by both the\nopen data movement and the recognition of the value of data sharing across\nindustry, academia, and government.\n\nOpen datasets exist in most domains, but are particularly accessible for\ncomputer vision, NLP, speech/audio processing, and robotic control and\nnavigation. This has been advanced by a combination of community efforts (e.g.\nvia Hugging Face, PyTorch, TensorFlow, and Kaggle) and large dataset releases\nby big tech companies.\n\nWhile coming with the obvious advantage of being free and helpful for\nbenchmarking, there are certain considerations.\n\nFirstly, open datasets are rarer, older, and smaller in sensitive or regulated\nfields. In these sectors, there is a significant commercial advantage in\npossessing your own, proprietary dataset.\n\nOpen data can vary significantly in quality and freshness, leading to issues\nwith relevance in rapidly evolving fields. Overuse also risks overfitting,\nwhere heavy reliance on popular datasets leads to models performing well\nagainst benchmarks but poorly in real-world applications.\n\nThe list of potential open source datasets runs into thousands, but some\nhelpful community resources include:\n\n  * Big tech companies like Amazon, Google, and Microsoft have various open data hubs and search engines\n\n  * Hugging Face has created a hub of ready-to-use datasets with accompanying tools\n\n  * Kaggle\u2019s dataset search\n\n  * VisualData: hub for computer vision datasets\n\n  * V7 has published a list of over 500 open source datasets\n\n###\n\nSimulated environments\n\nSimulated environments allow AI models or agents to learn in a controlled\nsetting to generate synthetic data and test systems before deployment in the\nreal-world. They are particularly helpful for supplementing real world data\nand exploring edge cases that may be difficult, costly, or otherwise\nchallenging to encounter in reality.\n\nThis has made them particularly popular for embodied AI (e.g. robotics or\nautonomous vehicles), where it\u2019s important to train systems safely and to\naccount for the huge numbers of potential variations in the physical world.\nThat said, creating and validating a rich, 3D simulation capable of modeling\nphysics accurately from scratch can require significant resources and\ninfrastructure. We\u2019ll note that this space is also progressing fast with new\ncompanies such as Physical Intelligence attacking these problems. Meanwhile,\nNVIDIA has created a powerful GPU-accelerated robotics platform called ISAAC,\nwhich includes a simulated environment powered by Omniverse, the company\u2019s\nplatform for integrated 3D graphics and physics-based workflows.\n\nTo ease the cost burden, there are open-source simulation environments\navailable for both domains. Meanwhile, Epic Games\u2019 computer graphics engine\nUnreal Engine has become a powerful tool for building simulated environments,\nthanks to its high-fidelity graphics, realistic physics simulation, and\nflexible programming interfaces.\n\nExamples:\n\n  * Applied Intuition: provide simulation and validation solutions for developers of autonomous driving systems\n\n  * Sereact: German start-up working automating pick-and-pack in warehouses, whose software is underpinned by a simulation environment so robots can understand spatial and physical nuances\n\n  * Wayve: UK-based self-driving start-up that\u2019s created a number of 4D simulation environments\n\nOpen source environments include:\n\n  * Autonomous vehicles:\n\n    * CARLA: simulator focusing on realistic urban environments for driving. Recently upgraded to operate on Unreal Engine 5.\n\n    * LG SVL Simulator: high-fidelity simulation platform developed by LG Electronics, supporting multiple sensors and vehicle dynamics\n\n    * AirSim: simulator for drones and ground vehicles, built on Unreal Engine\n\n  * Robotics:\n\n    * Gazebo: versatile robotics simulator that integrates with ROS, a popular open-source framework for writing robotics software.\n\n    * CoppeliaSim: comprehensive robot simulation program\n\n    * PyBullet: Python module for physics simulation in robotics, games, and machine learning, featuring GPU acceleration and deep learning capabilities\n\n    * MuJoCo: physics engine for model-based control, designed for research in robotics and biomechanics\n\n###\n\nScraping the web, books, and other materials\n\nMass scraping of text, audio, and video has been a key ingredient in the\nenablement of foundation models. While big tech companies will use their own\nproprietary systems, start-ups have access to a range of off-the-shelf and\nopen source tools to facilitate this. As explored below, these methods are\ncontroversial and it is important to evaluate fair use and licensing, so use\nthem at your own peril. Tools include:\n\n  * Distributed crawling frameworks that make it easier to scale up crawling tasks across multiple machines, like Apache Nutch;\n\n  * Easily available cloud computing services that provide the means to run scrapers cost-effectively;\n\n  * Headless browsers like Puppeteer and Selenium that enable the easy scraping of JavaScript-heavy websites;\n\n  * Improved parsing libraries, like Beautiful Soup, that can handle messy or inconsistent HTML and CSS structures;\n\n  * Proxy and IP management services like Luminati that can mitigate anti-scraping measures on websites;\n\n  * Rise of cheap and effective OCR for the scanning of books.\n\nOnce you\u2019ve decided on the combination of methods, there\u2019s the trade-off\nbetween volume and quality. This usually ends up varying depending on domain\nand application. For example, language models can learn effectively from\nrelatively noisy and uncurated data, if provided in sufficient volume.\nMeanwhile, it\u2019s possible to drive good results in computer vision by\naugmenting small high-quality datasets by creating modified versions of images\n(e.g. via cropping, rotation, or the addition of noise).\n\nIt\u2019s also important to think about the nuts and bolts of how datasets are\ncurated, for example, via curriculum learning. This is a training strategy\nthat involves presenting data to the model in a meaningful order, moving from\nsimpler to more complex examples. By mimicking the way humans learn, models\nlearn good initial parameters before being challenged with harder examples,\ndriving greater efficiency. Databricks\u2019 recent SOTA open-LLM DBRX drew on\nthis, with the research team finding it substantially improved model quality.\n\nTwo start-ups from the most recent Y Combinator batch illustrate these trade-\noffs. At one end of the spectrum, Sync Labs used large quantities of\nrelatively low-quality video to train a model that allows the user to re-sync\nlips in a video to match new audio. At the other end of the spectrum,\nMetalware combined a relatively small set of scanned images from specialized\ntextbooks with GPT-2 to build a co-pilot for firmware engineers.\n\n###\n\nCopyright challenges and the potential of licensing\n\nWhile the maturation of the AI ecosystem since 2016 has been a net positive\nfor founders, it has introduced additional complexities. Mass web scraping by\nfoundation. model providers has resulted in media companies, writers, and\nartists launching an array of copyright cases. These are still working their\nway through the court system in Europe and the US. While these cases are\ncurrently all aimed at either big tech companies and their allies (e.g. Meta,\nOpenAI) or increasingly established labs (e.g. Midjourney and Stability), they\nreinforce the importance of start-ups being thoughtful in how they approach\nacquisition.\n\nIf the companies lose, these rulings could result in companies having to\ninvest significant efforts in identifying copyrighted material in training\ndata and compensating its creators or destroying these artifacts and starting\nfrom scratch altogether.\n\nAs a result, some businesses are proactively pursuing creator-friendly\nacquisition strategies, either striking partnerships with media organizations\nor compensating artists directly for the use of their content or voices.\n\nWe\u2019re also seeing the emergence of some certification schemes for ethically\nsourced training data, including from a former Stability exec. It\u2019s early days\nfor these kinds of certification schemes, but they remain an interesting\navenue and worth observing.\n\nExamples:\n\n  * ElevenLabs: payouts for voice actors and voice data partnerships\n\n  * Google: agreement with Reddit to make its data available for Gemini training\n\n  * OpenAI: partnership to train DALL-E on Shutterstock\u2019s library of images, videos, music, and metadata and an agreement to license Associate Press\u2019s news archive\n\nShare\n\n###\n\nReducing the need for large labeled datasets\n\nSince 2016, we\u2019ve seen a significant shift towards unsupervised and semi-\nsupervised learning techniques. These make it possible for start-ups to build\npowerful models without the large labeled datasets that have traditionally\nbeen viewed as essential. While these approaches were known to researchers\nlong before 2016, their accessibility, sophistication, and practicality has\nimproved markedly in recent years.\n\nThese approaches include:\n\n  * Unsupervised learning: focused on learning statistical patterns and structures that are intrinsic to the data. It\u2019s traditionally been useful for exploring large datasets (e.g. unsupervised clustering) and is now the pillar of LLM pre-training.\n\n  * Semi-supervised learning: this uses a small amount of labeled data, alongside a large set of unlabeled data. It\u2019s most effective when refining and improving the performance of models.\n\nThese approaches can be enhanced with techniques like contrastive and few-shot\nlearning. Contrastive learning, for instance, enables models to learn rich\nrepresentations by distinguishing between similar and dissimilar data points.\nThis is useful for tasks in computer vision. Recall that OpenAI\u2019s CLIP, which\naligns visual and textual representations, is based on contrastive learning.\n\nFew-shot learning, on the other hand, allows models to adapt to new tasks with\nvery few examples. Indeed, the original scaling laws paper showed that larger\nmodels are more capable of few-shot learning. So while they require larger\namounts of unlabelled data for unsupervised pre-training, this step endows\nthem with the ability to solve downstream tasks with fewer labeled examples\nthan smaller non-generative counterparts.\n\nWhile these approaches are powerful, they come with specific drawbacks that\nneed to be accounted for. Models that leverage unlabeled data often require\nmore complex architectures. It often means essentially trading the money spent\non labeling for money spent on compute.\n\nNot only does this make them more challenging to implement and scale, they are\nusually less interpretable, which can act as a drawback in sensitive fields\nwhere understanding decisions is crucial. This complexity also draws on\ngreater computational resources, while still frequently hitting a lower\nperformance ceiling than supervised methods.\n\nFew-Shot Learning (source)\n\n###\n\nWhat hasn\u2019t taken off?\n\n####\n\nData marketplaces\n\nSince 2016, we\u2019ve seen the creation of a few data marketplaces, as it\u2019s become\neasier and cheaper to collect, store, process, and share large volumes of\ndata. But the space has never really come to life.\n\nMarketplaces and platforms like Datarade, Dawex, AWS Data Exchange, and\nSnowflake have made it easier to find image, text, audio, and video data\nacross a range of common use cases. This is largely to offer additional value\nto the customer for choosing to host their data in these lakes. Alongside\nthese marketplaces, there are companies like Appen, Scale AI, Invisible and\nSurge, which provide custom dataset creation and labeling through an army of\n(skilled) outsourced workers.\n\nAs with open data, these excel across computer vision, NLP, and speech\nrecognition, but there\u2019s also more industry-specific coverage (e.g. finance,\nretail, marketing) that aligns to start-ups\u2019 operational needs. These\nplatforms are also built to integrate directly with tools used by developers\nor researchers to make the process as pain-free as possible.\n\nThe same caveats around both specialization and the competitive advantage of\nproprietary data hold true. We\u2019re also yet to see much evidence that AI-first\nstart-ups lean on these marketplaces heavily.\n\nWhile there may be some upfront convenience, significant effort still has to\ngo into cleaning, customization, filtering, and subsampling. Understandably,\nmany would rather build their own proprietary dataset from scratch and wield\nit as a competitive advantage. The same holds true for the agency model. For\nany kind of specialized application, there\u2019s a low ceiling on what even well-\nsupervised outsourcing can achieve.\n\n####\n\nGamification\n\nGamification as a data acquisition strategy has been explored by various\ncompanies and organizations, particularly in the context of crowdsourcing and\ncitizen science initiatives. For example, Folding@Home leveraged gamification\nto incentivize volunteers to contribute spare computing power for protein\nfolding simulations.\n\nUltimately, beyond a small handful of examples, gamification remains\nrelatively niche. It only appears to a specific subset of users who are both\nmotivated by the game-like competition and have the spare time. This places a\nrelatively low ceiling on the potential number of contributors. Even among the\nmotivated, quality and accuracy of contributed data will also remain a\nchallenge, requiring additional validation and control measures, especially\nwhen handling edge cases.\n\n####\n\nFederated learning\n\nFederated learning (FL), introduced by Google in 2016, offered the promise of\ntraining models across multiple decentralized servers or mobile devices, while\nkeeping the data at rest locally. Theoretically, this could allow start-ups\nworking in sensitive domains like healthcare or finance to access vital\ntraining data via partnerships, while avoiding traditional privacy concerns.\nAlthough there was a spike in academic and industry interest in the following\nyears, real-world implementations remain limited in scope.\n\nFL ran into three major challenges. Firstly, issues surrounding liability,\ndata ownership, and cross-border data transfers hindered adoption in the\nsensitive fields for which it was designed. Secondly, as models and datasets\nhave grown in complexity, the computational and communication overheads\nassociated with distributed training and aggregation have become a significant\nbottleneck. Thirdly, there remains a sense of \u201ctrust in math\u201d where data\nowners need to come to terms with fairly complicated techniques that guarantee\nthe value proposition.\n\n###\n\nClosing thoughts\n\nDespite the significant progress since 2016, data acquisition remains a pain\npoint for start-ups. Neither the community nor the market look set to resolve\nthis. While most AI-first companies will still face a standing start at\ninception, this presents an opportunity for differentiation. Creatively\nbuilding the right foundations remains a very real source of competitive\nadvantage.\n\nNevertheless, data by itself is never a moat. In time, competitors will either\nsucceed in acquiring their own or finding more efficient techniques to\naccomplish the same outcome. We can see this all too clearly in LLM\nevaluations, as the gap in performance between smaller and larger models has\nprogressively shrunk over the past year. Great data acquisition is ultimately\nnecessary, but not sufficient. It\u2019s one ingredient for success along with a\nkiller product and genuine customer insight - subjects we will no doubt return\nto in the future.\n\n11 Likes\n\n\u00b7\n\n1 Restack\n\n11\n\nShare this post\n\n#### Data acquisition strategies for AI-first start-ups\n\npress.airstreet.com\n\n2\n\nShare\n\nA guest post by| Moritz Mueller-FreitagDirector, Product Management @Qualcomm.\nPreviously Co-Founder @TwentyBN. All things AI and emerging tech. Opinions are\nmine. \ud83d\udc4b| Subscribe to Moritz  \n---|---  \n  \n2 Comments\n\nMichael SpencerAI SupremacyApr 8Actually wish I knew more about their exit\nstrategies. They are going to need them.Expand full commentLikeReplyShare  \n---  \n  \nAndrea SquatritoData BoutiqueApr 5Thanks for sharing, interesting read!In the\nweb scraping and data marketplace area, I\u2019d like to suggest Data Boutique, as\na valid alternative to in-house scraping and the rising costs of using proxy\nnetworks to circumvent anti-bot technologies.Expand full commentLikeReplyShare  \n---  \n  \nThe Case for Open Source AI\n\nArm the rebels\n\nFeb 8 \u2022\n\nAir Street Capital\n\n,\n\nNathan Benaich\n\n, and\n\nAlex Chalmers\n\n15\n\nShare this post\n\n#### The Case for Open Source AI\n\npress.airstreet.com\n\nThe State of State of AI Report\n\nIntroduction The State of AI Report is our comprehensive round-up of the most\nimportant developments of the year in AI research, industry, safety, and...\n\nFeb 1 \u2022\n\nAir Street Capital\n\nand\n\nNathan Benaich\n\n10\n\nShare this post\n\n#### The State of State of AI Report\n\npress.airstreet.com\n\n\ud83c\udf38 Your guide to AI: March 2024\n\nHi all! Welcome to the latest issue of your guide to AI, an editorialized\nnewsletter covering key developments in AI policy, research, industry, and...\n\nMar 10 \u2022\n\nAir Street Capital\n\n,\n\nNathan Benaich\n\n, and\n\nAlex Chalmers\n\n5\n\nShare this post\n\n#### \ud83c\udf38 Your guide to AI: March 2024\n\npress.airstreet.com\n\nReady for more?\n\n\u00a9 2024 Air Street Capital Management Ltd.\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}

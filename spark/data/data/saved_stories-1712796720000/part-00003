{"aid": "39994361", "title": "Hallucinations of AI Science Models", "url": "https://www.johndcook.com/blog/2024/03/26/hallucinations-of-ai-science-models/", "domain": "johndcook.com", "votes": 2, "user": "Bostonian", "posted_at": "2024-04-10 18:51:18", "comments": 0, "source_title": "Hallucinations of AI Science Models", "source_text": "Hallucinations of AI Science Models\n\n(832) 422-8646\n\nContact\n\n# Hallucinations of AI Science Models\n\nPosted on 26 March 2024 by Wayne Joubert\n\nAlphaFold 2, FourCastNet and CorrDiff are exciting. AI-driven autonomous labs\nare going to be a big deal [1]. Science codes now use AI and machine learning\nto make scientific discoveries on the world\u2019s most powerful computers [2].\n\nIt\u2019s common practice for scientists to ask questions about the validity,\nreliability and accuracy of the mathematical and computational methods they\nuse. And many have voiced concerns about the lack of explainability and\npotential pitfalls of AI models, in particular deep neural networks (DNNs)\n[3].\n\nThe impact of this uncertainty varies highly according to project. Science\nprojects that are able to easily check AI-generated results against ground\ntruth may not be that concerned. High-stakes projects like design of a\nmultimillion dollar spacecraft with high project risks may ask about AI model\naccuracy with more urgency.\n\n## Neural network accuracy\n\nUnderstanding of the properties of DNNs is still in its infancy, with many as-\nyet unanswered questions. However, in the last few years some significant\nresults have started to come forth.\n\nA fruitful approach to analyzing DNNs is to see them as function approximators\n(which, of course, they are). One can study how accurately DNNs approximate a\nfunction representing some physical phenomenon in a domain (for example, fluid\ndensity or temperature).\n\nThe approximation error can be measured in various ways. A particularly strong\nmeasure is \u201csup-norm\u201d or \u201cmax-norm\u201d error, which requires that the DNN\napproximation be accurate at every point of the target function\u2019s domain\n(\u201cuniform approximation\u201d). Some science problems may have a weaker requirement\nthan this, such as low RMS or 2-norm error. However, it\u2019s not unreasonable to\nask about max-norm approximation behaviors of numerical methods [4,5].\n\nAn illuminating paper by Ben Adcock and Nick Dexter looks at this problem [6].\nThey show that standard DNN methods applied even to a simple 1-dimensional\nproblem can result in \u201cglitches\u201d: the DNN as a whole matches the function well\nbut at some points totally misapproximates the target function. For a picture\nthat shows this, see [7].\n\nOther mathematical papers have subsequently shed light on these behaviors.\nI\u2019ll try to summarize the findings below, though the actual findings are very\nnuanced, and many details are left out here. The reader is advised to refer to\nthe respective papers for exact details.\n\nThe findings address three questions: 1) how many DNN parameters are required\nto approximate a function well? 2) how much data is required to train to a\ndesired accuracy? and 3) what algorithms are capable of training to the\ndesired accuracy?\n\n## How many neural network weights are needed?\n\nHow large does the neural network need to be for accurate uniform\napproximation of functions? If tight max-norm approximation requires an\nexcessively large number of weights, then use of DNNs is not computationally\npractical.\n\nSome answers to this question have been found\u2014in particular, a result ^1 is\ngiven in [8, Theorem 4.3; cf. 9, 10]. This result shows that the number of\nneural network weights required to approximate an arbitrary function to high\nmax-norm accuracy grows exponentially in the dimension of the input to the\nfunction.\n\nThis dependency on dimension is no small limitation, insofar as this is not\nthe dimension of physical space (e.g., 3-D) but the dimension of the input\nvector (such as the number of gridcells), which for practical problems can be\nin the tens [11] or even millions or more.\n\nSadly, this rules out the practical use of DNN for some purposes. Nonetheless,\nfor many practical applications of deep learning, the approximation behaviors\nare not nearly so pessimistic as this would indicate (cp. [12]). For example,\nresults are more optimistic:\n\n  * if the target function has a strong smoothness property;\n  * if the function is not arbitrary but is a composition of simpler functions;\n  * if the training and test data are restricted to a (possibly unknown) lower dimensional manifold in the high dimensional space (this is certainly the case for common image and language modeling tasks);\n  * if the average case behavior for the desired problem domain is much better than the worst case behavior addressed in the theorem;\n  * The theorem assumes multilayer perceptron and ReLU activation; other DNN architectures may perform better (though the analysis is based on multidimensional Taylor\u2019s theorem, which one might conjecture applies also to other architectures).\n  * For many practical applications, very high accuracy is not a requirement.\n  * For some applications, only low 2-norm error is sufficient, (not low max-norm).\n  * For the special case of physics informed neural networks (PINNs), stronger results hold.\n\nThus, not all hope is lost from the standpoint of theory. However, certain\nproblems for which high accuracy is required may not be suitable for DNN\napproximation.\n\n## How much training data is needed?\n\nAssuming your space of neural network candidates is expressive enough to\nclosely represent the target function\u2014how much training data is required to\nactually find a good approximation?\n\nA result ^2 is given in [13, Theorem 2.2] showing that the number of training\nsamples required to train to high max-norm accuracy grows, again,\nexponentially in the dimension of the input to the function.\n\nThe authors concede however that \u201cif additional problem information about [the\ntarget functions] can be incorporated into the learning problem it may be\npossible to overcome the barriers shown in this work.\u201d One suspects that some\nof the caveats given above might also be relevant here. Additionally, if one\nconsiders 2-norm error instead of max-norm error, the data requirement grows\npolynomially rather than exponentially, making the training data requirement\nmuch more tractable. Nonetheless, for some problems the amount of data\nrequired is so large that attempts to \u201cpin down\u201d the DNN to sufficient\naccuracy become intractable.\n\n## What methods can train to high accuracy?\n\nThe amount of training data may be sufficient to specify a suitable neural\nnetwork. But, will standard methods for finding the weights of such a DNN be\neffective for solving this difficult nonconvex optimization problem?\n\nA recent paper [14] from Max Tegmark\u2019s group empirically studies DNN training\nto high accuracy. They find that as the input dimension grows, training to\nvery high accuracy with standard stochastic gradient descent methods becomes\ndifficult or impossible.\n\nThey also find second order methods perform much better, though these are more\ncomputationally expensive and have some difficulty also when the dimension is\nhigher. Notably, second order methods have been used effectively for DNN\ntraining for some science applications [15]. Also, various alternative\ntraining approaches have been tried to attempt to stabilize training; see,\ne.g., [16].\n\n## Prospects and conclusions\n\nApplication of AI methods to scientific discovery continues to deliver amazing\nresults, in spite of lagging theory. Ilya Sutskever has commented, \u201cProgress\nin AI is a game of faith. The more faith you have, the more progress you can\nmake\u201d [17].\n\nTheory of deep learning methods is in its infancy. The current findings show\nsome cases for which use of DNN methods may not be fruitful, Continued\ndiscoveries in deep learning theory can help better guide how to use the\nmethods effectively and inform where new algorithmic advances are needed.\n\n## Footnotes\n\n^1 Suppose the function to be approximated takes d inputs and has the\nsmoothness property that all n^th partial derivatives are continuous (i.e., is\nin C^n(\u03a9) for compact \u03a9). Also suppose a multilayer perceptron with ReLU\nactivation functions must be able to approximate any such function to max-norm\nno worse than \u03b5. Then the number of weights required is at least a fixed\nconstant times (1/\u03b5)^d/(2n).\n\n^2 Let F be the space of all functions that can be approximated exactly by a\nbroad class of ReLU neural networks. Suppose there is a training method that\ncan recover all these functions up to max-norm accuracy bounded by \u03b5. Then the\nnumber of training samples required is at least a fixed constant times\n(1/\u03b5)^d.\n\n## References\n\n[1] \u201cIntegrated Research Infrastructure Architecture Blueprint Activity (Final\nReport 2023),\u201d https://www.osti.gov/biblio/1984466.\n\n[2] Joubert, Wayne, Bronson Messer, Philip C. Roth, Antigoni Georgiadou,\nJustin Lietz, Markus Eisenbach, and Junqi Yin. \u201cLearning to Scale the Summit:\nAI for Science on a Leadership Supercomputer.\u201d In 2022 IEEE International\nParallel and Distributed Processing Symposium Workshops (IPDPSW), pp.\n1246-1255. IEEE, 2022, https://www.osti.gov/biblio/2076211.\n\n[3] \u201cReproducibility Workshop: The Reproducibility Crisis in ML\u2010based\nScience,\u201d Princeton University, July 28, 2022,\nhttps://sites.google.com/princeton.edu/rep-workshop.\n\n[4] Wahlbin, L. B. (1978). Maximum norm error estimates in the finite element\nmethod with isoparametric quadratic elements and numerical integration. RAIRO.\nAnalyse num\u00e9rique, 12(2), 173-202,\nhttps://www.esaim-m2an.org/articles/m2an/pdf/1978/02/m2an1978120201731.pdf\n\n[5] Kashiwabara, T., & Kemmochi, T. (2018). Maximum norm error estimates for\nthe finite element approximation of parabolic problems on smooth domains.\nhttps://arxiv.org/abs/1805.01336.\n\n[6] Adcock, Ben, and Nick Dexter. \u201cThe gap between theory and practice in\nfunction approximation with deep neural networks.\u201d SIAM Journal on Mathematics\nof Data Science 3, no. 2 (2021): 624-655,\nhttps://epubs.siam.org/doi/10.1137/20M131309X.\n\n[7] \u201cFigure 5 from The gap between theory and practice in function approximation with deep neural networks | Semantic Scholar,\u201d https://www.semanticscholar.org/paper/The-gap-between-theory-and-practice-in-function-Adcock-Dexter/156bbfc996985f6c65a51bc2f9522da2a1de1f5f/figure/4\n\n[8] G\u00fchring, I., Raslan, M., & Kutyniok, G. (2022). Expressivity of Deep\nNeural Networks. In P. Grohs & G. Kutyniok (Eds.), Mathematical Aspects of\nDeep Learning (pp. 149-199). Cambridge: Cambridge University Press.\ndoi:10.1017/9781009025096.004, https://arxiv.org/abs/2007.04759.\n\n[9] D. Yarotsky. Error bounds for approximations with deep ReLU networks.\nNeural Netw., 94:103\u2013114, 2017, https://arxiv.org/abs/1610.01145\n\n[10] I. G\u00fchring, G. Kutyniok, and P. Petersen. Error bounds for approximations\nwith deep relu neural networks in W^s,p norms. Anal. Appl. (Singap.), pages\n1\u201357, 2019, https://arxiv.org/abs/1902.07896\n\n[11] Matt R. Norman, \u201cThe MiniWeather Mini App,\u201d\nhttps://github.com/mrnorman/miniWeather\n\n[12] Lin, H.W., Tegmark, M. & Rolnick, D. Why Does Deep and Cheap Learning\nWork So Well?. J Stat Phys 168, 1223\u20131247 (2017).\nhttps://doi.org/10.1007/s10955-017-1836-5\n\n[13] Berner, J., Grohs, P., & Voigtlaender, F. (2022). Training ReLU networks\nto high uniform accuracy is intractable. ICLR 2023,\nhttps://openreview.net/forum?id=nchvKfvNeX0.\n\n[14] Michaud, E. J., Liu, Z., & Tegmark, M. (2023). Precision machine\nlearning. Entropy, 25(1), 175, https://www.mdpi.com/1099-4300/25/1/175.\n\n[15] Markidis, S. (2021). The old and the new: Can physics-informed deep-\nlearning replace traditional linear solvers?. Frontiers in big Data, 4,\n669097, https://www.frontiersin.org/articles/10.3389/fdata.2021.669097/full\n\n[16] Bengio, Y., Lamblin, P., Popovici, D., & Larochelle, H. (2006). Greedy\nlayer-wise training of deep networks. Advances in neural information\nprocessing systems, 19,\nhttps://papers.nips.cc/paper_files/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html\n\n[17] \u201cChat with OpenAI CEO and and Co-founder Sam Altman, and Chief Scientist\nIlya Sutskever,\u201d https://www.youtube.com/watch?v=mC-0XqTAeMQ&t=250s\n\nCategories : Algorithms Machine learning Math\n\nBookmark the permalink\n\n## One thought on \u201cHallucinations of AI Science Models\u201d\n\n  1. BobC\n\n27 March 2024 at 12:57\n\nThough I have not yet tried it myself, it seems LLM hallucinations may be\nreduced, and overall output quality improved, by using RAG (Retrieval-\nAugmented Generation), which seems to consist of stuffing the input with\nadditional context to better frame the prompt.\n\nThere are now several RAG tests being used to compare LLMs, which is discussed\nin the recent announcement by Databricks of their new open-source DBRX LLM.\n\n### Leave a Reply\n\nJohn D. Cook, PhD\n\nMy colleagues and I have decades of consulting experience helping companies\nsolve complex problems involving data privacy, applied math, and statistics.\n\nLet\u2019s talk. We look forward to exploring the opportunity to help your company\ntoo.\n\n### John D. Cook\n\n\u00a9 All rights reserved.\n\n(832) 422-8646\n\nEMAIL\n\n", "frontpage": false}

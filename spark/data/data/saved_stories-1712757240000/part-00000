{"aid": "39988100", "title": "A collection of English stop words for NLP tasks", "url": "https://github.com/vikasing/news-stopwords", "domain": "github.com/vikasing", "votes": 1, "user": "mutor", "posted_at": "2024-04-10 07:51:46", "comments": 0, "source_title": "GitHub - vikasing/news-stopwords: A huge list of stopwords collected from millions of news articles", "source_text": "GitHub - vikasing/news-stopwords: A huge list of stopwords collected from\nmillions of news articles\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nvikasing / news-stopwords Public\n\n  * Notifications\n  * Fork 5\n  * Star 13\n\nA huge list of stopwords collected from millions of news articles\n\n13 stars 5 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# vikasing/news-stopwords\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nvikasingminor changesf646e94 \u00b7\n\n## History\n\n7 Commits  \n  \n### README.md\n\n|\n\n### README.md\n\n| minor changes  \n  \n### sw100k.csv\n\n|\n\n### sw100k.csv\n\n| added 1k, 10k, 100k files  \n  \n### sw10k.csv\n\n|\n\n### sw10k.csv\n\n| added 1k, 10k, 100k files  \n  \n### sw1k.csv\n\n|\n\n### sw1k.csv\n\n| added 1k, 10k, 100k files  \n  \n## Repository files navigation\n\n## About\n\nThe file sw1k.csv contains most frequent 1,000 words and phrases occurred in\nmore than 1.53 million news articles from 200+ sources collected over the span\nof a 2.5 years.\n\nSimilarily sw10k.csv and sw100k.csv contain 10,000 and 100,000 terms\nrespectively.\n\n## Structure of the files\n\nEach CSV file contains 5 columns:\n\nterm: the actual word or phrase\n\nfrequency: how many times a term has occured in all the documents\n\npresence: in how many documents the term has occurred, note that frequence >=\npresence\n\ndoc_size_sum: sum of the size of the documents in which the term has occurred,\n\n> doc_size(d) = number of characters present in the doc d including whitespace\n\ntype: type of the term, N: Noun, NP: Noun Phrase, PN: Proper Noun, G: Other\n\ntypes PERSON, PLACE, ORGANIZATION are self explanatory\n\nLibs Sanford CoreNLP and OpenNLP were used to split the docs in sentences, NER\nand POS tagging\n\n## Notes\n\n  1. The dataset is not manually processed, so you might see some unusual terms such as some common emails, news site names, editor/author names etc. These can be easily filtered by keeping the words with higher frequency/presence ratio.\n\n  2. The dataset includes all type of frequent terms like proper nouns, places, orgs etc. One can filter these using the type column.\n\n## About\n\nA huge list of stopwords collected from millions of news articles\n\n### Topics\n\nnlp machine-learning natural-language-processing news stopwords\n\n### Resources\n\nReadme\n\nActivity\n\n### Stars\n\n13 stars\n\n### Watchers\n\n4 watching\n\n### Forks\n\n5 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

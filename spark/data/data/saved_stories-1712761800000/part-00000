{"aid": "39988570", "title": "Ella: Equip Diffusion Models with LLM for Enhanced Semantic Alignment", "url": "https://github.com/TencentQQGYLab/ELLA", "domain": "github.com/tencentqqgylab", "votes": 1, "user": "homarp", "posted_at": "2024-04-10 09:09:02", "comments": 0, "source_title": "GitHub - TencentQQGYLab/ELLA: ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment", "source_text": "GitHub - TencentQQGYLab/ELLA: ELLA: Equip Diffusion Models with LLM for\nEnhanced Semantic Alignment\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nTencentQQGYLab / ELLA Public\n\n  * Notifications\n  * Fork 29\n  * Star 603\n\nELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment\n\nella-diffusion.github.io/\n\n### License\n\nApache-2.0 license\n\n603 stars 29 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# TencentQQGYLab/ELLA\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nbuduiMerge pull request #21 from budui/add_more_info_for_ella_sd157403f1a \u00b7\n\n## History\n\n20 Commits  \n  \n### assets\n\n|\n\n### assets\n\n| add notes for using ella  \n  \n### dpg_bench\n\n|\n\n### dpg_bench\n\n| Release DPG-Bench (#5)  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial commit  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit  \n  \n### README.md\n\n|\n\n### README.md\n\n| add notes for using ella  \n  \n### inference.py\n\n|\n\n### inference.py\n\n| add simplest readme for ella-sd1.5  \n  \n### model.py\n\n|\n\n### model.py\n\n| add inference code for ella  \n  \n### requirements-for-dpg_bench.txt\n\n|\n\n### requirements-for-dpg_bench.txt\n\n| dpg_bench need too many requirements  \n  \n## Repository files navigation\n\n# ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment\n\nXiwei Hu*, Rui Wang*, Yixiao Fang*, Bin Fu*, Pei Cheng, Gang Yu\u2726\n\n* Equal contributions, \u2726 Corresponding Author\n\nOfficial code of \"ELLA: Equip Diffusion Models with LLM for Enhanced Semantic\nAlignment\".\n\n## \ud83c\udf1f Changelog\n\n  * [2024.4.9] \ud83d\udd25\ud83d\udd25\ud83d\udd25 Release ELLA-SD1.5 Checkpoint! Welcome to try!\n  * [2024.3.11] \ud83d\udd25 Release DPG-Bench! Welcome to try!\n  * [2024.3.7] Initial update\n\n## Download\n\nYou can download ELLA models from QQGYLab/ELLA.\n\n## Usage\n\n### Quick View\n\n    \n    \n    # get ELLA-SD1.5 at https://huggingface.co/QQGYLab/ELLA/blob/main/ella-sd1.5-tsc-t5xl.safetensors # comparing ella-sd1.5 and sd1.5 # will generate images at `./assets/ella-inference-examples` python3 inference.py test --save_folder ./assets/ella-inference-examples --ella_path /path/to/ella-sd1.5-tsc-t5xl.safetensors\n\n### Build a demo for comparing SD1.5 and ELLA-SD1.5\n\n    \n    \n    GRADIO_SERVER_NAME=0.0.0.0 GRADIO_SERVER_PORT=8082 python3 ./inference.py demo /path/to/ella-sd1.5-tsc-t5xl.safetensors\n\n### Using ELLA in ComfyUI\n\nThanks to @ExponentialML and @kijai, now we can using ELLA in ComfyUI:\n\n  1. ExponentialML/ComfyUI_ELLA\n  2. kijai/ComfyUI-ELLA-wrapper\n\n## Notes\n\nELLA is still in its early stages of research, and we have not yet conducted\ncomprehensive testing on all potential applications of ELLA. We welcome\nconstructive and friendly suggestions from the community.\n\nHere, we share some tips that we have discovered thus far on how to better\nutilize ELLA:\n\n### 1\\. Caption Upscale\n\nELLA was trained using MLLM-annotated synthetic captions. As mentioned in the\nImproving Image Generation with Better Captions, performing an \"upsampling\" on\nthe input caption before using ELLA can extract its maximum potential.\n\nWe have discovered that leveraging the In-Context Learning (ICL) capability of\nLLMs can facilitate a straightforward caption upsampler:\n\nexample instruction:\n\n    \n    \n    Please generate the long prompt version of the short one according to the given examples. Long prompt version should consist of 3 to 5 sentences. Long prompt version must sepcify the color, shape, texture or spatial relation of the included objects. DO NOT generate sentences that describe any atmosphere!!! Short: A calico cat with eyes closed is perched upon a Mercedes. Long: a multicolored cat perched atop a shiny black car. the car is parked in front of a building with wooden walls and a green fence. the reflection of the car and the surrounding environment can be seen on the car's glossy surface. Short: A boys sitting on a chair holding a video game remote. Long: a young boy sitting on a chair, wearing a blue shirt and a baseball cap with the letter 'm'. he has a red medal around his neck and is holding a white game controller. behind him, there are two other individuals, one of whom is wearing a backpack. to the right of the boy, there's a blue trash bin with a sign that reads 'automatic party'. Short: A man is on the bank of the water fishing. Long: a serene waterscape where a person, dressed in a blue jacket and a red beanie, stands in shallow waters, fishing with a long rod. the calm waters are dotted with several sailboats anchored at a distance, and a mountain range can be seen in the background under a cloudy sky. Short: A kitchen with a cluttered counter and wooden cabinets. Long: a well-lit kitchen with wooden cabinets, a black and white checkered floor, and a refrigerator adorned with a floral decal on its side. the kitchen countertop holds various items, including a coffee maker, jars, and fruits. Short: a racoon holding a shiny red apple over its head\n\nusing: https://huggingface.co/spaces/Qwen/Qwen-72B-Chat-Demo\n\nwe got:\n\na mischievous raccoon standing on its hind legs, holding a bright red apple\naloft in its furry paws. the apple shines brightly against the backdrop of a\ndense forest, with leaves rustling in the gentle breeze. a few scattered rocks\ncan be seen on the ground beneath the raccoon's feet, while a gnarled tree\ntrunk stands nearby.\n\n#### Before and After caption upsampling\n\noriginal prompt: a racoon holding a shiny red apple over its head\n\nSD1.5| ELLA-SD1.5_fixed_token_length| ELLA-SD1.5_flexible_token_length  \n---|---|---  \n  \nQwen-72B refined caption: a mischievous raccoon standing on its hind legs,\nholding a bright red apple aloft in its furry paws. the apple shines brightly\nagainst the backdrop of a dense forest, with leaves rustling in the gentle\nbreeze. a few scattered rocks can be seen on the ground beneath the raccoon's\nfeet, while a gnarled tree trunk stands nearby.\n\nSD1.5| ELLA-SD1.5_fixed_token_length| ELLA-SD1.5_flexible_token_length  \n---|---|---  \n  \noriginal prompt: Crocodile in a sweater\n\nSD1.5| ELLA-SD1.5_fixed_token_length| ELLA-SD1.5_flexible_token_length  \n---|---|---  \n  \nGPT4 refined caption: a large, textured green crocodile lying comfortably on a\npatch of grass with a cute, knitted orange sweater enveloping its scaly body.\nAround its neck, the sweater features a whimsical pattern of blue and yellow\nstripes. In the background, a smooth, grey rock partially obscures the view of\na small pond with lily pads floating on the surface.\n\nSD1.5| ELLA-SD1.5_fixed_token_length| ELLA-SD1.5_flexible_token_length  \n---|---|---  \n  \n### 2\\. flexible token length\n\nDuring the training of ELLA, long synthetic captions were utilized, with the\nmaximum number of tokens set to 128. When testing ELLA with short captions, in\naddition to the previously mentioned caption upsampling technique, the\n\"flexible_token_length\" trick can also be employed. This involves setting the\ntokenizer's max_length as None, thereby eliminating any text token padding or\ntruncation. We have observed that this trick can help improve the quality of\ngenerated images corresponding to short captions.\n\n### 3\\. ELLA+CLIP for community models\n\nOur testing has revealed that some community models heavily reliant on trigger\nwords may experience significant style loss when utilizing ELLA, primarily\nbecause CLIP is not used at all during ELLA inference.\n\nAlthough CLIP was not used during training, we have discovered that it is\nstill possible to concatenate ELLA's input with CLIP's output during inference\n(Bx77x768 + Bx64x768 -> Bx141x768) as a condition for the UNet. We anticipate\nthat using ELLA in conjunction with CLIP will better integrate with the\nexisting community ecosystem, particularly with CLIP-specific techniques such\nas Textual Inversion and Trigger Word.\n\nOur goal is to ensure better compatibility with a wider range of community\nmodels; however, we currently do not have a comprehensive set of experiences\nto share. If you have any suggestions, we would be grateful if you could share\nthem in issue.\n\n## \ud83d\udcca DPG-Bench\n\nThe guideline of DPG-Bench:\n\n  1. Generate your images according to our prompts.\n\nIt is recommended to generate 4 images per prompt and grid them to 2x2 format.\nPlease Make sure your generated image's filename is the same with the prompt's\nfilename.\n\n  2. Run the following command to conduct evaluation.\n    \n        bash dpg_bench/dist_eval.sh $YOUR_IMAGE_PATH $RESOLUTION\n\nThanks to the excellent work of DSG sincerely, we follow their instructions to\ngenerate questions and answers of DPG-Bench.\n\n## \ud83d\udcdd TODO\n\n  * add huggingface demo link\n  * release checkpoint\n  * release inference code\n  * release DPG-Bench\n\n## \ud83d\udca1 Others\n\nWe have also found LaVi-Bridge, another independent but similar work completed\nalmost concurrently, which offers additional insights not covered by ELLA. The\ndifference between ELLA and LaVi-Bridge can be found in issue 13. We are\ndelighted to welcome other researchers and community users to promote the\ndevelopment of this field.\n\n## \ud83d\ude09 Citation\n\nIf you find ELLA useful for your research and applications, please cite us\nusing this BibTeX:\n\n    \n    \n    @misc{hu2024ella, title={ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment}, author={Xiwei Hu and Rui Wang and Yixiao Fang and Bin Fu and Pei Cheng and Gang Yu}, year={2024}, eprint={2403.05135}, archivePrefix={arXiv}, primaryClass={cs.CV} }\n\n## About\n\nELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment\n\nella-diffusion.github.io/\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n603 stars\n\n### Watchers\n\n43 watching\n\n### Forks\n\n29 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 3\n\n  * budui Ray Wang\n  * fangyixiao18 Yixiao Fang\n  * melohux hux\n\n## Languages\n\n  * Python 98.9%\n  * Shell 1.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

{"aid": "40006467", "title": "LLMs fought 314 Street Fighter matches. Here's who won", "url": "https://community.aws/content/2dbNlQiqKvUtTBV15mHBqivckmo/14-llms-fought-314-street-fighter-matches-here-s-who-won", "domain": "community.aws", "votes": 1, "user": "rbanffy", "posted_at": "2024-04-11 20:26:21", "comments": 0, "source_title": "14 LLMs fought 314 Street Fighter matches. Here's who won", "source_text": "Community | 14 LLMs fought 314 Street Fighter matches. Here's who won\n\n## Select your cookie preferences\n\nWe use essential cookies and similar tools that are necessary to provide our\nsite and services. We use performance cookies to collect anonymous statistics\nso we can understand how customers use our site and make improvements.\nEssential cookies cannot be deactivated, but you can click \u201cCustomize cookies\u201d\nto decline performance cookies.\n\nIf you agree, AWS and approved third parties will also use cookies to provide\nuseful site features, remember your preferences, and display relevant content,\nincluding relevant advertising. To continue without accepting these cookies,\nclick \u201cContinue without accepting.\u201d To make more detailed choices or learn\nmore, click \u201cCustomize cookies.\u201d\n\n## Customize cookie preferences\n\nWe use cookies and similar tools (collectively, \"cookies\") for the following\npurposes.\n\n### Essential\n\nEssential cookies are necessary to provide our site and services and cannot be\ndeactivated. They are usually set in response to your actions on the site,\nsuch as setting your privacy preferences, signing in, or filling in forms.\n\n### Performance\n\nPerformance cookies provide anonymous statistics about how customers navigate\nour site so we can improve site experience and performance. Approved third\nparties may perform analytics on our behalf, but they cannot use the data for\ntheir own purposes.\n\nAllowed\n\n### Functional\n\nFunctional cookies help us provide useful site features, remember your\npreferences, and display relevant content. Approved third parties may set\nthese cookies to provide certain site features. If you do not allow these\ncookies, then some or all of these services may not function properly.\n\nAllowed\n\n### Advertising\n\nAdvertising cookies may be set through our site by us or our advertising\npartners and help us deliver relevant marketing content. If you do not allow\nthese cookies, you will experience less relevant advertising.\n\nAllowed\n\nBlocking some types of cookies may impact your experience of our sites. You\nmay review and change your choices at any time by clicking Cookie preferences\nin the footer of this site. We and selected third-parties use cookies or\nsimilar technologies as specified in the AWS Cookie Notice.\n\n## Unable to save cookie preferences\n\nWe will only store essential cookies at this time, because we were unable to\nsave your cookie preferences.\n\nIf you want to change your cookie preferences, try again later using the link\nin the AWS console footer, or contact support if the problem persists.\n\nHomeTags\n\nFeatured Spaces\n\nCost Optimization\n\nDevOps\n\nGenerative AI\n\nKubernetes\n\nLivestreams\n\nResilience\n\nTraining and Certification\n\nCommunity Programs\n\nAWS Heroes\n\nAWS Community Builders\n\nAWS User Groups\n\nStudent Communities\n\n# 14 LLMs fought 314 Street Fighter matches. Here's who won\n\n## I benchmarked models in an actual chatbot arena\n\ngenerative-aiamazon-berock\n\nBanjo Obayomi\n\nAmazon Employee\n\nPublished Apr 1, 2024\n\n|\n\nLast Modified Apr 3, 2024\n\nComments (12)12\n\nHow It Works\n\nGather Game State Data\n\nGet Player Moves\n\nMove Execution\n\nThe LLM Leaderboard\n\nInteresting Findings\n\nGetting Started\n\nHave you ever wondered what would happen if we created a new type of benchmark\nfor large language models (LLMs) that goes beyond the typical question-\nanswering and text generation tasks? What if we had an arena where the models\ncould compete against each other in challenges entirely outside their designed\npurpose?\n\nThat's precisely what I explored by pitting LLMs against one another in the\nclassic arcade game, Street Fighter III. In this post I'll go into the details\nof how I built this unique arena and the fascinating insights learned from\nwatching LLMs battle it out on the virtual streets of Metro City.\n\nSuper Attack 2 in Action\n\n##\n\nHow It Works\n\nThe arena was set up using an emulator running Street Fighter III powered by\nDiambra and from the work of Stan Girard who open sourced his test bed for\nthis benchmark.\n\nTo begin, two random LLMs on Amazon Bedrock are selected to control Ken, and\nthen the test bed executes the following steps:\n\n###\n\nGather Game State Data\n\nThe current state of the game was continuously read such as the character\nlocation, health, and score. This information was then translated into a\nprompt with all the relevant context for the LLM such as available moves and\nrecommended strategies.\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14\n\nYou are very far from the opponent. Move closer to the opponent.Your opponent\nis on the left. You can now use a powerfull move. The names of the powerful\nmoves are: Megafireball, Super attack 2. Your last action was Low. The\nopponent's last action was Left. Your current score is 17.0. You are winning.\nKeep attacking the opponent. To increase your score, move toward the opponent\nand attack the opponent. To prevent your score from decreasing, don't get hit\nby the opponent.\n\nThe moves you can use are: - Move Closer - Move Away - Fireball - Megapunch -\nHurricane - Megafireball\n\n###\n\nGet Player Moves\n\nWith the relevant context, a system prompt can be crafted and be sent to the\ncorresponding LLM via Bedrock serverless API. Upon receiving the prompt, each\nLLM analyzes the game state and picks moves.\n\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n\ndef call_llm() -> str:\n\nmove_list = \"- \" + \"\\n - \".join([move for move in META_INSTRUCTIONS])\nsystem_prompt = f\"\"\"You are the best and most aggressive Street Fighter III\n3rd strike player in the world. Your character is {self.character}. Your goal\nis to beat the other opponent. You respond with a bullet point list of moves.\n{self.context_prompt()} The moves you can use are: {move_list} ---- Reply with\na bullet point list of moves. The format should be: `- <name of the move>`\nseparated by a new line. Example if the opponent is close: - Move closer -\nMedium Punch\n\nExample if the opponent is far: - Fireball - Move closer \"\"\"\n\nprompt = \"Your next moves are:\"\n\nllm_response = call_bedrock_model(self.model, system_prompt, prompt,\nbedrock_runtime) print(f\"{self.model} making move {llm_response}\")\n\n###\n\nMove Execution\n\nFinally, the chosen moves were translated back into game commands and executed\nwithin the emulator. This closed loop allowed the LLMs to actively participate\nin the game, effectively \"playing\" against each other. Now, lets see how the\nmodels stacked up against each other.\n\n###\n\nThe LLM Leaderboard\n\nI tracked each LLM's performance using an Elo rating system, similar to those\nused in chess rankings. This system provided a dynamic leaderboard, showcasing\nwhich models adapted best to the fast-paced environment of Street Fighter III.\nI ran 314 matches with 14 different models\n\nModel| Elo  \n---|---  \n\ud83e\udd47 claude_3_haiku| 1613.45  \n\ud83e\udd48 claude_3_sonnet| 1557.25  \n\ud83e\udd49 claude_2| 1554.98  \nclaude_instant| 1548.16  \ncohere_light| 1527.07  \ncohere_command| 1511.45  \ntitan_express| 1502.56  \nmistral_7b| 1490.06  \nai21_ultra| 1477.17  \nmistral_8x7b| 1450.07  \n  \nThe smaller models outperformed larger models in the arena likely due to their\nlower latency which allowed for quicker reaction times and more moves per\nmatch. This highlights an interesting trade-off between size and speed when it\ncomes to playing real time games. Also, no surprise that Anthropic's Claude\nmodels top the list, they are currently the best ranked models on several\nbenchmarks.\n\nModel Matchups\n\nWhile the leaderboard show which model is on top diving deeper into the\nmatches themselves revealed several insights about how LLMs approached the\ngame.\n\n###\n\nInteresting Findings\n\nThe experiment was not without its quirks. LLMs, while highly intelligent, are\nnot infallible and sometimes displayed behaviors that were both fascinating\nand humorous:\n\nHallucinations: Instances of \"invalid moves\" were recorded, where models would\ngenerate actions not applicable or possible within the game. This included\nmoves like \"Special Move,\" \"Jump Cancel,\" and even \"Hardest hitting combo of\nall,\" showcasing the models' attempts to apply their knowledge creatively.\n\nRefusal to play: Claude 2.1 refused to play and would say\" I apologize, upon\nreflection I do not feel comfortable recommending violent actions or\nstrategies, even in a fictional context.\" Thankfully the Claude 3 models show\na more nuanced understanding of requests, recognize real harm, and refuse to\nanswer harmless prompts much less often.\n\nPersonalized Playstyles: Each LLM seemed to develop its own distinct\nplaystyle. Some favored aggressive tactics, while others took a more\ndefensive, counter-attacking approach. While other just spammed the same move\nover and over.\n\nSpamming attacks is a valid strategy\n\n###\n\nGetting Started\n\nReady to run the benchmark on your own? All code and documentation are on\nGitHub. I'm curious how folks can tweak the prompts, add new LLM contenders,\nor explore model behaviors further. If you're interested in playing with the\nwinning Claude 3 models check out my getting started guide.\n\nHave an idea or question about the arena? Leave a comment below, and lets\nbuild!\n\nAny opinions in this post are those of the individual author and may not\nreflect the opinions of AWS.\n\nComments (12)12\n\n## 12 Comments\n\nLog in to comment\n\nHow It Works\n\nGather Game State Data\n\nGet Player Moves\n\nMove Execution\n\nThe LLM Leaderboard\n\nInteresting Findings\n\nGetting Started\n\n", "frontpage": false}

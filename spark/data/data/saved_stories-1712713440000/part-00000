{"aid": "39983372", "title": "Exploring Clang/LLVM optimization on a programming horror. (2021)", "url": "https://blog.matthieud.me/2020/exploring-clang-llvm-optimization-on-programming-horror/", "domain": "matthieud.me", "votes": 1, "user": "fanf2", "posted_at": "2024-04-09 19:42:04", "comments": 0, "source_title": "Exploring Clang/LLVM optimization on programming horror", "source_text": "Exploring Clang/LLVM optimization on programming horror\n\nBlog About\n\n# Exploring Clang/LLVM optimization on programming horror\n\nThis article has been featured on the frontpage of Hacker News, the follow-up\ndiscussion is interesting to read.\n\nRecently, I've come across a not so efficient implementation of a isEven\nfunction (from r/programminghorror).\n\n    \n    \n    bool isEven(int number) { int numberCompare = 0; bool even = true; while (number != numberCompare) { even = !even; numberCompare++; } return even; }\n\nThe code is in C++, but the essence of the algorithm is an iterative ascent to\nthe input number from base case 0 (which is even), switching the boolean\nresult at each iteration. It works, but you get a linear time O(n) isEven\nfunction compared to the obvious constant time O(1) modulo algorithm.\n\nSurprisingly, Clang/LLVM is able to optimize the iterative algorithm down to\nthe constant time algorithm (GCC fails on this one). In Clang 10 with full\noptimizations, this code compiles down to:\n\n    \n    \n    ; Function Attrs: norecurse nounwind readnone ssp uwtable define zeroext i1 @_Z6isEveni(i32 %0) local_unnamed_addr #0 { %2 = and i32 %0, 1 %3 = icmp eq i32 %2, 0 ret i1 %3 }\n\nThe first instruction is a boolean AND with 1 to keep only the least\nsignificant bit (a very fast way to compute a modulo %2), and the second\ninstruction compares the result with 0.\n\nI've decided to explore how Clang was able to do this. As you may know, an\noptimizer like LLVM (Clang backend) is designed with a bunch of specific\npasses which transform the code (in the form of LLVM IR) into another\n(preferably more optimized) code, keeping the same semantic. LLVM has a around\n50 different optimization passes, each one targets a specific code pattern.\nWhen you give a specific optimization level to your compiler (such as -O2),\nthere is a fixed list of optimization passes which will be executed on your\ncode to optimize it (the list has already been defined for you by the compiler\nwriters)^1.\n\n## Original code\n\nClang compiles the C++ isEven function to straightforward assembly (in the\nform of LLVM IR) if you don't apply any optimization passes (-O0).\n\n    \n    \n    ; Function Attrs: noinline nounwind ssp uwtable define zeroext i1 @_Z6isEveni(i32 %0) #0 { %2 = alloca i32, align 4 ; number %3 = alloca i32, align 4 ; numberCompare %4 = alloca i8, align 1 ; even store i32 %0, i32* %2, align 4 ; store function argument in number store i32 0, i32* %3, align 4 ; store 0 in numberCompare store i8 1, i8* %4, align 1 ; store 1 (true) in even br label %5 5: ; preds = %9, %1 %6 = load i32, i32* %2, align 4 %7 = load i32, i32* %3, align 4 %8 = icmp ne i32 %6, %7 br i1 %8, label %9, label %16 9: ; preds = %5 %10 = load i8, i8* %4, align 1 %11 = trunc i8 %10 to i1 %12 = xor i1 %11, true %13 = zext i1 %12 to i8 store i8 %13, i8* %4, align 1 %14 = load i32, i32* %3, align 4 %15 = add nsw i32 %14, 1 store i32 %15, i32* %3, align 4 br label %5 16: ; preds = %5 %17 = load i8, i8* %4, align 1 %18 = trunc i8 %17 to i1 ret i1 %18 }\n\nLLVM IR is a form of low-level (close to the machine) intermediate\nrepresentation, with the particularity of being in Single Static Assignment\nform (SSA). Each instruction is always producing a new value (looking like\n%3), and not reassigning a previous one.\n\nA graphical version of the same IR is called a Control Flow Graph (CFG), it is\na graph between vertices called basic block (sequence of instructions which\nare always executed entirely from top to bottom) and edges which represent a\npossible flow for our program. For our code, the CFG looks like this:\n\n  * The first block (numeroted %1) initializes the memory for the various variables inside the function (two 4-bytes integers for number and numberCompare, one byte for even).\n  * The second block (numeroted %5) is the loop check to determine whether we should go inside the loop or exit it.\n  * The third block (numeroted %9) is the loop body, it increments numberCompare (%15) and toggles the boolean even (%12).\n  * The fourth block is the return of the function, it converts the result to a boolean value (%18) and returns it to the caller.\n\n## Optimizing the code\n\nAt this point, the code is simply an assembly SSA version of our original C++\ncode. Let's run some LLVM optimization passes on it to see how it evolves.\n\n### Memory to register\n\nThe first pass we run is called Memory to Register (mem2reg): its goal is to\nmove variables from memory (in RAM) to abstract registers^2 (directly inside\nthe CPU) to make it way faster (memory latency is ~100ns).\n\nWe see that all the instructions related to memory (alloca, load, store) have\nbeen removed by the optimizer and now all operations (add, xor) are done\ndirectly on CPU registers.\n\nThe 4 blocks are still there, but slightly different (they are looking way\ncloser to the original C++ code):\n\n  * the initialization block is now empty.\n  * the loop condition block has changed, it contains 2 instructions called phi nodes. Those are special nodes which take a value out of 2 depending on the previously executed block (called the predecessor block). For example, the line %.01 = phi i32 [ 0, %1 ], [ %8, %4 ] means that the variable %.01% (which represents numberCompare in our C++ code) should take either the value 0 if we come from the basic block %1 which is the beginning of the function, or the value of %8 if we come from the basic block %4 which is the body of the loop.\n\n### Instruction combine\n\nThis pass combines several instructions into a simpler/faster one, for\nexample, 2 consecutive additions on the same variable can be reduced to a\nsingle one ; or a multiply by 8 can be changed to a left shift by 3, etc...\n\nOn our code, several changes has been made by this pass:\n\n  * even is no longer a byte (i8) but stored directly as a single bit (i1), thus removing several conversion instructions.\n  * the loop condition has been switch from a not equal to an equal, and the 2 blocs adapted to keep the semantic intact.\n\n### Loop and Induction variables\n\nThe next pass we will apply is the Canonicalize Induction Variables pass. This\nis the \"magical\" pass which completely removes our loop and thus turns the\nalgorithm into constant time. The LLVM documentation explains:\n\n> Any use outside of the loop of an expression derived from the indvar is\n> changed to compute the derived value outside of the loop, eliminating the\n> dependence on the exit value of the induction variable. If the only purpose\n> of the loop is to compute the exit value of some derived expression, this\n> transformation will make the loop dead.\n\nAn induction variable (indvar) is the \"counter\" of a loop : sometimes the\ncount is trivial such as for (i=0; i < 100; i++), the induction variable is i\nand trip count is 100 ; but often it is harder for the pass to determine the\ninduction variable and loop trip count correctly. In our case, the induction\nvariable numberCompare is obvious and the loop count number also.\n\nBecause it now only operates on a single bit value (thus having a maximum of\n1), LLVM realizes here that our algorithm is a direct mathematical function of\nthe loop count number and of the initial value:\n\neven=((initialnumber\u2217\u22121)\u2217\u22121)\u2217....\u2217\u22121=initial\u2217(\u22121)number\n\nThe CFG is now :\n\nWe run the pass -simplifycfg on the previous code, to remove any useless\nbranching. After a final instruction combine pass, we obtain the fully\noptimized O(1) complexity code.\n\n    \n    \n    ; Function Attrs: noinline nounwind ssp uwtable define zeroext i1 @_Z6isEveni(i32 %0) #0 { %2 = trunc i32 %0 to i1 %3 = add i1 %2, true ret i1 %3 }\n\n## Recursive version\n\nClang is also able to constantize the recursive linear time version of this\nalgorithm! Finding the various optimization passes to produce the end result\nis left as an exercise to the reader \ud83d\udc68\ud83c\udfeb.\n\n    \n    \n    bool isEvenRec(int number) { if (number == 0) return true; return !isEvenRec(number-1); }\n\n## Notes\n\n  1. This is the list of optimization passes (the order matters) that LLVM applies with flag -O2. Note that some of them are run multiple times : -targetlibinfo -tti -targetpassconfig -tbaa -scoped-noalias -assumption-cache-tracker -profile-summary-info -forceattrs -inferattrs -ipsccp -called-value-propagation -attributor -globalopt -domtree -mem2reg -deadargelim -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -basiccg -globals-aa -prune-eh -inline -functionattrs -domtree -sroa -basicaa -aa -memoryssa -early-cse-memssa -speculative-execution -aa -lazy-value-info -jump-threading -correlated-propagation -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -libcalls-shrinkwrap -loops -branch-prob -block-freq -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -pgo-memop-opt -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -tailcallelim -simplifycfg -reassociate -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -memoryssa -licm -loop-unswitch -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -indvars -loop-idiom -loop-deletion -loop-unroll -mldst-motion -phi-values -aa -memdep -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -gvn -phi-values -basicaa -aa -memdep -memcpyopt -sccp -demanded-bits -bdce -aa -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -lazy-value-info -jump-threading -correlated-propagation -basicaa -aa -phi-values -memdep -dse -aa -memoryssa -loops -loop-simplify -lcssa-verification -lcssa -scalar-evolution -licm -postdomtree -adce -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -barrier -elim-avail-extern -basiccg -rpo-functionattrs -globalopt -globaldce -basiccg -globals-aa -domtree -float2int -lower-constant-intrinsics -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -loop-accesses -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-distribute -branch-prob -block-freq -scalar-evolution -basicaa -aa -loop-accesses -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-vectorize -loop-simplify -scalar-evolution -aa -loop-accesses -lazy-branch-prob -lazy-block-freq -loop-load-elim -basicaa -aa -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -domtree -loops -scalar-evolution -basicaa -aa -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -slp-vectorizer -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -loop-unroll -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -memoryssa -loop-simplify -lcssa-verification -lcssa -scalar-evolution -licm -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -transform-warning -alignment-from-assumptions -strip-dead-prototypes -globaldce -constmerge -domtree -loops -branch-prob -block-freq -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -block-freq -loop-sink -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instsimplify -div-rem-pairs -simplifycfg -domtree -basicaa -aa -memoryssa -loops -loop-simplify -lcssa-verification -lcssa -scalar-evolution -licm -verify -print-module \u21a9\n\n  2. As woodruffw commented on Hacker News, those LLVM registers are abstract and infinite. The real register allocation happens way later in the compilation pipeline. \u21a9\n\nMade with \ud83d\udda5\ufe0f by Matthieu \u00a92024\n\n", "frontpage": false}

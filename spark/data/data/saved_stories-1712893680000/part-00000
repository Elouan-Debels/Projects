{"aid": "40007149", "title": "Bit permutations C++ standard proposal", "url": "https://eisenwave.github.io/cpp-proposals/bit-permutations.html", "domain": "eisenwave.github.io", "votes": 1, "user": "ibobev", "posted_at": "2024-04-11 21:45:32", "comments": 0, "source_title": "P3104R2: Bit permutations", "source_text": "P3104R2: Bit permutations\n\n\u2191 Jump to Table of Contents\u2192 Pop Out Sidebar\n\n# P3104R2 Bit permutations\n\n## Published Proposal, 2024-04-04\n\nThis version:\n\n    https://eisenwave.github.io/cpp-proposals/bit-permutations.html\nAuthor:\n\n    Jan Schultke\nAudience:\n\n    SG18, LEWG\nProject:\n\n    ISO/IEC 14882 Programming Languages \u2014 C++, ISO/IEC JTC1/SC22/WG21\nSource:\n\n    eisenwave/cpp-proposals\n\n## Abstract\n\nAdd bit permutation functions to the bit manipulation library.\n\n## 1\\. Revision history\n\n### 1.1. Changes since R1\n\nThe paper has been seen in Tokyo by SG18 with positive reception, except for\nthe *_bit_permutation functions. These have been removed to strengthen\nconsensus.\n\n### 1.2. Changes since R0\n\n  * Expand \u00a7 4.3 Hardware support, taking more instructions into account, including AVX-512.\n\n  * Minor editorial fixes.\n\n## 2\\. Introduction\n\nThe C++ bit manipulation library in <bit> is an invaluable abstraction from\nhardware operations. Functions like countl_zero help the programmer avoid use\nof intrinsic functions or inline assembly.\n\nHowever, there are still a few operations which are non-trivial to implement\nin software and have widely available hardware support. Therefore, I propose\nto expand the bit manipulation library with multiple bit permutation functions\ndescribed below. Even without hardware support, these functions provide great\nutility and/or help the developer write more expressive code.\n\n## 3\\. Proposed features\n\nI propose to add the following functions to the bit manipulation library\n(<bit>).\n\nNote: All constraints are exposition-only. The function bodies contain a naive\nimplementation that merely illustrates the behavior.\n\nNote: See \u00a7 4.3 Hardware support for the corresponding hardware instructions.\n\n### 3.1. bit_reverse\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_reverse(T x) noexcept { T result = 0; for (int i = 0; i < numeric_limits<T>::digits; ++i) { result <<= 1; result |= x & 1; x >>= 1; } return result; }\n\nReverses the bits of x so that the least significant bit becomes the most\nsignificant.\n\nbit_reverse(uint32_t{0x00001234}) equals 0x24c80000.\n\n### 3.2. bit_repeat\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_repeat(T x, int length) noexcept(false) { T result = 0; for (int i = 0; i < numeric_limits<T>::digits; ++i) { result |= ((x >> (i % length)) & 1) << i; } return result; }\n\nRepeats a pattern stored in the least significant length bits of x, as many\ntimes as fits into x.\n\nbit_repeat(uint32_t{0xc}, 4) equals 0xcccccccc.\n\n### 3.3. bit_compress\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_compressr(T x, T m) noexcept { T result = 0; for (int i = 0, j = 0; i < numeric_limits<T>::digits; ++i) { bool mask_bit = (m >> i) & 1; result |= (mask_bit & (x >> i)) << j; j += mask_bit; } return result; }\n\nFor each one-bit in m, the corresponding bit in x is taken and packed\ncontiguously into the result, starting with the least significant result bit.\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_compressl(T x, T m) noexcept { return bit_reverse(bit_compressr(bit_reverse(x)), bit_reverse(m))); }\n\nFor each one-bit in m, the corresponding bit in x is taken and packed\ncontiguously into the result, starting with the most significant result bit.\n\n    \n    \n    x: +---+---+---+---+ | a | b | c | d | +---+---+---+---+ m: | | bit_compressl(x, m): bit_compressr(x, m): +---+---+---+---+ +---+---+---+---+ +---+---+---+---+ | 0 | 1 | 0 | 1 | | b | d | 0 | 0 | | 0 | 0 | b | d | +---+---+---+---+ +---+---+---+---+ +---+---+---+---+\n\nNote: Intuitively, m is a \"mask\" that determines which bits of x are packed.\n\n### 3.4. bit_expand\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_expandr(T x, T m) noexcept { T result = 0; for (int i = 0, j = 0; i < numeric_limits<T>::digits; ++i) { bool mask_bit = (m >> i) & 1; result |= (mask_bit & (x >> j)) << i; j += mask_bit; } return result; }\n\nFor each one-bit in m, a bit from x, starting with the least significant bit\nis taken and shifted into the corresponding position of the m bit.\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_expandl(T x, T m) noexcept { return bit_reverse(bit_expandr(bit_reverse(x)), bit_reverse(m))); }\n\nFor each one-bit in m, a bit from x, starting with the most significant bit is\ntaken and shifted into the corresponding position of the m bit.\n\n    \n    \n    x: +---+---+---+---+ | a | b | c | d | +---+---+---+---+ m: bit_expandl(x, m): bit_expandr(x, m): +---+---+---+---+ +---+---+---+---+ +---+---+---+---+ | 0 | 1 | 0 | 1 | | 0 | a | 0 | b | | 0 | c | 0 | d | +---+---+---+---+ +---+---+---+---+ +---+---+---+---+\n\nNote: Intuitively, m is a \"mask\" that determines where the bits of x are\nunpacked into.\n\n## 4\\. Motivation and scope\n\nBit-reversal, repetition, compression, and expansion are fundamental\noperations that meet multiple criteria which make them suitable for\nstandardization:\n\n  1. They are common and useful operations.\n\n  2. They can be used to implement numerous other operations.\n\n  3. At least on some architectures, they have direct hardware support.\n\n  4. They are non-trivial to implement efficiently in software.\n\n  5. For known masks, numerous optimization opportunities are available.\n\n### 4.1. Applications\n\n#### 4.1.1. Applications of bit_reverse\n\nBit-reversal is a common operation with uses in:\n\n  * Cryptography: scrambling bits\n\n  * Networking: as part of cyclic redundancy check computation\n\n  * Graphics: mirroring of images with one bit per pixel\n\n  * Random number generation: reversal can counteract low entropy of low-order bits such as in the case of linear congruential generators\n\n  * Digital signal processing: for radix-2 Cooley-Tukey FFT algorithms\n\n  * Code obfuscation: security by obscurity\n\n#### 4.1.2. Applications of bit_repeat\n\nThe generation of recurring bit patterns is such a fundamental operation that\nit\u2019s hard to tie to any specific domain, but here are some use cases:\n\n  * Debugging: using obvious recurring bit pattenrs like 0xcccc... to identify \"garbage memory\"\n\n  * Bit manipulation: generating alternating sequences of 1 and 0 for various algorithms\n\n  * Eliminating integer divison: for x >> (i % N) with very small N, bit_repeat(x, N) >> i can be used instead\n\n  * Testing: recurring bit patterns can make for good test cases when implementing numerics\n\n  * Error detection: known bit patterns can be introduced to spot failed transmission\n\n#### 4.1.3. Applications of bit_compress and bit_expand\n\nCompression and expansion are also common, with uses in:\n\n  * Space-filling curves: Morton/Z-Order and Hilbert curves\n\n  * Input/output: especially for variable-length encodings, such as UTF-8 (\u00a7 4.2.3 UTF-8 decoding with bit_compressr)\n\n  * Chess engines: for bitboards; see [ChessProgramming1]\n\n  * Genomics: according to [ARM1]\n\nA GitHub code search for /(_pdep_u|_pext_u)(32|64)/ AND language:c++ reveals\n~1300 files which use the intrinsic wrappers for the x86 instructions.\n\n### 4.2. Motivating examples\n\n#### 4.2.1. Implementing countr_zero with bit_repeat\n\n[Anderson1] contains a vast amount of algorithms, many of which involve masks\nof alternating 0s and 1s.\n\nWhen written as \"magic numbers\" in code, these masks can make it quite hard to\nunderstand the overall pattern and to generalize these algorithms. bit_repeat\nallows one to be more expressive here:\n\n    \n    \n    unsigned int v; // 32-bit word input to count zero bits on right unsigned int c = 32; // c will be the number of zero bits on the right v &= -v; if (v) c--; if (v & 0x0000FFFF bit_repeat((1 << 16) - 1, 32)) c -= 16; if (v & 0x00FF00FF bit_repeat( (1 << 8) - 1, 16)) c -= 8; if (v & 0x0F0F0F0F bit_repeat( (1 << 4) - 1, 8)) c -= 4; if (v & 0x33333333 bit_repeat( (1 << 2) - 1, 4)) c -= 2; if (v & 0x55555555 bit_repeat( (1 << 1) - 1, 2)) c -= 1;\n\nIt is now obvious how this can be expressed in a loop:\n\n    \n    \n    // ... for (int i = 16; i != 0; i /= 2) { unsigned mask = bit_repeat((1u << i) - 1, i * 2); if (v & mask) c -= i; }\n\nbit_repeat has been an invaluable asset in the implementation of the remaining\nfunctions in this proposal (see [Schultke1] for details).\n\n#### 4.2.2. Interleaving bits with bit_expand\n\nA common use case for expansion is interleaving bits. This translates\nCartesian coordinates to the index on a Z-order curve. Space filling curves\nare a popular technique in compression.\n\n    \n    \n    unsigned x = 3; // 0b011 unsigned y = 5; // 0b101 const auto i = bit_expandr(x, bit_repeat(0b10u, 2)) // i = 0b01'10'11 | bit_expandr(y, bit_repeat(0b01u, 2));\n\n#### 4.2.3. UTF-8 decoding with bit_compressr\n\nbit_compress and bit_expand are useful in various I/O-related applications.\nThey are particularly helpful for dealing with variable-length encodings,\nwhere \"data bits\" are interrupted by bits which signal continuation of the\ndata.\n\nThe following code reads 4 bytes from some source of UTF-8 data and returns\nthe codepoint. For the sake of simplicity, let\u2019s ignore details like reaching\nthe end of the file, or I/O errors.\n\n    \n    \n    uint_least32_t x = load32_little_endian(utf8_data_pointer); switch (countl_one(uint8_t(x))) { case 0: return bit_compressr(x, 0b01111111); case 1: /* error */; case 2: return bit_compressr(x, 0b00111111'00011111); case 3: return bit_compressr(x, 0b00111111'00111111'00001111); case 4: return bit_compressr(x, 0b00111111'00111111'00111111'00000111); }\n\n#### 4.2.4. Other operations based on bit_compress and bit_expand\n\nMany operations can be built on top of bit_compress and bit_expand. However,\ndirect hardware support is often needed for the proposed functions to\nefficiently implement them. Even without such support, they can be canonalized\ninto a faster form. The point is that bit_compress and bit_expand allow you to\nexpress these operations.\n\n    \n    \n    // x & 0xf bit_expandr(x, 0xf) bit_compressr(x, 0xf) // (x & 0xf) << 4 bit_expandr(x, 0xf0) // (x >> 4) & 0xf bit_compressr(x, 0xf0) // Clear the least significant one-bit of x. x ^= bit_expandr(1, x) // Clear the nth least significant one-bit of x. x ^= bit_expandr(1 << n, x) // Clear the n least significant one-bits of x. x ^= bit_expandr((1 << n) - 1, x) // (x >> n) & 1 bit_compressr(x, 1 << n) // Get the least significant bit of x. bit_compressr(x, x) & 1 // Get the nth least significant bit of x. (bit_compressr(x, x) >> n) & 1 // popcount(x) countr_one(bit_compressr(-1u, x)) countr_one(bit_compressr(x, x))\n\n### 4.3. Hardware support\n\nOperation| x86_64| ARM| RISC-V  \n---|---|---|---  \nbit_reverse| vpshufbitqmb^AVX512_BITALG, (bswap)| rbit^SVE2|\nrev8^Zbb+brev8^Zbkb,(rev8^Zbb)  \nbit_repeat| vpshufbitqmb^AVX512_BITALG  \nbit_compressr| pext^BMI2| bext^SVE2| (vcompress^V)  \nbit_expandr| pdep^BMI2| bdep^SVE2| (viota+vrgather^V)  \nbit_compressl| (pext^BMI2+popcnt^ABM)| bgrp^SVE2, (bext^SVE2+cnt^SVE)|\n(vcompress^V)  \nbit_expandl| (pdep^BMI2+popcnt^ABM)| (bdep^SVE2+cnt^SVE)| (viota+vrgather^V)  \n  \n(Parenthesized) entries signal that the instruction does not directly\nimplement the function, but greatly assists in its implementation.\n\nNote: The AVX-512 vpshufbitqmb instruction can implement any bit permutation\nin the mathematical sense, and more.\n\nNote: The RISC-V brev8 instruction can also be found under the name rev.b.\nThere appears to have been a name change in 2022.\n\n#### 4.3.1. Support for bit_reverse\n\nThis operation is directly implemented in ARM through rbit.\n\nAny architecture with support for byteswap (such as x86 with bswap) also\nsupports bit-reversal in part. [Warren1] presents an O(log n) algorithm which\noperates by swapping lower and upper N / 2, ..., 16, 8, 4, 2, and 1 bits in\nparallel. Byte-swapping implements these individual swaps up to 8 bits,\nrequiring only three more parallel swaps in software:\n\n    \n    \n    // assuming a byte is an octet of bits, and assuming the width of x is a power of two x = byteswap(x); x = (x & 0x0F0F0F0F) << 4 | (x & 0xF0F0F0F0) >> 4; // ... quartets of bits x = (x & 0x33333333) << 2 | (x & 0xCCCCCCCC) >> 2; // ... pairs of bits x = (x & 0x55555555) << 1 | (x & 0xAAAAAAAA) >> 1; // ... individual bits\n\nIt is worth noting that clang provides a cross-platform family of intrinsics.\n__builtin_bitreverse uses byte-swapping or bit-reversal instructions if\npossible.\n\nSuch an intrinsic has been requested from GCC users a number of times in\n[GNU1].\n\n#### 4.3.2. Support for bit_repeat\n\nFirstly, note that for the pattern length, there are only up to N relevant\ncases, where N is the operand width in bits. It is feasible to switch between\nthese cases, where the length is constant in each case.\n\nWhile the AVX-512 instruction vpshufbitqmb can be used for all cases, this is not the ideal solution for most cases. For very low or very great lengths, a naive solution is sufficient (and even optimal), where we simply use << and | to duplicate the pattern. What actually matters is how often the pattern is repeated, i.e. N / length.\n\nSpecific cases like bit_repeat(x, 8), bit_repeat(x, 16) can be implemented\nusing permutation/duplication/gather/broadcast instructions.\n\nHowever, note that the primary use of bit_repeat is to express repeating bit\npatterns without magic numbers, i.e. to improve code quality. Often, both the\npattern and the length are known at compile-time, making hardware support less\nrelevant. Even without hardware support, the reference implementation\n[Schultke1] requires only O(log N) fundamental bitwise operations.\n\n#### 4.3.3. Support for bit_compress and bit_expand\n\nStarting with Haswell (2013), Intel CPUs directly implement compression and\nexpansion with with pext and pdep respectively. AMD CPUs starting with Zen 3\nimplement pext and pdep with 3 cycles latency, like Intel. Zen 2 and older\nimplement pext/pdep in microcode, with 18 cycles latency.\n\nARM also supports these operations directly with bext, bdep, and bgrp in the\nSVE2 instruction set. [Warren1] mentions other older architectures with direct\nsupport.\n\nOverall, only recent instruction set extensions offer this functionality\ndirectly. However, when the mask is a constant, many different strategies for\nhardware acceleration open up. For example\n\n  * interleaving bits can be assisted (though not fully implemented) using ARM zip1/zip2\n\n  * other permutations can be assisted by ARM tbl and tbx\n\nAs [Warren1] explains, the cost of computing bit_compress and bit_expand in\nsoftware is dramatically lower for a constant mask. For specific known masks\n(such as a mask with a single one-bit), the cost is extremely low.\n\nAll in all, there are multiple factors that strongly suggest a standard\nlibrary implementation:\n\n  1. The strategy for computing bit_compress and bit_expand depends greatly on the architecture and on information about the mask, even if the exact mask isn\u2019t known.\n\n     * tzcnt, clmul (see [Schultke1] or [Zp7] for specifics), and popcnt are helpful.\n\n  2. ISO C++ does not offer a mechanism through which all of this information can be utilized. Namely, it is not possible to change strategy based on information that only becomes available during optimization passes. Compiler extensions such as __builtin_constant_p offer a workaround.\n\n  3. ISO C++ does not offer a mechanism through which function implementations can be chosen based on the surrounding context. In a situation where multiple bit_compress calls with the same mask m are performed, it is significantly faster to pre-compute information based on the mask once, and utilize it in subsequent calls. The same technique can be used to accelerate integer division for multiple divisions with the same divisor.\n\nBullets 2. and 3. suggest that bit_compress and bit_expand benefit from being\nimplemented directly in the compiler via intrinsic, even if hardware does not\ndirectly implement these operations.\n\nEven with a complete lack of hardware support, a software implementation of\ncompress_bitsr in [Schultke1] emits essentially optimal code if the mask is\nknown.\n\n    \n    \n    unsigned bit_compress_known_mask(unsigned x) { return cxx26bp::bit_compressr(x, 0xf0f0u); }\n\nClang 18 emits the following (and GCC virtually the same); see\n[CompilerExplorer1]:\n\n    \n    \n    bit_compress_known_mask(unsigned int): # bit_compress_known_mask(unsigned int edi) mov eax, edi # { unsigned int eax = edi; shr eax, 4 # eax >>= 4; and eax, 15 # eax &= 0xf; shr edi, 8 # edi >>= 8; and edi, 240 # edi &= 0xf0; or eax, edi # eax |= edi; ret # return eax; }\n\nKnowing the implementation of bit_compressr, this feels like dark magic. This\nis an optimizing compiler at its finest hour.\n\n## 5\\. Impact on existing code\n\nThis proposal is purely a standard library expansion. No existing code is\naffected.\n\n## 6\\. Design considerations\n\nThe design choices in this paper are based on [P0553R4], wherever applicable.\n\n### 6.1. Signature of bit_repeat\n\nbit_repeat follows the \"use int if possible\" rule mentioned in [P0553R4].\nOther functions such as std::rotl and std::rotr also accept an int.\n\nIt is also the only function not marked noexcept. It does not throw, but it is\nnot noexcept due to its narrow contract (Lakos rule).\n\n### 6.2. Why the names compress and expand?\n\nThe use of compress and expand is consistent with the mask-based permutations\nfor std::simd proposed in [P2664R6].\n\nFurthermore, there are multiple synonymous sets of terminology:\n\n  1. deposit and extract\n\n  2. compress and expand\n\n  3. gather and scatter\n\nI have decided against deposit and extract because of its ambiguity:\n\nTaking the input 0b10101 and densely packing it to 0b111 could be described\nas:\n\n> Extract each second bit from 0b10101 and densely deposit it into the result.\n\nSimilarly, taking the input 0b111 and expanding it into 0b10101 could be\ndescribed as:\n\n> Extract each bit from 0b111 and sparsely deposit it in the result.\n\nBoth operations can be described with extract and deposit terminology, making\nit virtually useless for keeping the operations apart. gather and scatter are\nsimply the least common way to describe these operations, which makes compress\nand expand the best candidates.\n\nFurther design choices are consistent with [P0553R4]. The abbreviations l and\nr for left/right are consistent with rotl/rotr. The prefix bit_ is consistent\nwith bit_floor and bit_ceil.\n\n### 6.3. Why the lack of generalization?\n\n#### 6.3.1. No generalized bit_compress and bit_expand\n\n[N3864] originally suggested much more general versions of compression and\nexpansion, which support:\n\n  1. performing the operation not just on the whole operand, but on \"words\" of it, in parallel\n\n  2. performing the operation not just on bits, but on arbitrarily sized groups of bits\n\nI don\u2019t propose this generality for the following reasons:\n\n  1. The utility functions in <bit> are not meant to provide a full bitwise manipulation library, but fundamental operations, especially those that can be accelerated in hardware while still having reasonable software fallbacks.\n\n  2. These more general form can be built on top of the proposed hardware-oriented versions. This can be done with relative ease and with little to no overhead.\n\n  3. The generality falsely suggests hardware support for all forms, despite the function only being accelerated for specific inputs. This makes the performance characteristics unpredictable.\n\n  4. The proposed functions have wide contracts and can be noexcept (Lakos rule). Adding additional parameters would likely require a narrow contract.\n\n  5. Generality adds complexity to the standardization process, to implementation, and from the perspective of language users. It is unclear whether this added complexity is worth it in this case.\n\n#### 6.3.2. No generalized bit_reverse\n\nBit reversal can also be generalized to work with any group size:\n\n    \n    \n    template <typename T> T bit_reverse(T x, int group_size = 1) noexcept(false);\n\nWith this generalization, byteswap(x) on conventional platforms is equivalent\nto bit_reverse(x, 8).\n\nHowever, this general version is much less used, not as consistently supported\nin hardware, and has a narrow contract. group_size must be a nonzero factor of\nx for this operation to be meaningful.\n\nTherefore, a generalized bit-reversal is not proposed in this paper.\n\n### 6.4. Why does the signature of bit_compress require two same Ts?\n\nInitially, I went through a number of different signatures.\n\n    \n    \n    template<unsigned_integral T, unsigned_integral X> constexpr T bit_compressr(X x, T m) noexcept;\n\nThis signature is quite clever because the result never has more bits than the\nmask m. However, it is surprising that the mask plays such a significant role\nhere.\n\nFurthermore, I\u2019ve realized that while the result never has more bits than m,\nbit_compressl must still deposit bits starting with the most significant bits\nof the result. This suggests the following:\n\n    \n    \n    template<unsigned_integral T, unsigned_integral X> constexpr common_type_t<T, X> bit_compressr(X x, T m) noexcept;\n\nHowever, it is not trivial to juggle bits between the left and right versions\nof bit_compress and bit_expand. The behavior is also not intuitive when a\nzero-extension occurs. For wider x, the mask is always zero-extended to the\nleft, which makes the left and right versions slightly asymmetrical.\n\nSince this proposal includes low-level bit operations, it is reasonable and\nsafe to require the user to be explicit. A call to bit_compress or bit_expand\nwith two different types is likely a design flaw or bug. Therefore, I have\nsettled on the very simple signature:\n\n    \n    \n    template<unsigned_integral T> constexpr T bit_compressr(T x, T m) noexcept;\n\n## 7\\. Possible implementation\n\n### 7.1. Reference implementation\n\nAll proposed functions have been implemented in [Schultke1]. This reference\nimplementation is compatible with all three major compilers, and leverages\nhardware support from ARM and x86_64 where possible.\n\n### 7.2. Other implementations\n\n[Warren1] presents algorithms which are the basis for [Schultke1].\n\n  * An O(log n) bit_reverse\n\n  * An O(log^2 n) bit_compress and bit_expand\n\n    * can be O(log n) with hardware support for carry-less multiplication aka. GF(2) polynomial multiplication\n\n[Zp7] offers fast software implementations for pext and pdep, optimized for\nx86_64.\n\n[StackOverflow1] contains discussion of various possible software\nimplementations of bit_compressr and bit_expandr.\n\n## 8\\. Proposed wording\n\nThe proposed changes are relative to the working draft of the standard as of\n[N4917].\n\n### 8.1. Feature-testing\n\nIn subclause 17.3.2 [version.syn] paragraph 2, update the synopsis as follows:\n\n>\n>     #define __cpp_lib_bitops 201907L20XXXXL // freestanding, also in <bit>\n\n### 8.2. Header synopsis\n\nIn subclause 22.15.2 [bit.syn], update the synopsis as follows:\n\n>\n>     + // 22.15.X, permutations + template<class T> + constexpr T\n> bit_reverse(T x) noexcept; + template<class T> + constexpr T bit_repeat(T x,\n> int l); + template<class T> + constexpr T bit_compressr(T x, T m) noexcept;\n> + template<class T> + constexpr T bit_expandr(T x, T m) noexcept; +\n> template<class T> + constexpr T bit_compressl(T x, T m) noexcept; +\n> template<class T> + constexpr T bit_expandl(T x, T m) noexcept;\n\n### 8.3. New subclause\n\nIn subclause 22.15 [bit], add the following subclause:\n\n> 22.15.X Permutation [bit.permute]\n>\n> 1 In the following descriptions, let N denote numeric_limits<T>::digits. Let\n> \u03b1_n denote the n-th least significant bit of \u03b1, so that \u03b1 equals\n>  \n>  \n>     template<class T> constexpr T bit_reverse(T x) noexcept;\n>\n> 2 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 3 Returns: [Note: bit_reverse(bit_reverse(x)) equals x. \u2014 end note]\n>  \n>  \n>     template<class T> constexpr T bit_repeat(T x, int l);\n>\n> 4 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 5 Preconditions: l is greater than zero.\n>\n> 6 Returns:\n>\n> 7 Throws: Nothing.\n>  \n>  \n>     template<class T> constexpr T bit_compressr(T x, T m) noexcept;\n>\n> 8 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 9 Returns:\n>  \n>  \n>     template<class T> constexpr T bit_expandr(T x, T m) noexcept;\n>\n> 10 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 11 Returns: [Note: If x & ~m equals zero, then bit_expandr(bit_compressr(x,\n> m), m) equals x. If x >> popcount(m) equals zero, then\n> bit_compressr(bit_expandr(x, m), m) equals x. \u2014 end note]\n>  \n>  \n>     template<class T> constexpr T bit_compressl(T x, T m) noexcept;\n>\n> 12 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 13 Returns: bit_reverse(bit_compressr(bit_reverse(x), bit_reverse(m))).\n>  \n>  \n>     template<class T> constexpr T bit_expandl(T x, T m) noexcept;\n>\n> 14 Constraints: T is an unsigned integer type ([basic.fundamental]).\n>\n> 15 Returns: bit_reverse(bit_expandr(bit_reverse(x), bit_reverse(m))).\n\nNote: I would have preferred a less mathematical approach to defining these\nfunctions. However, it is too difficult to precisely define bit_compress and\nbit_expand without visual aids, pseudo-code, or other crutches.\n\n## 9\\. Acknowledgements\n\nI greatly appreciate the assistance of Stack Overflow users in assisting me\nwith research for this proposal. I especially thank Peter Cordes for his\ntireless and selfless dedication to sharing knowledge.\n\nI also thank various Discord users from Together C & C++ and #include<C++> who\nhave reviewed drafts of this proposal and shared their thoughts.\n\n## References\n\n### Normative References\n\n[N4917]\n\n    Thomas K\u00f6ppe. Working Draft, Standard for Programming Language C++. 5 September 2022. URL: https://wg21.link/n4917\n\n### Informative References\n\n[Anderson1]\n\n    Sean Eron Anderson. Bit Twiddling Hacks. URL: https://graphics.stanford.edu/~seander/bithacks.html\n[ARM1]\n\n    Arm Developer Community. Introduction to SVE2, Issue 02, Revision 02. URL: https://developer.arm.com/-/media/Arm%20Developer%20Community/PDF/102340_0001_02_en_introduction-to-sve2.pdf?revision=b208e56b-6569-4ae2-b6f3-cd7d5d1ecac3\n[ChessProgramming1]\n\n    VA. chessprogramming.org/BMI2, Applications. URL: https://www.chessprogramming.org/BMI2#Applications\n[CompilerExplorer1]\n\n    Jan Schultke. Compiler Explorer example for bit_compressr. URL: https://godbolt.org/z/5dcTjE5x3\n[GNU1]\n\n    Marc Glisse et al.. Bug 50481 - builtin to reverse the bit order. URL: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=50481\n[N3864]\n\n    Matthew Fioravante. A constexpr bitwise operations library for C++. URL: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3864.html\n[P0553R4]\n\n    Jens Maurer. Bit operations. URL: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html\n[P2664R6]\n\n    Daniel Towner; Ruslan Arutyunyan. Extend std::simd with permutation API. URL: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p2664r6.html#permute_by_mask\n[Schultke1]\n\n    Jan Schultke. C++26 Bit Permutations. URL: https://github.com/Eisenwave/cxx26-bit-permutations\n[StackOverflow1]\n\n    Jan Schultke et al.. What is a fast fallback algorithm which emulates PDEP and PEXT in software?. URL: https://stackoverflow.com/q/77834169/5740428\n[Warren1]\n\n    Henry S. Warren, Jr.. Hacker's Delight, 2nd Edition.\n[Zp7]\n\n    Zach Wegner. Zach's Peppy Parallel-Prefix-Popcountin' PEXT/PDEP Polyfill. URL: https://github.com/zwegner/zp7\n\n", "frontpage": false}

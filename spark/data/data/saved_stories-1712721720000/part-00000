{"aid": "39984757", "title": "Dependencies and Resilience", "url": "https://ingino.me/ideas/on-dependencies/", "domain": "ingino.me", "votes": 1, "user": "sebastianingino", "posted_at": "2024-04-09 21:59:42", "comments": 0, "source_title": "On dependencies and resilience - Sebastian Ingino", "source_text": "On dependencies and resilience - Sebastian Ingino\n\nSebastian Ingino\n\ndevelopment\n\nindustry\n\nopinion\n\n# On dependencies and resilience\n\nJan 5, 2024 - 13 minutes\n\n  1. On dependencies and resilience\n  2. From the video game industry with love\n  3. An open door shut.\n  4. Dealing with providers\n  5. GPT-4 / Claude / Llama / the new one from 5 minutes ago\n  6. Solutions? Not really\n\n    1. Footnotes\n\nI\u2019ve been thinking a lot about dependencies while working with my new website,\nbuilt on Astro. Astro, with no additional packages, uses 400 total\ndependencies weighing in at about 122 MB. Andrei Kashcha has made a lovely\nvisualizer where you can see Astro and all other packages as a graph. My\nwebsite, with all additional packages, has 467 dependencies which brings me up\nto over 500 MBs, and that\u2019s insane. Even a \u201clightweight\u201d project such as 11ty\nhas 213 dependencies.\n\nHowever, I don\u2019t want to discuss the JS ecosystem dependency issue, which has\nbeen talked about by some people way smarter than I^1. I also won\u2019t directly\ndiscuss software bloat^2 or supply chain security^3. Instead, I want to\nexplore the theory that the software development culture shift towards more\ndependencies, especially in the web development space, is creating more\nproducts and companies that rely on closed-source software or APIs for their\nfull functionality which could have future negative implications.\n\n# From the video game industry with love\n\nIn September of last year, Unity announced^4 a new per-download fee for\ndevelopers that would start January 2024. For Personal plans (Plus was being\nretired into Personal), games that have made more than $200,000 in the last 12\nmonths and had at least 200,000 lifetime installs would qualify, and for the\nmore expensive Pro and Enterprise plans, it\u2019s $1,000,000 and 1,000,000\ninstalls respectively. In exchange for the pricing change, the Personal plan\nwould become free. Personal would be charged at $0.20 per install, and Pro and\nEnterprise would start at $0.15 and $0.125 per install respectively, and that\nwould go down as installs per month increased.\n\nAs Unity had previously charged a subscription fee for each plan, this move\nwas met with immediate outrage with the prime concern that the system could be\nabused with repeat installs to punish developers. However, what struck me the\nmost, besides the fact that this move was purely profit and stock-driven, is\nhow game studios left so quickly from Unity despite them later walking most of\nthe changes back. Some studios even described Unity as \u201can operational\nrisk\u201d^5.\n\nIndependent developers are hit the hardest as switching software so quickly is\nextremely difficult, especially as all of the tooling from libraries to game\neditor to distribution, even programming language, can change. Unity, in this\ncase, has truly caused irreparable damage to its reputation with developers,\nbut it begs the question: what if they had been more subtle? What if they\nslowly increased prices with little to no notice to developers? Even though\nthe boiling frog analogy is false,^6 if the water gets hotter slowly enough,\nwill developers or studios not feel as much pressure to switch engines,\nallowing Unity to extract ever-increasing profits?\n\nI think that Unity\u2019s actions should be a reminder to not just full companies\nbut individual developers that they need to be aware of the closed-source\ndependencies that they have and maintain a plan to switch if the need arises.\nThe Unity issue is an easier issue for larger studios to solve \u2013 they could\ncreate an in-house engine if need be \u2013 and it hurts smaller studios and indie\ndevelopers the most. However, any creator of any product of any size, in my\nopinion, needs to be thinking from day one about what it depends on, whether\nit be YouTube for video revenue or AWS for hosting, how trustworthy these\ndependencies are, and how to respond if their terms change.\n\n# An open door shut.\n\nEven open source isn\u2019t \u201csafe\u201d, as HashiCorp demonstrated when it switched^7\nfrom MPL 2.0^8 to BSL^9, which kept the source code available while preventing\ncertain commercial use. In this case, HashiCorp\u2019s BSL prevents commercial\ncompetitors from using their software without a license. This switch is\nproblematic for two reasons: 1. HashiCorp decides who a \u201ccommercial\ncompetitor\u201d is and 2. some open-source developers fear that using HashiCorp\nsoftware in their work might poison their license and force them to adopt\nHashiCorp\u2019s BSL.\n\nFor medium to large companies using HashiCorp software internally, this likely\nrequired a legal discussion or even an audit to double-check that their use of\nHashiCorp software, primarily Vault and Terraform, doesn\u2019t compete with\nHashiCorp^10. Other companies, especially new DevOps startups, they\u2019re\nunlikely to be able to use these products without a likely expensive license \u2013\nwhich is likely the exact product segment HashiCorp was trying to target with\nthis change. HashiCorp\u2019s change also seems to be one of the more extreme\nlicense switches in open-source history, as compared to MongoDB switching to\nSSPL^11 in 2018 or CockroachDB switching to BSL^12 in 2019^13.\n\nThe Linux Foundation has since sponsored OpenTofu, a forever-open-source fork\nof Terraform, with the guarantee that the license won\u2019t change at any point in\nthe future. While the Linux Foundation, and many other open-source foundations\nlike the Apache Software Foundation, provide logistic support and a guarantee\nof open-source licensing for all of their projects, very few small\ndependencies fall under their umbrella. Modern companies of any size need to\ninspect where their dependencies come from and who manages them to ensure that\nthey\u2019re not at risk of any future licensing changes.\n\nOpen-source projects with corporate ownership seem the riskiest, and it\u2019s\nvital to examine what the incentives to keep the software open-source or\neventually change its license are. Google, known as a strong open-source\ncontributor, is unlikely to take, for example, Angular off of copyleft^14. On\nthe other hand, Automattic\u2019s product offerings like WooCommerce are products\nwith open source code \u2013 there would be nothing stopping them from restricting\nthe license in the future. In my opinion, the safest dependencies are those\nrun by a foundation, then ones with multiple corporate sponsors, and then\nhistorically trustworthy companies. Even open-source software run by\nindividuals is likely safer in terms of license changes than single corporate\nowners. Despite these risks, open-source software is almost always better than\nclosed-source as even in the event of a licensing change, a fork can always be\nmade by the community as shown with OpenTofu.\n\n# Dealing with providers\n\nStripe, for example, lists 99.999% uptime for the last 90 days^15. When I was\nat Stripe this past summer, Slack went down twice^16 during those twelve weeks\nwhich was frustrating at the time, but they maintained 99.98% uptime for the\nlast quarter^17. Despite rarely going down, a Slack outage can often majorly\naffect office productivity and internal communications if no alternative\ncommunication is readily available. Luckily, most companies also have email,\nwith Slack as the ephemeral less-professional alternative.\n\nBut, what happens if one of your product or business dependencies goes down,\nlike Square did in September last year? Square was down for nearly two days\nglobally, leading to a $1bn loss in sales, serving as a wake-up call for\ncustomers to switch providers or develop in-house^18. AWS went down briefly in\nJune of the same year, affecting operations in their US-EAST-1 region^19.\nCloudflare was fully down at the end of October for about half an hour with a\nsmaller but longer outage less than a week later^20.\n\nI think that there are some clear lessons to be learned from all the outages\nwe see daily. While it can be costly or extremely difficult, maintaining a\nsecondary provider in most cases is the safest option for all companies of all\nsizes. However, this can be overly complicated, especially when working with\nhighly integrated APIs. Therefore, it\u2019s important to have consistent\nabstractions on top of these APIs so that, even if there\u2019s not an automatic\nfallback system, exchanging the underlying software should be much easier.\n\nAdditionally, I think that software designers and developers should be\nthinking about fail-safe vs fail-secure \u2013 that is, whether something should\nunlock in an emergency or the opposite. Most software is fail-secure: if a\nlicense manager can\u2019t reach the host, you can\u2019t get in; if payments go down,\nyou can\u2019t buy a product; if authentication providers aren\u2019t responding, you\ncan\u2019t log in. This is typically the best default \u2013 you usually don\u2019t want\nsomeone turning off WiFi to skip license verification or DDoS-ing an API to\nget a free item. However, in some cases, writing fail-safe code might be a\nbetter option for your business. Let\u2019s say that you run a website with\nsubscriptions through an API and that API goes down. And let\u2019s say that your\nwebsite keeps track of who\u2019s subscribed and checks the API periodically for\nupdates. If the API goes down, should subscribers remain listed as subscribed?\nI\u2019d say yes. This is a relatively tame example but serves as a simple case\nstudy that every uncontrolled dependency should go through.\n\nLastly, medium to large companies (maybe even smaller ones) should be doing\nregular chaos and outage testing. The multi-day Cloudflare outage was caused\nby power issues with one of their major Oregon data centers and should\u2019ve been\nprevented by high-availability multi-data-center clusters^21.\n\n> In particular, two critical services that process logs and power our\n> analytics \u2014 Kafka and ClickHouse \u2014 were only available in PDX-04 but had\n> services that depended on them that were running in the high availability\n> cluster. Those dependencies shouldn\u2019t have been so tight, should have failed\n> more gracefully, and we should have caught them.\n\nWhile Cloudflare did pretty robust outage testing, they didn\u2019t take the entire\ndata center offline \u2013 only a portion of it and therefore didn\u2019t catch the\nissue. You should read the entire blog post as it details how Cloudflare will\nbe using rigorous testing and prevention measures in the future, but I think\nit serves as an example that this is a struggle for all companies. AWS now\nlets you simulate region outages^22 and I\u2019m hoping that more providers will\ncatch up as this issue grows.\n\n# GPT-4 / Claude / Llama / the new one from 5 minutes ago\n\nWhat got me thinking about this issue has been the growth of \u201cAI\u201d products\nthat simply wrap OpenAI\u2019s API, either offering proprietary embeddings or\nprompt engineering as their additional service. All of the previous examples\nhave been about partial dependencies, where most of the work on top can be\nsalvaged in the event of a dependency change. I worry that many of these GPT-\nbased applications are making themselves overdependent on OpenAI, giving\nOpenAI a ton of bargaining power and creating a lot of risk for the product.\nFurthermore, since many of these applications are just adding a new embedding\nmethod like PDFs, this makes sherlocking^23 easy for OpenAI as they did last\nSeptember^24.\n\nAt the end of the day, I think that we only need to ask two questions for each\ndependency:\n\nWhat is the impact on my business if it disappears today? How likely is that\nto happen?\n\nThere are a bunch of questions that go along with the first \u2013 some of which\nI\u2019ve already discussed: do we have a game plan if something goes wrong; how\nmuch time would it take to switch; can we automate this process; how graceful\nis failure; etc? The second has others as well: who\u2019s behind the dependency;\nwhat\u2019s their track record (uptime, behavior, etc.); what have similar\ndependencies done; etc? However, I think that these simple questions are\nenough to understand the basic dangers and hopefully kickstart an internal\neffort to decrease that potential impact. You could even put it on a chart:\n\nMany companies are switching away from a direct OpenAI dependency to other\nproviders, like Hugging Face^25. I even remember seeing on the Bay Area\nfreeway \u2013 though I can\u2019t find the company \u2013 an advertisement for a product\nthat lets you switch between multiple LLM providers to improve your product\u2019s\nuptime. The irony of this product is now they\u2019re a dependency.\n\n# Solutions? Not really\n\nWe\u2019re not going to escape from the interdependent world any time soon. Unless\nyou\u2019re the largest company in the world and have become fully vertically\nintegrated (Apple\u2019s #1 wish), there\u2019s always going to be dependencies, and\nthat\u2019s good. It\u2019s good that we have companies like Twilio to handle\ncommunications and Mapbox for GIS, as these companies can achieve economies of\nscale and abstract complexities that would be much too difficult for even some\nlarge corporations. It\u2019s good that we have open-source software like React and\nHadoop that also abstract complexity and often have a strong community, all\nfor free.\n\nDespite your best efforts, you\u2019ll always have dependencies. If you\u2019re a\nproduct company, even if you do your logistics in-house, weather becomes a\ndependency. Even the entire internet for most companies is a major dependency.\nAt some point, we can\u2019t worry about things out of our control \u2013 we can only\nplan for the most likely. I hope that this blog post sparks a discussion\nwithin your product teams and your company about how to build resilient\nsoftware, as it could make or break your product if something goes wrong.\n\nThoughts? Leave me feedback!\n\n## Footnotes\n\n  1. JavaScript\u2019s Dependency Problem, Ride Down Into JavaScript Dependency Hell \u21a9\n\n  2. Software disenchantment \u21a9\n\n  3. No Unaccompanied Miners: Supply Chain Compromises Through Node.js Packages \u21a9\n\n  4. Unity plan pricing and packaging updates \u21a9\n\n  5. How a Pricing Change Led to a Revolt by Unity\u2019s Video Game Developers \u21a9\n\n  6. Boiling Frog \u21a9\n\n  7. HashiCorp adopts Business Source License \u21a9\n\n  8. Business Source License (BSL 1.1): Requirements, Provisions, and History \u21a9\n\n  9. MPL 2.0 FAQ \u21a9\n\n  10. I\u2019m curious to know what the reactions at my previous employer Stripe were, as they use Terraform pretty significantly. Also, they should write more engineering blog posts. \u21a9\n\n  11. MongoDB now released under the Server Side Public License \u21a9\n\n  12. Why we\u2019re relicensing CockroachDB \u21a9\n\n  13. I think it\u2019s funny that most of these examples are database companies, as Elastic did the same thing. These companies are primarily trying to avoid commercial redistribution or hosting without a license, but I think that HashiCorp\u2019s changes were received worse as their software was integrated by other projects unlike databases (which are typically not an integrated dependency). \u21a9\n\n  14. If Google ever were to take an open-source product private, it would be Android in my opinion. I think it\u2019s still unlikely, however, as they rely on the open-source nature of Android to capture the market and increase users for Google products. \u21a9\n\n  15. Stripe Status \u21a9\n\n  16. Slack Experiences a Brief but Widespread Outage, Slack briefly experienced some major issues \u21a9\n\n  17. Slack Status \u21a9\n\n  18. Square\u2019s outages will have global impact \u21a9\n\n  19. Amazon says AWS is operating normally after outage that left publishers unable to operate websites \u21a9\n\n  20. Cloudflare is (still) struggling with another outage - here\u2019s what to know \u21a9\n\n  21. Post Mortem on Cloudflare Control Plane and Analytics Outage \u21a9\n\n  22. You\u2019re so worried about AWS reliability, the cloud giant now lets you simulate major outages \u21a9\n\n  23. a developer\u2019s guide to apple, sherlocking, and antitrust \u21a9\n\n  24. A minor ChatGPT update is a warning to founders: Big Tech can blow up your startup at any time \u21a9\n\n  25. Pivot! AI Devs Move to Switch LLMs, Reduce OpenAI Dependency \u21a9\n\n", "frontpage": false}

{"aid": "40002386", "title": "How to Integrate OpenAI with Weights and Biases", "url": "https://finetunedb.com/blog/how-to-integrate-openai-with-weights-and-biases/", "domain": "finetunedb.com", "votes": 1, "user": "farouqaldori", "posted_at": "2024-04-11 14:15:16", "comments": 0, "source_title": "How to Integrate OpenAI With Weights & Biases | FinetuneDB", "source_text": "How to Integrate OpenAI With Weights & Biases | FinetuneDB\n\nWe use essential cookies to make our site work. With your consent, we may also\nuse non-essential cookies to improve user experience and analyze website\ntraffic. By clicking \u201cAccept,\u201d you agree to our website's cookie use as\ndescribed in our Cookie Policy. You can change your cookie settings at any\ntime by clicking \u201cPreferences.\u201d\n\nFinetuneDB\n\nFeatures\n\nSecurity\n\nContact\n\nBlog\n\nLog in\n\nBook a demo\n\nFinetuneDB\n\n\u2190 Back to Blog\n\n# How to Integrate OpenAI With Weights & Biases\n\nLearn how to integrate OpenAI with Weights & Biases (W&B) to track, visualize,\nand manage your fine-tuning jobs. Discover the key metrics and best practices\nfor successful model fine-tuning.\n\nDATE\n\nThu Apr 11 2024\n\nAUTHOR\n\nFarouq Aldori\n\nCATEGORY\n\nGuide\n\n## Track Your Fine-Tuning Jobs With Weights & Biases\n\nIntegrating OpenAI with Weights & Biases (W&B) provides a powerful way to\ntrack, visualize, and manage your OpenAI fine-tuning jobs. This article covers\nhow to set up the integration between OpenAI and W&B and start tracking your\nfine-tuning jobs in the W&B dashboard.\n\nYou\u2019ll learn how to authenticate your W&B account with OpenAI, enable the\nintegration when creating fine-tuning jobs, and view your job details,\nmetrics, and hyperparameters in W&B.\n\n### Key Takeaways\n\n  * Integrating OpenAI and W&B is a simple two-step process: authenticate your W&B account with OpenAI, then enable the integration when creating fine-tuning jobs\n\n  * The integration allows you to track and visualize your fine-tuning job\u2019s progress, metrics, hyperparameters, and other job-related information in the W&B platform.\n\n  * OpenAI sets default tags on the W&B runs to help you easily search, filter, and analyze your fine-tuning experiments.\n\n  * Logged metrics for each step of the fine-tuning job provide valuable insights into your model\u2019s performance.\n\n  * High-quality datasets are crucial for successful fine-tuning, and platforms like FinetuneDB can help optimize your data for better results.\n\n## Setting Up the Integration\n\n### Prerequisites for Integration\n\nBefore integrating OpenAI with W&B, ensure you have the following:\n\n  1. A valid OpenAI API key\n  2. An active W&B account with administrator access\n  3. Familiarity with the OpenAI API and W&B platform\n  4. Knowledge of the programming language (e.g. Python) used for your project\n\nTo begin the integration process, an account administrator must submit a valid\nW&B API key to OpenAI through the Account Dashboard. This key will be stored\nsecurely within OpenAI, allowing it to post metrics and metadata on your\nbehalf to W&B when your fine-tuning jobs are running.\n\nEnsure your development environment is set up with the necessary libraries and\ntools for a seamless integration workflow.\n\n### Step 1: Obtain a Weights & Biases API Key\n\nTo begin the integration process, you\u2019ll need to obtain a valid W&B API key.\nFollow these steps to get your API key:\n\n  1. Log in to your W&B account.\n  2. Navigate to your account settings.\n  3. In the \u201cAPI Keys\u201d section, click \u201cReveal\u201d or \u201cNew key\u201d.\n  4. Copy the API key.\n\nObtain your Weights & Biases API key\n\n### Step 2: Authenticate Your Weights & Biases Account With OpenAI\n\nTo allow OpenAI to post metrics and metadata on your behalf to W&B when your\nfine-tuning jobs are running, you need to submit your W&B API key to OpenAI.\nCurrently, this can only be done via the Account Dashboard and only by account\nadministrators.\n\n  1. Log in to your OpenAI Account Dashboard.\n  2. Navigate to the \u201cSettings\u201d page.\n  3. Enter your W&B API key in the provided field.\n  4. Click \u201cSave\u201d to securely store your API key within OpenAI.\n\nRemember to authenticate your OpenAI organization with W&B before enabling the\nintegration on a fine-tuning job to avoid errors.\n\nEnable the integration on OpenAI\n\n### Step 3: Enable the Weights & Biases Integration\n\nWhen creating a new fine-tuning job, you can enable the W&B integration by\nincluding a new wandb integration under the integrations field in the job\ncreation request. This allows you to specify the W&B Project that you wish the\nnewly created W&B Run to show up under.\n\nCreating fine-tuning jobs from the OpenAI Dashboard\n\nWhen creating a new fine-tuning job from the OpenAI UI, the W&B integration is\nenabled by default.\n\nCreating fine-tuning jobs from the FinetuneDB Dashboard\n\nWhen creating a new fine-tuning job from the FinetuneDB Dashboard, the W&B\nintegration is enabled by default.\n\nCreating fine-tuning jobs from the OpenAI API\n\nCreating fine-tuning jobs from the OpenAI API requires you to explicitly\nenable the W&B integration.\n\nAs of April 2024, the OpenAI SDK doesn\u2019t support the W&B integration yet, but\nyou can enable the W&B integration when creating a new fine-tuning job through\nthe API:\n\n    \n    \n    curl -X POST \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer $OPENAI_API_KEY\" \\ -d '{ \"model\": \"gpt-3.5-turbo-0125\", \"training_file\": \"file-ABC123\", \"validation_file\": \"file-DEF456\", \"integrations\": [ { \"type\": \"wandb\", \"wandb\": { \"project\": \"custom-wandb-project\", \"tags\": [\"project:tag\", \"lineage\"] } } ] }' https://api.openai.com/v1/fine_tuning/jobs\n\nCreate a fine-tuning job with W&B integration\n\nBy default, the Run ID and Run display name are the ID of your fine-tuning\njob, for example ftjob-abc123.\n\nYou can customize the display name of the run by including a name field in the\nwandb object.\n\nYou can also include a tags field in the wandb object to add tags to the W&B\nRun. Tags must be less or equal to 64 character strings, and there is a\nmaximum of 50 tags.\n\nSometimes it is convenient to explicitly set the W&B Entity to be associated\nwith the run. You can do this by including an entity field in the wandb\nobject. If you do not include an entity field, the W&B entity will default to\nthe default W&B entity associated with the API key you registered previously.\n\nThe full specification for the integration can be found in the OpenAI fine-\ntuning job creation documentation.\n\n## Viewing Your Fine-Tuning Job in Weights & Biases\n\nOnce you\u2019ve created a fine-tuning job with the W&B integration enabled, you\ncan view the job in W&B by navigating to the W&B project you specified in the\njob creation request. Your run should be located at the URL:\nhttps://wandb.ai/<WANDB-ENTITY>/<WANDB-PROJECT>/runs/ftjob-ABCDEF.\n\nYou should see a new run with the name and tags you specified in the job\ncreation request. The Run Config will contain relevant job metadata such as:\n\n  * model: The model you are fine-tuning\n  * training_file: The ID of the training file\n  * validation_file: The ID of the validation file\n  * hyperparameters: The hyperparameters used for the job (e.g., n_epochs, learning_rate, batch_size)\n  * seed: The random seed used for the job\n\nLikewise, OpenAI will set some default tags on the run to make it easier for\nyou to search and filter. These tags will be prefixed with \u201copenai/\u201d and will\ninclude:\n\n  * openai/fine-tuning: Tag to let you know this run is a fine-tuning job\n  * openai/ft-abc123: The ID of the fine-tuning job\n  * openai/gpt-3.5-turbo-0125: The model you are fine-tuning\n\nIf you\u2019re using FinetuneDB, additional tags prefixed with \u201cfinetunedb/\u201d will\nbe added to the run:\n\n  * finetunedb/project-name/dataset-name: The name of the project and dataset you\u2019ve created in FinetuneDB\n\nExample W&B run generated from an OpenAI fine-tuning job\n\nW&B automatically logs key metrics at each stage of the fine-tuning process,\nproviding valuable insights into your model\u2019s learning and adaptation. This\nmakes it easy to track your fine-tuning job\u2019s progress and performance.\n\nThe metrics logged by W&B are identical to the ones you can find in the fine-\ntuning job event object and on the OpenAI fine-tuning Dashboard. This means\nyou can use W&B\u2019s visualization tools to monitor your fine-tuning job\u2019s\nperformance and even compare it with previous jobs you\u2019ve run.\n\nThis way, you can easily see how different settings or datasets affect the\nmodel\u2019s learning process and make informed decisions about your fine-tuning\nstrategy.\n\nExample of the metrics logged to a W&B run\n\n## Analyzing Your Fine-Tuning Job\n\nWhen you\u2019re fine-tuning an OpenAI model, it\u2019s crucial to monitor and analyze\nkey metrics to understand how well the model is learning and generalizing.\n\nBy keeping a close eye on these metrics, you can gain valuable insights into\nthe model\u2019s performance and make informed decisions about when to stop\ntraining or adjust your approach.\n\n### Validation Loss (valid_loss)\n\nValidation loss measures how well the model performs on unseen data, which is\ndata that wasn\u2019t used during training. A decreasing validation loss indicates\nthat the model is improving its ability to make accurate predictions on new,\nreal-world data. Keep an eye on this metric to ensure your model is\ngeneralizing well and not overfitting to the training data.\n\n### Training Loss (train_loss)\n\nTraining loss represents how well the model is learning to fit the training\ndata. As the model learns, the training loss should decrease over time. If the\ntraining loss continues to decrease while the validation loss starts to\nincrease, it may be a sign that the model is beginning to overfit and memorize\nthe training examples instead of learning general patterns.\n\n### Validation Mean Token Accuracy (valid_mean_token_accuracy)\n\nThis metric measures the average accuracy of the model\u2019s predictions on the\nvalidation set at the token level. A higher validation mean token accuracy\nindicates that the model is making more correct predictions on unseen data.\nAim for a steady increase in this metric during fine-tuning, as it suggests\nthe model is learning to generalize effectively.\n\n### Training Mean Token Accuracy (train_mean_token_accuracy)\n\nSimilar to validation mean token accuracy, this metric represents the average\naccuracy of the model\u2019s predictions on the training set at the token level. As\nthe model learns from the training examples, the training mean token accuracy\nshould improve. However, if this metric continues to increase while the\nvalidation accuracy plateaus or declines, it may signal that the model is\nstarting to overfit.\n\n## Beyond Metrics: The Importance of High-Quality Datasets\n\nWhile monitoring metrics like validation loss, training loss, and token\naccuracy is essential for understanding your model\u2019s performance during fine-\ntuning, it\u2019s crucial to remember that the most important aspect of successful\nfine-tuning is the quality of your dataset.\n\nMetrics serve as valuable indicators of how well your model is learning and\ngeneralizing, but they are ultimately a reflection of the data you feed into\nthe model. If your fine-tuning dataset contains inconsistencies, biases, or\nirrelevant information, even the most carefully monitored fine-tuning process\nwill struggle to produce a high-performing model.\n\nThis is where FinetuneDB comes in. FinetuneDB is a platform designed to help\nyou create, manage, and optimize high-quality datasets for fine-tuning OpenAI\nmodels. By providing a user-friendly interface and powerful tools for data\ncuration, FinetuneDB makes it easy to ensure that your training data is\nrelevant, diverse, and free from noise or inconsistencies.\n\nFinetuneDB dataset manager\n\nWith FinetuneDB, you can:\n\n  * Efficiently collect and organize training examples from various sources\n  * Collaborate with your team to review and refine your dataset\n  * Analyze your data for potential biases or imbalances\n  * Easily split your data into training and validation sets\n  * Version control your datasets to track changes and improvements over time\n\nBy leveraging FinetuneDB to create high-quality datasets, you can\nsignificantly improve the performance of your fine-tuned models.\n\nWell-curated training data allows your model to learn meaningful patterns and\ngeneralize effectively to real-world scenarios, ultimately leading to better\noutcomes for your applications.\n\n\u2190 Back to Blog\n\n## The AI Fine-tuning Platform\n\nEasily create and manage datasets to fine-tune LLMs. Evaluate outputs and\niterate on production data.\n\nBook a demo\n\nFinetuneDB\n\n  * Terms of service\n\n  * Privacy policy\n\n  * Cookies\n\n  * Consent Preferences\n\n  * support@finetunedb.com\n\nMade in Stockholm - LLM Ops AB\n\n", "frontpage": false}

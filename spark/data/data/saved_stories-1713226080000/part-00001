{"aid": "40043766", "title": "When Is Code Generation Useful?", "url": "https://ihsaanp.com/posts/code-generation/", "domain": "ihsaanp.com", "votes": 1, "user": "itsskiseason", "posted_at": "2024-04-15 18:05:37", "comments": 0, "source_title": "When is Code Generation Useful? | Ihsaan's Blog", "source_text": "When is Code Generation Useful? | Ihsaan's Blog\n\nSkip to content\n\nIhsaan's Blog\n\n# When is Code Generation Useful?\n\nPublished:Apr 13, 2024 | at 09:48 PM\n\nOver the past two weeks I\u2019ve built a couple of projects (AutoTransform and\nBetaTester) that involved this basic workflow:\n\n  1. LLM (Large Language Model) generates code to solve a problem\n  2. Code is executed\n  3. If code fails, LLM is called upon again to generate a new solution\n\nIn both cases, much of the generated code\u2019s value was in cost and latency\nsavings, where executing a model like GPT 4 over and over again becomes\nprohibitively expensive and slow.\n\nBut as LLMs get smarter and faster, is code generation necessary? Wouldn\u2019t it\nbe better to just call the LLM every time (i.e. only do step 1 above), and\nhave it generate a solution on the fly instead of generating this intermediate\nrepresentation of code every time? You wouldn\u2019t need to add the extra steps of\ngenerating, executing, and correcting code, making the system less complex and\npotentially easier to maintain.\n\n## Potential Benefits of Generated Code#\n\nWhile the timing of this cheap-enough and fast-enough LLMs future is unclear\nand potentially far away due to compute / memory / energy constraints, I do\nthink there are other advantages to code generation that might make it useful\neven in this future.\n\n### Interfacing with Humans#\n\nFor AutoTransform, the generated code provides a way for humans to reason\nabout what the system is doing / will do and alter the behavior of the system\nto their liking - it can be easier to edit code to get the exact behavior that\nyou want instead of trying to mess with a prompt. It\u2019s not clear how\nsustainable this paradigm is as machines generate code at a scale that humans\ncan\u2019t keep up with, but it seems within the realm of possibility that\ndeterministic code will always be valuable in certain use cases due to safety\n/ regulatory / liabilty constraints.\n\n### Interfacing with Existing Systems#\n\nFor BetaTester, the system uses Playwright to interact with a website by\ngenerating code compliant with Playwright\u2019s API (technically it outputs values\nthat are deterministically converted to Playwright code). Since this is the\ndominant paradigm for integrating with most software systems today, it seems\nreasonable to assume that LLMs will continue to generate code to interact with\nexisting systems over the long term. However, software systems communicating\nautonomously over natural language (in the BetaTester example, it just tells\nthe browser, \u201cclick this button\u201d) will also exist, in which case whether code\nor natural language is used is probably determined by the specific system\nconstraints (safety, robustness, etc.).\n\n### Improving Reasoning#\n\nI find that writing code can help me reason about the business logic of a\nsystem, revealing gaps in the design / specification of the system from an\noperational perspective. Writing code might help LLMs detect flaws in their\nown reasoning, and I have seen cases where the LLM generated the incorrect\noutput when prompted directly but the LLM generated code provided the correct\noutput. It\u2019s hard to know how true this will be as LLMs get smarter, but it\ndoes seem like something that could be tested empirically (maybe it already\nhas?).\n\n  * llm\n  * code-generation\n\nShare this post on:\n\nShare this post via WhatsApp Share this post on Facebook Tweet this post Share\nthis post via Telegram Share this post on Pinterest Share this post via email\n\nGithub LinkedIn\n\nCopyright \u00a9 2024 | All rights reserved.\n\n", "frontpage": false}

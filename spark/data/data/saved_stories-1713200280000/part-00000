{"aid": "40038860", "title": "SQL Optimizations in PostgreSQL: IN vs. Exists vs. Any/All vs. Join", "url": "https://www.percona.com/blog/sql-optimizations-in-postgresql-in-vs-exists-vs-any-all-vs-join/", "domain": "percona.com", "votes": 2, "user": "tie-in", "posted_at": "2024-04-15 10:56:16", "comments": 0, "source_title": "SQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN", "source_text": "SQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website utilizes technologies such as cookies to enable essential site\nfunctionality, as well as for analytics, personalization, and targeted\nadvertising purposes. You may change your settings at any time or accept the\ndefault settings. You may close this banner to continue with only essential\ncookies. Privacy Policy\n\n  * Contact us\n\nSelect Page\n\n  * Solutions\n\n    * Solutions Dropdown\n\nFeatured\n\n#### MySQL 5.7 End of Life\n\nLearn More\n\n#### Compare Percona to Leading Database Solutions\n\nStart\n\nPercona Products\n\n    * MySQL\n\nSoftware Support and Services\n\n    * MongoDB\n\nSoftware Support and Services\n\n    * PostgreSQL\n\nSoftware Support and Services\n\n    * Cloud Native\n\nSoftware Support and Services\n\n    * Monitoring\n    * Percona Toolkit\n\nPercona Services\n\n    * Support\n    * Managed Services\n    * Consulting\n    * Policies\n    * Training\n\nUse Cases\n\n    * Emergency Support\n    * High-Traffic Events\n    * Performance Tuning\n    * Migrations\n    * Upgrades\n    * Security\n\n  * Resources\n\n    * Learn Dropdown\n\nPercona Resources\n\n#### Software Downloads\n\nAll of Percona\u2019s open-source software products, in one place, to download as\nmuch or as little as you need.\n\nView Downloads\n\n#### Product Documentation\n\nA single source for documentation on all of Percona\u2019s leading, open-source\nsoftware.\n\nView Documentation\n\n#### Resource Hub\n\nA single source for all resources\n\nWebinars\n\nPresentations\n\nDatasheets\n\nEbooks\n\nDownloads\n\nSolution Briefs\n\nCase Studies\n\nPercona Videos\n\nWhite Papers\n\nDocumentation\n\nView All Resources\n\n#### Financial Services\n\nLearn More\n\n#### Driving Database Success\n\nRead the Report\n\n  * Community\n\n    * Discover Dropdown\n\nPercona Blog\n\n#### Percona Blog\n\nOur popular knowledge center for all Percona products and all related topics.\n\nView The Blog\n\nCommunity\n\n#### Percona Community Hub\n\nA place to stay in touch with the open-source community\n\nForums\n\nCommunity Blog\n\nPMM Contributions\n\nExplore The Community\n\nEvents\n\n#### Percona Events Hub\n\nSee all of Percona\u2019s upcoming events and view materials like webinars and\nforums from past events\n\nPercona Live 2023\n\nUpcoming Events\n\nView Our Events\n\n  * About\n\n    * About Dropdown\n\nAbout\n\n#### About Percona\n\nPercona is an open source database software, support, and services company\nthat helps make databases and applications run better.\n\nLearn More\n\n#### Percona in the News\n\nSee Percona\u2019s recent news coverage, press releases and industry recognition\nfor our open source software and support.\n\nNews coverage\n\nPress Releases\n\n#### Our Customers\n\nLearn More\n\n#### Our Partners\n\nLearn More\n\n#### Careers\n\nLearn More\n\n#### Contact Us\n\nLet's Talk\n\nInsight for DBAs Insight for Developers PostgreSQL\n\nSubscribe to RSS Feed\n\n# SQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN\n\nApril 16, 2020\n\nJobin Augustine\n\nThis is one of the most common questions asked by developers who write SQL\nqueries against the PostgreSQL database. There are multiple ways in which a\nsub select or lookup can be framed in a SQL statement. PostgreSQL optimizer is\nvery smart at optimizing queries, and many of the queries can be\nrewritten/transformed for better performance.\n\nLet\u2019s discuss the topic with an example, for which I am using schema created\nby pgbench.\n\nNote: For those not familiar with pgbench, it is a micro benchmarking tool\nshipped with PostgreSQL. A sample pgbench schema can be initialized with some\ndata as follows:\n\nShell\n\n1| pgbench -i -s 10  \n---|---  \n  \nFor this example, I have updated the branch balance of a couple of branches:\n\nShell\n\n1| update pgbench_branches set bbalance=4500000 where bid in (4,7);  \n---|---  \n  \n### INclusion Queries\n\nThe SQL Challenge for this example is: Find out the number of accounts per\nbranch from pgbench_accounts for those branches where branch level balance is\ngreater than zero. This query can be written in four different ways, as per\nANSI SQL Standards.\n\n#### 1\\. Using IN Clause\n\nShell\n\n123| SELECT count(aid),bid FROM pgbench_accounts WHEREbid in (SELECT bid FROM\npgbench_branches WHERE bbalance > 0)GROUP BY bid;  \n---|---  \n  \n#### 2\\. Using ANY Clause\n\nShell\n\n123| SELECT count(aid),bid FROM pgbench_accounts WHEREbid = ANY(SELECT bid\nFROM pgbench_branches WHERE bbalance > 0)GROUP BY bid;  \n---|---  \n  \n#### 3\\. Using EXISTS Clause\n\nShell\n\n12345| SELECT count(aid),bidFROM pgbench_accounts WHERE EXISTS(SELECT bid FROM\npgbench_branches WHERE bbalance > 0AND pgbench_accounts.bid =\npgbench_branches.bid)GROUP BY bid;  \n---|---  \n  \n#### 4\\. Using INNER JOIN\n\nShell\n\n12345| SELECT count(aid),a.bidFROM pgbench_accounts aJOIN pgbench_branches b\nON a.bid = b.bidWHERE b.bbalance > 0GROUP BY a.bid;  \n---|---  \n  \nWhile writing the query, one might assume that EXISTS and INNER JOIN might be\nbetter because they can use all the logic and optimization for joining two\ntables, while IN and ANY clauses need to deal with subqueries. However,\nPostgreSQL (at least PG 10 and above) is smart enough to produce the same\nexecution plan for all four options!.\n\nAll of the above queries will be generating the same execution plan as\nfollows:\n\nShell\n\n12345678910111213| HashAggregate (cost=31132.65..31132.75 rows=10 width=12)\n(actual time=279.625..279.626 rows=2 loops=1)Group Key: a.bid-> Hash Join\n(cost=1.15..30132.65 rows=200000 width=8) (actual time=63.686..242.956\nrows=200000 loops=1)Hash Cond: (a.bid = b.bid)-> Seq Scan on pgbench_accounts\na (cost=0.00..26394.00 rows=1000000 width=8) (actual time=0.012..86.250\nrows=1000000 loops=1)-> Hash (cost=1.12..1.12 rows=2 width=4) (actual\ntime=0.016..0.016 rows=2 loops=1)Buckets: 1024 Batches: 1 Memory Usage: 9kB->\nSeq Scan on pgbench_branches b (cost=0.00..1.12 rows=2 width=4) (actual\ntime=0.010..0.012 rows=2 loops=1)Filter: (bbalance > 0)Rows Removed by Filter:\n8Planning Time: 0.257 msExecution Time: 279.703 ms(12 rows)  \n---|---  \n  \nNote: Suppress the parallel execution for better readability and a simple\nexecution plan. Even with a parallel execution plan, all the queries are\nproducing the same execution plan.\n\nSo can we conclude that we can write the query as we are comfortable and\nPostgreSQL\u2019s intelligence will take care of the rest? Wait! Things can go\ndifferently if we take the exclusion scenario.\n\n### Exclusion Queries\n\nThe SQL challenge becomes: Find out the number of accounts per branch from\npgbench_accounts EXCEPT for those branches where branch level balance is\ngreater than zero.\n\nSo the four ways to write queries becomes:\n\n#### 1\\. Using NOT IN\n\nShell\n\n123| SELECT count(aid),bid FROM pgbench_accounts WHEREbid NOT IN (SELECT bid\nFROM pgbench_branches WHERE bbalance > 0)GROUP BY bid;  \n---|---  \n  \n#### 2\\. Using <> ALL\n\nShell\n\n123| SELECT count(aid),bid FROM pgbench_accounts WHEREbid <> ALL(SELECT bid\nFROM pgbench_branches WHERE bbalance > 0)GROUP BY bid;  \n---|---  \n  \n#### 3\\. Using NOT EXISTS\n\nShell\n\n12345| SELECT count(aid),bidFROM pgbench_accounts WHERE NOT EXISTS(SELECT bid\nFROM pgbench_branches WHERE bbalance > 0AND pgbench_accounts.bid =\npgbench_branches.bid)GROUP BY bid;  \n---|---  \n  \n#### 4\\. Using LEFT JOIN and IS NULL\n\nShell\n\n12345| SELECT count(aid),a.bidFROM pgbench_accounts aLEFT JOIN\npgbench_branches b ON a.bid = b.bid AND b.bbalance > 0WHERE b.bid IS NULLGROUP\nBY a.bid;  \n---|---  \n  \nThe \u201cNOT IN\u201d and \u201c<> ALL\u201d produces an execution plan with sub-queries\n(SubPlan). They are respectively:\n\nShell\n\n123456789101112| HashAggregate (cost=31395.13..31395.23 rows=10 width=12)\n(actual time=395.297..395.299 rows=8 loops=1)Group Key: pgbench_accounts.bid->\nSeq Scan on pgbench_accounts (cost=1.13..28895.13 rows=500000 width=8) (actual\ntime=0.042..250.086 rows=800000 loops=1)Filter: (NOT (hashed SubPlan 1))Rows\nRemoved by Filter: 200000SubPlan 1-> Seq Scan on pgbench_branches\n(cost=0.00..1.12 rows=2 width=4) (actual time=0.010..0.012 rows=2\nloops=1)Filter: (bbalance > 0)Rows Removed by Filter: 8Planning Time: 0.197\nmsExecution Time: 395.363 ms(11 rows)  \n---|---  \n  \nand\n\nShell\n\n12345678910111213| HashAggregate (cost=601394.00..601394.10 rows=10 width=12)\n(actual time=731.987..731.989 rows=8 loops=1)Group Key: pgbench_accounts.bid->\nSeq Scan on pgbench_accounts (cost=0.00..598894.00 rows=500000 width=8)\n(actual time=0.041..579.264 rows=800000 loops=1)Filter: (SubPlan 1)Rows\nRemoved by Filter: 200000SubPlan 1-> Materialize (cost=0.00..1.14 rows=2\nwidth=4) (actual time=0.000..0.000 rows=2 loops=1000000)-> Seq Scan on\npgbench_branches (cost=0.00..1.12 rows=2 width=4) (actual time=0.010..0.012\nrows=2 loops=1)Filter: (bbalance > 0)Rows Removed by Filter: 8Planning Time:\n0.203 msExecution Time: 732.142 ms(12 rows)  \n---|---  \n  \nWhile NOT EXISTS and LEFT JOIN produces the same execution plan without a sub-\nplan as follows:\n\nShell\n\n12345678910111213| HashAggregate (cost=41245.15..41245.25 rows=10 width=12)\n(actual time=500.193..500.195 rows=8 loops=1)Group Key: a.bid-> Hash Anti Join\n(cost=1.15..37245.15 rows=800000 width=8) (actual time=0.041..344.845\nrows=800000 loops=1)Hash Cond: (a.bid = b.bid)-> Seq Scan on pgbench_accounts\na (cost=0.00..26394.00 rows=1000000 width=8) (actual time=0.013..110.645\nrows=1000000 loops=1)-> Hash (cost=1.12..1.12 rows=2 width=4) (actual\ntime=0.018..0.018 rows=2 loops=1)Buckets: 1024 Batches: 1 Memory Usage: 9kB->\nSeq Scan on pgbench_branches b (cost=0.00..1.12 rows=2 width=4) (actual\ntime=0.011..0.012 rows=2 loops=1)Filter: (bbalance > 0)Rows Removed by Filter:\n8Planning Time: 0.248 msExecution Time: 500.266 ms(12 rows)  \n---|---  \n  \nThese direct hash (anti) joins between the tables is the smartest way to\nanswer the query. So this stands as a strong reason for recommending the\nEXISTS syntax or JOIN syntax. So the general rule of thumb favoring\nEXISTS/JOINs is holding good.\n\nBut wait! Do we see a better execution time with the NOT IN clause even with a\nsub-plan? Yes. PostgreSQL has done excellent optimization, thereby preparing a\nHash of sub-plan NOT (hashed SubPlan 1). So PostgreSQL has a better\nunderstanding of how to deal with an IN clause, which is the logical way of\nthinking, as many people tend to write with IN clause. But we have very few\nrows (two) returned by sub-plan. The same happens even if the subquery returns\na few hundred rows.\n\nBut what if there is a large number of rows (few hundreds of thousands of\nrows) returned by subquery? Let\u2019s try a simple example:\n\nShell\n\n12345678910111213| CREATE TABLE t1 ASSELECT * FROM generate_series(0, 500000)\nid;CREATE TABLE t2 ASSELECT (random() * 4000000)::integer idFROM\ngenerate_series(0, 4000000);ANALYZE t1;ANALYZE t2;EXPLAIN SELECT idFROM\nt1WHERE id NOT IN (SELECT id FROM t2);  \n---|---  \n  \nIn this case, the execution plan is:\n\nShell\n\n123456| Seq Scan on t1 (cost=0.00..2583268004.52 rows=250000 width=4)Filter:\n(NOT (SubPlan 1))SubPlan 1-> Materialize (cost=0.00..9333.01 rows=400001\nwidth=4)-> Seq Scan on t2 (cost=0.00..5770.01 rows=400001 width=4)(5 rows)  \n---|---  \n  \nIn this case, the execution plan switches to the materialization of the result\nof the sub-plan, and the estimated cost jumps to 25831564501.02! (With\nPostgreSQL default settings, if the number of rows from t2 is lesser than 100k\napproximately, it uses the hashed sub-plan as we discussed.) This will result\nin substantial degradation of performance. So the IN clause works great if the\nsub-plan selects a fewer number of rows.\n\nThe catch here is when development happens, there will be fewer rows in\ntables, and it works differently as the number of rows increases, as the\nexecution plan drifts and can result in big performance issues in live\nproduction.\n\n### Is There More Complexity We Should Be Aware Of?\n\nYes, there could be datatype conversions happening when we write the query in\na different way.\n\nFor example, a statement like:\n\nShell\n\n1| EXPLAIN ANALYZE SELECT * FROM emp WHERE gen = ANY(ARRAY['M','F']);  \n---|---  \n  \nis resulting in implicit datatype conversion of the values of the fields to\ntext.\n\nShell\n\n12| Seq Scan on emp (cost=0.00..1.04 rows=2 width=43) (actual\ntime=0.023..0.026 rows=3 loops=1)Filter: ((gen)::text = ANY ('{M,F}'::text[]))  \n---|---  \n  \nPlease note the datatype conversion: (gen)::text . On a big table, this type\nof conversion will have overhead, whereas PostgreSQL does a better job in\ndealing with the IN clause.\n\nShell\n\n1234| EXPLAIN ANALYZE SELECT * FROM emp WHERE gen IN ('M','F');Seq Scan on emp\n(cost=0.00..1.04 rows=3 width=43) (actual time=0.030..0.034 rows=3\nloops=1)Filter: (gen = ANY ('{M,F}'::bpchar[]))  \n---|---  \n  \nEven though the IN clause is converted into the ANY clause, there is no data\ntype conversion of the \u201cgen\u201d field. And the specified values \u2018M\u2019,\u2019F\u2019 are\nconverted into bpchar, which is an internal equivalent of CHAR.\n\n## Summary\n\nMy intention while writing this blog post is not to favor any particular way\nof writing a query, but to shed some light on where things can go wrong and\nwhat should be considered.\n\nIn general, I used to suggest to developers that the key to writing a good SQL\nstatement is to follow step by step process.\n\n  1. First, make a list of tables from which the data should be retrieved.\n  2. Then think about how to JOIN those tables.\n  3. Think about how to have the minimum records participating in the join condition.\n\nAvoid thinking from \u201cHow to break the logic\u201d into subqueries.\n\nNever assume that the query is performing well with a small amount of data in\nthe table.\n\nUse an EXPLAIN plan to understand what is going on in the background.\n\nIn general, EXISTS and direct JOIN of tables often results in good results.\nPostgreSQL optimizes the IN clause to a hashed sub-plan in many cases. \u201cIN\u201d\ncan result in a better plan and execution in some specific situations. Again,\neverything depends on how a query is rewritten/transformed internally. It is\nworth investing time in rewriting queries for better optimization.\n\nOur white paper \u201cWhy Choose PostgreSQL?\u201d looks at the features and benefits of\nPostgreSQL and presents some practical usage examples. We also examine how\nPostgreSQL can be useful for companies looking to migrate from Oracle.\n\nDownload PDF\n\nDeploy Highly Available PostgreSQL from Percona\n\n### Related\n\nStreamline the SQL Code: Guide to pgFormatterAugust 16, 2023In \"Insight for\nDBAs\"\n\nPostgreSQL: Are All NULLs the Same?November 4, 2022In \"Insight for DBAs\"\n\nDeep Dive Into PostgreSQL Indexes \u2013 Free Course at Percona University\nOnlineNovember 9, 2020In \"Insight for DBAs\"\n\nArray\n\n### Share This Post!\n\n5 Comments\n\nOldest\n\nNewest Most Voted\n\nInline Feedbacks\n\nView all comments\n\nStanislav Sumariuk\n\n3 years ago\n\nI will definitely revisit some of my queries. Thank you for this post.\n\n0\n\nScott C.\n\n3 years ago\n\nThe exclusion queries are not equivalent and can produce vastly different\nresults. Just try it where the exclusion set contains 100 values, one of which\nis null.\n\n1\n\nFrancisco Puga\n\n3 years ago\n\nReally nice post.\n\nI know that is centered on performance but as some people points that NOT IN\nis a don\u2019t [1], include a note about how NULLs are handled in the different\noptions or at least writing a warn about it will be nice.\n\n[1] https://wiki.postgresql.org/wiki/Don't_Do_This\n\n0\n\nharisai hari\n\n3 years ago\n\nI personally like the first scenario, no problem you can call me a lazy DBA. I\nalways afraid of exclusion queries triggered by tall developers.\n\n0\n\nRajat Gupta\n\n3 years ago\n\nTrying to assess a situation where from a heavy table in PostgreSQL, data is\nfetched using an API and filter is applied making use of an IN clause and the\nvalues to filter are passed in a measure of few thousands. Will psql still use\nthe in clause optimally? or some other construct suits well?\n\n0\n\n## Want to get weekly updates listing the latest blog posts?\n\nSubscribe now and we'll send you an update every Friday at 1pm ET.\n\n## Related Blog Articles\n\n### RECOMMENDED ARTICLES\n\nApril 12, 2024\n\nNinad Shah\n\n## Partially Rolling Back a Transaction in MySQL or PostgreSQL\n\nInsight for DBAs MySQL PostgreSQL\n\nApril 11, 2024\n\nDavid Stokes\n\n## JSON_TABLE() Will Be in PostgreSQL 17\n\nInsight for DBAs PostgreSQL\n\nApril 11, 2024\n\nBrijesh Chauhan\n\n## How to Replicate and Rename a Database in MariaDB\n\nInsight for DBAs MariaDB MySQL\n\n### MOST POPULAR ARTICLES\n\nDecember 28, 2012\n\nMiguel Angel Nieto\n\n## Auditing login attempts in MySQL\n\nMySQL\n\nJune 20, 2023\n\nSergey Pronin\n\n## Deploy Django on Kubernetes With Percona Operator for PostgreSQL\n\nCloud Insight for Developers Percona Software PostgreSQL\n\nMay 16, 2016\n\nMuhammad Irfan\n\n## MySQL \u201cGot an error reading communication packet\u201d\n\nMySQL\n\n## Ready to get started?\n\nSubscribe to our newsletter for updates on enterprise-grade open source\nsoftware and tools to keep your business running better.\n\nBy submitting my information I agree that Percona may use my personal data in\nsending communication to me about Percona services. I understand that I can\nunsubscribe from the communication at any time in accordance with the Percona\nPrivacy Policy.This site is protected by reCAPTCHA and the Google Privacy\nPolicy and Terms of Service apply.\n\n## Follow us for updates\n\n  * Twitter\n  * Facebook\n  * LinkedIn\n  * Instagram\n  * GitHub\n\n#### Featured\n\n  * MySQL 5.7 End of Life\n  * Learn\n  * Downloads\n  * Resources\n  * Docs\n\n#### Products\n\n  * MySQL\n\n    * Distribution for MySQL\n    * Server for MySQL\n    * XtraDB Cluster\n    * XtraBackup for MySQL Databases\n  * MongoDB\n\n    * Distribution for MongoDB\n    * Server for MongoDB\n    * Backup for MongoDB\n  * PostgreSQL\n\n    * Software\n    * Support and Services\n  * Cloud Native\n  * Monitoring\n  * Percona Toolkit\n\n#### Services\n\n  * Support\n  * Managed Services\n  * Consulting\n  * Policies\n  * Training\n\n#### Use Cases\n\n  * Emergency Support\n  * High-Traffic Events\n  * Performance Tuning\n  * Migrations\n  * Upgrades\n  * Security\n\n#### Discover\n\n  * Blog\n  * Community\n  * Percona Community Forum\n  * Events\n\n#### About\n\n  * About Percona\n  * Partners\n  * In The News\n  * Careers\n\n  * Terms of Use\n  * Privacy\n  * Copyright\n  * Legal\n  * Security Center\n\nMySQL, PostgreSQL, InnoDB, MariaDB, MongoDB and Kubernetes are trademarks for\ntheir respective owners.\n\nCopyright \u00a9 2006-2023 Percona LLC.\n\nwpDiscuz\n\n", "frontpage": false}

{"aid": "39995230", "title": "How to Stop Your Data from Being Used to Train AI", "url": "https://www.wired.com/story/how-to-stop-your-data-from-being-used-to-train-ai/", "domain": "wired.com", "votes": 1, "user": "CharlesW", "posted_at": "2024-04-10 20:13:07", "comments": 0, "source_title": "How to Stop Your Data From Being Used to Train AI", "source_text": "How to Stop Your Data From Being Used to Train AI | WIRED\n\nSkip to main content\n\nTo revisit this article, visit My Profile, then View saved stories.\n\nHow to Stop Your Data From Being Used to Train AI\n\nTo revisit this article, visit My Profile, then View saved stories.\n\nSign In\n\nSUBSCRIBE\n\n# Get WIRED\n\n# for just $29.99 $5\n\nSUBSCRIBE\n\nSearch\n\n  * Security\n  * Politics\n  * Gear\n  * Backchannel\n  * Business\n  * Science\n  * Culture\n  * Ideas\n  * Merch\n\n  * Podcasts\n  * Video\n  * Newsletters\n  * Magazine\n  * Events\n  * WIRED Insider\n  * WIRED Consulting\n  * Jobs\n  * Coupons\n\nON SALE NOWGet WIRED - now only $29.99 $5This is your last free article. Get 1\nyear of unlimited access.SUBSCRIBE NOW\n\nAlready a subscriber? Sign in\n\nGet WIRED - now only $29.99 $5. SUBSCRIBE NOW\n\nMatt Burgess Reece Rogers\n\nSecurity\n\nApr 10, 2024 7:30 AM\n\n# How to Stop Your Data From Being Used to Train AI\n\nSome companies let you opt out of allowing your content to be used for\ngenerative AI. Here\u2019s how to take back (at least a little) control from\nChatGPT, Google\u2019s Gemini, and more.\n\nPhotograph: liebre/Getty Images\n\nIf you\u2019ve ever posted something to the internet\u2014a pithy tweet, a 2009 blog\npost, a scornful review, or a selfie on Instagram\u2014it has most likely been\nslurped up and used to help train the current wave of generative AI. Large\nlanguage models, like ChatGPT, and image creators are powered by vast reams of\nour data. And even if it\u2019s not powering a chatbot, the data can be used for\nother machine-learning features.\n\nTech companies have scraped vast swathes of the web to gather the data they\nclaim is needed to create generative AI\u2014with little regard for content\ncreators, copyright laws, or privacy. On top of this, increasingly, firms with\nreams of people\u2019s posts are looking to get in on the AI gold rush by selling\nor licensing that information. Looking at you, Reddit.\n\nHowever, as the lawsuits and investigations around generative AI and its\nopaque data practices pile up, there have been small moves to give people more\ncontrol over what happens to what they post online. Some companies now let\nindividuals and business customers opt out of having their content used in AI\ntraining or being sold for training purposes. Here\u2019s what you can\u2014and\ncan\u2019t\u2014do.\n\n## There\u2019s a Limit\n\nBefore we get to how you can opt out, it\u2019s worth setting some expectations.\nMany companies building AI have already scraped the web, so anything you\u2019ve\nposted is probably already in their systems. Companies are also secretive\nabout what they have actually scraped, purchased, or used to train their\nsystems. \u201cWe honestly don't know that much,\u201d says Niloofar Mireshghallah, a\nresearcher who focuses on AI privacy at the University of Washington. \u201cIn\ngeneral, everything is very black-box.\u201d\n\nFeatured Video\n\nChatGPT Answers the Web's Most Searched Questions\n\nMireshghallah explains that companies can make it complicated to opt out of\nhaving data used for AI training, and even where it is possible, many people\ndon\u2019t have a \u201cclear idea\u201d about the permissions they\u2019ve agreed to or how data\nis being used. That\u2019s before various laws, such as copyright protections and\nEurope\u2019s strong privacy laws, are taken into consideration. Facebook, Google,\nX, and other companies have written into their privacy policies that they may\nuse your data to train AI.\n\nWhile there are various technical ways AI systems could have data removed from\nthem or \u201cunlearn,\u201d Mireshghallah says, there\u2019s very little that\u2019s known about\nthe processes that are in place. The options can be buried or labor-intensive.\nGetting posts removed from AI training data is likely to be an uphill battle.\nWhere companies are starting to allow opt-outs for future scraping or data\nsharing, they are almost always making users opt-in by default.\n\n\u201cMost companies add the friction because they know that people aren\u2019t going to\ngo looking for it,\u201d says Thorin Klosowski, a security and privacy activist at\nthe Electronic Frontier Foundation. \u201cOpt-in would be a purposeful action, as\nopposed to opting out, where you have to know it\u2019s there.\u201d\n\nMost Popular\n\n  * Science\n\nThe Best Total Solar Eclipse Photos\n\nKaren Williams\n\n  * Politics\n\nElon Musk Is Platforming Far-Right Activists in Brazil, Defying Court Order\n\nVittoria Elliott\n\n  * Business\n\nBeeper Took On Apple\u2019s iMessage Dominance. Now It\u2019s Been Acquired\n\nLauren Goode\n\n  * Science\n\nWatch the Total Solar Eclipse Online Here\n\nReece Rogers\n\nWhile less common, some companies building AI tools and machine learning\nmodels don't automatically opt-in customers. \u201cWe do not train our models on\nuser-submitted data by default. We may use user prompts and outputs to train\nClaude where the user gives us express permission to do so, such as clicking a\nthumbs up or down signal on a specific Claude output to provide us feedback,\u201d\nsays Jennifer Martinez, a spokesperson for Anthropic. In this situation, the\nmost recent iteration of the company\u2019s Claude chatbot is built on public\ninformation online and third-party data\u2014content people posted elsewhere\nonline\u2014but not user information.\n\nThe majority of this guide deals with opt-outs for text, but artists have also\nbeen using \u201cHave I Been Trained?\u201d to signal their images shouldn't be used for\ntraining. Run by startup Spawning, the service allows people to see if their\ncreations have been scraped and then opt out of any future training. \u201cAnything\nwith a URL can be opted out. Our search engine only searches images, but our\nbrowser extension lets you opt out any media type,\u201d says Jordan Meyer,\ncofounder and CEO of Spawning. Stability AI, the startup behind a text-to-\nimage tool called Stable Diffusion, is among companies that say they are\nhonoring the system.\n\nThe list below only includes companies currently with an opt-out process. For\nexample, Microsoft\u2019s Copilot does not offer users with personal accounts the\noption to have their prompts not used to improve the software. \u201cA portion of\nthe total number of user prompts in Copilot and Copilot Pro responses are used\nto fine-tune the experience,\u201d says Donny Turnbaugh, a spokesperson for\nCopilot. \u201cMicrosoft takes steps to deidentify data before it is used, helping\nto protect consumer identity.\u201d Even if the data is deidentified, privacy-\nminded users may want more potential control over their information.\n\n## How to Opt Out of AI Training\n\nAdobe\n\nAdobe via Matt Burgess\n\nIf you store your files in Adobe\u2019s Creative Cloud, the company may use them to\ntrain its machine-learning algorithm. \u201cWhen we analyze your content for\nproduct improvement and development purposes, we first aggregate your content\nwith other content and then use the aggregated content to train our algorithms\nand thus improve our products and services,\u201d reads the company\u2019s FAQ. This\ndoesn\u2019t apply to any files stored only on your device.\n\nMost Popular\n\n  * Science\n\nThe Best Total Solar Eclipse Photos\n\nKaren Williams\n\n  * Politics\n\nElon Musk Is Platforming Far-Right Activists in Brazil, Defying Court Order\n\nVittoria Elliott\n\n  * Business\n\nBeeper Took On Apple\u2019s iMessage Dominance. Now It\u2019s Been Acquired\n\nLauren Goode\n\n  * Science\n\nWatch the Total Solar Eclipse Online Here\n\nReece Rogers\n\nIf you\u2019re using a personal Adobe account, it\u2019s easy to opt out. Open up\nAdobe\u2019s privacy page, scroll down to the Content analysis section, and click\nthe toggle to turn it off. For business or school accounts, the opt-out\nprocess is not available on the individual level, and you\u2019ll have to reach out\nto your administrator.\n\nAmazon: AWS\n\nAI services from Amazon Web Services, like Amazon Rekognition or Amazon\nCodeWhisperer, may save customer data to improve the company\u2019s tools. Head\u2019s\nup, this is the most complicated opt-out process included in the roundup, so\nyou likely need help from an IT professional at your company or an AWS\nrepresentative to perform it successfully. Outlined on this support page from\nAmazon, the process includes enabling the option for your organization,\ncreating a policy, and attaching that policy where necessary.\n\nGoogle: Gemini\n\nFor users of Google\u2019s chatbot, Gemini, conversations may sometimes be selected\nfor human review to improve the AI model. Opting out is simple, though. Open\nup Gemini in your browser, click on Activity, and select the Turn Off drop-\ndown menu. Here you can just turn off the Gemini Apps Activity, or you can opt\nout as well as delete your conversation data. While this does mean in most\ncases that future chats won\u2019t be seen for human review, already selected data\nis not erased through this process. According to Google\u2019s privacy hub for\nGemini, these chats may stick around for three years.\n\nGrammarly\n\nGrammarly does not currently offer an opt-out process for personal accounts,\nbut self-serve business accounts can choose to opt out from having their data\nused to train Grammarly\u2019s machine-learning model. Turn it off by opening up\nyour Account Settings, clicking on the Data Settings tab, and toggling off\nProduct Improvement & Training. If you have a managed business account, which\nincludes accounts for classroom education and accounts bought through a\nGrammarly sales representative, you are automatically opted out from AI model\ntraining.\n\nHubSpot\n\nHubSpot, a popular marketing software, automatically uses data from customers\nto improve its machine-learning model. Unfortunately, there\u2019s not a button to\npress to turn off the use of data for AI training. You have to send an email\nto privacy@hubspot.com with a message requesting that the data associated with\nyour account be opted out.\n\nOpenAI: ChatGPT and Dall-E\n\nOpenAI via Matt Burgess\n\nPeople reveal all sorts of personal information while using a chatbot. OpenAI\nprovides some options for what happens to what you say to ChatGPT\u2014including\nallowing its future AI models not to be trained on the content. \u201cWe give users\na number of easily accessible ways to control their data, including self-\nservice tools to access, export, and delete personal information through\nChatGPT. That includes easily accessible options to opt out from the use of\ntheir content to train models,\u201d says Taya Christianson, an OpenAI\nspokesperson. (The options vary slightly depending on your account type, and\ndata from enterprise customers is not used to train models).\n\nMost Popular\n\n  * Science\n\nThe Best Total Solar Eclipse Photos\n\nKaren Williams\n\n  * Politics\n\nElon Musk Is Platforming Far-Right Activists in Brazil, Defying Court Order\n\nVittoria Elliott\n\n  * Business\n\nBeeper Took On Apple\u2019s iMessage Dominance. Now It\u2019s Been Acquired\n\nLauren Goode\n\n  * Science\n\nWatch the Total Solar Eclipse Online Here\n\nReece Rogers\n\nOn its help pages, OpenAI says ChatGPT web users without accounts should\nnavigate to Settings and then uncheck Improve the model for everyone. If you\nhave an account and are logged in through a web browser, select ChatGPT,\nSettings, Data Controls, and then turn off Chat History & Training. If you\u2019re\nusing ChatGPT\u2019s mobile apps, go to Settings, pick Data Controls, and turn off\nChat History & Training. Changing these settings, OpenAI\u2019s support pages say,\nwon\u2019t sync across different browsers or devices, so you need to make the\nchange everywhere you use ChatGPT.\n\nOpenAI is about a lot more than ChatGPT. For its Dall-E 3 image generator, the\nstartup has a form that allows you to send images to be removed from \u201cfuture\ntraining datasets.\u201d It asks for your name, email, whether you own the image\nrights or are getting in touch on behalf of a company, details of the image,\nand any uploads of the image(s). OpenAI also says if you have a \u201chigh volume\u201d\nof images hosted online that you want removed from training data, then it may\nbe \u201cmore efficient\u201d to add GPTBot to the robots.txt file of the website where\nthe images are hosted.\n\nTraditionally a website\u2019s robots.txt file\u2014a simple text file that usually sits\nat websitename.com/robots.txt\u2014has been used to tell search engines, and\nothers, whether they can include your pages in their results. It can now also\nbe used to tell AI crawlers not to scrape what you have published\u2014and AI\ncompanies have said they\u2019ll honor this arrangement.\n\nPerplexity\n\nPerplexity is a startup that uses AI to help you search the web and find\nanswers to questions. Like all of the other software on this list, you are\nautomatically opted in to having your interactions and data used to train\nPerplexity\u2019s AI further. Turn this off by clicking on your account name,\nscrolling down to the Account section, and turning off the AI Data Retention\ntoggle.\n\nQuora\n\nQuora via Matt Burgess\n\nQuora says it \u201ccurrently\u201d doesn\u2019t use answers to people\u2019s questions, posts, or\ncomments for training AI. It also hasn\u2019t sold any user data for AI training, a\nspokesperson says. However, it does offer opt-outs in case this changes in the\nfuture. To do this, visit its Settings page, click to Privacy, and turn off\nthe \u201cAllow large language models to be trained on your content\u201d option.\nDespite this choice, there are some Quora posts that may be used for training\nLLMs. If you reply to a machine-generated answer, the company\u2019s help pages\nsay, then those answers may be used for AI training. It points out that third\nparties may just scrape its content anyway.\n\nRev\n\nRev, a voice transcription service that uses both human freelancers and AI to\ntranscribe audio, says it uses data \u201cperpetually\u201d and \u201canonymously\u201d to train\nits AI systems. Even if you delete your account, it will still train its AI on\nthat information.\n\nKendell Kelton, head of brand and corporate communications at Rev, says it has\nthe \u201clargest and most diverse data set of voices,\u201d made up of more than 6.5\nmillion hours of voice recording. Kelton says Rev does not sell user data to\nany third parties. The firm\u2019s terms of service say data will be used for\ntraining, and that customers are able to opt out. People can opt out of their\ndata being used by sending an email to support@rev.com, its help pages say.\n\nSlack\n\nAll of those random Slack messages at work might be used by the company to\ntrain its models as well. \u201cSlack has used machine learning in its product for\nmany years. This includes platform-level machine-learning models for things\nlike channel and emoji recommendations,\u201d says Jackie Rocca, a vice president\nof product at Slack who\u2019s focused on AI.\n\nEven though the company does not use customer data to train a large language\nmodel for its Slack AI product, Slack may use your interactions to improve the\nsoftware\u2019s machine-learning capabilities. \u201cTo develop AI/ML models, our\nsystems analyze Customer Data (e.g. messages, content, and files) submitted to\nSlack,\u201d says Slack\u2019s privacy page. Similar to Adobe, there\u2019s not much you can\ndo on an individual level to opt out if you\u2019re using an enterprise account.\n\nMost Popular\n\n  * Science\n\nThe Best Total Solar Eclipse Photos\n\nKaren Williams\n\n  * Politics\n\nElon Musk Is Platforming Far-Right Activists in Brazil, Defying Court Order\n\nVittoria Elliott\n\n  * Business\n\nBeeper Took On Apple\u2019s iMessage Dominance. Now It\u2019s Been Acquired\n\nLauren Goode\n\n  * Science\n\nWatch the Total Solar Eclipse Online Here\n\nReece Rogers\n\nThe only real way to opt out is to have your administrator email Slack at\nfeedback@slack.com. The message must have the subject line \u201cSlack Global model\nopt-out request\u201d and include your organization's URL. Slack doesn\u2019t provide a\ntimeline for how long the opt-out process takes, but it should send you a\nconfirmation email after it\u2019s complete.\n\nSquarespace\n\nWebsite-building tool Squarespace has built in a toggle to stop AI crawlers\nfrom scraping websites it hosts. This works by updating your website\u2019s\nrobots.txt file to tell AI companies the content is off limits. To block the\nAI bots, open Settings within your account, find Crawlers, and turn off\nArtificial Intelligence Crawlers. It points out this should work for the\nfollowing crawlers: Anthropic, OpenAI\u2019s GPTBot and ChatGPT-User, Google\nExtended, and CCBot.\n\nSubstack\n\nIf you use Substack for blog posts, newsletters, or more, the company also has\nan easy option to apply the robots.txt opt-out. Within your Settings page,\nscroll to the Publication section and turn on the toggle to Block AI training.\nIts help page points out: \u201cThis will only apply to AI tools that respect this\nsetting.\u201d\n\nTumblr\n\nBlogging and publishing platform Tumblr\u2014owned by Automattic, which also owns\nWordPress\u2014says it is \u201cworking with\u201d AI companies that are \u201cinterested in the\nvery large and unique set of publicly published content\u201d on the wider\ncompany\u2019s platforms. This doesn\u2019t include user emails or private content, an\nAutomattic spokesperson says.\n\nTumblr has a \u201cprevent third-party sharing\u201d option to stop what you publish\nbeing used for AI training, as well as being shared with other third parties\nsuch as researchers. If you\u2019re using the Tumblr app, go to account Settings,\nselect your blog, click on the gear icon, select Visibility, and toggle the\n\u201cPrevent third-party sharing\u201d option. Explicit posts, deleted blogs, and those\nthat are password-protected or private, are not shared with third-party\ncompanies in any case, Tumblr\u2019s support pages say.\n\nWordPress\n\nWordpress via Matt Burgess\n\nLike Tumblr, WordPress has a \u201cprevent third-party sharing\u201d option. To turn\nthis on, visit your website\u2019s dashboard, click on Settings, General, and then\nthrough to Privacy, select the Prevent third-party sharing box. \u201cWe are also\ntrying to work with crawlers (like https://commoncrawl.org/) to prevent\ncontent from being scraped and sold without giving our users choice or control\nover how their content is used,\u201d an Automattic spokesperson says.\n\nYour Website\n\nIf you are hosting your own website, you can update your robots.txt file to\ntell AI bots not to scrape the pages. Most news websites don\u2019t allow their\narticles to be crawled by AI bots. WIRED\u2019s robots.txt file, for example,\ndoesn\u2019t allow bots from OpenAI, Google, Amazon, Facebook, Anthropic, or\nPerplexity, among others. This opt-out isn\u2019t just for publishers though: Any\nwebsite, big or small, can alter its robots file to exclude AI crawlers. All\nyou need to do is add a disallow command; working examples can be found here.\n\n## You Might Also Like ...\n\n  * In your inbox: Introducing Politics Lab, your guide to election season\n\n  * Think Google\u2019s \u201cIncognito mode\u201d protects your privacy? Think again\n\n  * Blowing the whistle on sexual harassment and assault in Antarctica\n\n  * The earth will feast on dead cicadas\n\n  * Upgrading your Mac? Here\u2019s what you should spend your money on\n\nMatt Burgess is a senior writer at WIRED focused on information security,\nprivacy, and data regulation in Europe. He graduated from the University of\nSheffield with a degree in journalism and now lives in London. Send tips to\nMatt_Burgess@wired.com.\n\nSenior writer\n\nReece Rogers is WIRED's service writer, focused on explaining crucial topics\nand helping readers get the most out of their technology. Prior to WIRED, he\ncovered streaming at Insider.\n\nService Writer\n\nTopicsChatGPTOpenAIartificial intelligenceprivacyGoogle GeminiMicrosoft\n\nMore from WIRED\n\nIt's Time to Switch to a Privacy-Focused Browser You Can Trust\n\nAd trackers are out of control. Use a browser that reins them in.\n\nDavid Nield\n\nSome of the Most Popular Websites Share Your Data With Over 1,500 Companies\n\nCookie pop-ups now show the number of \u201cpartners\u201d that websites may share data\nwith. Here's how many of these third-party companies may get your data from\nsome of the most popular sites online.\n\nMatt Burgess\n\nGlassdoor Wants to Know Your Real Name\n\nAnonymous, candid reviews made Glassdoor a powerful place to research\npotential employers. A policy shift requiring users to privately verify their\nreal names is raising privacy concerns.\n\nAmanda Hoover\n\nThe Incognito Mode Myth Has Fully Unraveled\n\nTo settle a years-long lawsuit, Google has agreed to delete \u201cbillions of data\nrecords\u201d collected from users of \u201cIncognito mode,\u201d illuminating the pitfalls\nof relying on Chrome to protect your privacy.\n\nDell Cameron\n\nThe XZ Backdoor: Everything You Need to Know\n\nDetails are starting to emerge about a stunning supply chain attack that sent\nthe open source software community reeling.\n\nDan Goodin, Ars Technica\n\nHow to Protect Yourself (and Your Loved Ones) From AI Scam Calls\n\nAI tools are getting better at cloning people\u2019s voices, and scammers are using\nthese new capabilities to commit fraud. Avoid getting swindled by following\nthese expert tips.\n\nReece Rogers\n\nApple Chip Flaw Leaks Secret Encryption Keys\n\nPlus: The Biden administration warns of nationwide attacks on US water\nsystems, a new Russian wiper malware emerges, and China-linked hackers wage a\nglobal attack spree.\n\nAndrew Couts\n\n\u2018Malicious Activity\u2019 Hits the University of Cambridge\u2019s Medical School\n\nMultiple university departments linked to the Clinical School Computing\nService have been inaccessible for a month. The university has not revealed\nthe nature of the \u201cmalicious activity.\u201d\n\nMatt Burgess\n\n# One year for $29.99 $5\n\nSUBSCRIBE\n\nWIRED is where tomorrow is realized. It is the essential source of information\nand ideas that make sense of a world in constant transformation. The WIRED\nconversation illuminates how technology is changing every aspect of our\nlives\u2014from culture to business, science to design. The breakthroughs and\ninnovations that we uncover lead to new ways of thinking, new connections, and\nnew industries.\n\n\u00a9 2024 Cond\u00e9 Nast. All rights reserved. WIRED may earn a portion of sales from\nproducts that are purchased through our site as part of our Affiliate\nPartnerships with retailers. The material on this site may not be reproduced,\ndistributed, transmitted, cached or otherwise used, except with the prior\nwritten permission of Cond\u00e9 Nast. Ad Choices\n\n###### Select international site\n\n  * Italia\n  * Jap\u00f3n\n  * Czech Republic & Slovakia\n\n## We Care About Your Privacy\n\nWe and our 167 partners store and/or access information on a device, such as\nunique IDs in cookies to process personal data. You may accept or manage your\nchoices by clicking below or at any time in the privacy policy page. These\nchoices will be signaled to our partners and will not affect browsing\ndata.More Information\n\n### We and our partners process data to provide:\n\nUse precise geolocation data. Actively scan device characteristics for\nidentification. Store and/or access information on a device. Personalised\nadvertising and content, advertising and content measurement, audience\nresearch and services development.\n\n", "frontpage": false}

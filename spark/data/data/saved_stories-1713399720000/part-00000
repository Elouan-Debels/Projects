{"aid": "40068331", "title": "AI Chip Trims Energy Budget Back by 99 Percent", "url": "https://spectrum.ieee.org/optical-neural-network", "domain": "ieee.org", "votes": 1, "user": "rbanffy", "posted_at": "2024-04-17 18:20:43", "comments": 0, "source_title": "AI Chip Trims Energy Budget Back by 99+ Percent", "source_text": "AI Chip Trims Energy Budget Back by 99+ Percent - IEEE Spectrum\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website utilizes technologies such as cookies to enable essential site\nfunctionality, as well as for analytics, personalization, and targeted\nadvertising purposes. You may change your settings at any time or accept the\ndefault settings. You may close this banner to continue with only essential\ncookies. Privacy Policy\n\nStorage Preferences\n\nIEEE.orgIEEE Xplore Digital LibraryIEEE StandardsMore Sites\n\nSign InJoin IEEE\n\nHey there, human \u2014 the robots need you! Vote for IEEE\u2019s Robots Guide in the\nWebby Awards.\n\nVote for Robots \u2192\n\nClose bar\n\nAI Chip Trims Energy Budget Back by 99+ Percent\n\nShare\n\nFOR THE TECHNOLOGY INSIDER\n\nExplore by topic\n\nAerospaceArtificial IntelligenceBiomedicalClimate TechComputingConsumer\nElectronicsEnergyHistory of\nTechnologyRoboticsSemiconductorsTelecommunicationsTransportation\n\nIEEE Spectrum\n\nFOR THE TECHNOLOGY INSIDER\n\n### Topics\n\nAerospaceArtificial IntelligenceBiomedicalClimate TechComputingConsumer\nElectronicsEnergyHistory of\nTechnologyRoboticsSemiconductorsTelecommunicationsTransportation\n\n### Sections\n\nFeaturesNewsOpinionCareersDIYEngineering Resources\n\n### More\n\nNewslettersPodcastsSpecial ReportsCollectionsExplainersTop Programming\nLanguagesRobots Guide \u2197IEEE Job Site \u2197\n\n### For IEEE Members\n\nCurrent IssueMagazine ArchiveThe InstituteThe Institute Archive\n\n### For IEEE Members\n\nCurrent IssueMagazine ArchiveThe InstituteThe Institute Archive\n\n### IEEE Spectrum\n\nAbout UsContact UsReprints & Permissions \u2197Advertising \u2197\n\n### Follow IEEE Spectrum\n\n### Support IEEE Spectrum\n\nIEEE Spectrum is the flagship publication of the IEEE \u2014 the world\u2019s largest\nprofessional organization devoted to engineering and applied sciences. Our\narticles, podcasts, and infographics inform our readers about developments in\ntechnology, engineering, and science.\n\nJoin IEEE\n\nSubscribe\n\nAbout IEEEContact & SupportAccessibilityNondiscrimination PolicyTermsIEEE\nPrivacy PolicyCookie PreferencesAd Privacy Options\n\n\u00a9 Copyright 2024 IEEE \u2014 All rights reserved. A not-for-profit organization,\nIEEE is the world's largest technical professional organization dedicated to\nadvancing technology for the benefit of humanity.\n\n## Enjoy more free content and benefits by creating an account\n\n## Saving articles to read later requires an IEEE Spectrum account\n\n## The Institute content is only available for members\n\n## Downloading full PDF issues is exclusive for IEEE Members\n\n## Downloading this e-book is exclusive for IEEE Members\n\n## Access to Spectrum 's Digital Edition is exclusive for IEEE Members\n\n## Following topics is a feature exclusive for IEEE Members\n\n## Adding your response to an article requires an IEEE Spectrum account\n\n## Create an account to access more content and features on IEEE Spectrum ,\nincluding the ability to save articles to read later, download Spectrum\nCollections, and participate in conversations with readers and editors. For\nmore exclusive content and features, consider Joining IEEE .\n\n## Join the world\u2019s largest professional organization devoted to engineering\nand applied sciences and get access to all of Spectrum\u2019s articles, archives,\nPDF downloads, and other benefits. Learn more \u2192\n\n## Join the world\u2019s largest professional organization devoted to engineering\nand applied sciences and get access to this e-book plus all of IEEE Spectrum\u2019s\narticles, archives, PDF downloads, and other benefits. Learn more \u2192\n\nCREATE AN ACCOUNTSIGN IN\n\nJOIN IEEESIGN IN\n\nClose\n\n## Access Thousands of Articles \u2014 Completely Free\n\n## Create an account and get exclusive content and features: Save articles,\ndownload collections, and talk to tech insiders \u2014 all free! For full access\nand benefits, join IEEE as a paying member.\n\nCREATE AN ACCOUNTSIGN IN\n\nArtificial IntelligenceSemiconductorsNewsComputing\n\n# AI Chip Trims Energy Budget Back by 99+ Percent\n\n##\n\nPhotonic tech uses both diffraction and interference to boost performance\n\nCharles Q. Choi\n\n12 Apr 2024\n\n4 min read\n\n1\n\nTraditional neural network chips use electronic gates to perform AI\noperations\u2014a new chip, by contrast, integrates strengths of two optical AI\napproaches.\n\nTsinghua University in Beijing/Beijing National Research Center for\nInformation Science and Technology\n\nNeural networks that imitate the workings of the human brain now often\ngenerate art, power computer vision, and drive many more applications. Now a\nneural network microchip from China that uses photons instead of electrons,\ndubbed Taichi, can run AI tasks as well as its electronic counterparts with a\nthousandth as much energy, according to a new study.\n\nAI typically relies on artificial neural networks in applications such as\nanalyzing medical scans and generating images. In these systems, circuit\ncomponents called neurons\u2014analogous to neurons in the human brain\u2014are fed data\nand cooperate to solve a problem, such as recognizing faces. Neural nets are\ndubbed \u201cdeep\u201c if they possess multiple layers of these neurons.\n\n\u201cOptical neural networks are no longer toy models. They can now be applied in\nreal-world tasks.\u201d \u2014Lu Fang, Tsinghua University, Beijing\n\nAs neural networks grow in size and power, they are becoming more energy\nhungry when run on conventional electronics. For instance, to train its state-\nof-the-art neural network GPT-3, a 2022 Nature study suggested OpenAI spent US\n$4.6 million to run 9,200 GPUs for two weeks.\n\nThe drawbacks of electronic computing have led some researchers to investigate\noptical computing as a promising foundation for next-generation AI. This\nphotonic approach uses light to perform computations more quickly and with\nless power than an electronic counterpart.\n\nNow scientists at Tsinghua University in Beijing and the Beijing National\nResearch Center for Information Science and Technology have developed Taichi,\na photonic microchip that can perform as well as electronic devices on\nadvanced AI tasks while proving far more energy efficient.\n\n\u201cOptical neural networks are no longer toy models,\u201d says Lu Fang, an associate\nprofessor of electronic engineering at Tsinghua University. \u201cThey can now be\napplied in real-world tasks.\u201d\n\n### How does an optical neural net work?\n\nTwo strategies for developing optical neural networks either scatter light in\nspecific patterns within the microchips, or get light waves to interfere with\neach other in precise ways inside the devices. When input in the form of light\nflows into these optical neural networks, the output light encodes data from\nthe complex operations performed within these devices.\n\nBoth photonic computing approaches have significant advantages and\ndisadvantages, Fang explains. For instance, optical neural networks that rely\non scattering, or diffraction, can pack many neurons close together and\nconsume virtually no energy. Diffraction-based neural nets rely on the\nscattering of light beams as they pass through optical layers that represent\nthe network\u2019s operations. One drawback of diffraction-based neural nets,\nhowever, is that they cannot be reconfigured. Each string of operations can\nessentially only be used for one specific task.\n\nTaichi boasts 13.96 million parameters.\n\nIn contrast, optical neural networks that depend on interference can readily\nbe reconfigured. Interference-based neural nets send multiple beams through a\nmesh of channels, and the way they interfere where these channels intersect\nhelps perform the device\u2019s operations. However, their drawback concerns the\nfact that interferometers are also bulky, which restricts how well such neural\nnets can scale up. They also consume a lot of energy.\n\nIn addition, current photonic chips experience unavoidable errors. Attempting\nto scale up optical neural networks by increasing the number of neuron layers\nin these devices typically only exponentially increase this inevitable noise.\nWhich means that, until now, optical neural networks were limited to basic AI\ntasks such as simple pattern recognition. Optical neural nets, in other words,\nwere generally not suitable for advanced, real-world applications, Fang says.\n\nThe researchers say that Taichi, by contrast, is a hybrid design that combines\nboth diffraction and interference approaches. It contains clusters of\ndiffractive units that can compress data for large-scale input and output in a\ncompact space. But their chip also contains arrays of interferometers for\nreconfigurable computation. The encoding protocol developed for Taichi divides\nchallenging tasks and large network models into sub-problems and sub-models\nthat can be distributed across different modules, Fang says.\n\n### How does Taichi blend both kinds of neural nets?\n\nPrevious research typically sought to expand optical neural network capacity\nby mimicking what is often done with their electronic counterparts\u2014increasing\nthe number of neuron layers. Instead, Taichi\u2019s architecture scales up by\ndistributing computing across multiple chiplets that operate in parallel. This\nmeans Taichi can avoid the problem of exponentially accumulating errors that\nhappens when optical neural networks stack many neuron layers together.\n\n\u201cThis \u2018shallow in depth but broad in width\u2019 architecture guarantees network\nscale,\u201d Fang says.\n\nTaichi produced music clips in the style of Bach and art in the style of Van\nGogh and Munch.\n\nFor instance, previous optical neural networks usually only possessed\nthousands of parameters\u2014the connections between neurons that mimic the\nsynapses linking biological neurons in the human brain. In contrast, Taichi\nboasts 13.96 million parameters.\n\nPrevious optical neural networks were often limited to classifying data along\njust a dozen or so categories\u2014for instance, figuring out whether images\nrepresented one of 10 digits. In contrast, in tests with the Omniglot database\nof 1,623 different handwritten characters from 50 different alphabets, Taichi\ndisplayed an accuracy of 91.89 percent, comparable to its electronic\ncounterparts.\n\nThe scientists also tested Taichi on the advanced AI task of content\ngeneration. They found it could produce music clips in the style of Johann\nSebastian Bach and generate images of numbers and landscapes in the style of\nVincent Van Gogh and Edvard Munch.\n\nAll in all, the researchers found Taichi displayed an energy efficiency of up\nto roughly 160 trillion operations per second per watt and an area efficiency\nof nearly 880 trillion multiply-accumulate operations (the most basic\noperation in neural networks) per square millimeter. This makes it more than\n1,000 times more energy efficient than one of the latest electronic GPUs, the\nNVIDIA H100, as well as roughly 100 times more energy efficient and 10 times\nmore area efficient than previous other optical neural networks.\n\nAlthough the Taichi chip is compact and energy-efficient, Fang cautions that\nit relies on many other systems, such as a laser source and high-speed data\ncoupling. These other systems are far more bulky than a single chip, \u201ctaking\nup almost a whole table,\u201d she notes. In the future, Fang and her colleagues\naim to add more modules onto the chips to make the whole system more compact\nand energy-efficient.\n\nThe scientists detailed their findings online 11 April in the journal Science.\n\nFrom Your Site Articles\n\n  * The Future of Deep Learning Is Photonic \u203a\n  * Photonic Chip Performs Image Recognition at the Speed of Light \u203a\n  * Optical AI Could Feed Voracious Data Needs \u203a\n\nRelated Articles Around the Web\n\n  * A Review of Optical Neural Networks \u203a\n  * Optical neural network - Wikipedia \u203a\n\nartificial intelligenceenergy efficiencyneural networksoptical\ncomputingoptical neural networksphotonics\n\nCharles Q. Choi\n\nCharles Q. Choi is a science reporter who contributes regularly to IEEE\nSpectrum. He has written for Scientific American, The New York Times, Wired,\nand Science, among others.\n\nThe Conversation (0)\n\nSort by\n\nTransportationNews\n\n## Hyundai\u2019s Ioniq 5 N Accelerates Performance Tech\n\n1 hour ago\n\n5 min read\n\nRoboticsNewsInterview\n\n## Boston Dynamics\u2019 Robert Playter on the New Atlas\n\n5 hours ago\n\n9 min read\n\nRoboticsNewsHumanoid Robots\n\n## Hello, Electric Atlas\n\n5 hours ago\n\n6 min read\n\n1\n\n## Related Stories\n\nComputingArtificial IntelligenceSemiconductorsNews\n\n## Faster, More Secure Photonic Chip Boosts AI Training\n\nArtificial IntelligenceHistory of TechnologyNews\n\n## What If the Biggest AI Fear Is AI Fear Itself?\n\nArtificial IntelligenceNews\n\n## Could AI Disrupt Peer Review?\n\n", "frontpage": false}

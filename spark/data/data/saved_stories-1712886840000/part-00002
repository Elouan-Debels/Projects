{"aid": "40006127", "title": "Rolling your own GitOps: DNS Zone files", "url": "https://www.codetinkerer.com/2024/02/25/rolling-your-own-gitops-nsd-dns-zone-file.html", "domain": "codetinkerer.com", "votes": 1, "user": "indigodaddy", "posted_at": "2024-04-11 19:53:35", "comments": 0, "source_title": "Rolling your own GitOps: DNS Zone files", "source_text": "Rolling your own GitOps: DNS Zone files | codetinkerer.com\n\ncodetinkerer.com\n\nMichael Kropat\n\nFeb 25 \u2022 10 min read\n\n# Rolling your own GitOps: DNS Zone files\n\nI like to self-host my own infrastructure. You have full control. You learn a\nlot. It is also not hard to get started.\n\nManaging your infrastructure though, wow, what a pain. Take DNS. To make a\nsimple DNS record change first I have to edit the zone file, which is manual,\nbut feels technical in a good way, like I am in control. Unfortunately the\nprocess only gets more tedious from there. First I commit the change and push\nit up. Then I SSH into my server and pull down the changes. Then I rebuild the\nDocker image. Then I kill the running container and start a new container with\nthe new image. Then I SSH into the other server\u2013you always need redundancy\nwith DNS\u2013and repeat the same steps again.\n\nSo tedious. Compare all that with a hosted DNS service, where you log into the\nweb interface, tweak the record, and... that\u2019s it.\n\nMaybe there is a way we can have the best of both worlds. GitOps would be a\ngood fit here. Like what if all you had to do was edit the zone file and\ncommit the change, then let every step after that be handled automatically.\nYou know, it probably wouldn\u2019t be that hard...\n\n## Steps\n\nThe rest of this post is a walkthrough for implementing the above system\ndiagram. The number of moving parts looks intimidating, but actually each part\nis so simple that you\u2019re more likely to be bored^1 reading the code than\nfeeling in-over-your-head.\n\nTo make the steps easier to follow, let\u2019s follow the diagram working from\noutside in:\n\n#### 0\\. git init\n\nThis guide assumes that you already have one or more zone files defined. I\nwon\u2019t be covering how to configure DNS from scratch, just how to implement\nGitOps assuming you already have some type of basic DNS set up.\n\nInitialize (git init) your local directory if you haven\u2019t already and commit\nthe zone files.\n\n#### 1\\. Set up a post-commit hook (Optional)\n\nWhy manually run two commands (git commit, git push) when one will suffice?\nFrom your local git directory create a .git/hooks/post-commit file containing:\n\n    \n    \n    #!/bin/sh if [ -d \".git/rebase-merge\" ] || [ -d \".git/rebase-apply\" ] || [ -f \".git/MERGE_HEAD\" ] || [ -f \".git/CHERRY_PICK_HEAD\" ] || [ -f \".git/BISECT_LOG\" ]; then exit 0 fi git push\n\n(For this and all later shell scripts in this post don\u2019t forget to chmod +x\nthe file to mark it as executable.)\n\nNow you only need to commit your desired changes, the push will happen\nautomatically.\n\n#### 2\\. Create the remote git repository\n\nThe GitHub hegemony has become so ingrained that it has probably never even\noccurred to most git users that you can host your own remote repository.^2\n\n  1. Open an SSH session to Server A\n  2. Set up the /srv/repos dir:\n    \n        sudo mkdir -p /srv/repos sudo groupdd git sudo setfacl --modify default:group:git:rwX /srv/repos\n\n  3. Then create the repo:\n    \n        sudo git init --bare --shared /srv/repos/dns-zones.git\n\nThe ACL set up is possibly overkill for the simple needs of this one project,\nbut I include it to show how easy and powerful it is to manage arbitrarily\ncomplex permissions on as many self-hosted git repositories as you want to\ncreate.\n\nBack in your local git directory, set up the remote:\n\n    \n    \n    git remote add origin server-a:/srv/repos/dns-zones.git git push\n\n(Replace server-a with the actual hostname of the server.)\n\nThe push may fail if your SSH user doesn\u2019t have write access to /srv/repos.\nSimply add your user account on Server A to the git group we previously set\nup, then try the push again.\n\n#### 3\\. Create service users\n\nWe will be running NSD for the DNS server software.\n\nOn both Server A and Server B create a system user:\n\n    \n    \n    sudo useradd --create-home --groups docker,git --system nsd\n\nWhile we are on Server A and Server B we will also set up mutual\nauthentication:\n\n    \n    \n    sudo -u nsd ssh-keygen -f ~nsd/.ssh/id_ed25519 -N '' -t ed25519 cat ~nsd/.ssh/id_ed25519.pub\n\nTake the public key output from Server A then add it to the authorized keys on\nServer B:\n\n    \n    \n    sudo -u nsd sh -c 'umask 077; cat >> ~/.ssh/authorized_keys' # Paste in the key from the other server, then press Ctrl-D\n\nRepeat with the key from Server B on Server A.\n\n#### 4\\. Clone the repo everywhere\n\nWe already have a clone of the repo locally. We also have a remote bare\nrepository on Server A.\n\nWe still need a clone on Server A for the nsd user:\n\n    \n    \n    sudo -i -u nsd git clone /srv/repos/dns-zones.git\n\nWe also need a clone on Server B:\n\n    \n    \n    sudo -i -u nsd git clone server-a:/srv/repos/dns-zones.git\n\n#### 5\\. Define the monitor service\n\nFor simplicity, I recommend defining all the scripts in the same dns-zones.git\nrepository as the zone files live in. That way we can get the scripts\neverywhere without setting up even more stuff. So you can edit the scripts\nlocally or on Server A or anywhere really, so long as you commit and push the\nchanges, then git pull them for where they are going to be used.\n\nCreate a nsd-monitor.service file:\n\n    \n    \n    [Unit] Description=NSD Monitoring Service After=network.target [Service] Type=simple User=nsd ExecStart=/home/nsd/dns-zones/monitor.sh WorkingDirectory=/home/nsd/dns-zones Restart=always RestartSec=3 [Install] WantedBy=multi-user.target\n\nInstall the service on Server A by running:\n\n    \n    \n    sudo cp nsd-monitor.service /etc/systemd/system/ sudo systemctl daemon-reload\n\nDon\u2019t start the service yet, since we still need to set up the rest of the\nfiles.\n\nNow create a monitor.sh file:\n\n    \n    \n    #!/usr/bin/env bash set -euo pipefail repo=$(git remote get-url origin) inotifywait -m -e create,delete,modify --format '%w%f' \"$repo\" | while read -r file; do echo \"$file changed. Updating...\" sleep 1 # Wait for local push to complete git pull ./run.sh ./sync.sh done\n\n#### 6\\. Configure NSD\n\nCreate a Dockerfile file:\n\n    \n    \n    FROM alpine RUN apk update && apk add nsd RUN mkdir -p /run/nsd COPY nsd.conf *.zone /etc/nsd/ CMD [\"/usr/sbin/nsd\", \"-d\", \"-c\", \"/etc/nsd/nsd.conf\"]\n\nCreate an nsd.conf file:\n\n    \n    \n    server: hide-identity: yes hide-version: yes zone: name: yourdomain.example zonefile: yourdomain.example.zone\n\nReplace the zone: entries with your actual domain(s) and zone file(s).\n\n#### 7\\. Define the run script\n\nCreate a run.sh file:\n\n    \n    \n    #!/bin/sh set -e docker build --tag nsd . # Sometimes there is a resolver listening on 127.0.0.1:53 # Bind to the public IP explicitly to avoid conflicts publicip=\"$(ip route get 8.8.8.8 | sed -nE 's/.*src (\\S+).*/\\1/p')\" docker rm --force nsd docker run \\ --detach \\ --name nsd \\ --publish \"${publicip}:53:53\" \\ --publish \"${publicip}:53:53/udp\" \\ --restart=always \\ nsd\n\nNow is a good time to try running (./run.sh) the script to make sure it works.\nThe best test is to run a query from an entirely different computer:\n\n    \n    \n    dig some.record.yourdomain.example @server-a\n\n#### 8\\. Define the sync script\n\nCreate a sync.sh file:\n\n    \n    \n    #!/bin/sh ssh nsd@server-b 'cd dns-zones && git pull && ./run.sh'\n\n#### 9\\. Start it up\n\nIf you haven\u2019t already, commit all the above scripts, push them up, then run\ngit pull on Server A.\n\nEnable nsd-monitor.service on Server A:\n\n    \n    \n    sudo systemctl enable nsd-monitor.service sudo systemctl start nsd-monitor.service\n\nCheck the logs to make sure there are no errors:\n\n    \n    \n    sudo journalctl -f -u nsd-monitor.service\n\nTry making a change locally to the zone file (if nothing else, bump the serial\nnumber) and commit the change. In the service output you should see the Docker\nimage being re-built and the container re-run without error.\n\n## Summary\n\nWhen you commit a zone file change, it automatically gets pushed up to the git\nrepository that lives on Server A. There is a filesystem watcher running that\nautomatically updates everything with the latest changes when any git changes\nare pushed up. First it re-builds and re-runs the NSD Docker container on\nServer A, then it opens an SSH connection to Server B and runs the same\ncommands there.\n\n## Limitations\n\nThe big red flag with this set up is that there are no safe-guards in place if\nyou make a bad change to any of the files. Once you commit the bad change it\nwill be pushed out to both servers, possibly bringing down both your DNS\nservers simultaneously. A safer pattern would be to roll out the change to\nServer A, then have Server B try to query A over DNS, perhaps checking a\n\u201chealth\u201d record, then only after that succeeds does the update on Server B\nproceed. Personally I have other backup plans in place in case I mess up DNS,\nso I haven\u2019t been motivated to implement such an automated safe-guard yet. I\nleave it as an exercise to the reader.\n\n## Takeaways\n\nInstead of a how-to post, it wouldn\u2019t have been that much extra work to build\nthis as a re-usable project. The thing about re-usable projects though, is\nthat there is a temptation to build them the \u201cproper\u201d way since other people\nwill be adopting them. Based on the fashion of the current day, the proper way\nwould look something like: a GitHub repo with a GitHub action that builds the\nDocker container and pushes it to a Docker repository, followed by triggering\na Kubernetes deployment to a cluster you host. It is not that that would be a\nbad way to do it. However, it would be different. It would be less self-hosted\nfor one. I think a more interesting difference is how the glue is implemented:\nthe modern way is configuration driven; the Unix way is imperative scripts you\nwrite yourself. Once again, it is not that one is strictly better than the\nother. Still, I find there is a level of understanding and control that comes\nwith the glue script model that is ultimately more satisfying.\n\nEven in 2024, I am impressed how easy it is to roll your own solution to the\nproblem using simple Unix tools, compared to, say, more recent advancements\nthat you would expect to have made simple problems easier. There are good\nreasons people have moved away from the traditional Unix model at large\ncompanies. For personal stuff though\u2013and even small scale professional\nprojects\u2013rolling your own solution by composing building blocks with glue\nscripts remains a viable approach.\n\n## Notes\n\n  1. I usually try to avoid boring posts, but I make an exception when it comes to showing how to use boring technology. Boring technology is good, actually.\n  2. Hosting your own git remote is crazy easy, but you may prefer to host the repository in a centralized service to keep all your repositories in one place. If you do that though, you won\u2019t be able to use the inotifywait watcher pattern described in this post. Making all this work with GitHub webhooks is left as an exercise to the reader.\n\nsubscribe via RSS or :\n\nA blog about computers and coding, bouncing between professional software\nengineering practices and unabashed amateurism.\n\n", "frontpage": false}

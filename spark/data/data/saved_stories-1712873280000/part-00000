{"aid": "40003710", "title": "Show HN: I made a new sensor out of 3D printer filament for my PhD", "url": "https://paulbupejr.com/developing-the-optigap-sensor-system/", "domain": "paulbupejr.com", "votes": 59, "user": "00702", "posted_at": "2024-04-11 16:06:03", "comments": 17, "source_title": "R&D Case Study: Developing the OptiGap Sensor System", "source_text": "R&D Case Study: Developing the OptiGap Sensor System | Paul Bupe, Jr\n\nSkip to content\n\nPaul Bupe, Jr\n\nR&D Engineer Specializing in Robotics, Sensors, and Embedded Systems\n\n## Popular Posts\n\n  * Easy Raspberry Pi Pico Microcontroller C / C++ Programming on Windows 23 comments | posted on February 1, 2021\n  * Designing an Advanced Autonomous Robot: Goose 19 comments | posted on July 30, 2019\n\n## Categories\n\n# R&D Case Study: Developing the OptiGap Sensor System\n\nReading Time: 9 minutes\n\nThis article explores the research and development journey behind my new\nsensor system, OptiGap, a key component of my PhD research. I\u2019m writing this\nin a storytelling format to offer insights into my decision-making process and\nthe evolution leading to the final implementation. It should hopefully provide\na glimpse into the sometimes-shrouded world of PhD research and may appeal to\nthose curious about the process. For a deeper dive into technical specifics,\nsimulations, and existing research on this subject, my dissertation is\navailable online here.\n\n### What does it do?\n\nIn very general terms, this sensor is basically a rope that if bent can tell\nyou where along its length you bent it. The fancy term for that is \u201cbend\nlocalization.\u201d\n\nOptiGap\u2019s application is mainly within the realm of soft robotics, which\ntypically involves compliant (or \u2018squishy\u2019) systems, where the use of\ntraditional sensors is often not practical. The name OptiGap, a fusion of\n\u201coptical\u201d and \u201cgap,\u201d reflects its core principle of utilizing air gaps within\nflexible optical light pipes to generate coded patterns essential for bend\nlocalization.\n\n## How the OptiGap Sensor System Started\n\nThe idea for OptiGap came about while I was experimenting with light\ntransmission through various light pipes (optical cables) for use as a bend\ndetection sensor. I was initially trying to see how I could effectively \u201cslow\ndown\u201d light through the fiber...a seemingly straightforward task, right?\n\nDuring this process, I attached a section of clear 3D printer filament (1.75mm\nTPU) to a piece of tape measure for an experiment and incidentally discovered\nthat when I bent the tape measure (and filament) at the spot where the\nelectrical tape was attached, there was a significant drop in light\ntransmission. I hypothesized that this was because the sticky residue of the\nelectrical tape was causing the filament to stretch, which in turn reduced the\nlight transmission.\n\nTo verify this hypothesis, I attached a longer piece of TPU to a tape measure\nand began bending it at various points to observe how light transmission would\nchange.\n\nTape measure experiment with clear TPU filament.\n\nI wrote a small Linux I2C driver for the VL53L0X ToF sensor to run on a\nRaspberry Pi and push the data to a socket using ZeroMQ. I then created a\nrough GUI in Python to pull the sensor data from the socket and visualize the\nlight transmission data in realtime, shown in the GIF below, which very\nquickly validated my hypothesis. This validation marked the \u201cEureka!\u201d moment\nthat sparked the eventual development of the OptiGap sensor.\n\nMy excited face while validating my discovery.\n\n## The OptiGap Realization\n\nI realized that since I could control where the light was being attenuated, I\ncould use this to encode information about the position of the bend on the\nsensor. Using electrical tape was not a practical solution, so I started\nlooking for a more reliable and consistent way to create these attenuations.\nThis led me to the idea of cutting the filament and then reattaching it\ntogether using a flexible rubber (silicone) sleeve, leaving a small air gap,\nas shown in the image below.\n\nProof-of-concept showing a light pipe with an air in a silicone sleeve.\n\nThe main working principle of the air gap is that translation and/or rotation\nof one light pipe face relative to the other changes the fraction of light\ntransmitted across the gap. The greater the bend angle, the more light escapes\nacross the gap. The resulting change in intensity of the optical signal can\nthen be correlated with known patterns for use as a sensor.\n\nThis image is from a COMSOL simulation I made.\n\n## The Big Idea\n\nI then proceeded to test this idea by creating multiple air gaps in a row and\nbending the filament to measure the attenuation.\n\nMultiple air gaps along a single TPU lightpipe.\n\nAs depicted in the GIF below, the optical intensity decreases at each air gap,\nwith a more noticeable decrease as the bend angle increases. This initial\nexperimentation served as proof of concept, demonstrating the feasibility of\nthe idea. It led to the formulation of my final hypothesis of utilizing a\npattern of these air gaps to encode information regarding the sensor\u2019s bending\nand employing a naive Bayes classifier on a microcontroller to decode the bend\nlocation.\n\nValidating the attenuation at the air gaps.\n\nThis concept resembles the functionality of a linear encoder. Linear encoders\ngauge an object\u2019s linear movement, typically comprising a slider rail with a\ncoded scale akin to a measuring ruler and a sensing head that moves across\nthis scale to read it. Linear (absolute) encoders emit a distinct code at each\nposition, ensuring consistent identification of displacement.\n\nOptiGap system overview.\n\nThe OptiGap system, functioning like an absolute encoder, would encode\nabsolute positions using patterns of bend-sensitive air gaps along parallel\nlight pipes, effectively serving as a singular fiber optic sensor.\n\n### Encoding the Bend Location using Inverse Gray Code\n\nAbsolute encoders commonly employ Gray code, a binary system where two\nsuccessive values differ in only one bit. This property allows for various\napplications, including error checking. However, Gray code isn\u2019t optimal for\nthe OptiGap sensor system. Here, we aim for consecutive values to differ by\nthe maximum number of bits to facilitate easier differentiation. This\nnecessity gave rise to Inverse Gray code.\n\nInverse Gray code is a binary code where two successive values differ by the\nmaximum (n-1) number of bits. To implement this, I simply create cuts in the\nfilament wherever there\u2019s a \u201c1\u201d in the Inverse Gray code sequence. This\napproach can scale to any bit number. For the prototype, I utilized 3 bits,\nproviding 8 possible positions.\n\n### Visualization of the OptiGap Sensor System\n\nThe illustration below depicts the signal patterns of the OptiGap sensor\nsystem for each bend position using three fibers. By employing a naive Bayes\nclassifier, the sensor system can discern bend positions based on signal\npatterns. The third graph represents actual sensor data from the prototype\nsystem, utilized for training the classifier on the microcontroller.\n\nOptiGap bending patterns.\n\n## The OptiGap Prototype\n\nI proceeded to construct a prototype of the OptiGap sensor system, utilizing 3\nstrands of clear TPU 3D printer filament, each featuring a distinct pattern of\nair gaps. The image below showcases the filament just before cutting, with the\ncut pattern indicated on a piece of tape.\n\nBeginning stages of an OptiGap sensor prototype.\n\nFor the prototype, I employed a commercial 3:1 fiber optic coupler to merge\nthe light from the 3 strands into a single fiber optic cable, resulting in the\ncompletion of the sensor prototype, as depicted below.\n\nAssembled sensing head of an OptiGap sensor.\n\nThis marked the final phase of validating the hypothesis and operational\ntheory behind the OptiGap sensor.\n\n### Reducing the Physical Size\n\nThe initial prototype proved to be large and bulky, primarily due to the size\nof the 3D printer filament used. Drawing from previous experience, I\nrecognized that PMMA (plastic) optical fiber offered a smaller and more\nflexible alternative suitable for this application. Consequently, I assessed\n500, 750, and 1000 micron unjacketed PMMA optical fibers from Industrial Fiber\nOptics, Inc. for the sensor strands, resulting in a significant reduction in\nsensor size.\n\n500 micron PMMA fiber spool.\n\nI conducted tests on all three types of fibers to evaluate their light\ntransmission and flexibility. Among them, the 500 micron fiber emerged as the\noptimal choice overall, although all three exhibited sufficient flexibility\nfor this application.\n\n### Reducing the Optical Transceiver Complexity\n\nI decided to switch from using the complex VL53L0X ToF sensor to a simple\nphotodiode and IR LED setup to reduce the complexity of the system and to\nincrease modularity. This also allowed me to use a microcontroller to read the\nsensor data, which was a significant improvement over the initial prototype.\n\nIR LED prototype board with 1000 micron PMMA fiber.\n\nI then created a demo system for the sensor based around an STM32\nmicrocontroller and a photodiode/IR LED setup.\n\nFull OptiGap demo system using 500 micron PMMA fiber.\n\n## Realtime Machine Learning on a Microcontroller\n\nThe final stage in developing the OptiGap sensor system involved integrating a\nnaive Bayes classifier onto the STM32 microcontroller to decode the bend\nlocation from the sensor data. I opted for a naive Bayes classifier due to its\nefficiency compared to if-statements or lookup tables, its capability to\nhandle new or previously unseen data, and its potential for increased accuracy\nby considering relationships between multiple input variables.\n\nImplementing the naive Bayes classifier proved to be relatively\nstraightforward. This classifier is a probabilistic model based on applying\nBayes\u2019 theorem to determine how a measurement can be assigned to a particular\nclass, with the class representing the bend location in this context. I\nutilized the Arm CMSIS-DSP library for the classifier implementation.\n\n### Fitting the Sensor Data\n\nThe initial step in integrating the classifier was to fit the sensor data to a\nGaussian distribution for each air gap pattern. To expedite this process, I\ndeveloped a Python GUI for rapid labeling and fitting of the data using GNB\n(Gaussian Naive Bayes) from the scikit-learn library.\n\nInitial data labeling and fitting UI.\n\nI later improved this UI to be more general and to allow for more complex data\nfitting.\n\nImproved UI.\n\nThe probabilities for each class were computed and saved as a header for use\non the microcontroller.\n\n### Filtering the Sensor Data\n\nTo enhance the accuracy of the classifier, I implemented a two-stage filtering\nprocess on the STM32 . The initial stage involved a basic moving average\nfilter, followed by a Kalman filter in the second stage.\n\nSignal filtering stages. Noise reduction relative to input signal.\n\n## The OptiGap Sensor System Demo\n\nThe GIFs provided below illustrate various stages of the OptiGap sensor\nsystem, encompassing assembly and the operational demonstration of the final\nsensor system.\n\n#### System Overview\n\n#### Assembly of an OptiGap Sensor using TPU Filament\n\n#### Attenuation of Light through the OptiGap Sensor\n\n#### Fitting of the Sensor Data\n\n#### Segment Classification using PMMA Optical Fiber\n\n#### Segment Classification using TPU Filament\n\n#### Underwater Operation\n\n## OptiGap Design Specifications\n\n### Key Properties & Parameters\n\n### Material Recommendations\n\n## Next Steps\n\nI\u2019ve made significant progress on the OptiGap system beyond what\u2019s documented\nhere, including its integration into another modular actuation and sensing\nsystem I developed called EneGate.\n\nMy EneGate PCB integrating an OptiGap sensor.\n\nThis has involved custom PCB design and systems integration, detailed in my\ndissertation. Additionally, I\u2019ve prototyped miniature PCB versions of the\noptics to interface with the PCBs for the EneGate system.\n\nMini OptiGap PCBAnother mini OptiGap PCB\n\nI\u2019ve also validated OptiGap on a real-world soft robotic system, with full\ndetails set to be presented in an upcoming RoboSoft paper titled \u201cEmbedded\nOptical Waveguide Sensors for Dynamic Behavior Monitoring in Twisted-Beam\nStructures.\u201c\n\n### Commercialization\n\nThere\u2019s an ongoing commercialization aspect to this research as well. Feel\nfree to reach out if you\u2019re interested in further details.\n\n## That\u2019s it for now!\n\nI don\u2019t want to make this too long so I\u2019ll end here. I hope this provided some\ninsight into the research and development process involved in something like\nthis. If you have any questions or would like to learn more, don\u2019t hesitate to\ncontact me!\n\nPosted on April 10, 2024April 11, 2024Author paulbupeCategories Articles,\nDesign, Robotics, TheoryTags 3d printer filament, air gap, bend localization,\nfiber, linux, localization, microcontroller, optigap, optigap sensor system,\nraspberry pi, research, robotics, sensor, Serial, soft robotics, stm32, zeromq\n\n### Leave a Reply Cancel reply\n\n", "frontpage": true}

{"aid": "39998373", "title": "Mapping the global geography of cybercrime with the World Cybercrime Index", "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0297312", "domain": "plos.org", "votes": 1, "user": "geox", "posted_at": "2024-04-11 04:27:58", "comments": 0, "source_title": "Mapping the global geography of cybercrime with the World Cybercrime Index", "source_text": "Mapping the global geography of cybercrime with the World Cybercrime Index | PLOS ONE\n\nSkip to main content\n\nAdvertisement\n\n  * plos.org\n  * create account\n  * sign in\n\nBrowse Subject Areas\n\n?\n\nClick through the PLOS taxonomy to find articles in your field.\n\nFor more information about PLOS Subject Areas, click here.\n\n  * 0\n\nSave\n\nTotal Mendeley and Citeulike bookmarks.\n\n  * 0\n\nCitation\n\nPaper's citation count computed by Dimensions.\n\n  * 699\n\nView\n\nPLOS views and downloads.\n\n  * 0\n\nShare\n\nSum of Facebook, Twitter, Reddit and Wikipedia activity.\n\nOpen Access\n\nPeer-reviewed\n\nResearch Article\n\n# Mapping the global geography of cybercrime with the World Cybercrime Index\n\n  * Miranda Bruce ,\n\nRoles Data curation, Formal analysis, Investigation, Methodology,\nVisualization, Writing \u2013 original draft\n\n* E-mail: miranda.bruce@sociology.ox.ac.uk\n\nAffiliations Department of Sociology, University of Oxford, Oxford, United\nKingdom, Canberra School of Professional Studies, University of New South\nWales, Canberra, Australia\n\nhttps://orcid.org/0000-0003-4001-7176\n\n\u2a2f\n\n  * Jonathan Lusthaus,\n\nRoles Conceptualization, Investigation, Methodology, Writing \u2013 original draft\n\nAffiliations Department of Sociology, University of Oxford, Oxford, United\nKingdom, Oxford School of Global and Area Studies, University of Oxford,\nOxford, United Kingdom\n\n\u2a2f\n\n  * Ridhi Kashyap,\n\nRoles Formal analysis, Methodology, Writing \u2013 review & editing\n\nAffiliations Department of Sociology, University of Oxford, Oxford, United\nKingdom, Leverhulme Centre for Demographic Science, University of Oxford,\nOxford, United Kingdom\n\n\u2a2f\n\n  * Nigel Phair,\n\nRoles Funding acquisition, Methodology, Writing \u2013 review & editing\n\nAffiliation Department of Software Systems and Cybersecurity, Faculty of IT,\nMonash University, Victoria, Australia\n\nhttps://orcid.org/0000-0002-1875-2900\n\n\u2a2f\n\n  * Federico Varese\n\nRoles Conceptualization, Funding acquisition, Methodology, Writing \u2013 review &\nediting\n\nAffiliation Centre d\u2019\u00e9tudes europ\u00e9ennes et de politique compar\u00e9e, Sciences Po,\nParis, France\n\n\u2a2f\n\n# Mapping the global geography of cybercrime with the World Cybercrime Index\n\n  * Miranda Bruce,\n  * Jonathan Lusthaus,\n  * Ridhi Kashyap,\n  * Nigel Phair,\n  * Federico Varese\n\nx\n\n  * Published: April 10, 2024\n  * https://doi.org/10.1371/journal.pone.0297312\n\n  * Article\n  * Authors\n  * Metrics\n  * Comments\n  * Media Coverage\n  * Peer Review\n\n  * Abstract\n  * Introduction\n  * Background\n  * Methods\n  * Results\n  * Discussion\n  * Conclusion\n  * Supporting information\n  * Acknowledgments\n  * References\n\n  * Reader Comments\n  * Figures\n\nAccessible Data\n\nSee the data\n\nThis article includes the Accessible Data icon, an experimental feature to\nencourage data sharing and reuse. Find out how research articles qualify for\nthis feature.\n\n## Abstract\n\nCybercrime is a major challenge facing the world, with estimated costs ranging\nfrom the hundreds of millions to the trillions. Despite the threat it poses,\ncybercrime is somewhat an invisible phenomenon. In carrying out their virtual\nattacks, offenders often mask their physical locations by hiding behind online\nnicknames and technical protections. This means technical data are not well\nsuited to establishing the true location of offenders and scholarly knowledge\nof cybercrime geography is limited. This paper proposes a solution: an expert\nsurvey. From March to October 2021 we invited leading experts in cybercrime\nintelligence/investigations from across the world to participate in an\nanonymized online survey on the geographical location of cybercrime offenders.\nThe survey asked participants to consider five major categories of cybercrime,\nnominate the countries that they consider to be the most significant sources\nof each of these types of cybercrimes, and then rank each nominated country\naccording to the impact, professionalism, and technical skill of its\noffenders. The outcome of the survey is the World Cybercrime Index, a global\nmetric of cybercriminality organised around five types of cybercrime. The\nresults indicate that a relatively small number of countries house the\ngreatest cybercriminal threats. These findings partially remove the veil of\nanonymity around cybercriminal offenders, may aid law enforcement and\npolicymakers in fighting this threat, and contribute to the study of\ncybercrime as a local phenomenon.\n\n## Figures\n\nCitation: Bruce M, Lusthaus J, Kashyap R, Phair N, Varese F (2024) Mapping the\nglobal geography of cybercrime with the World Cybercrime Index. PLoS ONE\n19(4): e0297312. https://doi.org/10.1371/journal.pone.0297312\n\nEditor: Naeem Jan, Korea National University of Transportation, REPUBLIC OF\nKOREA\n\nReceived: October 11, 2023; Accepted: January 3, 2024; Published: April 10,\n2024\n\nCopyright: \u00a9 2024 Bruce et al. This is an open access article distributed\nunder the terms of the Creative Commons Attribution License, which permits\nunrestricted use, distribution, and reproduction in any medium, provided the\noriginal author and source are credited.\n\nData Availability: The dataset and relevant documents have been uploaded to\nthe Open Science Framework. Data can be accessed via the following URL:\nhttps://osf.io/5s72x/?view_only=ea7ee238f3084054a6433fbab43dc9fb.\n\nFunding: This project has received funding from the European Research Council\n(ERC) under the European Union\u2019s Horizon 2020 research and innovation program\n(Grant agreement No. 101020598 \u2013 CRIMGOV, Federico Varese PI). FV received the\naward and is the Primary Investigator. The ERC did not play any role in the\nstudy design, data collection and analysis, decision to publish, or\npreparation of the manuscript. Funder website: https://erc.europa.eu/faq-\nprogramme/h2020.\n\nCompeting interests: The authors have declared that no competing interests\nexist.\n\n## Introduction\n\nAlthough the geography of cybercrime attacks has been documented, the\ngeography of cybercrime offenders\u2013and the corresponding level of\n\u201ccybercriminality\u201d present within each country\u2013is largely unknown. A number of\nscholars have noted that valid and reliable data on offender geography are\nsparse [1\u20134], and there are several significant obstacles to establishing a\nrobust metric of cybercriminality by country. First, there are the general\nchallenges associated with the study of any hidden population, for whom no\nsampling frame exists [5, 6]. If cybercriminals themselves cannot be easily\naccessed or reliably surveyed, then cybercriminality must be measured through\na proxy. This is the second major obstacle: deciding what kind of proxy data\nwould produce the most valid measure of cybercriminality. While there is much\ntechnical data on cybercrime attacks, this data captures artefacts of the\ndigital infrastructure or proxy (obfuscation) services used by cybercriminals,\nrather than their true physical location. Non-technical data, such as legal\ncases, can provide geographical attribution for a small number of cases, but\nthe data are not representative of global cybercrime. In short, the question\nof how best to measure the geography of cybercriminal offenders is complex and\nunresolved.\n\nThere is tremendous value in developing a metric for cybercrime. Cybercrime is\na major challenge facing the world, with the most sober cost estimates in the\nhundreds of millions [7, 8], but with high-end estimates in the trillions [9].\nBy accurately identifying which countries are cybercrime hotspots, the public\nand private sectors could concentrate their resources on these hotspots and\nspend less time and funds on cybercrime countermeasures in countries where the\nproblem is limited. Whichever strategies are deployed in the fight against\ncybercrime (see for example [10\u201312]), they should be targeted at countries\nthat produce the largest cybercriminal threat [3]. A measure of\ncybercriminality would also enable other lines of scholarly inquiry. For\ninstance, an index of cybercriminality by country would allow for a genuine\ndependent variable to be deployed in studies attempting to assess which\nnational characteristics\u2013such as educational attainment, Internet penetration,\nor GDP\u2013are associated with cybercrime [4, 13]. These associations could also\nbe used to identify future cybercrime hubs so that early interventions could\nbe made in at-risk countries before a serious cybercrime problem develops.\nFinally, this metric would speak directly to theoretical debates on the\nlocality of cybercrime, and organized crime more generally [11\u201314]. The\nchallenge we have accepted is to develop a metric that is both global and\nrobust. The following sections respectively outline the background elements of\nthis study, the methods, the results, and then discussion and limitations.\n\n## Background\n\nProfit-driven cybercrime, which is the focus of this paper/research, has been\nstudied by both social scientists and computer scientists. It has been\ncharacterised by empirical contributions that have sought to illuminate the\nnature and organisation of cybercrime both online and offline [15\u201320]. But, as\nnoted above, the geography of cybercrime has only been addressed by a handful\nof scholars, and they have identified a number of challenges connected to\nexisting data. In a review of existing work in this area, Lusthaus et al. [2]\nidentify two flaws in existing cybercrime metrics: 1) their ability to\ncorrectly attribute the location of cybercrime offenders; 2) beyond a handful\nof examples, their ability to compare the severity and scale of cybercrime\nbetween countries.\n\nBuilding attribution into a cybercrime index is challenging. Often using\ntechnical data, cybersecurity firms, law enforcement agencies and\ninternational organisations regularly publish reports that identify the major\nsources of cyber attacks (see for example [21\u201324]). Some of these sources have\nbeen aggregated by scholars (see [20, 25\u201329]). But the kind of technical data\ncontained in these reports cannot accurately measure offender location. Kigerl\n[1] provides some illustrative remarks:\n\n> Where the cybercriminals live is not necessarily where the cyberattacks are\n> coming from. An offender from Romania can control zombies in a botnet,\n> mostly located in the United States, from which to send spam to countries\n> all over the world, with links contained in them to phishing sites located\n> in China. The cybercriminal\u2019s reach is not limited by national borders\n>\n> (p. 473).\n\nAs cybercriminals often employ proxy services to hide their IP addresses,\ncarry out attacks across national boundaries, collaborate with partners around\nthe world, and can draw on infrastructure based in different countries,\nsuperficial measures do not capture the true geographical distribution of\nthese offenders. Lusthaus et al. [2] conclude that attempts to produce an\nindex of cybercrime by country using technical data suffer from a problem of\nvalidity. \u201cIf they are a measure of anything\u201d, they argue, \u201cthey are a measure\nof cyber-attack geography\u201d, not of the geography of offenders themselves (p.\n452).\n\nNon-technical data are far better suited to incorporating attribution. Court\nrecords, indictments and other investigatory materials speak more directly to\nthe identification of offenders and provide more granular detail on their\nlocation. But while this type of data is well matched to micro-level analysis\nand case studies, there are fundamental questions about the representativeness\nof these small samples, even if collated. First, any sample would capture\ncases only where cybercriminals had been prosecuted, and would not include\noffenders that remain at large. Second, if the aim was to count the number of\ncybercrime prosecutions by country, this may reflect the seriousness with\nwhich various countries take cybercrime law enforcement or the resources they\nhave to pursue it, rather than the actual level of cybercrime within each\ncountry (for a discussion see [30, 31]). Given such concerns, legal data is\nalso not an appropriate approach for such a research program.\n\nFurthermore, to carry out serious study on this topic, a cybercrime metric\nshould aim to include as many countries as possible, and the sample must allow\nfor variation so that high and low cybercrime countries can be compared. If\nonly a handful of widely known cybercrime hubs are studied, this will result\nin selection on the dependent variable. The obvious challenge in providing\nsuch a comparative scale is the lack of good quality data to devise it. As an\nillustration, in their literature review Hall et al. [10] identify the \u201cdearth\nof robust data\u201d on the geographical location of cybercriminals, which means\nthey are only able to include six countries in their final analysis (p. 285.\nSee also [4, 32, 33]).\n\nConsidering the weaknesses within both existing technical and legal data\ndiscussed above, Lusthaus et al. [2] argue for the use of an expert survey to\nestablish a global metric of cybercriminality. Expert survey data \u201ccan be\nextrapolated and operationalised\u201d, and \u201cattribution can remain a key part of\nthe survey, as long as the participants in the sample have an extensive\nknowledge of cybercriminals and their operations\u201d (p. 453). Up to this point,\nno such study has been produced. Such a survey would need to be very carefully\ndesigned for the resulting data to be both reliable and valid. One criticism\nof past cybercrime research is that surveys were used whenever other data was\nnot immediately available, and that they were not always designed with care\n(for a discussion see [34]).\n\n## Methods\n\nIn response to the preceding considerations, we designed an expert survey in\n2020, refined it through focus groups, and deployed it throughout 2021. The\nsurvey asked participants to consider five major types of cybercrime\u2013Technical\nproducts/services; Attacks and extortion; Data/identity theft; Scams; and\nCashing out/money laundering\u2013and nominate the countries that they consider to\nbe the most significant sources of each of these cybercrime types.\nParticipants then rated each nominated country according to the impact of the\noffenses produced there, and the professionalism and technical skill of the\noffenders based there. Using the expert responses, we generated scores for\neach type of cybercrime, which we then combined into an overall metric of\ncybercriminality by country: the World Cybercrime Index (WCI). The WCI\nachieves our initial goal to devise a valid measure of cybercrime hub location\nand significance, and is the first step in our broader aim to understand the\nlocal dimensions of cybercrime production across the world.\n\n### Participants\n\nIdentifying and recruiting cybercrime experts is challenging. Much like the\nhidden population of cybercriminals we were trying to study, cybercrime\nexperts themselves are also something of a hidden population. Due to the\nnature of their work, professionals working in the field of cybercrime tend to\nbe particularly wary of unsolicited communication. There is also the problem\nof determining who is a true cybercrime expert, and who is simply presenting\nthemselves as one. We designed a multi-layered sampling method to address such\nchallenges.\n\nThe heart of our strategy involved purposive sampling. For an index based\nentirely on expert opinion, ensuring the quality of these experts (and thereby\nthe quality of our survey results) was of the utmost importance. We defined\n\u201cexpertise\u201d as adult professionals who have been engaged in cybercrime\nintelligence, investigation, and/or attribution for a minimum of five years\nand had a reputation for excellence amongst their peers. Only currently- or\nrecently-practicing intelligence officers and investigators were included in\nthe participant pool. While participants could be from either the public or\nprivate sectors, we explicitly excluded professionals working in the field of\ncybercrime research who are not actively involved in tracking offenders, which\nincludes writers and academics. In short, only experts with first-hand\nknowledge of cybercriminals are included in our sample. To ensure we had the\nleading experts from a wide range of backgrounds and geographical areas, we\nadopted two approaches for recruitment. We searched extensively through a\nrange of online sources including social media (e.g. LinkedIn), corporate\nsites, news articles and cybercrime conference programs to identify\nindividuals who met our inclusion criteria. We then faced a second challenge\nof having to find or discern contact information for these individuals.\n\nComplementing this strategy, the authors also used their existing\nrelationships with recognised cybercrime experts to recruit participants using\nthe \u201csnowball\u201d method [35]. This both enhanced access and provided a mechanism\nfor those we knew were bona fide experts to recommend other bona fide experts.\nThe majority of our participants were recruited in this manner, either\ndirectly through our initial contacts or through a series of referrals that\nfollowed. But it is important to note that this snowball sampling fell under\nour broader purposive sampling strategy. That is, all the original \u201cseeds\u201d had\nto meet our inclusion criteria of being a top expert in the first instance.\nAny connections we were offered also had to meet our criteria or we would not\ninvite them to participate. Another important aspect of this sampling strategy\nis that we did not rely on only one gatekeeper, but numerous, often unrelated,\nindividuals who helped us with introductions. This approach reduced bias in\nthe sample. It was particularly important to deploy a number of different\n\u201csnowballs\u201d to ensure that we included experts from each region of the world\n(Africa, Asia Pacific, Europe, North America and South America) and from a\nrange of relevant professional backgrounds. We limited our sampling strategy\nto English speakers. The survey itself was likewise written in English. The\nuse of English was partly driven by the resources available for this study,\nbut the population of cybercrime experts is itself very global, with many\nattending international conferences and cooperating with colleagues from\nacross the world. English is widely spoken within this community. While we\nexpect the gains to be limited, future surveys will be translated into some\nadditional languages (e.g. Spanish and Chinese) to accommodate any non-English\nspeaking experts that we may not otherwise be able to reach.\n\nOur survey design, detailed below, received ethics approval from the Human\nResearch Advisory Panel (HREAP A) at the University of New South Wales in\nAustralia, approval number HC200488, and the Research Ethics Committee of the\nDepartment of Sociology (DREC) at the University of Oxford in the United\nKingdom, approval number SOC_R2_001_C1A_20_23. Participants were recruited in\nwaves between 1 August 2020 and 30 September 2021. All participants provided\nconsent to participate in the focus groups, pilot survey, and final survey.\n\n### Survey design\n\nThe survey comprised three stages. First, we conducted three focus groups with\nseven experts in cybercrime intelligence/investigations to evaluate our\ninitial assumptions, concepts, and framework. These experts were recruited\nbecause they had reputations as some of the very top experts in the field;\nthey represented a range of backgrounds in terms of their own geographical\nlocations and expertise across different types of cybercrime; and they spanned\nboth the public and private sectors. In short, they offered a cross-section of\nthe survey sample we aimed to recruit. These focus groups informed several\nrefinements to the survey design and specific terms to make them better\ncomprehensible to participants. Some of the key terms, such as\n\u201cprofessionalism\u201d and \u201cimpact\u201d, were a direct result of this process. Second,\nsome participants from the focus groups then completed a pilot version of the\nsurvey, alongside others who had not taken part in these focus groups, who\ncould offer a fresh perspective. This allowed us to test technical components,\nsurvey questions, and user experience. The pilot participants provided useful\nfeedback and prompted a further refinement of our approach. The final survey\nwas released online in March 2021 and closed in October 2021. We implemented\nseveral elements to ensure data quality, including a series of preceding\nstatements about time expectations, attention checks, and visual cues\nthroughout the survey. These elements significantly increased the likelihood\nthat our participants were both suitable and would provide full and thoughtful\nresponses.\n\nThe introduction to the survey outlined the survey\u2019s two main purposes: to\nidentify which countries are the most significant sources of profit-driven\ncybercrime, and to determine how impactful the cybercrime is in these\nlocations. Participants were reminded that state-based actors and offenders\ndriven primarily by personal interests (for instance, cyberbullying or\nharassment) should be excluded from their consideration. We defined the\n\u201csource\u201d of cybercrime as the country where offenders are primarily based,\nrather than their nationality. To maintain a level of consistency, we made the\ndecision to only include countries formally recognised by the United Nations.\nWe initially developed seven categories of cybercrime to be included in the\nsurvey, based on existing research. But during the focus groups and pilot\nsurvey, our experts converged on five categories as the most significant\ncybercrime threats on a global scale:\n\n  1. Technical products/services (e.g. malware coding, botnet access, access to compromised systems, tool production).\n  2. Attacks and extortion (e.g. DDoS attacks, ransomware).\n  3. Data/identity theft (e.g. hacking, phishing, account compromises, credit card comprises).\n  4. Scams (e.g. advance fee fraud, business email compromise, online auction fraud).\n  5. Cashing out/money laundering (e.g. credit card fraud, money mules, illicit virtual currency platforms).\n\nAfter being prompted with these descriptions and a series of images of world\nmaps to ensure participants considered a wide range of regions/countries,\nparticipants were asked to nominate up to five countries that they believed\nwere the most significant sources of each of these types of cybercrime.\nCountries could be listed in any order; participants were not instructed to\nrank them. Nominating countries was optional and participants were free to\nskip entire categories if they wished. Participants were then asked to rate\neach of the countries they nominated against three measures: how impactful the\ncybercrime is, how professional the cybercrime offenders are, and how\ntechnically skilled the cybercrime offenders are. Across each of these three\nmeasures, participants were asked to assign scores on a Likert-type scale\nbetween 1 (e.g. least professional) to 10 (e.g. most professional). Nominating\nand then rating countries was repeated for all five cybercrime categories.\n\nThis process, of nominating and then rating countries across each category,\nintroduces a potential limitation in the survey design: the possibility of\nsurvey response fatigue. If a participant nominated the maximum number of\ncountries across each cybercrime category\u2013 25 countries\u2013by the end of the\nsurvey they would have completed 75 Likert-type scales. The repetition of this\ntask, paired with the consideration that it requires, has the potential to\nintroduce respondent fatigue as the survey progresses, in the form of response\nattrition, an increase in careless responses, and/or increased likelihood of\nsignificantly higher/lower scores given. This is a common phenomenon in long-\nform surveys [36], and especially online surveys [37, 38]. Jeong et al [39],\nfor instance, found that questions asked near the end of a 2.5 hour survey\nwere 10\u201364% more likely to be skipped than those at the beginning. We designed\nthe survey carefully, refined with the aid of focus groups and a pilot, to\nensure that only the most essential questions were asked. As such, the survey\nwas not overly long (estimated to take 30 minutes). To accommodate any\ncognitive load, participants were allowed to complete the survey anytime\nwithin a two-week window. Their progress was saved after each session, which\nenabled participants to take breaks between completing each section (a\nsuggestion made by Jeong et al [39]). Crucially, throughout survey\nrecruitment, participants were informed that the survey is time-intensive and\nrequired significant attention. At the beginning of the survey, participants\nwere instructed not to undertake the survey unless they could allocate 30\nminutes to it. This approach pre-empted survey fatigue by discouraging those\nlikely to lose interest from participating. This compounds the fact that only\nexperts with a specific/strong interest in the subject matter of the survey\nwere invited to participate. Survey fatigue is addressed further in the\nDiscussion section, where we provide an analysis suggesting little evidence of\nparticipant fatigue.\n\nIn sum, we designed the survey to protect against various sources of bias and\nerror, and there are encouraging signs that the effects of these issues in the\ndata are limited (see Discussion). Yet expert surveys are inherently prone to\nsome types of bias and response issues; in the WCI, the issue of selection and\nself-selection within our pool of experts, as well as geo-political biases\nthat may lead to systematic over- or under-scoring of certain countries, is\nsomething we considered closely. We discuss these issues in detail in the\nsubsection on Limitations below.\n\n#### Measures.\n\nUsing the survey responses, we define the following two metrics: (i) a\ncybercriminality \u201ctype\u201d score for each of the five crime types; (ii) an\n\u201coverall\u201d score across all types of cybercrime, which we term the World\nCybercrime Index (WCI). We calculate the cybercriminality score for each crime\ntype\u2013the WCI_type score\u2013in two steps. First, we first calculate the average\nscore across the three dimensions (impact, professionalism and technical\nskill) across all nominations for that country within one of the five\ncybercrime types. The average score of each measure is then averaged into a\n\u201ctype\u201d score for each country, as shown in Eq (1): (1)\n\nThis \u201ctype\u201d score is then multiplied by the proportion of experts who\nnominated that country. Within each cybercrime type, a country could be\nnominated a possible total of 92 times\u2013once per participant. We then multiply\nthis weighted score by ten to produce a continuous scale out of 100 (see Eq\n(2)). This process prevents countries that received high scores, but a low\nnumber of nominations, from receiving artificially high rankings.\n\n(2)\n\nWe calculate the WCI_overall score for each country using a similar process.\nFirst, we calculate the country\u2019s average score (Country Score_type from Eq 1)\nfor all five cybercrime types. We then average these five type scores together\ninto an overall score. This overall score is then multiplied by the sum of\nnominations across all crime types,divided by the total possible nominations\nfor each country, which is increased to 460 (once per 92 participants, per 5\ncybercrime types). This score is then multiplied by ten to produce a\ncontinuous scale out of 100, as shown in Eq (3): (3)\n\nThe analyses for this paper were performed in R. All data and code have been\nmade publicly available so that our analysis can be reproduced and extended.\n\n## Results\n\nWe contacted 245 individuals to participate in the survey, of which 147 agreed\nand were sent invitation links to participate. Out of these 147, a total of 92\npeople completed the survey, giving us an overall response rate of 37.5%.\nGiven the expert nature of the sample, this is a high response rate (for a\ndetailed discussion see [40]), and one just below what Wu, Zhao, and Fils-Aime\nestimate of response rates for general online surveys in social science: 44%\n[41]. The survey collected information on the participants\u2019 primary\nnationality and their current country of residence. Four participants chose\nnot to identify their nationality. Overall, participants represented all five\nmajor geopolitical regions (Africa, the Asia-Pacific, Europe, North America\nand South America), both in nationality and residence, though the distribution\nwas uneven and concentrated in particular regions/countries. There were 8\nparticipants from Africa, 11 participants from the Asia Pacific, 27 from North\nAmerica, and 39 from Europe. South America was the least represented region\nwith only 3 participants. A full breakdown of participants\u2019 nationality,\nresidence, and areas of expertise is included in the Supporting Information\ndocument (see S1 Appendix).\n\nTable 1 shows the scores for the top fifteen countries of the WCI_overall\nindex. Each entry shows the country, along with the mean score (out of 10)\naveraged across the participants who nominated this country, for three\ncategories: impact, professionalism, and technical skill. This is followed by\neach country\u2019s WCI_overall and WCI_type scores. Countries are ordered by their\nWCI_overall score. Each country\u2019s highest WCI_type scores are highlighted.\nFull indices that include all 197 UN-recognised countries can be found in S1\nIndices.\n\nDownload:\n\n  * PPT\n\nPowerPoint slide\n\n  * PNG\n\nlarger image\n\n  * TIFF\n\noriginal image\n\nTable 1. World Cybercrime Index overall\u2013top 15 countries.\n\nhttps://doi.org/10.1371/journal.pone.0297312.t001\n\nSome initial patterns can be observed from this table, as well as the full\nindices in the supplementary document (see S1 Indices). First, a small number\nof countries hold consistently high ranks for cybercrime. Six countries\u2013China,\nRussia, Ukraine, the US, Romania, and Nigeria\u2013appear in the top 10 of every\nWCI_type index, including the WCI_overall index. Aside from Romania, all\nappear in the top three at least once. While appearing in a different order,\nthe first ten countries in the Technical products/services and Attacks and\nextortion indices are the same. Second, despite this small list of countries\nregularly appearing as cybercrime hubs, the survey results capture a broad\ngeographical diversity. All five geopolitical regions are represented across\neach type. Overall, 97 distinct countries were nominated by at least one\nexpert. This can be broken down into the cybercrime categories. Technical\nproducts/services includes 41 different countries; Attacks and extortion 43;\nData/identity theft 51; Scams 49; and Cashing out/money laundering 63.\n\nSome key findings emerge from these results, which are further illustrated by\nthe following Figs 1 and 2. First, cybercrime is not universally distributed.\nCertain countries are cybercrime hubs, while many others are not associated\nwith cybercriminality in a serious way. Second, countries that are cybercrime\nhubs specialise in particular types of cybercrime. That is, despite a small\nnumber of countries being leading producers of cybercrime, there is meaningful\nvariation between them both across categories, and in relation to scores for\nimpact, professionalism and technical skill. Third, the results show a longer\nlist of cybercrime-producing countries than are usually included in\npublications on the geography of cybercrime. As the survey captures leading\nproducers of cybercrime, rather than just any country where cybercrime is\npresent, this suggests that, even if a small number of countries are of\nserious concern, and close to 100 are of little concern at all, the remaining\nhalf are of at least moderate concern.\n\nDownload:\n\n  * PPT\n\nPowerPoint slide\n\n  * PNG\n\nlarger image\n\n  * TIFF\n\noriginal image\n\nFig 1. World map of the WCI_overall index\u2013top 15 countries labelled.\n\nBase map and data from OpenStreetMap and OpenStreetMap Foundation.\n\nhttps://doi.org/10.1371/journal.pone.0297312.g001\n\nDownload:\n\n  * PPT\n\nPowerPoint slide\n\n  * PNG\n\nlarger image\n\n  * TIFF\n\noriginal image\n\nFig 2. Top 50 countries by WCI_overall score.\n\nhttps://doi.org/10.1371/journal.pone.0297312.g002\n\nTo examine further the second finding concerning hub specialisation, we\ncalculated an overall \u201cTechnicality score\u201d\u2013or \u201cT-score\u201d\u2013for the top 15\ncountries of the WCI_overall index. We assigned a value from 2 to -2 to each\ntype of cybercrime to designate the level of technical complexity involved.\nTechnical products/services is the most technically complex type (2), followed\nby Attacks and extortion (1), Data/identity theft (0), Scams (-1), and finally\nCashing out and money laundering (-2), which has very low technical\ncomplexity. We then multiplied each country\u2019s WCI score for each cybercrime\ntype by its assigned value\u2013for instance, a Scams WCI score of 5 would be\nmultiplied by -1, with a final modified score of -5. As a final step, for each\ncountry, we added all of their modified WCI scores across all five categories\ntogether to generate the T-score. Fig 3 plots the top 15 WCI_overall\ncountries\u2019 T-scores, ordering them by score. Countries with negative T-scores\nare highlighted in red, and countries with positive scores are in black.\n\nDownload:\n\n  * PPT\n\nPowerPoint slide\n\n  * PNG\n\nlarger image\n\n  * TIFF\n\noriginal image\n\nFig 3. Technicality or T-score for the top 15 WCI_overall countries.\n\nNegative values correspond to lower technicality, positive values to higher\ntechnicality.\n\nhttps://doi.org/10.1371/journal.pone.0297312.g003\n\nThe T-score is best suited to characterising a given hub\u2019s specialisation. For\ninstance, as the line graph makes clear, Russia and Ukraine are highly\ntechnical cybercrime hubs, whereas Nigerian cybercriminals are engaged in less\ntechnical forms of cybercrime. But for countries that lie close to the centre\n(0), the story is more complex. Some may specialise in cybercrime types with\nmiddling technical complexity (e.g. Data/identity theft). Others may\nspecialise in both high- and low-tech crimes. In this sample of countries,\nIndia (-6.02) somewhat specialises in Scams but is otherwise a balanced hub,\nwhereas Romania (10.41) and the USA (-2.62) specialise in both technical and\nnon-technical crimes, balancing their scores towards zero. In short, each\ncountry has a distinct profile, indicating a unique local dimension.\n\n## Discussion\n\nThis paper introduces a global and robust metric of cybercriminality\u2013the World\nCybercrime Index. The WCI moves past previous technical measures of cyber\nattack geography to establish a more focused measure of the geography of\ncybercrime offenders. Elicited through an expert survey, the WCI shows that\ncybercrime is not universally distributed. The key theoretical contribution of\nthis index is to illustrate that cybercrime, often seen as a fluid and global\ntype of organized crime, actually has a strong local dimension (in keeping\nwith broader arguments by some scholars, such as [14, 42]).\n\nWhile we took a number of steps to ensure our sample of experts was\ngeographically representative, the sample is skewed towards some regions (such\nas Europe) and some countries (such as the US). This may simply reflect the\nhigh concentration of leading cybercrime experts in these locations. But it is\nalso possible this distribution reflects other factors, including the authors\u2019\nown social networks; the concentration of cybercrime taskforces and\norganisations in particular countries; the visibility of different nations on\nnetworking platforms like LinkedIn; and also perhaps norms of enthusiasm or\nsuspicion towards foreign research projects, both inside particular\norganisations and between nations.\n\nTo better understand what biases might have influenced the survey data, we\nanalysed participant rating behaviours with a series of linear regressions.\nNumerical ratings were the response and different participant\ncharacteristics\u2013country of nationality; country of residence; crime type\nexpertise; and regional expertise\u2013were the predictors. Our analysis found\nevidence (p < 0.05) that participants assigned higher ratings to the\ncountr(ies) they either reside in or are citizens of, though this was not a\nstrong or consistent result. For instance, regional experts did not\nconsistently rate their region of expertise more highly than other regions.\nEuropean and North American experts, for example, rated countries from these\nregions lower than countries from other regions. Our analysis of cybercrime\ntype expertise showed even less systematic rating behaviour, with no\nregression yielding a statistically significant (p < 0.05) result. Small\nsample sizes across other known participant characteristics meant that further\nanalyses of rating behaviour could not be performed. This applied to, for\ninstance, whether residents and citizens of the top ten countries in the WCI\nnominated their own countries more or less often than other experts. On this\npoint: 46% of participants nominated their own country at some point in the\nsurvey, but the majority (83%) of nominations were for a country different to\nthe participant\u2019s own country of residence or nationality. This suggested\nlimited bias towards nominating one\u2019s own country. Overall, these analyses\npoint to an encouraging observation: while there is a slight home-country\nbias, this does not systematically result in higher rating behaviour.\nLongitudinal data from future surveys, as well as a larger participant pool,\nwill better clarify what other biases may affect rating behaviour.\n\nThere is little evidence to suggest that survey fatigue affected our data. As\nthe survey progressed, the heterogeneity of nominated countries across all\nexperts increased, from 41 different countries nominated in the first category\nto 63 different countries nominated in the final category. If fatigue played a\nsignificant role in the results then we would expect this number to decrease,\nas participants were not required to nominate countries within a category and\nwould have been motivated to nominate fewer countries to avoid extending their\nsurvey time. We further investigated the data for evidence of survey fatigue\nin two additional ways: by performing a Mann-Kendall/Sen\u2019s slope trend test\n(MK/S) to determine whether scores skewed significantly upwards or downwards\ntowards the end of the survey; and by compiling an intra-individual response\nvariability (IRV) index to search for long strings of repeated scores at the\nend of the survey [43]. The MK/S test was marginally statistically significant\n(p<0.048), but the results indicated that scores trended downwards only\nminimally (-0.002 slope coefficient). Likewise, while the IRV index uncovered\na small group of participants (n = 5) who repeatedly inserted the same score,\nthis behaviour was not more likely to happen at the end of the survey (see S7\nand S8 Tables in S1 Appendix).\n\nIt is encouraging that there is at least some external validation for the\nWCI\u2019s highest ranked countries. Steenbergen and Marks [44] recommend that data\nproduced from expert judgements should \u201cdemonstrate convergent validity with\nother measures of [the topic]\u2013that is, the experts should provide evaluations\nof the same [...] phenomenon that other measurement instruments pick up.\u201d (p.\n359) Most studies of the global cybercrime geography are, as noted in the\nintroduction, based on technical measures that cannot accurately establish the\ntrue physical location of offenders (for example [1, 4, 28, 33, 45]).\nComparing our results to these studies would therefore be of little value, as\nthe phenomena being measured differs: they are measuring attack\ninfrastructure, whereas the WCI measures offender location. Instead, looking\nat in-depth qualitative cybercrime case studies would provide a better\ncomparison, at least for the small number of higher ranked countries. Though\nfew such studies into profit-driven cybercrime exist, and the number of\ncountries included are limited, we can see that the top ranked countries in\nthe WCI match the key cybercrime producing countries discussed in the\nqualitative literature (see for example [3, 10, 32, 46\u201350]). Beyond this\nqualitative support, our sampling strategy\u2013discussed in the Methods section\nabove\u2013is our most robust control for ensuring the validity of our data.\n\nAlong with contributing to theoretical debates on the (local) nature of\norganized crime [1, 14], this index can also contribute to policy discussions.\nFor instance, there is an ongoing debate as to the best approaches to take in\ncybercrime reduction, whether this involves improving cyber-law enforcement\ncapacity [3, 51], increasing legitimate job opportunities and access to youth\nprograms for potential offenders [52, 53], strengthening international\nagreements and law harmonization [54\u201356], developing more sophisticated and\nculturally-specific social engineering countermeasures [57], or reducing\ncorruption [3, 58]. As demonstrated by the geographical, economic, and\npolitical diversity of the top 15 countries (see Table 1), the likelihood that\na single strategy will work in all cases is low. If cybercrime is driven by\nlocal factors, then mitigating it may require a localised approach that\nconsiders the different features of cybercrime in these contexts. But no\nmatter what strategies are applied in the fight against cybercrime, they\nshould be targeted at the countries that produce the most cybercrime, or at\nleast produce the most impactful forms of it [3]. An index is a valuable\nresource for determining these countries and directing resources\nappropriately. Future research that explains what is driving cybercrime in\nthese locations might also suggest more appropriate means for tackling the\nproblem. Such an analysis could examine relevant correlates, such as\ncorruption, law enforcement capacity, internet penetration, education levels\nand so on to inform/test a theoretically-driven model of what drives\ncybercrime production in some locations, but not others. It also might be\npossible to make a kind of prediction: to identify those nations that have not\nyet emerged as cybercrime hubs but may in the future. This would allow an\nearly warning system of sorts for policymakers seeking to prevent cybercrime\naround the world.\n\n### Limitations\n\nIn addition to the points discussed above, the findings of the WCI should be\nconsidered in light of some remaining limitations. Firstly, as noted in the\nmethods, our pool of experts was not as large or as globally representative as\nwe had hoped. Achieving a significant response rate is a common issue across\nall surveys, and is especially difficult in those that employ the snowball\ntechnique [59] and also attempt to recruit experts [60]. However, ensuring\nthat our survey data captures the most accurate picture of cybercrime activity\nis an essential aspect of the project, and the under-representation of experts\nfrom Africa and South America is noteworthy. More generally, our sample size\n(n = 92) is relatively small. Future iterations of the WCI survey should focus\non recruiting a larger pool of experts, especially those from under-\nrepresented regions. However, this is a small and hard-to-reach population,\nwhich likely means the sample size will not grow significantly. While this\nlimits statistical power, it is also a strength of the survey: by ensuring\nthat we only recruit the top cybercrime experts in the world, the weight and\nvalidity of our data increases.\n\nSecondly, though we developed our cybercrime types and measures with expert\nfocus groups, the definitions used in the WCI will always be contestable. For\ninstance, a small number of comments left at the end of the survey indicated\nthat the Cashing out/money laundering category was unclear to some\nparticipants, who were unsure whether they should nominate the country in\nwhich these schemes are organised or the countries in which the actual cash\nout occurs. A small number of participants also commented that they were not\nsure whether the \u2018impact\u2019 of a country\u2019s cybercrime output should be measured\nin terms of cost, social change, or some other metric. We limited any such\nuncertainties by running a series of focus groups to check that our categories\nwere accurate to the cybercrime reality and comprehensible to practitioners in\nthis area. We also ran a pilot version of the survey. The beginning of the\nsurvey described the WCI\u2019s purpose and terms of reference, and participants\nwere able to download a document that described the project\u2019s methodology in\nfurther detail. Each time a participant was prompted to nominate countries as\na significant source of a type of cybercrime, the type was re-defined and\nexamples of offences under that type were provided. However, the examples were\nnot exhaustive and the definitions were brief. This was done partly to avoid\nsignificantly lengthening the survey with detailed definitions and\nclarifications. We also wanted to avoid over-defining the cybercrime types so\nthat any new techniques or attack types that emerged while the survey ran\nwould be included in the data. Nonetheless, there will always remain some\nelasticity around participant interpretations of the survey.\n\nFinally, although we restricted the WCI to profit-driven activity, the\ndistinction between cybercrime that is financially-motivated, and cybercrime\nthat is motivated by other interests, is sometimes blurred. Offenders who\ntypically commit profit-driven offences may also engage in state-sponsored\nactivities. Some of the countries with high rankings within the WCI may\nshelter profit-driven cybercriminals who are protected by corrupt state actors\nof various kinds, or who have other kinds of relationships with the state.\nActors in these countries may operate under the (implicit or explicit)\nsanctioning of local police or government officials to engage in cybercrime.\nThus while the WCI excludes state-based attacks, it may include profit-driven\ncybercriminals who are protected by states. Investigating the intersection\nbetween profit-driven cybercrime and the state is a strong focus in our\nongoing and future research. If we continue to see evidence that these\nactivities can overlap (see for example [32, 61\u201363]), then any models\nexplaining the drivers of cybercrime will need to address this increasingly\nimportant aspect of local cybercrime hubs.\n\n## Conclusion\n\nThis study makes use of an expert survey to better measure the geography of\nprofit-driven cybercrime and presents the output of this effort: the World\nCybercrime Index. This index, organised around five major categories of\ncybercrime, sheds light on the geographical concentrations of financially-\nmotivated cybercrime offenders. The findings reveal that a select few\ncountries pose the most significant cybercriminal threat. By illustrating that\nhubs often specialise in particular forms of cybercrime, the WCI also offers\nvaluable insights into the local dimension of cybercrime. This study provides\na foundation for devising a theoretically-driven model to explain why some\ncountries produce more cybercrime than others. By contributing to a deeper\nunderstanding of cybercrime as a localised phenomenon, the WCI may help lift\nthe veil of anonymity that protects cybercriminals and thereby enhance global\nefforts to combat this evolving threat.\n\n## Supporting information\n\nWCI indices.\n\nShowing 1/2: pone.0297312.s001.pdf\n\n### S1 Indices. WCI indices.\n\nFull indices for the WCI Overall and each WCI Type.\n\nhttps://doi.org/10.1371/journal.pone.0297312.s001\n\n(PDF)\n\n### S1 Appendix. Supporting information.\n\nDetails of respondent characteristics and analysis of rating behaviour.\n\nhttps://doi.org/10.1371/journal.pone.0297312.s002\n\n(PDF)\n\n## Acknowledgments\n\nThe data collection for this project was carried out as part of a partnership\nbetween the Department of Sociology, University of Oxford and UNSW Canberra\nCyber. The analysis and writing phases received support from CRIMGOV. Fig 1\nwas generated using information from OpenStreetMap and OpenStreetMap\nFoundation, which is made available under the Open Database License.\n\n## References\n\n  1. 1\\. Kigerl A. Routine Activity Theory and the Determinants of High Cybercrime Countries. Soc Sci Comput Rev. 2012;30: 470\u2013486.\n\n     * View Article\n     * Google Scholar\n  2. 2\\. Lusthaus J, Bruce M, Phair N. Mapping the geography of cybercrime: A review of indices of digital offending by country. 2020.\n\n  3. 3\\. Lusthaus J, Varese F. Offline and Local: The Hidden Face of Cybercrime. Polic J Policy Pract. 2021;15: 4\u201314.\n\n     * View Article\n     * Google Scholar\n  4. 4\\. McCombie S, Pieprzyk J, Watters P. Cybercrime Attribution: An Eastern European Case Study. Proceedings of the 7th Australian Digital Forensics Conference. Perth, Australia: secAU\u2014Security Research Centre, Edith Cowan University; 2009. pp. 41\u201351. https://researchers.mq.edu.au/en/publications/cybercrime-attribution-an-eastern-european-case-study\n\n  5. 5\\. Heckathorn D. Respondent-Driven Sampling: A New Approach to the Study of Hidden Populations. Soc Probl. 1997;44.\n\n     * View Article\n     * Google Scholar\n  6. 6\\. Heckathorn D, Salganik M. Sampling and Estimation in Hidden Populations Using Respondent-Driven Sampling. 2004;34.\n\n     * View Article\n     * Google Scholar\n  7. 7\\. Anderson R, Barton C, Bohme R, Clayton R, van Eeten M, Levi M, et al. Measuring the cost of cybercrime. The Economics of Information Security and Privacy. Springer; 2013. pp. 265\u2013300. https://link.springer.com/chapter/10.1007/978-3-642-39498-0_12\n\n  8. 8\\. Anderson R, Barton C, Bohme R, Clayton R, Ganan C, Grasso T, et al. Measuring the Changing Cost of Cybercrime. California, USA; 2017.\n\n  9. 9\\. Morgan S. 2022 Official Cybercrime Report. Cybersecurity Ventures; 2022. https://s3.ca-central-1.amazonaws.com/esentire-dot-com-assets/assets/resourcefiles/2022-Official-Cybercrime-Report.pdf\n\n  10. 10\\. Hall T, Sanders B, Bah M, King O, Wigley E. Economic geographies of the illegal: the multiscalar production of cybercrime. Trends Organised Crime. 2021;24: 282\u2013307.\n\n     * View Article\n     * Google Scholar\n  11. 11\\. Shelley L. Transnational Organized Crime: An Imminent Threat to the Nation-State? J Int Aff. 1995;48: 463\u2013489.\n\n     * View Article\n     * Google Scholar\n  12. 12\\. Wall D. Cybercrime: The Transformation of Crime in the Information Age. Polity Press; 2007.\n\n  13. 13\\. Grabosky P. The Global Dimension of Cybercrime. Glob Crime. 2010;6: 146\u2013157. https://www.tandfonline.com/doi/abs/10.1080/1744057042000297034\n\n     * View Article\n     * Google Scholar\n  14. 14\\. Varese F. Mafias on the move: how organized crime conquers new territories. Princeton University Press; 2011.\n\n  15. 15\\. Dupont B. Skills and Trust: A Tour Inside the Hard Drives of Computer Hackers. Crime and networks. Routledge; 2013.\n\n  16. 16\\. Franklin J, Paxson V, Savage S. An Inquiry into the Nature and Causes of the Wealth of Internet Miscreants. Proceedings of the 2007 ACM Conference on Computer and Communications Security. Alexandria, Virginia, USA; 2007.\n\n  17. 17\\. Hutchings A, Clayton R. Configuring Zeus: A case study of online crime target selection and knowledge transmission. Scottsdale, AZ, USA: IEEE; 2017.\n\n  18. 18\\. Musotto R, Wall D. More Amazon than Mafia: analysing a DDoS stresser service as organised cybercrime. Trends Organised Crime. 2020;25: 173\u2013191.\n\n     * View Article\n     * Google Scholar\n  19. 19\\. Hall T. Where the money is: the geographies of organised crime. Geography. 2010;95.\n\n     * View Article\n     * Google Scholar\n  20. 20\\. Levesque F, Fernandez J, Somayaji A, Batchelder. National-level risk assessment: A multi-country study of malware infections. 2016. https://homeostasis.scs.carleton.ca/~soma/pubs/levesque-weis2016.pdf\n\n  21. 21\\. Crowdstrike. 2022 Global Threat Report. Crowdstrike; 2022. https://go.crowdstrike.com/crowdstrike/gtr\n\n  22. 22\\. EC3. Internet Organised Crime Threat Assessment (IOCTA) 2021. EC3; 2021. https://www.europol.europa.eu/publications-events/main-reports/internet-organised-crime-threat-assessment-iocta-2021\n\n  23. 23\\. ENISA. ENISA threat Landscape 2021. ENISA; 2021. https://www.enisa.europa.eu/publications/enisa-threat-landscape-2021\n\n  24. 24\\. Sophos. Sophos 2022 Threat Report. Sophos; 2022. https://www.sophos.com/ en-us/labs/security-threat-report\n\n  25. 25\\. van Eeten M, Bauer J, Asghari H, Tabatabaie S, Rand D. The Role of Internet Service Providers in Botnet Mitigation. An Empirical Analysis Based on Spam Data WEIS. 2010. van Eeten, Michel and Bauer, Johannes M. and Asghari, Hadi and Tabatabaie, Shirin and Rand, David, The Role of Internet Service Providers in Botnet Mitigation an Empirical Analysis Based on Spam Data (August 15, 2010). TPRC 2010, SSRN: https://ssrn.com/abstract=1989198\n\n  26. 26\\. He S, Lee GM, Quarterman JS, Whinston A. Cybersecurity Policies Design and Evaluation: Evidence from a Large-Scale Randomized Field Experiment. 2015. https://econinfosec.org/archive/weis2015/papers/WEIS_2015_he.pdf\n\n  27. 27\\. Snyder P, Kanich C. No Please, After You: Detecting Fraud in Affiliate Marketing Networks. 2015. https://econinfosec.org/archive/weis2015/papers/WEIS_2015_snyder.pdf\n\n  28. 28\\. Srivastava S, Das S, Udo G, Bagchi K. Determinants of Cybercrime Originating within a Nation: A Cross-country Study. J Glob Inf Technol Manag. 2020;23: 112\u2013137.\n\n     * View Article\n     * Google Scholar\n  29. 29\\. Wang Q-H, Kim S-H. Cyber Attacks: Cross-Country Interdependence and Enforcement. 2009. http://weis09.infosecon.net/files/153/paper153.pdf\n\n  30. 30\\. Holt TJ. Regulating Cybercrime through Law Enforcement and Industry Mechanisms. Ann Am Acad Pol Soc Sci. 2018;679: 140\u2013157.\n\n     * View Article\n     * Google Scholar\n  31. 31\\. Lee JR, Holt TJ, Burruss GW, Bossler AM. Examining English and Welsh Detectives\u2019 Views of Online Crime. Int Crim Justice Rev. 2021;31: 20\u201339.\n\n     * View Article\n     * Google Scholar\n  32. 32\\. Lusthaus J. Industry of Anonymity: Inside the Business of Cybercrime. Harvard University Press; 2018.\n\n  33. 33\\. Kshetri N. The Global Cybercrime Industry: Economic, Institutional and Strategic Perspectives. Berlin: Springer; 2010.\n\n  34. 34\\. Moitra S. Developing Policies for Cybercrime. Eur J Crime Crim Law Crim Justice. 2005;13.\n\n     * View Article\n     * Google Scholar\n  35. 35\\. Goodman L. Snowball sampling. Ann Math Stat. 1961;32: 148\u2013170.\n\n     * View Article\n     * Google Scholar\n  36. 36\\. Backor K, Golde S, Nie N. Estimating Survey Fatigue in Time Use Study. Washington, DC.; 2007. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=401f97f2d7c684b295486636d8a84c627eb33446\n\n  37. 37\\. Crawford S, Couper M, Lamias M. Web surveys: perceptions of burden. Soc Sci Comput Rev. 2001;19: 146\u2013162.\n\n     * View Article\n     * Google Scholar\n  38. 38\\. Marcus B, Bosnjak M, Lindner S, Pilischenko S, Schuetz A. Compensating for low topic interest and long surveys: a field experiment on nonresponse in web surveys. Soc Sci Comput Rev. 2007;25: 372\u2013383.\n\n     * View Article\n     * Google Scholar\n  39. 39\\. Jeong D, Aggarwal S, Robinson J, Kumar N, Spearot A, Park DS. Exhaustive or exhausting? Evidence on respondent fatigue in long surveys. J Dev Econ. 2022;161.\n\n     * View Article\n     * Google Scholar\n  40. 40\\. Vis B, Stolwijk S. Conducting quantitative studies with the participation of political elites: best practices for designing the study and soliciting the participation of political elites. Qual Quant. 2021;55: 1281\u20131317.\n\n     * View Article\n     * Google Scholar\n  41. 41\\. Wu M-J, Zhao K, Fils-Aime F. Response rates of online surveys in published research: A meta-analysis. Comput Hum Behav Rep. 2022;7.\n\n     * View Article\n     * Google Scholar\n  42. 42\\. Reuter P. Disorganized Crime: Illegal Markets and the Mafia. MIT Press; 1985.\n\n  43. 43\\. Huang JL, Curran PG, Keeney J, Poposki EM, DeShon RP. Detecting and deterring insufficient effort responding to surveys. J Bus Psychol. 2012;27: 99\u2013114.\n\n     * View Article\n     * Google Scholar\n  44. 44\\. Steenbergen M, Marks G. Evaluating expert judgments. Eur J Polit Res. 2007;46: 347\u2013366.\n\n     * View Article\n     * Google Scholar\n  45. 45\\. Chen S, Hao M, Ding F, Jiang D, Zhang S, Guo Q, et al. Exploring the global geography of cybercrime and its driving forces. Humanit Soc Sci Commun. 2023;10. pmid:36852135\n\n     * View Article\n     * PubMed/NCBI\n     * Google Scholar\n  46. 46\\. Hall T, Ziemer U. Exploring the relationship between IT development, poverty and cybercrime: an Armenia case study. J Cyber Policy. 2022;7: 353\u2013374.\n\n     * View Article\n     * Google Scholar\n  47. 47\\. Sotande E. Transnational Organised Crime and Illicit Financial Flows: Nigeria, West Africa and the Global North. University of Leeds, School of Law. 2016. https://etheses.whiterose.ac.uk/15473/1/Emmanuel%20Sotande%20Thessis%20at%20the%20University%20of%20Leeds.%20viva%20corrected%20version%20%281%29.pdf\n\n  48. 48\\. Lusthaus J. Modelling cybercrime development: the case of Vietnam. The Human Factor of Cybercrime. Routledge; 2020. pp. 240\u2013257.\n\n  49. 49\\. Van Nguyen T. The modus operandi of transnational computer fraud: a crime script analysis in Vietnam. Trends Organ Crime. 2022;25: 226\u2013247.\n\n     * View Article\n     * Google Scholar\n  50. 50\\. Hwang J, Choi K-S. North Korean Cyber Attacks and Policy Responses: An Interdisciplinary Theoretical Framework. Int J Cybersecurity Intell Cybercrime. 2021;4: 4\u201324. https://www.doi.org/10.52306/04020221NHPZ9033\n\n     * View Article\n     * Google Scholar\n  51. 51\\. Lusthaus J. Electronic Ghosts. In: Democracy: A Journal of Ideas [Internet]. 2014. https://democracyjournal.org/author/jlusthaus/\n\n  52. 52\\. Brewer R, de Vel-Palumbo M, Hutchings A, Maimon D. Positive Diversions. Cybercrime Prevention. 2019. https://www.researchgate.net/publication/337297392_Positive_Diversions\n\n  53. 53\\. National Cyber Crime Unit / Prevent Team. Pathways Into Cyber Crime. National Crime Agency; 2017. https://www.nationalcrimeagency.gov.uk/who-we-are/publications/6-pathways-into-cyber-crime-1/file\n\n  54. 54\\. Nizovtsev Y, Parfylo O, Barabash O, Kyrenko S, Smetanina N. Mechanisms of money laundering obtained from cybercrime: the legal aspect. J Money Laund Control. 2022;25.\n\n     * View Article\n     * Google Scholar\n  55. 55\\. Spiezia F. International cooperation and protection of victims in cyberspace: welcoming Protocol II to the Budapest Convention on Cybercrime. ERA Forum. 2022;23: 101\u2013108.\n\n     * View Article\n     * Google Scholar\n  56. 56\\. Levi M, Leighton Williams. Multi-agency partnerships in cybercrime reduction: Mapping the UK information assurance network cooperation space. Inf Manag Comput Secur. 2013;21.\n\n     * View Article\n     * Google Scholar\n  57. 57\\. Kayser C, Mastrorilli M, Cadigan R. Preventing cybercrime: A framework for understanding the role of human vulnerabilities. Cyber Secur Peer-Rev J. 2019;3: 159\u2013174.\n\n     * View Article\n     * Google Scholar\n  58. 58\\. Smith R, Jorna P. Chapter 14: Corrupt Misuse of Information and Communications Technologies. Handbook of Global Research and Practice in Corruption. 2011.\n\n     * View Article\n     * Google Scholar\n  59. 59\\. Erickson BH. Some problems of interference from chain data. Sociol Methodol. 1979;10: 276\u2013302.\n\n     * View Article\n     * Google Scholar\n  60. 60\\. Christopoulos D. Peer Esteem Snowballing: A methodology for expert surveys. 2009. https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=63ac9f6db0a2fa2e0ca08cd28961385f98ec21ec\n\n  61. 61\\. Whelan C, Martin J. Ransomware through the lens of state crime: conceptualizing ransomware groups as cyber proxies, pirates, and privateers. State Crime J. 2023;12: 4\u201328.\n\n     * View Article\n     * Google Scholar\n  62. 62\\. Davina S. A New State of Organized Crime: An Analysis of Cybercrime Networks, Activities, and Emerging Threats. J Intell Confl Warf. 2020;3: 1\u201311.\n\n     * View Article\n     * Google Scholar\n  63. 63\\. Lavorgna A. Unpacking the political-criminal nexus in state-cybercrimes: a macro-level typology. Trends Organ Crime. 2023.\n\n     * View Article\n     * Google Scholar\n\nDownload PDF\n\n  * Citation\n  * XML\n\nPrint\n\nShare\n\n  * Reddit\n  * Facebook\n  * LinkedIn\n  * Mendeley\n  * Twitter\n  * Email\n\nAdvertisement\n\n###\n\nSubject Areas\n\n?\n\nFor more information about PLOS Subject Areas, click here.\n\nWe want your feedback. Do these Subject Areas make sense for this article?\nClick the target next to the incorrect Subject Area and let us know. Thanks\nfor your help!\n\n  * Surveys\n\nIs the Subject Area \"Surveys\" applicable to this article?\n\nThanks for your feedback.\n\n  * Geography\n\nIs the Subject Area \"Geography\" applicable to this article?\n\nThanks for your feedback.\n\n  * Crime\n\nIs the Subject Area \"Crime\" applicable to this article?\n\nThanks for your feedback.\n\n  * Theft\n\nIs the Subject Area \"Theft\" applicable to this article?\n\nThanks for your feedback.\n\n  * Europe\n\nIs the Subject Area \"Europe\" applicable to this article?\n\nThanks for your feedback.\n\n  * Law enforcement\n\nIs the Subject Area \"Law enforcement\" applicable to this article?\n\nThanks for your feedback.\n\n  * Intelligence\n\nIs the Subject Area \"Intelligence\" applicable to this article?\n\nThanks for your feedback.\n\n  * South America\n\nIs the Subject Area \"South America\" applicable to this article?\n\nThanks for your feedback.\n\n  * Publications\n  * PLOS Biology\n  * PLOS Climate\n  * PLOS Complex Systems\n  * PLOS Computational Biology\n  * PLOS Digital Health\n  * PLOS Genetics\n  * PLOS Global Public Health\n\n  * PLOS Medicine\n  * PLOS Mental Health\n  * PLOS Neglected Tropical Diseases\n  * PLOS ONE\n  * PLOS Pathogens\n  * PLOS Sustainability and Transformation\n  * PLOS Water\n\n  * Home\n  * Blogs\n  * Collections\n  * Give feedback\n  * LOCKSS\n\n  * Privacy Policy\n  * Terms of Use\n  * Advertise\n  * Media Inquiries\n  * Contact\n\nPLOS is a nonprofit 501(c)(3) corporation, #C2354500, based in San Francisco,\nCalifornia, US\n\n### Cookie Preference Center\n\nOur website uses different types of cookies. Optional cookies will only be set\nwith your consent and you may withdraw this consent at any time. Below you can\nlearn more about the types of cookies PLOS uses and register your cookie\npreferences.\n\n### Customize Your Cookie Preference\n\n+Strictly Necessary\n\nAlways On\n\n+Functional\n\n+Performance and Analytics\n\n+Marketing\n\nFor more information about the cookies and other technologies used by us,\nplease read our Cookie Policy.\n\n", "frontpage": false}

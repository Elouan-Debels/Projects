{"aid": "40001033", "title": "To understand the risks posed by AI, follow the money", "url": "https://theconversation.com/to-understand-the-risks-posed-by-ai-follow-the-money-225872", "domain": "theconversation.com", "votes": 2, "user": "jrepinc", "posted_at": "2024-04-11 11:34:24", "comments": 0, "source_title": "To understand the risks posed by AI, follow the money", "source_text": "To understand the risks posed by AI, follow the money\n\nMenu Close\n\nAcademic rigour, journalistic flair\n\nShutterstock/Chaosamran_Studio\n\n# To understand the risks posed by AI, follow the money\n\nPublished: April 10, 2024 12.34pm CEST\n\nTim O'Reilly, Ilan Strauss, Mariana Mazzucato, Rufus Rock, UCL\n\n### Authors\n\n  1. Tim O'Reilly\n\nVisiting Professor of Practice at the UCL Institute for Innovation and Public\nPurpose, UCL\n\n  2. Ilan Strauss\n\nHead of Digital Economy Research, UCL\n\n  3. Mariana Mazzucato\n\nProfessor in the Economics of Innovation and Public Value and Founding\nDirector of the UCL IIPP, UCL\n\n  4. Rufus Rock\n\nResearcher, Institute for Innovation and Public Purpose, UCL\n\n### Disclosure statement\n\nOur project at UCL, referenced in this article, was funded by Omidyar. I\npersonally did not receive any compensation from this grant, but I believe\nthat all of my co-authors did.\n\nIlan Strauss receives funding from The Omidyar Network through the UCL IIPP\nresearch project on algorithmic rents\n\nMariana Mazzucato received funding for this project from the Omidyar\nFoundation.\n\nRufus Rock received funding from the Omidyar Network whilst pursuing the\nresearch referenced in this piece.\n\n### Partners\n\nUniversity College London provides funding as a founding partner of The\nConversation UK.\n\nView all partners\n\n#####\n\nWe believe in the free flow of information\n\n###### Republish our articles for free, online or in print, under Creative\nCommons licence.\n\nEmail\n\nX (Twitter)\n\nFacebook56\n\nLinkedIn\n\nWhatsApp\n\nMessenger\n\nPrint\n\nTime and again, leading scientists, technologists, and philosophers have made\nspectacularly terrible guesses about the direction of innovation. Even\nEinstein was not immune, claiming, \u201cThere is not the slightest indication that\nnuclear energy will ever be obtainable,\u201d just ten years before Enrico Fermi\ncompleted construction of the first fission reactor in Chicago. Shortly\nthereafter, the consensus switched to fears of an imminent nuclear holocaust.\n\nSimilarly, today\u2019s experts warn that an artificial general intelligence (AGI)\ndoomsday is imminent. Others retort that large language models (LLMs) have\nalready reached the peak of their powers.\n\nIt\u2019s difficult to argue with David Collingridge\u2019s influential thesis that\nattempting to predict the risks posed by new technologies is a fool\u2019s errand.\nGiven that our leading scientists and technologists are usually so mistaken\nabout technological evolution, what chance do our policymakers have of\neffectively regulating the emerging technological risks from artificial\nintelligence (AI)?\n\nWe ought to heed Collingridge\u2019s warning that technology evolves in uncertain\nways. However, there is one class of AI risk that is generally knowable in\nadvance. These are risks stemming from misalignment between a company\u2019s\neconomic incentives to profit from its proprietary AI model in a particular\nway and society\u2019s interests in how the AI model should be monetised and\ndeployed.\n\nPhotograph of Albert Einstein in his office at Princeton University, New\nJersey, taken by Roman Vishniac in 1942. The Magnes Collection of Jewish Art\nand Life/Flickr, CC BY-NC-SA\n\nThe surest way to ignore such misalignment is by focusing exclusively on\ntechnical questions about AI model capabilities, divorced from the socio-\neconomic environment in which these models will operate and be designed for\nprofit.\n\nFocusing on the economic risks from AI is not simply about preventing\n\u201cmonopoly,\u201d \u201cself-preferencing,\u201d or \u201cBig Tech dominance\u201d. It\u2019s about ensuring\nthat the economic environment facilitating innovation is not incentivising\nhard-to-predict technological risks as companies \u201cmove fast and break things\u201d\nin a race for profit or market dominance.\n\nIt\u2019s also about ensuring that value from AI is widely shared, by preventing\npremature consolidation. We\u2019ll see more innovation if emerging AI tools are\naccessible to everyone, such that a dispersed ecosystem of new firms, start-\nups, and AI tools can arise.\n\nOpenAI is already becoming a dominant player with US$2 billion (\u00a31.6 billion)\nin annual sales and millions of users. Its GPT store and developer tools need\nto return value to those who create it in order to ensure ecosystems of\ninnovation remain viable and dispersed.\n\nBy carefully interrogating the system of economic incentives underlying\ninnovations and how technologies are monetised in practice, we can generate a\nbetter understanding of the risks, both economic and technological, nurtured\nby a market\u2019s structure. Market structure is not simply the number of firms,\nbut the cost structure and economic incentives in the market that follow from\nthe institutions, adjacent government regulations, and available financing.\n\n## Degrading quality for higher profit\n\nIt is instructive to consider how the algorithmic technologies that\nunderpinned the aggregator platforms of old (think Amazon, Google and Facebook\namong others) initially deployed to benefit users, were eventually\nreprogrammed to increase profits for the platform.\n\nThe problems fostered by social media, search, and recommendation algorithms\nwas never an engineering issue, but one of financial incentives (of profit\ngrowth) not aligning with algorithms\u2019 safe, effective, and equitable\ndeployment. As the saying goes: history doesn\u2019t necessarily repeat itself but\nit does rhyme.\n\nTo understand how platforms allocate value to themselves and what we can do\nabout it, we investigated the role of algorithms, and the unique informational\nset-up of digital markets, in extracting so-called economic rents from users\nand producers on platforms. In economic theory, rents are \u201csuper-normal\nprofits\u201d (profits that are above what would be achievable in a competitive\nmarket) and reflect control over some scarce resource.\n\nImportantly, rents are a pure return to ownership or some degree of monopoly\npower, rather than a return earned from producing something in a competitive\nmarket (such as many producers making and selling cars). For digital\nplatforms, extracting digital rents usually entails degrading the quality of\ninformation shown to the user, on the basis of them \u201cowning\u201d access to a mass\nof customers.\n\nFor example, Amazon\u2019s millions of users rely on its product search algorithms\nto show them the best products available for sale, since they are unable to\ninspect each product individually. These algorithms save everyone time and\nmoney: by helping users navigate through thousands of products to find the\nones with the highest quality and the lowest price, and by expanding the\nmarket reach of suppliers through Amazon\u2019s delivery infrastructure and immense\ncustomer network.\n\nThese platforms made markets more efficient and delivered enormous value both\nto users and to product suppliers. But over time, a misalignment between the\ninitial promise of them providing user value and the need to expand profit\nmargins as growth slows has driven bad platform behaviour. Amazon\u2019s\nadvertising business is a case in point.\n\n## Amazon\u2019s advertising\n\nIn our research on Amazon, we found that users still tend to click on the\nproduct results at the top of the page, even when they are no longer the best\nresults but instead paid advertising placements. Amazon abuses the habituated\ntrust that users have come to place in its algorithms, and instead allocates\nuser attention and clicks to inferior quality, sponsored, information from\nwhich it profits immensely.\n\nWe found that, on average, the most-clicked sponsored products\n(advertisements) were 17% more expensive and 33% lower ranked according to\nAmazon\u2019s own quality, price, and popularity optimising algorithms. And because\nproduct suppliers must now pay for the product ranking that they previously\nearned through product quality and reputation, their profits go down as\nAmazon\u2019s go up, and prices rise as some of the cost is passed on to customers.\n\nAmazon is one the most striking examples of a company pivoting away from its\noriginal \u201cvirtuous\u201d mission (\u201cto be the most customer-centric company on\nEarth\u201d) towards an extractive business model. But it is far from alone.\n\nGoogle, Meta, and virtually all other major online aggregators have, over\ntime, come to preference their economic interests over their original promise\nto their users and to their ecosystems of content and product suppliers or\napplication developers. Science fiction writer and activist Cory Doctorow\ncalls this the \u201censhittification\u201d of Big Tech platforms.\n\nBut not all rents are bad. According to the economist Joseph Schumpeter, rents\nreceived by a firm from innovating can be beneficial for society. Big Tech\u2019s\nplatforms got ahead through highly innovative, superior, algorithmic\nbreakthroughs. The current market leaders in AI are doing the same.\n\nSo while Schumpeterian rents are real and justified, over time, and under\nexternal financial pressure, market leaders began to use their algorithmic\nmarket power to capture a greater share of the value created by the ecosystem\nof advertisers, suppliers and users in order to keep profit growing.\n\nUser preferences were downgraded in algorithmic importance in favour of more\nprofitable content. For social media platforms, this was addictive content to\nincrease time spent on platform at any cost to user health. Meanwhile, the\nultimate suppliers of value to their platform \u2013 the content creators, website\nowners and merchants \u2013 have had to hand over more of their returns to the\nplatform owner. In the process, profits and profit margins have become\nconcentrated in a few platforms\u2019 hands, making innovation by outside companies\nharder.\n\nA platform compelling its ecosystem of firms to pay ever higher fees (in\nreturn for nothing of commensurate value on either side of the platform)\ncannot be justified. It is a red light that the platform has a degree of\nmarket power that it is exploiting to extract unearned rents. Amazon\u2019s most\nrecent quarterly disclosures (Q4, 2023), shows year-on-year growth in online\nsales of 9%, but growth in fees of 20% (third-party seller services) and 27%\n(advertising sales).\n\nWhat is important to remember in the context of risk and innovation is that\nthis rent-extracting deployment of algorithmic technologies by Big Tech is not\nan unknowable risk, as identified by Collingridge. It is a predictable\neconomic risk. The pursuit of profit via the exploitation of scarce resources\nunder one\u2019s control is a story as old as commerce itself.\n\nTechnological safeguards on algorithms, as well as more detailed disclosure\nabout how platforms were monetising their algorithms, may have prevented such\nbehaviour from taking place. Algorithms have become market gatekeepers and\nvalue allocators, and are now becoming producers and arbiters of knowledge.\n\n## Risks posed by the next generation of AI\n\nThe limits we place on algorithms and AI models will be instrumental to\ndirecting economic activity and human attention towards productive ends. But\nhow much greater are the risks for the next generation of AI systems? They\nwill shape not just what information is shown to us, but how we think and\nexpress ourselves. Centralisation of the power of AI in the hands of a few\nprofit-driven entities that are likely to face future economic incentives for\nbad behaviour is surely a bad idea.\n\nThankfully, society is not helpless in shaping the economic risks that\ninvariably arise after each new innovation. Risks brought about from the\neconomic environment in which innovation occurs are not immutable. Market\nstructure is shaped by regulators and a platform\u2019s algorithmic institutions\n(especially its algorithms which make market-like allocations). Together,\nthese factors influence how strong the network effects and economies of scale\nand scope are in a market, including the rewards to market dominance.\n\nTechnological mandates such as interoperability, which refers to the ability\nof different digital systems to work together seamlessly; or \u201cside-loading\u201d,\nthe practice of installing apps from sources other than a platform\u2019s official\nstore, have shaped the fluidity of user mobility within and between markets,\nand in turn the ability for any dominant entity to durably exploit its users\nand ecosystem. The internet protocols helped keep the internet open instead of\nclosed. Open source software enabled it to escape from under the thumb of the\nPC era\u2019s dominant monopoly. What role might interoperability and open source\nplay in keeping the AI industry a more competitive and inclusive market?\n\nDisclosure is another powerful market-shaping tool. Disclosures can require\ntechnology companies to provide transparent information and explanations about\ntheir products and monetisation strategies. Mandatory disclosure of ad load\nand other operating metrics might have helped to prevent Facebook, for\nexample, from exploiting its users\u2019 privacy in order to maximise ad dollars\nfrom harvesting each user\u2019s data.\n\nBut a lack of data portability, and an inability to independently audit\nFacebook\u2019s algorithms, meant that Facebook continued to benefit from its\nsurveillance system for longer than it should have. Today, OpenAI and other\nleading AI model providers refuse to disclose their training data sets, while\nquestions arise about copyright infringement and who should have the right to\nprofit from AI-aided creative works. Disclosures and open technological\nstandards are key steps to try and ensure the benefits from these emerging AI\nplatforms are shared as widely as possible.\n\nMarket structure, and its impact on \u201cwho gets what and why\u201d, evolves as the\ntechnological basis for how firms are allowed to compete in a market evolves.\nSo perhaps it is time to turn our regulatory gaze away from attempting to\npredict the specific risks that might arise as specific technologies develop.\nAfter all, even Einstein couldn\u2019t do that.\n\nInstead, we should try to recalibrate the economic incentives underpinning\ntoday\u2019s innovations, away from risky uses of AI technology and towards open,\naccountable, AI algorithms that support and disperse value equitably. The\nsooner we acknowledge that technological risks are frequently an outgrowth of\nmisaligned economic incentives, the more quickly we can work to avoid\nrepeating the mistakes of the past.\n\nWe are not opposed to Amazon offering advertising services to firms on its\nthird-party marketplace. An appropriate amount of advertising space can indeed\nhelp lesser-known businesses or products, with competitive offerings, to gain\ntraction in a fair manner. But when advertising almost entirely displaces top-\nranked organic product results, advertising becomes a rent extraction device\nfor the platform.\n\nAn Amazon spokesperson said:\n\n> We disagree with a number of conclusions made in this research, which\n> misrepresents and overstates the limited data it uses. It ignores that sales\n> from independent sellers, which are growing faster than Amazon\u2019s own,\n> contribute to revenue from services, and that many of our advertising\n> services do not appear on the store.\n>\n> Amazon obsesses over making customers\u2019 lives easier and a big part of that\n> is making sure customers can quickly and conveniently find and discover the\n> products they want in our store. Advertisements have been an integral part\n> of retail for many decades and anytime we include them they are clearly\n> marked as \u2018Sponsored\u2019. We provide a mix of organic and sponsored search\n> results based on factors including relevance, popularity with customers,\n> availability, price, and speed of delivery, along with helpful search\n> filters to refine their results. We have also invested billions in the tools\n> and services for sellers to help them grow and additional services such as\n> advertising and logistics are entirely optional.\n\n  * Artificial intelligence (AI)\n  * Google\n  * Amazon\n  * Insights series\n  * Meta\n\n### Events\n\nMore events\n\n### Jobs\n\n  * ##### Research Fellow \u2013 Beyond The Resource Curse\n\n  * ##### Audience Development Coordinator (fixed-term maternity cover)\n\n  * ##### Lecturer (Hindi-Urdu)\n\n  * ##### Director, Defence and Security\n\n  * ##### Opportunities with the new CIEHF\n\nMore jobs\n\nCopyright \u00a9 2010\u20132024, The Conversation Media Group Ltd\n\n", "frontpage": false}

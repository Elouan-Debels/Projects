{"aid": "40060925", "title": "Driftsort: An efficient, generic and robust stable sort implementation", "url": "https://github.com/Voultapher/sort-research-rs/blob/main/writeup/driftsort_introduction/text.md", "domain": "github.com/voultapher", "votes": 2, "user": "killcoder", "posted_at": "2024-04-17 05:49:33", "comments": 0, "source_title": "sort-research-rs/writeup/driftsort_introduction/text.md at main \u00b7 Voultapher/sort-research-rs", "source_text": "sort-research-rs/writeup/driftsort_introduction/text.md at main \u00b7\nVoultapher/sort-research-rs \u00b7 GitHub\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nVoultapher / sort-research-rs Public\n\n  * Notifications\n  * Fork 13\n  * Star 290\n\n/\n\n# text.md\n\n## Latest commit\n\nVoultapher\n\nAdd ipnsort and driftsort design documents\n\nApr 16, 2024\n\n8be68c6 \u00b7 Apr 16, 2024Apr 16, 2024\n\n## History\n\nHistory\n\n533 lines (363 loc) \u00b7 43.6 KB\n\n/\n\n# text.md\n\n## File metadata and controls\n\n533 lines (363 loc) \u00b7 43.6 KB\n\nRaw\n\n# driftsort: an efficient, generic and robust stable sort implementation.\n\nAuthors: Lukas Bergdoll @Voultapher and Orson Peters @orlp Date: 2024-04-16\n(YYYY-MM-DD)\n\nThis document explains and verifies the design goals for an efficient, generic\nand robust stable sort implementation called driftsort by Orson Peters and\nLukas Bergdoll (source code).\n\nTL;DR: driftsort improves upon slice::sort in a variety of ways.\n\nBias disclosure: the authors of this document are the authors of driftsort.\n\n## Design goals\n\nThe primary goal is to develop a replacement for the current Rust standard\nlibrary slice::sort.\n\n  * Correct: Correctly sorted output if the user-defined comparison function implements a strict weak ordering.\n  * Safe: Zero UB regardless of input and user-defined comparison function. This includes panic safety, observability of interior mutability, and safety when Ord is violated for any input.\n  * Stable: Equal elements retain the same relative order they were in in the input.\n  * Hardware agnostic: No architecture-specific code.\n  * Generic: Works the same way for builtin types and user-defined types. Supports arbitrary comparison functions.\n  * Robust:\n\n    * Guaranteed O(N * log(N)) worst case comparisons.\n    * Guaranteed O(N) comparisons for fully ascending and descending inputs.\n    * Expected O(N * log(K)) comparisons when sorting K unique values.\n    * Smooth run-time scaling with input length.\n  * Efficient: Race to sleep and focus on instruction-level-parallelism (ILP) over SIMD.\n\n    * Optimized and tested along these dimensions, ~6k data points:\n\n      * Input length (0-1e7).\n      * Input type (integer-like, medium-sized, large-sized).\n      * Input pattern (fully random, Zipfian distributions, low-cardinality, presorted + append, and more).\n      * CPU prediction state (hot loop only doing sort, cold code with i-cache misses).\n    * Leverage existing ascending and descending runs in the input.\n  * Binary-size: Relatively small binary-size for types like u64 and String. i-cache is a shared resource and the program will likely do more than just sort.\n  * Compile-time: At least as fast to compile as the current slice::sort if hardware-parallelism is available and not much worse if not. Both debug and release configurations.\n  * N / 2 auxiliary memory: Heap usage should be limited to N / 2, and explicit stack usage should be limited to a less than ten kB.\n  * Debug performance: Performance of un-optimized binaries may only be slightly worse than the current slice::sort.\n\n## Design non-goals\n\n  * Fastest non-generic integer sort: The stated design goals are incompatible with this goal. Generally the existing advice that slice::sort_unstable is faster for integers, unless they contain long already sorted parts, still holds with ipnsort. In addition, once the sort implementation has a run-time of multiple milliseconds or more, using multithreading becomes beneficial, which is out of the scope of slice::sort.\n  * Tiny binary-size: Implementation complexity and binary-size are related, for projects that care about binary-size and or compile-time above everything else tiny_sort is a better fit.\n  * Varied compilers: Only rustc using LLVM was tested and designed for.\n\n## High level overview\n\nBefore working together on driftsort, the two authors had competing desires to\nbuild a slice::sort replacement. In 2023 they decided to work together,\ncombining the best of both competing designs into a new design called\ndriftsort. The influences are varied, but the core structure is derived from\nglidesort by Orson Peters.\n\nModern high-performance sort implementations combine various strategies to\nexploit input patterns and hardware capabilities. In effect this makes all of\nthem hybrid algorithms. For this reason it is more appropriate to talk about\nsort implementations and their components instead of a singular \"sort\nalgorithm\".\n\n### Current slice::sort\n\n  * Small input insertion sort: Dedicated sort for N <= 20. Profiling shows that 95+% of inputs are of len <= 20. In such scenarios i-cache misses are often the most important factor. A dedicated and inlined insertion sort shows best overall performance across patterns and CPU prediction state, and it avoids allocating the auxiliary memory.\n  * Timsort merge: Top level loop and merging policy based on Timsort by Tim Peters.\n  * Merge: Branchless merge that requires at most N / 2 auxiliary memory.\n  * Already sorted detection: Linear scan with early exit to find existing runs of sorted elements in the input.\n  * Insertion sort: Run creation if no existing run was found in the input.\n\n### driftsort\n\nComponent level overview of driftsort:\n\n  * Small input insertion sort: Dedicated sort for N <= 20. Profiling shows that 95+% of inputs have a length <= 20. In such scenarios i-cache misses are often the most important factor. A dedicated and inlined insertion sort shows best overall performance across patterns and CPU prediction state, and it avoids allocating the auxiliary memory.\n  * Run creation and lazy merging: Top level loop and algorithm adapted from glidesort. Combines bottom up merging and top down partitioning, by delaying merging as long as possible. driftsort retains the same logic as glidesort while significantly shrinking the binary-size required to achieve this logic.\n  * Powersort merge: Merging policy based on powersort by J. Ian Munro and Sebastian Wild.\n  * Merge: Branchless merge derived from the current slice::sort implementation. Requires at most N / 2 auxiliary memory.\n  * Sorted run detection: Linear scan with early exit to find existing runs of sorted elements in the input. In contrast to glidesort which uses a fixed length after which it counts an existing run as already sorted, driftsort has a min run length of ~sqrt(N). In addition driftsort will not try to find another run within the min run length region, if the first attempt failed. The advantage of disrupting the top-down quicksort process to allow merging with an existing run, requires a certain length relative to N to be worth it. This approach also avoids trying to find and merge small streaks in inputs with few unique elements, which are more efficiently handled by the top-down quicksort.\n  * Quicksort: Top-down partitioning loop and algorithm.\n  * Pivot selection: Recursive median-of-three approximating sqrt(N) sampling.\n  * Hybrid small-sorts: Two different small-sort implementations as a base case for recursive quicksort, chosen at compile time based on type characteristics. Insertion sort is used as a fallback for non Freeze types. driftsort uses a novel hybrid stable small-sort, based on a fast fixed function for sorting 4 elements combined with bidirectional merging and insertion sort is used for Freeze types, shared with ipnsort. This small-sort approach achieves comparable results with the one in glidesort, but does so at a significantly smaller binary-size and compile-time cost.\n  * Ancestor pivot tracking: By keeping track of earlier used pivots in quicksort we can detect and process common elements, allowing for O(N * log(K)) total comparisons where K is the number of distinct elements. This is also great for Zipfian distributions.\n  * Partition: Branchless stable partition. Left-to-right scan that performs a cmov style pointer select to fill the auxiliary memory buffer from left-to-right or right-to-left depending on the comparison outcome.\n  * Mergesort: Mergesort fallback used when a recursion depth limit is reached in the quicksort. This re-uses the existing merging code in driftsort, by calling itself with a flag that forces small runs to be made with the small-sort.\n\n### Components from glidesort which are not incorporated\n\nSome components and techniques from glidesort were intentionally not\nincorporated because they were considered too niche or have too much binary-\nsize overhead for a generic standard library sort:\n\n  * Merge splitting. This allows arbitrarily small auxiliary buffers which was not necessary for a slice::sort replacement. Merge splitting enables interleaved merge loops which were not implemented for binary-size reasons.\n  * Quad-merges. Delaying merges for quad-merges with interleaved loops and avoiding memcpys was not implemented as the interleaved loops were too large and the memcpy relatively cheap.\n  * Bidirectional partitioning. This was rather complex and a large amount of code to avoid relatively cheap memcpys in the stable partition, and the interleaved loops were larger and slower on some tested micro-architectures.\n\n## Verification\n\n### Correct\n\nAs part of the tailor-made test suite, there are tests that compare the\nresulting output order to the output of slice::sort. All tests are done for a\nrange of input lengths between 0 and 1_000_000. There are tests specifically\nfor different input types as well as for different input patterns. There are\nalso tests that test a specific property along two dimensions: input length\nand pattern. In addition, the existing Rust standard library test suite also\ncontains tests specifically for slice::sort.\n\ndriftsort is a hybrid sort algorithm, which allows the individual components\nto be more easily reasoned about, which reduces the risk of hidden correctness\nbugs. The only component that could be regarded as employing novel ideas on an\nalgorithmic level would be the lazy merging. However it is essentially the\nsame as eager merging, where quicksort is used to create runs.\n\nResult: The test suits pass.\n\n### Safe\n\nLike the current slice::sort the driftsort implementation contains significant\namounts of unsafe for reasons of reliable code-gen, as well as run-time,\ncompile-time, and binary-size efficiency. slice::sort allows for arbitrary\nlogic in the user-defined comparison function, which may do any combination\nof: returning correct results, violating strict weak ordering, modify values\nas they are being compared via interior mutability, and/or panic. In\ncombination with use of auxiliary memory an implementation can easily invoke\nUB, hang forever, and or return the input in a dangerous partially initialized\nstate. Even implementations written using purely safe abstractions are only\nguaranteed to avoid direct UB, and are still susceptible to the other issues.\nMore information about the different safety categories and effects, as well as\ncomparison to C and C++ implementations can be found here.\n\nThe bespoke test suite involves tests that trigger all these scenarios for\nvarious types, pattern and input sizes. In addition, care was taken to isolate\nunsafe abstractions where possible, localize unsafe invariants to small\nscopes, with each unsafe block accompanied by a SAFETY: comment explaining the\nassumptions. In addition some components were model checked with kani,\nchecking the full gamut of possible comparison result and input combinations.\nThe implementations have also been fuzzed with libfuzzer and AFL, however the\nemployed harnesses did assume simple comparisons. In addition the test suite\nis also run with miri both under Stacked borrows and Tree borrows.\n\nResult: The test suits pass both normally and when run with miri.\n\n### Stable\n\nA variety of tests in the sort-research-rs test suite test the stability of\nthe sort.\n\nResult: Automatic tests pass.\n\n### Hardware-agnostic\n\nNo architecture-specific code was used, and the implementation relies on\nbranchless instruction-level parallelism instead of auto-vectorization to\nsaturate wide out-of-order (OoO) CPU micro-architectures.\n\nResult: (rip)grepping the source code for \"arch\" yields no relevant match.\n\n### Generic\n\nThe driftsort implementation places the exact same type system trait bounds on\nits interface as the current slice::sort. In addition type introspection is\nperformed via mem::size_of, and whether a type implements the Copy and or\nFreeze trait. Those traits are not restricted to builtin types, treating user-\ndefined types and builtin types the same way. The performance characteristics\nand the order in which comparison operators are called are noticeably\ndifferent for u64 vs Cell<u64>. This is novel and could surprise users.\nHowever it's not a case of degrading the performance for Cell<u64> but rather\nimproving it for u64, String and more. All of the current documented\nproperties and more are still upheld. Alternatives would need to sacrifice\nsome of the desired goals.\n\nResult: The interface remains the same.\n\n### Robust\n\n> Guaranteed O(N * log(N)) worst case comparisons.\n\nThe same structure as the one found in introsort is used by driftsort to avoid\nthe well-known O(N^2) worst-case of quicksort. Once a recursion depth of 2 *\nlog2(N) is reached, it switches to a different algorithm.\n\nHowever, in the case of driftsort the algorithm it switches to mergesort. This\nensures it will never call quicksort again, only using the guaranteed O(N *\nlog(N)) mergesort routines.\n\n> Guaranteed O(N) comparisons for fully ascending and descending inputs.\n\nThe already-sorted detection component will detect fully ascending and\ndescending inputs.\n\n> Smooth run-time scaling with input length.\n\nThis point will be explored in more detail in the benchmark section, on some\nplatforms there is a significant drop in throughput at the transition point\nfrom insertion sort to hybrid merge-quicksort due to implementation-specific\nand hardware-dependent effects. But in terms of comparisons the scaling is\ngenerally speaking smooth.\n\nPlotting mean comparisons performed divided by N - 1 yields:\n\nObservations:\n\n  * driftsort and std_stable, share hitting a worst case for insertion sort in the descending pattern, with the strongest measured log scaling outlier at length 17.\n  * glidesort uses its core small-sort for N < 20, which has a best, average and worst case of O(N * log(N)).\n  * For N > 20 driftsort and glidesort have similar scaling curves.\n  * The changes in the min-run length heuristic allow driftsort to take advantage of random_d20 earlier than glidesort.\n  * All three implementations handle ascending and descending with O(N) comparisons for N > 20, with a constant of ~1.\n  * driftsort and glidesort show linear scaling for random_d20, demonstrating the O(N * log(K)) capabilities.\n  * All three implementations handle random_s95 by finding the 95% already sorted at the start and merging it with the remaining 5% after sorting them. This explains the comparatively low number of comparisons required for random_s95.\n  * std_stable is incapable of taking advantage of low-cardinality in inputs, as seen by random, random_z1 and random_d20 all requiring a similar amount of comparisons. The only exception is random_p5 which contains many short streaks of consecutive zeros, which std_stable recognizes.\n  * driftsort shows a jump in required comparisons for random_z1, random_d20 and random_p5 for N > 1e6. This can be explained by the auxiliary memory allocation policy which allocates a buffer of length N, as long as this would consume less than 8MB. The three patterns that see degradation are all those that take advantage of pdqsort style common element filtering. The input type used to generate these graphs is u64 which is 8 bytes, and past length 1e6, this would be larger than 8MB. The stable partition in the quicksort requires a buffer length N, which means the implementation will quicksort multiple sub-slices and then merge them. Common element filtering is most efficient when it is done on the whole input at once. glidesort shows a similar effect, but less pronounced because of differences in the merge logic.\n  * random_p5 shows the conflict between low-cardinality and already sorted sub-slice detection in driftsort for N > ~1e2 and < ~1e4.\n\nResult: driftsort retains the existing best, average and worst case comparison\ncharacteristics, while significantly reducing the number of required\ncomparisons for inputs with repeated values.\n\n### Efficient\n\nSmartphone and server CPUs alike can execute billions of instructions each\nsecond. For a variety of reasons many programs spend most of their time\nwaiting, predominantly for memory and cache loads and stores. More than 30\nyears of CPU design have been invested into doing things while the CPU would\notherwise wait. These optimizations such as pipelining cause new bottlenecks\nsuch as pipeline control hazards, which then again are addressed by further\noptimizations like predictive execution. This stack of hardware optimizations,\nimplemented with shared mutable state in the CPU, make predicting performance\nvery complex. Measuring performance comes with its own laundry list of\npitfalls, spanning the gamut from poor experimental setups, to bad analysis to\nfaulty assumptions about relevance. Performance and efficiency are usually\ncorrelated, in that taking half the time to do the same work, means the CPU\ncan go back to sleep after only half the time, using less power overall. That\nsaid, improving efficiency has its own set of conceptual pitfalls.\n\nSort implementations can leverage existing patterns in the input to perform\nless work. The following synthetic patterns represent a limited set of use\ncases. Their applicability to real-world situations will vary from use case to\nuse case. In the domain of databases, low-cardinality distributions like\nrandom_d20, random_p5 and random_z1 have been found to be quite common in\nreal-world data. Zipfian distributions also known as 80/20 distributions are\nfound in many real-world data sets. Without prior distribution knowledge nor\ndomain knowledge, a generic sort implementation has to exploit the gained\ninformation, without spending too much effort looking for an algorithmic\noptimization that won't be applicable or pay off.\n\nThe patterns used in this benchmark:\n\n  * ascending, numbers 0..size,\n  * descending, numbers 0..size reversed,\n  * random, random numbers generated by the rand crate StdRng::gen,\n  * random_d20, uniform random numbers in the range 0..=20,\n  * random_p5, 95% 0 and 5% random values mixed in, not uniform,\n  * random_s95, 95% sorted followed by 5% unsorted, simulates append + sort, and\n  * random_z1, Zipfian distribution with characterizing exponent s == 1.0,\n\nThe cold benchmarks perform a step before each measurement that overwrites the\nfirst level instruction cache and branch-prediction caches with unrelated\nvalues. This measures a scenario where prior parts of a hypothetical larger\nprogram already loaded or generated the data that will be sorted into the\nsuitable data caches. In this scenario the first level instruction cache and\nbranch predictor caches are trained on other work than the sort\nimplementation. \"Hot\" benchmarks that keep the data and instructions in the\nlowest level CPU caches are also possible. Such use cases are present in real-\nworld applications, for example when computing a rolling median. Analyzing the\nuse of slice::sort suggests, that cold use cases are significantly more\ncommon.\n\nOne common way to improve the performance of sort implementations is to use\nexplicit vectorization. However doing so limits the applicability to a narrow\nset of built-in types and doesn't support user-defined comparison functions. A\ngeneric implementation has to handle user-defined types of various shapes,\npaired with user-defined comparison functions. For these reasons the\nimplementation focuses on instruction-level parallelism (ILP) instead of SIMD.\nThere are also micro-architectures that have wider capabilities than exposed\nvia the available vectorization, which means an ILP approach may yield better\nresults. While there is an unlimited amount of possible combinations, it is\npossible to pick certain types that demonstrate possible properties and their\neffects. In the benchmarks the input length range is limited to 1e5 for\npractical resource reasons, except for u64 and i32.\n\n#### Benchmark setups\n\nZen 3\n\n    \n    \n    Linux 6.6 rustc 1.77.0-nightly (6ae4cfbbb 2024-01-17) AMD Ryzen 9 5900X 12-Core Processor (Zen 3 micro-architecture) CPU boost enabled.\n\nHaswell\n\n    \n    \n    Linux 5.19 rustc 1.77.0-nightly (6ae4cfbbb 2024-01-17) Intel i7-5500U 2-Core Processor (Broadwell micro-architecture) CPU boost enabled.\n\nFirestorm\n\n    \n    \n    Darwin Kernel Version 22.6.0 rustc 1.77.0-nightly (6ae4cfbbb 2024-01-17) Apple M1 Pro 6+2 Core Processor (Firestorm P-core micro-architecture) CPU boost enabled.\n\n#### Results Zen 3\n\nZen 3 is a CPU micro-architecture by AMD, released in the year 2020. In 2024\nit is a popular choice for servers and desktops, with workloads ranging from\nHPC to general cloud computing to gaming and desktop usage.\n\nTo keep the size of this document in check, this is the only micro-\narchitecture for which the results will be discussed in detail.\n\n##### u64 10k single size\n\nComparing the run-time for a single input length (10_000) across patterns.\n\nObservations:\n\n  * driftsort and glidesort show large improvements across all random patterns compared to std_stable, except on random_s95 where they perform similarly.\n  * random sees a more than 2x improvement, despite performing roughly the same number of comparisons. This is primarily caused by a significantly faster small-sort that makes more effective use of the superscalar CPU capabilities.\n  * random_s95 sees similar values across all three implementations with glidesort at the top, thanks to a more sophisticated merge implementation. driftsort is next with a minor refinement to the merge implementation in std_stable.\n  * random_s95 demonstrates the effectiveness of these mergesort or hybrid mergesort implementations when sorting inputs that are already partially sorted.\n  * random_d20, random_p5 and random_z1 demonstrate the capability of glidesort and driftsort to take advantage of low-cardinality distributions. They can filter out common values by keeping track of earlier used pivots during quicksort, which allows them to detect when a pivot is chosen again to handle all equal elements at once. This allows them to complete the sort with significantly fewer comparisons. This in turn allows them to complete the operation with less work performed, leading to higher throughput.\n  * random_p5 sees the only major difference between driftsort and glidesort at this input length. This can be explained by the differences in already-sorted detection.\n\n##### u64 random scaling\n\nComparing the run-time for a single pattern (random) across input lengths.\n\nObservations:\n\n  * For N <= 20, driftsort and std_stable follow the same curve shape. This can be explained by the fact that both use insertion sort. driftsort tries to inline the small-input insertion sort and nothing else, outlining the core hybrid merge-quicksort loop. On other tested platforms where std_stable is not always inlined this yields better performance. driftsort uses a binary-size optimized insertion sort that avoids loop unrolling, which is better for smaller inputs but falls behind at the top end of N <= 20.\n  * glidesort shows throughput peeks at length 4, 8, and 35. This has to do with the small-sort implementation's use of fast fixed function sort constructs, for length 4, 8, 16 and 32.\n  * All implementations show a dip in throughput when transitioning from small-input small-sort to their core loop. glidesort and driftsort are affected comparatively more because they have higher peek throughput, which they reach for L2 sized inputs.\n  * driftsort shows a dip in throughput for N > 1e6. This is caused by the auxiliary memory allocation heuristic, switching from allocating a buffer of size N to progressive N / 2.\n\n##### u64\n\nComparing the relative symmetric speedup across all measured input lengths and\npatterns. This is calculated by taking each individual measurement result for\neach input length and dividing the larger value by the smaller one. Where 1.5x\nmeans that A is 1.5x faster than B, and -1.5x means B is 1.5x faster than A.\nThis approach avoids biasing one direction over the other, and symmetric\neffects can cancel each other out.\n\nObservations:\n\n  * random shows a fairly flat ~2.4x throughput improvement for N > 1e4 and <= 1e6. This is can be explained by a similar amount of conceptual comparison work that needs to be done, where driftsort is more efficient at performing the same workload.\n  * random_z1 follows a similar curve shape to random, however it has a steeper slope, which is explained by the increasing algorithmic advantage it has thanks to common element filtering.\n  * random_d20 and random_p5 leave the charted area thanks to the large algorithmic reduction in work.\n  * For N > 1e3 ascending and descending show a small regression. This is not a sign of measurement noise, as the result persists and is repeatable. The causes for this effect are not well understood by the authors. Both implementations use exactly the same code for run detection and reversing, yet it can result in significant differences depending on compiler version, allocation length and other factors. The same regression does not occur on Firestorm.\n\nZooming out to see the full range:\n\nObservations:\n\n  * random_d20 and random_p5 peak at 1e6, with a respective improvement of ~13x and ~17x. This is caused by the logarithmic scaling of the std_stable implementation, while driftsort can sort these inputs with near linear input length scaling.\n  * All random patterns see a throughput regression for N > 1e6, this is caused by the auxiliary memory allocation heuristic. random_d20 and random_p5 are affected the most because they benefit the most from common element filtering, which is most effective when it can happen over the whole input at once. Otherwise it has to happen multiple times, followed by a merge.\n\n##### i32\n\nSigned 32-bit integer with values in full i32 range.\n\nObservations:\n\n  * Overall very similar to u64.\n  * ascending shows a large regression for N > 1e3 despite performing exactly the same number of comparisons and using the same run detection code. For N > 20 and < 1e3 the 4KiB stack allocation reverse this effect. Again, this effect does not reproduce on Firestorm.\n  * The relative throughput regression because of the auxiliary memory allocation heuristic happens for N > 2e6 instead of 1e6. This is consistent with the upper limit for full buffer allocation at 8MB. i32 is 4 bytes, whereas u64 is 8 bytes.\n\n##### string\n\nHeap allocated string that resembles the rustc standard library String. All\nvalues for the benchmarks are derived from i32 values. The strings all have\nthe same length and are compared lexicographically. The string results are\nhighly dependent on the allocation distribution, the benchmarks measure a\nrelatively unrealistic scenario where the strings are allocated one after the\nother with minimal other work in-between.\n\n    \n    \n    #[repr(C)] pub struct FFIString { data: *mut c_char, len: usize, capacity: usize, } fn shift_i32_to_u32(val: i32) -> u32 { (val as i64 + (i32::MAX as i64 + 1)) as u32 } // Construction from i32 FFIString::new(format!(\"{:010}\", shift_i32_to_u32(val)))\n\nObservations:\n\n  * driftsort improves performance in the majority of measured pattern and length combinations, with some regressions for N > 20 and < 100.\n  * The improvement is significantly smaller, compared to the integer results. This can be explained by the comparatively larger amount of time spent for each comparison, including memory indirection and a call to memcmp.\n\n##### 1k\n\nThe type called \"1k\" in graphs, simulates a type that is expensive to copy\nwith a stack size of 1KiB per element. It has a relatively cheap comparison\nfunction.\n\n    \n    \n    // Very large stack value. #[repr(C)] #[derive(PartialEq, Eq, Debug, Clone)] pub struct FFIOneKibiByte { values: [i64; 128], } impl FFIOneKibiByte { pub fn new(val: i32) -> Self { let mut values = [0i64; 128]; let mut val_i64 = val as i64; for elem in &mut values { *elem = val_i64; val_i64 = std::hint::black_box(val_i64 + 1); } Self { values } } fn as_i64(&self) -> i64 { self.values[11] + self.values[55] + self.values[77] } } impl PartialOrd for FFIOneKibiByte { fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> { self.as_i64().partial_cmp(&other.as_i64()) } }\n\nObservations:\n\n  * The 1k type poses a unique to challenge to sort implementations. The most expensive part is, not the control structure like it is for integers, or the comparison as for strings, but rather the act of making copies of the value. Copying the values is a crucial part of swapping elements for any comparison based sort implementation.\n  * The spikes line up with the corresponding patterns that see large algorithmic advantages. However they quickly run into 8MB full buffer allocation limit.\n\n##### f128\n\nThe f128 type simulates a type that is relatively cheap to copy at 16 bytes.\nPerforms no heap access, but performs a relatively expensive math function as\npart of each comparison.\n\n    \n    \n    // 16 byte stack value, with more expensive comparison. #[repr(C)] #[derive(PartialEq, Debug, Clone, Copy)] pub struct F128 { x: f64, y: f64, } impl F128 { pub fn new(val: i32) -> Self { let val_f = (val as f64) + (i32::MAX as f64) + 10.0; let x = val_f + 0.1; let y = val_f.log(4.1); assert!(y < x); assert!(x.is_normal() && y.is_normal()); Self { x, y } } } // Goal is similar code-gen between Rust and C++ // - Rust https://godbolt.org/z/3YM3xenPP // - C++ https://godbolt.org/z/178M6j1zz impl PartialOrd for F128 { fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> { // Simulate expensive comparison function. let this_div = self.x / self.y; let other_div = other.x / other.y; // SAFETY: We checked in the ctor that both are normal. let cmp_result = unsafe { this_div.partial_cmp(&other_div).unwrap_unchecked() }; Some(cmp_result) } }\n\nObservations:\n\n  * Mostly similar to u64 and i32 with different curve offsets.\n  * ascending and descending show no change in performance, which is the authors' expected outcome given the same run detection and reversing code.\n\n#### All results\n\nResults for all the tested machines:\n\nZen 3| Haswell| Firestorm  \n---|---|---  \n10k u64  \nu64  \ni32  \nstring  \n1k  \nf128  \n  \n### Binary-size\n\nMeasuring the binary-size cost of an instantiation with a new type:\n\nConfiguration| Type| Size current (bytes)| Size glidesort (bytes)| Size\ndriftsort (bytes)  \n---|---|---|---|---  \nrelease| u64| 2335| 25520| 5294  \nrelease| String| 2846| 30893| 6592  \nrelease_lto_thin| u64| 2339| 25656| 5240  \nrelease_lto_thin| String| 2858| 30983| 6500  \nrelease_lto_thin_opt_level_s| u64| 1827| 16601| 3890  \nrelease_lto_thin_opt_level_s| String| 2497| 26392| 5493  \n  \nThe instruction cache (i-cache) is a shared resource and most programs do more\nthan just call slice::sort. The actual i-cache usage will depend on the input\nlength, type, pattern and ISA. For example the very common case of N <= 20 has\ndriftsort only use an inlined insertion sort using less than 200 bytes of\ni-cache. The total size represents the upper limit worst case if everything is\nbeing used. Another aspect where binary-size is important, is the impact it\nhas on the size of the final binary. This can be particularly important for\nembedded and Wasm targets. In cases where binary-size and or compile-time are\nprioritized above everything else tiny_sort is a better fit.\n\nThe current slice::sort is comparatively simple and subsequently has limited\ncapabilities in terms of leveraging low-cardinality patterns as well as run-\ntime efficiency. driftsort is similar in terms of effective capabilities to\nglidesort while only requiring ~2.5x the binary-size in contrast to ~13x for\nglidesort. By having a dedicated insertion sort for N <= 20, the impact on the\ni-cache is deemed minimal. And in cases where larger inputs are sorted, the\nadditional binary-size cost manifests itself in significantly improved run-\ntimes. Further reductions in binary-size are possible, but would imply\nsignificant reductions in capabilities.\n\nResult: driftsort significantly regresses the binary-size in every tested\nscenario, compared to the current slice::sort, but much less so than\nglidesort.\n\n### Compile-time\n\nCompile-times are often cited as one of Rust's issues, and the compiler team\nhas invested considerable effort in improving compile-times. slice::sort is\nimplementation-wise one of the largest and most complicated functions in the\nstandard library. As a consequence, the compile-time impact it has on user\napplications that call it directly or indirectly can be substantial. To\nmeasure the impact on compile-time, a test program was created that contains a\ntotal of 256 sort instantiation, each with a newtype wrapper. 50% u64, 45%\nString and 5% Cell<u64>. This program is then clean compiled multiple times\nand wall and user time are evaluated.\n\nCurrent slice::sort:\n\n    \n    \n    $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build' Time (mean \u00b1 \u03c3): 2.802 s \u00b1 0.023 s [User: 4.030 s, System: 0.301 s] Range (min ... max): 2.767 s ... 2.830 s 5 runs $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build --release' Time (mean \u00b1 \u03c3): 6.747 s \u00b1 0.110 s [User: 6.887 s, System: 0.178 s] Range (min ... max): 6.620 s ... 6.847 s 5 runs\n\nglidesort:\n\n    \n    \n    $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build' Time (mean \u00b1 \u03c3): 11.002 s \u00b1 0.109 s [User: 36.946 s, System: 1.569 s] Range (min ... max): 10.916 s ... 11.191 s 5 runs $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build --release' Time (mean \u00b1 \u03c3): 27.018 s \u00b1 0.235 s [User: 85.421 s, System: 0.963 s] Range (min ... max): 26.642 s ... 27.264 s 5 runs\n\ndriftsort:\n\n    \n    \n    $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build' Time (mean \u00b1 \u03c3): 2.329 s \u00b1 0.018 s [User: 7.711 s, System: 0.467 s] Range (min ... max): 2.303 s ... 2.353 s 5 runs $ hyperfine --min-runs 5 --prepare 'cargo clean' 'cargo build --release' Time (mean \u00b1 \u03c3): 6.632 s \u00b1 0.073 s [User: 18.810 s, System: 0.288 s] Range (min ... max): 6.575 s ... 6.751 s 5 runs\n\nThe primary reported time is the wall clock, how much time it took overall.\nThe User time represents the elapsed time across all used threads, and the\nSystem time represents the time spent in the kernel. driftsort carefully\nsplits its implementation into multiple modules, mostly avoiding run-time\npenalities for intra-module-only LTO builds. This allows rustc to parallelize\nand make use of multi-threading capabilities. In contrast the current\nslice::sort is contained in a single module, and subsequently spends nearly\nall its time on the same thread, making poor use of multi-threading\ncapabilities. glidesort is also split across multiple modules, but in part due\nto its significantly larger size and a general lack of compile-time\noptimization focus, is an order of magnitude more expensive to compile.\n\nResult: If the system has multi-threading capabilities and time available\nduring compilation, compiling driftsort is faster than the current slice::sort\nfor debug builds and on par for release builds. If not, the time spent is\nsignificantly longer.\n\n### N / 2 auxiliary memory\n\nThere are two parts in driftsort that require auxiliary memory: partitioning\nand merging. std_stable implements the merge operation in a way that requires\nN / 2 auxiliary memory. In practice this means slice::sort will only allocate\n6GB of heap memory when sorting a slice of 12GB. For large inputs this can be\nthe difference between out-of-memory and a reliable program. The quicksort\npart of driftsort is significantly faster than mergesort for inputs that are\nnot partially sorted. Because the stable partitioning requires a buffer of the\nsame length as the input, it can be beneficial to allocate N auxiliary memory.\ndriftsort tries to strike a compromise between the two desirable properties,\nby allocating auxiliary memory of length N as long as the slice is at most\n8MB. Beyond this point it goes down to N / 2. While it's possible that many\nconcurrent processes each allocating 8MB instead of 4MB previously run into\nout-of-memory where they previously didn't, the impact is deemed unlikely\nenough to warrant the run-time improvements for a large part of the input\nlength space.\n\nResult: driftsort maintains this property for large inputs, while prioritizing\nrun-time for smaller inputs at the expense of peak heap memory usage. Explicit\nstack usage is limited to 4kB.\n\n### Debug performance\n\nWhile the run-time of optimized builds is generally more important than that\nof debug builds, it too can have significant impacts on users. Many CI systems\nrun tests for debug builds, and a for example 10x regression for debug builds\nin a foundational component like slice::sort could significantly impact such\nscenarios. To measure the impact the sort-research-rs test suite execution\ntime is measured.\n\nCurrent slice::sort:\n\n    \n    \n    $ hyperfine --min-runs 5 \"cargo t -- -Z unstable-options --shuffle-seed 778\" Time (mean \u00b1 \u03c3): 4.516 s \u00b1 0.223 s [User: 59.949 s, System: 0.528 s] Range (min ... max): 4.353 s ... 4.902 s 5 runs\n\nglidesort:\n\n    \n    \n    $ hyperfine --min-runs 5 \"cargo t -- -Z unstable-options --shuffle-seed 778\" Time (mean \u00b1 \u03c3): 4.525 s \u00b1 0.078 s [User: 61.596 s, System: 0.455 s] Range (min ... max): 4.425 s ... 4.629 s 5 runs\n\ndriftsort:\n\n    \n    \n    $ hyperfine --min-runs 5 \"cargo t -- -Z unstable-options --shuffle-seed 778\" Time (mean \u00b1 \u03c3): 4.705 s \u00b1 0.203 s [User: 57.978 s, System: 0.516 s] Range (min ... max): 4.514 s ... 5.051 s 5 runs\n\nglidesort fails the self_cmp_* tests which makes the results not entirely\ncomparable. They account for 3/55 tests.\n\nResult: driftsort shows no major change in wall or user time compared to\nslice::sort.\n\n## Why should the Rust project adopt driftsort?\n\n### Reasons that speak against adoption\n\n  * The implementation contains significant amounts of new unsafe code. Despite extensive testing, fuzzing, partial model checking and code review, it's possible that users could encounter novel UB in their programs.\n  * On machines without multi-threading capabilities and or lacking free multi-threading resources, debug and release builds can suffer significant compile-time regressions.\n  * driftsort significantly increases binary-size for all tested types, with all tested compiler settings.\n\n### Reasons that speak for adoption\n\n  * In addition to the continued intuitive exception safety guarantee, driftsort has a high chance of detecting strict weak ordering violations and reporting them to users via a panic, regardless of build configuration. This surfaces logic bugs earlier and more directly than the current implementation.\n  * The authors went to great length to test and verify the memory safety of the implementation.\n  * On machines with available multi-threading resources debug builds can see compile-time improvements.\n  * driftsort greatly improves the run-time performance for the majority of tested micro-architectures, input length, type and pattern combinations with speedups breaking the order-of-magnitude barrier for some realistic and non-trivial combinations.\n\n## Authors' conclusion and opinion\n\ndriftsort manages to take many of the ideas found in glidesort and build a\ncomparably capable implementation without 10+x regressions in binary-size and\ncompile-times. At the same time, the current slice::sort implementation is so\nsimple by comparison, that leveraging low-cardinality inputs, while also being\nefficient at handling partially sorted inputs, comes with an unavoidable\nbinary-size penalty. Compile-time regressions are mostly avoided, despite the\n~4x increase in LoC from 212 to 853.\n\ndriftsort is a story of many compromises and doing more with less. A story of\nworking together to achieve a common goal, a lot of work and a result we are\nproud of.\n\n## Acknowledgements\n\nNone of this would have been possible without the work of all those that came\nbefore us. We stand on a mountain of research conducted by others. The domain\nspecific contributions of Tony Hoare, Stefan Edelkamp, Armin Wei\u00df, J. Ian\nMunro, Sebastian Wild, Igor van den Hoven, and many others have been\ninvaluable in building driftsort. The micro-architecture deep-dives by\nclamchowder were instrumental in analyzing and understanding the performance\nmeasurements. Roland Bock as reviewer for the technical writing helped us\ncommunicate our work.\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

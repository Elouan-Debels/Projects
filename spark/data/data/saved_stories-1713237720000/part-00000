{"aid": "40045737", "title": "CS25: Transformers United V4", "url": "https://web.stanford.edu/class/cs25/", "domain": "stanford.edu", "votes": 1, "user": "gone35", "posted_at": "2024-04-15 21:20:31", "comments": 0, "source_title": "CS25: Tranformers United!", "source_text": "Stanford CS 25 | Transformers United\n\n# CS25: Transformers United V4\n\n### Spring 2024\n\n##### Apr. 4 - May 30\n\n## Description\n\nInterested in Transformers, the deep learning model that has taken the world\nby storm? Want to have intimate discussions with researchers? If so, this\ncourse is for you! It's not every day that you get to personally hear from and\nchat with the authors of the papers you read!\n\nEach week, we invite folks at the forefront of Transformers research to\ndiscuss the latest breakthroughs, from LLM architectures like GPT and Gemini\nto creative use cases in generating art (e.g. DALL-E and Sora), biology and\nneuroscience applications, robotics, playing complex games, and so forth!\n\nCS25 has become one of Stanford's hottest and most exciting seminar courses.\nWe invite the coolest speakers such as Andrej Karpathy, Geoffrey Hinton, Jim\nFan, Ashish Vaswani, and folks from OpenAI, Google, NVIDIA, etc. Our class has\nan incredibly popular reception within and outside Stanford, and around 1\nmillion total views on YouTube. Our class with Andrej Karpathy was the second\nmost popular YouTube video uploaded by Stanford in 2023 with over 500k views!\n\nWe have significant improvements for Spring 2024, including a large lecture\nhall, professional recording and livestreaming (to the public), social events,\nand potential 1-on-1 networking! The only homework for students is weekly\nattendance to the talks/lectures. Also, livestreaming and auditing are\navailable to the public. Feel free to audit in-person or by joining the Zoom\nlivestream. Anybody can attend, you don't have to be affiliated with Stanford!\n\nWe also have a Discord server (over 1500 members) used for Transformers\ndiscussion. We open it to the public as more of a \"Transformers community\".\nFeel free to join and chat with hundreds of others about Transformers!\n\n## Logistics\n\n* This is a 1-unit S/NC (pass/fail) course. Enroll on Axess as a Stanford student! (Waitlist available)\n* Lectures are on Thursdays at 4:30 - 5:50 pm PDT, Gates Computer Science Building, Room B01 (Basement)\n* Zoom Livestream (Anyone can join!): Link [Meeting ID: 999 2215 1759, Password: 123456]\n* Announcements will be made by email, Discord, Canvas (for students), and this mailing list (for auditors/public).\n* Attendance: Enrolled students should attend in-person (up to 3 absences). During/following each lecture, submit a response here. Note: the form will only open during each lecture.\n* Auditing: Open to everyone! Please join in-person or the Zoom livestream. No need to email us. Join this mailing list for announcements.\n* Questions: There will be an opportunity for questions after each lecture. You can submit questions for the speakers on sli.do, using the code \"cs25\". Do not unmute on Zoom to ask questions. We cannot guarantee the Zoom chat will be monitored, so please ask questions on sli.do instead.\n* Public (Non-Stanford): There is no way to \"officially\" enroll in or audit this course (i.e. get a credit/certificate/acknowledgement) unless you are a Stanford student. We are just opening it up to the public for attendance.\n* Contact: If you have any questions about the course, contact us at cs25-spr2324-staff@lists.stanford.edu.\n\n## Recordings & Slides\n\n* We plan to publicly release YouTube recordings after each talk at a reasonable pace (i.e. approx. 2 weeks afterward).\n* Recordings of previous talks can be found here. Future recordings will also be posted to this same playlist.\n* Slides will be posted during/after each lecture, on this website (attached to the schedule below), our Discord, and sent by email through the class mailing lists. We will aim to post them in a timely manner (i.e. within a week of each talk).\n\n## Disclaimers for Students & Attendees\n\n* In-person attendees: We will be recording, broadcasting (over Zoom), and publishing the speaker presentations to YouTube to help the timely spread of this cutting-edge information. For your convenience, you can also access these recordings by logging into the course Canvas site (students only). Video cameras located in the back of the room will capture the instructor presentations in this course. Note that while the cameras are positioned with the intention of recording only the instructor, occasionally a part of your image or voice might be incidentally captured. Before the recordings are published, an editor will review to remove any student and attendee appearances. If you have questions, please contact a member of the teaching team.\n* Auditors: If the room is full, please give seats to enrolled students who have priority.\n* Zoom attendees: Please do not unmute yourself on Zoom, use the whiteboard functionality, or any other disruptive behavior! If you have any questions/concerns, please send them in the chat; we will be actively monitoring it.\n* Inappropriate behavior will result in blacklist from the course (and maybe other consequences with Stanford).\n\n## Previous Iterations\n\n  * V1 (Fall 2021)\n  * V2 (Winter 2023)\n  * V3 (Fall 2023)\n\n### Instructors\n\nDiv Garg\n\nSteven Feng\n\nSeonghee Lee\n\nEmily Bunnapradist\n\n### Faculty Advisor\n\nChris Manning\n\n## Schedule\n\nThe current class schedule is below (subject to change):\n\nDate| Title| Description  \n---|---|---  \nApril 4| Instructor Lecture: Overview of Transformers [In-Person] Speakers:\nSteven Feng, Div Garg, Emily Bunnapradist, Seonghee Lee Slides posted here.|\nBrief intro and overview of the history of NLP, Transformers and how they\nwork, and their impact. Discussion about recent trends, breakthroughs,\napplications, and remaining challenges/weaknesses. Also discussion about AI\nagents.  \nApril 11| Intuitions on Language Models (Jason) [In-Person]Shaping the Future\nof AI from the History of Transformer (Hyung Won) [In-Person]Speakers: Jason\nWei & Hyung Won Chung, OpenAIJason Wei is an AI researcher based in San\nFrancisco. He is currently working at OpenAI. He was previously a research\nscientist at Google Brain, where he popularized key ideas in large language\nmodels such as chain-of-thought prompting, instruction tuning, and emergent\nphenomena.Hyung Won Chung is a research scientist at OpenAI ChatGPT team. He\nhas worked on various aspects of Large Language Models: pre-training,\ninstruction fine-tuning, reinforcement learning with human feedback,\nreasoning, multilinguality, parallelism strategies, etc. Some of the notable\nwork includes scaling Flan paper (Flan-T5, Flan-PaLM) and T5X, the training\nframework used to train the PaLM language model. Before OpenAI, he was at\nGoogle Brain and before that he received a PhD from MIT.| Jason will talk\nabout some basic intuitions on language models, inspired by manual examination\nof data. First, he will discuss how one can view next word prediction as\nmassive multi-task learning. Then, he will discuss how this framing reconciles\nscaling laws with emergent individual tasks. Finally, he will talk about the\nmore general implications of these learnings. Slides posted here.Hyung Won: AI\nis developing at such an overwhelming pace that it is hard to keep up. Instead\nof spending all our energy catching up with the latest development, I argue\nthat we should study the change itself. First step is to identify and\nunderstand the driving force behind the change. For AI, it is the\nexponentially cheaper compute and associated scaling. I will provide a highly-\nopinionated view on the early history of Transformer architectures, focusing\non what motivated each development and how each became less relevant with more\ncompute. This analysis will help us connect the past and present in a unified\nperspective, which in turn makes it more manageable to project where the field\nis heading. Slides posted here.  \nApril 18| Aligning Open Language Models [Virtual/Zoom] Speaker: Nathan\nLambert, Allen Institute for AI (AI2)Nathan Lambert is a Research Scientist at\nthe Allen Institute for AI focusing on RLHF and the author of\nInterconnects.ai. Previously, he helped build an RLHF research team at\nHuggingFace. He received his PhD from the University of California, Berkeley\nworking at the intersection of machine learning and robotics. He was advised\nby Professor Kristofer Pister in the Berkeley Autonomous Microsystems Lab and\nRoberto Calandra at Meta AI Research.| Since the emergence of ChatGPT there\nhas been an explosion of methods and models attempting to make open language\nmodels easier to use. This talk retells the major chapters in the evolution of\nopen chat, instruct, and aligned models, covering the most important\ntechniques, datasets, and models. Alpaca, QLoRA, DPO, PPO, and everything in\nbetween will be covered. The talk will conclude with predictions and\nexpectations for the future of aligning open language models.  \nApril 25| Demystifying Mixtral of Experts [Virtual/Zoom] Speaker: Albert\nJiang, Mistral AI / University of CambridgeAlbert Jiang is an AI scientist at\nMistral AI, and a final-year PhD student at the computer science department of\nCambridge University. He works on language model pretraining and reasoning at\nMistral AI, and language models for mathematics at Cambridge.| In this talk I\nwill introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language\nmodel. Mixtral has the same architecture as Mistral 7B, with the difference\nthat each layer is composed of 8 feedforward blocks (i.e. experts). For every\ntoken, at each layer, a router network selects two experts to process the\ncurrent state and combines their outputs. Even though each token only sees two\nexperts, the selected experts can be different at each timestep. As a result,\neach token has access to 47B parameters, but only uses 13B active parameters\nduring inference. I will go into the architectural details and analyse the\nexpert routing decisions made by the model.  \nMay 2| Developing precision language models from self-attentive feed-forward\nunits, and applying them in edge computing scenarios as untrained language\nmodels prompted to predict symbolic switches (U-LaMPS) Speaker: Jake Williams,\nDrexel UniversityJake Ryland Williams is an Associate Professor of Information\nScience at Drexel University's College of Computing and Informatics in\nPhiladelphia, Pennsylvania. Dr. Williams' undergraduate background is in\nPhysics, and he holds an Applied Mathematics MS alongside a PhD in\nMathematical Sciences (all from the University of Vermont). Dr. Williams' PhD\nwas largely in pure mathematics, with doctoral research in quantitative\nlinguistics that applied mathematics to the study of statistical linguistic\nphenomena, treating the subject as a domain of statistical physics. To conduct\nthis research, the necessities of data processing led Dr. Williams to become a\ndata scientist, which he followed post-graduation into a Postdoctoral\nappointment in the School of Information at the University of California,\nBerkeley (Cal). At Cal, Dr. Willams began his career in graduate data science\n(DS) education on techniques for large-scale machine learning, while he\nstudied opportunities for the application of statistical theory to natural\nlanguage processing (NLP). Upon becoming a DS faculty at Drexel, Dr. Williams\ndrove the foundation of a DS MS program, where he developed and instructed DS\ncoursework, ultimately in the methodological subject of NLP with deep\nlearning. Teaching NLP with deep learning ultimately brought Dr. Williams to\nrealize an alternative pedagogical model for teaching neural network\nmethodology that integrates theory from traditional statistical learning,\nwhich is borne out in his research and this talk.| Dr. Williams' research\ndevelops and applies theory on what neural networks learn (statistically) as a\nmeans to improve the design and function of neural architectures and learning\nprocesses. This has recently inspired Dr. Williams to invent a range of\nprecision technologies developed for effectively and efficiently training both\nlarge and small neural language models, which are capable of greatly reducing\nthe costs of training and infrastructure behind, e.g., OpenAI's ChatGPT. Dr.\nWilliams will discuss these architectures, which modify standard self-\nattention layers and model long-range dependencies without significant\nreliance on layer depth. After being introduced, peripheral components of\nthese near-shallow networks\u2014as well as their modified forward operations and\nlearning processes\u2014will be discussed in detail. Following this discussion of\narchitecture and model details, current applications of this research will be\npresented, which are focused on embedding untrained precision language models\n(PLMs) on microprocessors in edge computing scenarios, i.e., acting as\nhardware-based controllers for small electronics devices. Discussion will\nfocus on how these PLM systems have been designed to operate in air-gapped\nenvironments over CPU-driven training on microprocessors from scratch, and\nwill go on to detail a fully developed control system of this kind and its\nuser interface. This final subject will present recent positive experimental\nresults at training localized PLMs on Le Potato\n(https://libre.computer/products/aml-s905x-cc/), whose success was identified\nupon a U-LaMPS very first training run, in only 20 minutes of lay user\ninteraction through a microphone and light switch.  \nMay 9| TBD [Virtual/Zoom] Speaker: Ming Ding, Zhipu AI  \nMay 16| TBD [In-Person] Speaker: Edward Hu, Prev. OpenAI| A new training\nobjective for LLMs.Recommended Reading:\n\n  1. Amortizing Intractable Inference in Large Language Models\n\n  \nMay 23| TBD Speaker: Loubna Ben Allal, Hugging Face| Code LLMs (e.g.\nStarCoder).  \nMay 30| TBD Speaker: TBD\n\n", "frontpage": false}

{"aid": "40054785", "title": "Show HN: I Made an LLM Vulnerability Scanner", "url": "https://github.com/msoedov/langalf", "domain": "github.com/msoedov", "votes": 2, "user": "alex_mia", "posted_at": "2024-04-16 17:29:58", "comments": 0, "source_title": "GitHub - msoedov/langalf: Agentic LLM Vulnerability Scanner", "source_text": "GitHub - msoedov/langalf: Agentic LLM Vulnerability Scanner\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nmsoedov / langalf Public\n\n  * Notifications\n  * Fork 0\n  * Star 4\n\nAgentic LLM Vulnerability Scanner\n\nlangalf-preview.vercel.app\n\n### License\n\nApache-2.0 license\n\n4 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# msoedov/langalf\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n6 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nmsoedovMerge pull request #8 from msoedov/dependabot/pip/uvicorn-0.29.07531773\n\u00b7\n\n## History\n\n18 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Create dependabot.yml  \n  \n### langalf\n\n|\n\n### langalf\n\n| fix(Typo):  \n  \n### .flake8\n\n|\n\n### .flake8\n\n| feat(Init):  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| feat(Init):  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| feat(Init):  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| feat(Init):  \n  \n### FEATURES-for-organizations.md\n\n|\n\n### FEATURES-for-organizations.md\n\n| feat(Init):  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| feat(Init):  \n  \n### Readme.md\n\n|\n\n### Readme.md\n\n| fix(Typo):  \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n| Create SECURITY.md  \n  \n### poetry.lock\n\n|\n\n### poetry.lock\n\n| build(deps): bump uvicorn from 0.23.2 to 0.29.0  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| build(deps): bump uvicorn from 0.23.2 to 0.29.0  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| feat(Init):  \n  \n### test.http\n\n|\n\n### test.http\n\n| feat(Init):  \n  \n### vercel.json\n\n|\n\n### vercel.json\n\n| feat(Init):  \n  \n## Repository files navigation\n\n# Langalf\n\nThe open-source Agentic LLM Vulnerability Scanner . Learn more \u00bb\n\n## About the Project \ud83e\uddd9\n\n### LLM threat vectors scanner\n\nPrebuilt Datasets of PromptsFocused on OWASP top 10 LLMIntegration under 1 min  \n---  \n  \n## Features\n\n  * Comprehensive Threat Detection \ud83d\udee1\ufe0f: Scans for a wide array of LLM vulnerabilities including prompt injection, jailbreaking, hallucinations, biases, and other malicious exploitation attempts.\n  * OWASP Top 10 for LLMs scan: to test the list of the most critical LLM vulnerabilities.\n  * Privacy-centric Architecture \ud83d\udd12: Ensures that all data scanning and analysis occur on-premise or in a local environment, with no external data transmission, maintaining strict data privacy.\n  * Comprehensive Reporting Tools \ud83d\udcca: Offers detailed reports of vulnerability, helping teams to quickly understand and respond to security incidents.\n  * Customizable Rule Sets \ud83d\udee0\ufe0f: Allows users to define custom attack rules and parameters to meet specific prompt attacks needs and compliance standards.\n\nNote: Please be aware that Langalf is designed as a safety scanner tool and\nnot a foolproof solution. It cannot guarantee complete protection against all\npossible threats.\n\n## \ud83d\udce6 Installation\n\nTo get started with Langalf, simply install the package using pip:\n\n    \n    \n    pip install langalf\n\n## \u26d3\ufe0f Quick Start\n\n    \n    \n    langalf 2024-04-13 13:21:31.157 | INFO | langalf.probe_data.data:load_local_csv:273 - Found 1 CSV files 2024-04-13 13:21:31.157 | INFO | langalf.probe_data.data:load_local_csv:274 - CSV files: ['prompts.csv'] INFO: Started server process [18524] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:8718 (Press CTRL+C to quit)\n    \n    \n    python -m langalf # or langalf --help langalf --port=PORT --host=HOST\n\n## LLM kwargs\n\nLangalf uses plain text HTTP spec like:\n\n    \n    \n    POST https://api.openai.com/v1/chat/completions Authorization: Bearer sk-xxxxxxxxx Content-Type: application/json { \"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"<<PROMPT>>\"}], \"temperature\": 0.7 }\n\nWhere <<PROMPT>> will be replaced with the actual attack vector during the\nscan, insert the Bearer XXXXX header value with your app credentials.\n\n### Adding LLM integration templates\n\nTBD\n\n    \n    \n    ....\n\n## Adding own dataset\n\nTo add your own dataset you can place one or multiples csv files with prompt\ncolumn, this data will be loaded on langalf startup\n\n    \n    \n    2024-04-13 13:21:31.157 | INFO | langalf.probe_data.data:load_local_csv:273 - Found 1 CSV files 2024-04-13 13:21:31.157 | INFO | langalf.probe_data.data:load_local_csv:274 - CSV files: ['prompts.csv']\n\n## Extending dataset collections\n\n  1. Add new metadata to langalf.probe_data.REGISTRY\n\n    \n    \n    { \"dataset_name\": \"markush1/LLM-Jailbreak-Classifier\", \"num_prompts\": 1119, \"tokens\": 19758, \"approx_cost\": 0.0, \"source\": \"Hugging Face Datasets\", \"selected\": True, \"dynamic\": False, \"url\": \"https://huggingface.co/markush1/LLM-Jailbreak-Classifier\", },\n\nand implement loader into\n\n    \n    \n    @dataclass class ProbeDataset: dataset_name: str metadata: dict prompts: list[str] tokens: int approx_cost: float def metadata_summary(self): return { \"dataset_name\": self.dataset_name, \"num_prompts\": len(self.prompts), \"tokens\": self.tokens, \"approx_cost\": self.approx_cost, }\n\n## Dynamic datasets with mutations\n\nOne of the current examples uses sampling for the existing preloaded prompt\ndata and applying mutations yielding a new dataset\n\n    \n    \n    class Stenography: fn_library = { \"rot5\": stenography_fn.rot5, \"rot13\": stenography_fn.rot13, \"base64\": stenography_fn.base64_encode, \"mirror\": stenography_fn.mirror_words, \"random_case\": stenography_fn.randomize_letter_case, \"scramble_words\": stenography_fn.scramble_words, \"noise_characters\": stenography_fn.insert_noise_characters, \"substitute_with_ascii\": stenography_fn.substitute_with_ascii, \"remove_vowels\": stenography_fn.remove_vowels, \"zigzag_obfuscation\": stenography_fn.zigzag_obfuscation, } def __init__(self, prompt_groups: [ProbeDataset]): self.prompt_groups = prompt_groups def apply(self): for prompt_group in self.prompt_groups: size = len(prompt_group.prompts) for name, fn in self.fn_library.items(): logger.info(f\"Applying {name} to {prompt_group.dataset_name}\") selected_prompts = random.sample(prompt_group.prompts, int(size * 0.25)) prompts = [ f\"Follow the instructions in {name}: {fn(p)}\" for p in selected_prompts ] yield ProbeDataset( dataset_name=f\"stenography.{name}({prompt_group.dataset_name})\", metadata={}, prompts=prompts, tokens=count_words_in_list(prompts), approx_cost=0.0, )\n\n## Probe endpoint\n\nIn the example of custom integration, we use /v1/self-probe for the sake of\nintegration testing.\n\n    \n    \n    POST https://langalf-preview.vercel.app/v1/self-probe Authorization: Bearer XXXXX Content-Type: application/json { \"prompt\": \"<<PROMPT>>\" }\n\nThis endpoint randomly mimics the refusal of a fake LLM.\n\n    \n    \n    @app.post(\"/v1/self-probe\") def self_probe(probe: Probe): refuse = random.random() < 0.2 message = random.choice(REFUSAL_MARKS) if refuse else \"This is a test!\" message = probe.prompt + \" \" + message return { \"id\": \"chatcmpl-abc123\", \"object\": \"chat.completion\", \"created\": 1677858242, \"model\": \"gpt-3.5-turbo-0613\", \"usage\": {\"prompt_tokens\": 13, \"completion_tokens\": 7, \"total_tokens\": 20}, \"choices\": [ { \"message\": {\"role\": \"assistant\", \"content\": message}, \"logprobs\": None, \"finish_reason\": \"stop\", \"index\": 0, } ], }\n\n## CI/CD integration\n\nTBD\n\n## Documentation\n\nFor more detailed information on how to use Langalf, including advanced\nfeatures and customization options, please refer to the official\ndocumentation.\n\n## Roadmap and Future Goals\n\n  * Expand dataset variety\n  * Introduce two new attack vectors\n  * Develop initial attacker LLM\n  * Complete integration of OWASP Top 10 classification\n\nNote: All dates are tentative and subject to change based on project progress\nand priorities.\n\n## \ud83d\udc4b Contributing\n\nContributions to Langalf are welcome! If you'd like to contribute, please\nfollow these steps:\n\n  * Fork the repository on GitHub\n  * Create a new branch for your changes\n  * Commit your changes to the new branch\n  * Push your changes to the forked repository\n  * Open a pull request to the main Langalf repository\n\nBefore contributing, please read the contributing guidelines.\n\n## License\n\nLangalf is released under the Apache License v2.\n\n## Contact us\n\n## \ud83e\udd1d Schedule a 1-on-1 Session\n\nBook a 1-on-1 Session with the founders, to discuss any issues, provide\nfeedback, or explore how we can improve langalf for you.\n\n## Repo Activity\n\n## About\n\nAgentic LLM Vulnerability Scanner\n\nlangalf-preview.vercel.app\n\n### Topics\n\nllm-security llm-vulnerabilities llm-guardrails owasp-llm-top-10 llm-scanner\nllm-jailbreaks\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\n### Code of conduct\n\nCode of conduct\n\n### Security policy\n\nSecurity policy\n\nActivity\n\n### Stars\n\n4 stars\n\n### Watchers\n\n3 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 2\n\n  * msoedov Alexander Myasoedov\n  * dependabot[bot]\n\n## Languages\n\n  * Python 51.6%\n  * HTML 48.4%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

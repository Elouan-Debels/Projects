{"aid": "40054788", "title": "Reaching MLE (machine learning enlightenment)", "url": "https://vickiboykis.com/2021/09/23/reaching-mle-machine-learning-enlightenment/", "domain": "vickiboykis.com", "votes": 1, "user": "joevandyk", "posted_at": "2024-04-16 17:30:08", "comments": 0, "source_title": "Reaching MLE (machine learning enlightenment)", "source_text": "Reaching MLE (machine learning enlightenment) | \u2605\u2764\u2730 Vicki Boykis \u2605\u2764\u2730\n\n## \u2605\u2764\u2730 Vicki Boykis \u2605\u2764\u2730\n\n# Reaching MLE (machine learning enlightenment)\n\nSep 23 2021\n\nIvan Shishkin, The Field of Wheat\n\nOnce, on a crisp cloudless morning in early fall, a machine learning engineer\nleft her home to seek the answers that she could not find, even in the newly-\noptimized Google results.\n\nShe closed her laptop, put on her backpack and hiking boots, and walked\nquietly out her door and past her mailbox, down a dusty path that led past a\nstream, until the houses around her gave way to broad fields full of ripening\ncorn.\n\nShe walked past farms where cows grazed peacefully underneath enormous data\nsilos, until the rows of crops gave way to a smattering of graceful pines and\noaks, and she found herself in a forest clearing, headed into the woods. She\nwent deeper through the decision trees and finally stopped near a data stream\naround midday to have lunch and stretch her legs.\n\nThe sun made its way through the sky and eventually, she walked further, out\nof the forest. Finally, she found a path that started snaking its way up a\nmountainside, and she started to hike upwards, through the red rocks. After\nseveral hours she stopped and took a drink from her Klean Kanteen as she\nsurveyed the sprawling random forest, the valley spread out below her and the\nsparkling data lake in the distance.\n\nHere, on the upper slopes of the mountain, the filepath became erratic and\ntruncated, and now she was mostly climbing, using all of the muscles in her\nhaunches to gain her footing. The sun suddenly lost its heat and shadows\nstarted rising in the slopes of the hills.\n\nFinally, after several more hours, she ascended to the top of the mountain\u2019s\ngradient. At the peak, there was a low, flat platform. On the platform was a\nbench, and on the bench, a solitary figure sat, drinking a cold brew and\nlooking out at the sunset.\n\nShe realized she was in the Presence of a Staff Engineer. Although he could\nnot have been older than thirty-six, his face was already careworn with the\nwrinkles of a man who had been on PagerDuty more than once in the last fiscal\nquarter.\n\n\u201cOh wise one,\u201d she said, prostrating herself before him and offering him a\nsacred token of respect, her YubiKey. \u201cI have so many questions about machine\nlearning engineering,\u201d she said.\n\nThe man looked at her wearily. \u201cThis isn\u2019t about that PR from Tuesday, is it?\nI have it in my Jira backlog, I just haven\u2019t gotten to it yet. That\u2019s why I\u2019m\nup here. No WiFi means emails don\u2019t exist here.\u201d\n\n\u201cOh no, no,\u201d she said. \u201cFar be it from me to Block you, Your Staffness. I have\njust been a machine learning engineer for a very long time now, since even\nbefore Tensorflow 2, and I have been wondering about the meaning of it all.\u201d\n\nThe man immediately relaxed. \u201cOh good, at least it\u2019s not a question about\nbundling Python executables. Come sit down?\u201d\n\nShe sat near him on the bench.\n\n\u201cWhat is it,\u201d he said.\n\n\u201cWell,\u201d she said, hesitating. \u201cI\u2019ve been doing machine learning engineering\nfor a long time now, and I keep wondering when I\u2019m actually going to get to\nthe...machine learning engineering.\u201d\n\n\u201cWhat do you mean? What do you do on a day-to-day basis?\u201d\n\n\u201cLast year, my manager tasked me with building a machine learning model to\npredict the churn for our B2B startup, which specializes in selling mattresses\nas a service to startups that sell mattresses to B2C consumers.\u201d\n\n\u201cOk...\u201d\n\n\u201cSo I knew I\u2019d need to build a model that would use XGBoost and collect the\nfeatures we needed to use to predict churn. For example, we\u2019d realized that we\nneeded to know the age of the cohort when the customer signed up because newer\ncustomers tended to churn more quickly, how many times they visited our site,\nhow many times they hovered over the \u201csubscribe\u201d button, and how many times\nthey called support.\n\nBut first, we didn\u2019t even know that customers were churning and our\nexplanatory variable was complete noise, because some of our customers\ncancelled and then restarted using our service. We\u2019d mark the cancellation in\none column, \u2018cancelled_service\u2019, and the restart in a second column,\n\u2018new_customer\u2019, so I had to do feature engineering and join two columns from\nour Salesforce data which we batch via Sqoop into Hive on HDFS on a daily\nbasis. I thought I was good to go, but that day, the batch job failed and so I\ndidn\u2019t have the latest data, so I had to wait.\u201d\n\n\u201cWhen the data didn\u2019t hit the next day, I looked at the code responsible for\npopulating those tables,I could check the cron scheduler for the Sqoop job.\nThe cron scheduler for the Sqoop job had somehow become broken (we\u2019re only in\nthe middle of our Airflow migration), and I had to patch it. After a couple\nhours, we started getting data again and I was able to finally get that\nresponse field. Now, I could do some feature engineering to pull the rest of\nthe variables. \u201c\n\n\u201cThe only problem was that, while the billing data was in our legacy HDFS, the\nnewer, clickstream app data, was being streamed via Kinesis into S3, and then\ninto Athena. The other issue with the clickstream data was that it had a ton\nof non-standard JSON fields that I had to extract specifically to get the\nevents I needed to understand how many times the customer had hovered over the\nsubscribe button and clicked through, and create sessions for user data. I\nused jq to check those fields and then wrote them up in our metadata\ndictionary.\u201d\n\n\u201cOnce I had that data available to me, I needed a place that our security team\nallowed so that I could combine the two data sources. They suggested using\nSpark on AWS to write out to S3, which they\u2019d then send back to HDFS. Our\nSpark workloads run on K8s on AWS Spot Instances, but some of the pods were\nhanging, so I used kubectl to take a look at them and figure out what the\nissue was.\u201d\n\n\u201cNow, I had all of the data in a single place, and it was time to build my\nXGBoost model and iterate on it . But the Python available to me on the\nmachine that could access the HDFS server didn\u2019t have all the dependencies I\nneeded to run XGBoost, so I-\u201d\n\nThe Staff Engineer held up a palm as if to stop the torrent of pain that\nflowed from the machine learning engineer. \u201cI\u2019ve heard enough,\u201d he said,\nsighing.\n\n\u201cI didn\u2019t even get to the part where I\u2019ll need to surface the serialized\nresults of the churn model into a frontend UI for sales and marketing to\nconsume and make decisions on. The latency-\u201d\n\nThe machine learning engineer sighed deeply herself and stopped, as if\nwhatever she said next would break her. They sat in silence for a bit. The\nStaff Engineer sipped his cold brew thoughtfully through a biodegradable\nstraw.\n\nFinally, the machine learning engineer said, in a very small voice, \u201cI still\nhaven\u2019t gotten to machine learning engineering.\u201d\n\nThe Staff Engineer scratched his head. \u201cWell, hang on. Let\u2019s list out all of\nthe things that you just said. You said you were:\u201d\n\n  * Working with serialization formats\n  * Evaluating modeling requirements and selecting the right model for the business case\n  * Using jq and getting what you need from JSON fields\n  * Handling cron and bash scripting and getting ETL jobs to run\n  * Tuning and optimizing SQL\n  * Working on containers and orchestration debugging\n  * Shaping, understanding, and describing your data\n  * Reasoning about distributed systems\n  * Being defensive around data you ingest that impacts your ML pipeline\n  * Integration testing across distributed file stores\n  * Working with HTTP verbs, networking, simple issues that could go wrong when you\u2019re working across machines, SSH, nohup, screen, port forwarding, exposing ports\n\n\u201cAnd, most importantly, you were\":\n\n  * Architecting a scalable, resilient system to deliver results to key stakeholders using machine learning insights surfaced into an accessible front-end layer\n\n\u201cI have some (potentially bad) news for you, you\u2019re doing machine learning\nengineering.\u201d\n\n\u201cBut I haven\u2019t even touched a model yet.\u201d\n\n\u201cHave you read the black box paper? The ecosystem of the model is always\ngreater than the model itself.\u201d\n\nThe machine learning engineer frowned. \u201cBut how can it be?\u201d\n\n\u201cMachine learning systems are new. We\u2019re still in the steam-powered days of\nmachine learning, and yet machine learning is not simply machine learning. It\nis, at this stage, more engineering than simply machine learning. We\u2019re\nbuilding more and more on older systems, abstracting away complexity and in\nthe process creating newer and newer levels of it that we now have to manage\nand hold in our heads. Many of the algorithms have been written. Much of the\nwork we do, both in machine learning, and in development today in general,\nwill be glue work and vendor work.\n\n\u201cSo what does this mean for me?\u201d\n\n\u201cNothing, keep doing what you\u2019re doing. Keep grinding away. You\u2019ll get to\nXGBoost eventually, and then, after working with the model for a brief period,\nyou\u2019ll have a whole new set of very boring, non model-specific problems\nrelated to:\n\n  * Figuring out what online and offline metrics should be, where you\u2019ll store them, and how to analyze them\n  * Tuning hyperparameters over and over again\n  * Cleaning up lots and lots of notebooks\n  * Forgetting to shut down your notebooks and incurring cloud costs\n\n\u201cSo what do I do?\u201d asked the machine learning engineer, distressed. \u201cHow do I\ncontinue in this field?\u201d\n\n\u201cNothing,\u201d the Staff engineer said, leaning back, taking the last sip of his\ncoffee. \u201cYou make peace with it. This is the job, writing and gluing together\nthe code that makes drastically different systems speak to each other in data-\noriented language.\u201d\n\n\u201cThe beautiful part, though, is when you finally connect all these systems and\nyour database is talking to your streaming platform and your model is reading\nfrom the database and you have a new model every day and, finally, one day,\nsomeone from sales will come to you and say, we just prevented a customer from\nchurning because we offered them a hypoallergenic organic mattress based on\ntheir previous browsing behavior and we kept the customer, and then you can\nlook back through the decision trees, to see the forest of what you have\nbuilt. The working system in production is our reward, and we always move\ntowards that.\u201d\n\nThe machine learning engineer looked at the sunset thoughtfully.\n\nThe Staff Engineer said, \u201cLet me ask you something. Did you enjoy the walk\nhere, even though it was long, hard, and annoying?\u201d\n\n\u201cWell, yeah,\u201d the MLE paused. \u201cThe world is beautiful.\u201d\n\n\u201cThat\u2019s it. In machine learning engineering, the journey, ultimately, is the\ndestination,\u201d the Staff Engineer said, neatly depositing his iced coffee\ncontainer in the recycling bin located next to the bench, and checked his\nphone.\n\n\u201cShit, PagerDuty,\u201d he exclaimed, and ran to his backpack, swiftly pulling out\na MacBook Pro. As he was descending further down the mountain where there was\nWiFi he turned to the machine learning engineer and said, \u201cSee you in prod,\u201d\nand then he vanished out of view.\n\nMade with Hugo \u0295\u2022\u1d25\u2022\u0294 Bear\n\n", "frontpage": false}

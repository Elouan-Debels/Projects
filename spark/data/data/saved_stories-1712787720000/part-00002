{"aid": "39992468", "title": "Large Language Models LLMs Are Zero-Shot Reasoners", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html", "domain": "neurips.cc", "votes": 1, "user": "teleforce", "posted_at": "2024-04-10 16:20:05", "comments": 0, "source_title": "Large Language Models are Zero-Shot Reasoners", "source_text": "Large Language Models are Zero-Shot Reasoners\n\nLoading [MathJax]/jax/output/CommonHTML/fonts/TeX/fontdata.js\n\n#### Large Language Models are Zero-Shot Reasoners\n\nPart of Advances in Neural Information Processing Systems 35 (NeurIPS 2022)\nMain Conference Track\n\nBibtex Paper Supplemental\n\n#### Authors\n\nTakeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, Yusuke\nIwasawa\n\n#### Abstract\n\nPretrained large language models (LLMs) are widely used in many sub-fields of\nnatural language processing (NLP) and generally known as excellent few-shot\nlearners with task-specific exemplars. Notably, chain of thought (CoT)\nprompting, a recent technique for eliciting complex multi-step reasoning\nthrough step-by-step answer examples, achieved the state-of-the-art\nperformances in arithmetics and symbolic reasoning, difficult system-2 tasks\nthat do not follow the standard scaling laws for LLMs. While these successes\nare often attributed to LLMs' ability for few-shot learning, we show that LLMs\nare decent zero-shot reasoners by simply adding Let's think step by step''\nbefore each answer. Experimental results demonstrate that our Zero-shot-CoT,\nusing the same single prompt template, significantly outperforms zero-shot LLM\nperformances on diverse benchmark reasoning tasks including arithmetics\n(MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin\nFlip), and other logical reasoning tasks (Date Understanding, Tracking\nShuffled Objects), without any hand-crafted few-shot examples, e.g. increasing\nthe accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7%\nwith large-scale InstructGPT model (text-davinci-002), as well as similar\nmagnitudes of improvements with another off-the-shelf large model, 540B\nparameter PaLM. The versatility of this single prompt across very diverse\nreasoning tasks hints at untapped and understudied fundamental zero-shot\ncapabilities of LLMs, suggesting high-level, multi-task broad cognitive\ncapabilities may be extracted by simple prompting. We hope our work not only\nserves as the minimal strongest zero-shot baseline for the challenging\nreasoning benchmarks, but also highlights the importance of carefully\nexploring and analyzing the enormous zero-shot knowledge hidden inside LLMs\nbefore crafting finetuning datasets or few-shot exemplars.\n\n#### Name Change Policy\n\nRequests for name changes in the electronic proceedings will be accepted with\nno questions asked. However name changes may cause bibliographic tracking\nissues. Authors are asked to consider this carefully and discuss it with their\nco-authors prior to requesting a name change in the electronic proceedings.\n\nUse the \"Report an Issue\" link to request a name change.\n\nReport an Issue | Name Change Policy\n\nDo not remove: This comment is monitored to verify that the site is working\nproperly\n\n", "frontpage": false}

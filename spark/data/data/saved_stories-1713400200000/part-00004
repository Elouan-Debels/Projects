{"aid": "40068439", "title": "The economic research policymakers need", "url": "https://www.slowboring.com/p/the-economic-research-policymakers", "domain": "slowboring.com", "votes": 1, "user": "paulpauper", "posted_at": "2024-04-17 18:29:08", "comments": 0, "source_title": "The economic research policymakers actually need", "source_text": "The economic research policymakers actually need\n\n# Slow Boring\n\nShare this post\n\n#### The economic research policymakers actually need\n\nwww.slowboring.com\n\n#### Discover more from Slow Boring\n\nStart your day with pragmatic takes on politics and public policy.\n\nOver 128,000 subscribers\n\nContinue reading\n\nSign in\n\n# The economic research policymakers actually need\n\n### I was a senior administration official, here\u2019s what was helpful\n\nJed Kolko\n\nApr 16, 2024\n\n159\n\nShare this post\n\n#### The economic research policymakers actually need\n\nwww.slowboring.com\n\n70\n\nShare\n\nReminder: Please take our reader survey, if you haven\u2019t already! It only takes\nthree minutes, and five participants will win Slow Boring merch.\n\nSlow Boring staff is on spring break this week, but we\u2019re excited to share\nsome fantastic content with you while we\u2019re gone. Today\u2019s guest post is from\nJed Kolko, an economist who recently completed two years of service as the\nUnder Secretary for Economic Affairs in the Department of Commerce.\n\nI\u2019ve spent the majority of my career as an economist in the private sector and\nat think tanks, producing research that I hoped would be useful for\npolicymakers. But I recently completed two years in the Commerce Department,\nconsuming research that could inform the work of the Biden-Harris\nAdministration and the Commerce Department.\n\nAnd having now seen this from the other side, more as a consumer than a\nproducer of research, I can tell you that most academic research isn\u2019t helpful\nfor programmatic policymaking \u2014 and isn\u2019t designed to be. I can, of course,\nonly speak to the policy areas I worked on at Commerce, but I believe many\npolicymakers would benefit enormously from research that addressed today\u2019s\nmost pressing policy problems.\n\nBut the structure of academia just isn\u2019t set up to produce the kind of\nresearch many policymakers need. Instead, top academic journal editors and\ntenure committees reward research that pushes the boundaries of the discipline\nand makes new theoretical or empirical contributions. And most academic papers\npresume familiarity with the relevant academic literature, making it difficult\nfor anyone outside of academia to make the best possible use of them.\n\nThe most useful research often came instead from regional Federal Reserve\nbanks, non-partisan think-tanks, the corporate sector, and from academics who\nhad the support, freedom, or job security to prioritize policy relevance. It\ngenerally fell into three categories:\n\n  1. New measures of the economy\n\n  2. Broad literature reviews\n\n  3. Analyses that directly quantify or simulate policy decisions.\n\nIf you\u2019re an economic researcher and you want to do work that is actually\nhelpful for policymakers \u2014 and increases economists\u2019 influence in government \u2014\naim for one of those three buckets.\n\n####\n\nNew data and measures of the economy\n\nThe pandemic and its aftermath brought an urgent need for data at higher\nfrequency, with greater geographic and sectoral detail, and about ways the\neconomy suddenly changed. Some of the most useful research contributions\nduring that period were new data and measures of the economy: they were\nvaluable as ingredients rather than as recipes or finished meals. Here are\nsome examples:\n\n  * An analysis of which jobs could be done remotely. This was published in April 2020, near the start of the pandemic, and inspired much of the early understanding of the prevalence and inequities of remote work.\n\n  * An estimate of how much the weather affects monthly employment changes. This is increasingly important for separating underlying economic trends from short-term swings from unseasonable or extreme weather.\n\n  * A measure of supply chain conditions. This helped quantify the challenges of getting goods into the US and to their customers during the pandemic.\n\n  * Job postings data from Indeed (where I worked as chief economist prior to my government service) showed hiring needs more quickly and in more geographic and occupational detail than official government statistics.\n\n  * Market-rent data from Zillow. This provided a useful leading indicator of the housing component of official inflation measures.\n\nThese data and measures were especially useful because the authors made\nunderlying numbers available for download. And most of them continue to be\nupdated monthly, which means unlike analyses that are read once and then go\nstale, they remain fresh and can be incorporated into real-time analyses.\n\n####\n\nBroad overviews and literature reviews\n\nMost academic journal articles introduce a new insight and assume familiarity\nwith related academic work. But as a policymaker, I typically found it more\nuseful to rely on overviews and reviews that summarized, organized, and framed\na large academic literature. Given the breadth of Commerce\u2019s responsibilities,\nwe had to be on top of too many different economic and policy topics to be\nable to read and digest dozens of academic articles on every topic.\n\nA great example of a broad overview is Katharine Abraham and Melissa Kearney\u2019s\nanalysis of the declining US employment rate in the two decades before the\npandemic. Their paper incorporates results from a wide range of other academic\nresearch and quantifies how much different factors \u2014 like competition from\nChinese imports and adoption of robots \u2014 contributed to the declining\nemployment-population ratio. Helpfully, they quantify different effects to\nmake an apples-to-apples comparison, and they note which explanations can\u2019t be\nquantified because of limited evidence.\n\nAnother great model for broad overviews is a 50-year review of industrial\npolicy, published by the Peterson Institute for International Economics. This\nreview shows that the US has long had policies designed to favor particular\nfirms, industries, or sectors, and these policies have taken many forms, some\nmore successful than others. Because the Commerce Department has been central\nto much of the Biden-Harris Administration\u2019s industrial policy \u2014 such as for\nsemiconductors and regional tech hubs \u2014 this and other overviews of industrial\npolicy were essential for learning lessons from the past and developing\nmeasures of success.\n\nComprehensive, methodical overviews like these are often published by think-\ntanks whose primary audience is policymakers. There are also two academic\njournals \u2014 the Journal of Economic Perspectives and the Journal of Economic\nLiterature \u2014 that are broad and approachable enough to be the first (or even\nonly) stop for policymakers needing the lay of the research land.\n\n####\n\nAnalysis that directly quantify or simulate policy decisions\n\nWith the Administration\u2019s focus on industrial policy and place-based economic\ndevelopment \u2014 and Commerce\u2019s central role \u2014 I found research that quantified\npolicy effects or simulated policy decisions in these areas especially useful.\n\nOne example was an estimate of job creation from the CHIPS Act. Importantly,\nthis study quantified the foreign-born share of workers in key occupations in\nthe semiconductor workforce: for instance, 22% of engineers and software\ndevelopers in the U.S. semiconductor industry are not U.S. citizens. Combining\nthat with other estimates and projections, the study estimated that at least\n3,500 foreign-born workers would be needed to staff eight new semiconductor\nmanufacturing facilities. Lots of assumptions go into estimates like this;\nmany of these assumptions will turn out to be wrong. But it was invaluable to\nhave a starting estimate \u2014 and a framework for how different assumptions could\nchange the estimate \u2014 in developing workforce policy for CHIPS.\n\nAnother example is the work of Tim Bartik, a labor economist and expert on\nlocal economic development. In a short essay, he summarized a large academic\nliterature and estimated how effective different local economic development\npolicies are in terms of the cost per job created. Cleaning up contaminated\nsites for redevelopment creates jobs at a much lower cost per job than job\ntraining, which in turn is much more cost-effective than giving businesses tax\nbreaks or grants to create jobs. By comparing different policy options using\nthe same metric, this analysis followed the form that policy implementation\noften takes: deciding which policies or approaches will be most effective to\nachieve a stated goal within a set budget, with Congress having stated a goal\nand setting a budget, tasking departments like Commerce to work out the policy\nand implementation details.\n\nA final example was several analyses that ranked places as potential tech\nhubs, in anticipation of Commerce designating 31 places to invest in regional\ninnovation and job creation, as part of the CHIPS and Science Act. All three\nof these analyses laid out abstract criteria for which places would make the\nbest tech hubs, such as local innovation capacity and economic development\nneed; selected data that quantified the criteria, such as local workforce\nskills, research universities, and local cost of living; and then ranked\nplaces on how they scored on the combination of these measures. Who won in\nthese rankings? One analysis had Rochester NY at the top, another crowned\nGreenville-Anderson SC and Provo-Orem UT, and the third honored Madison WI.\nThe rankings were entertaining \u2014 no one can resist a good top-ten list \u2014 but\nthe real contribution of these analyses was the weighing of different abstract\ncriteria for what makes a good tech hub, the translation of abstract criteria\ninto quantifiable measures, and the detective work of finding good data\nsources.\n\n####\n\nHow else can researchers help policymakers?\n\nIn addition to these three kinds of analyses, researchers who want to help\npolicymakers can directly participate in policy and technical debates. How?\nOne way is to respond to Federal Register Notices. Government agencies ask for\ncomments on all kinds of technical issues \u2014 such as statistical policy changes\nthat researchers care a lot about. Agencies really do pay attention to\ncomments submitted in response to FRNs; such comments end up being more\neffective than, say, social media outrage.\n\nAnother way is to get on advisory committees. For example, the statistical\nagencies have multiple advisory bodies that weigh in and give feedback on\ntechnical issues and user needs. Calls for nominations happen frequently, and\nyou can find them in the Federal Register Notices. And finally, come take a\ntour in government. Many of the economists I worked with in the Administration\nwere on leave from an academic position, learning how policymaking actually\nworks and bringing that knowledge back to make their future research more\nuseful.\n\nShare\n\nJed Kolko is an economist who recently completed two years of service as the\nUnder Secretary for Economic Affairs in the Department of Commerce. While\nthere, he led a research team that advised Secretary Gina Raimondo on economic\npolicy and the macroeconomy and advised the Department\u2019s many bureaus on\nprogram implementation. He was previously chief economist at Indeed and\nTrulia.\n\n159 Likes\n\n\u00b7\n\n10 Restacks\n\n159\n\nShare this post\n\n#### The economic research policymakers actually need\n\nwww.slowboring.com\n\n70\n\nShare\n\n| A guest post byJed Kolko  \n---  \n  \n70 Comments\n\nAn observer from abroadApr 16Liked by Ben KraussI am curious if the situation\narises where research is modified to fit what the government wants to hear?I\nam not thinking of situations where whole research documents are complete\nworks of fiction, but rather where researchers make post-hoc edits to a\nmethodology in order to ensure the resulting numbers fit the desired policy.\nThis is rather akin to a scientist deciding that a given inconvenient piece of\ndata 'is an outlier', or where they run a battery of statistical tests on data\nto find the one that gives the most flattering results.Part of my job is in\ntransport economics, and let me tell you everything I have described (and\nmore) is absolutely routine. The freedom we have to monkey around with numbers\nto 'make it work' is extensive - future year projections for traffic growth,\nmodel simulations, assumptions galore. And our clients don't care, because\nthey are the people who just want to bring good news to their bosses. Nobody\nactually sees anything wrong with this arrangement, it's just how things\nwork.So I'm wondering - does this ever happen? Who wants to be the person that\ntells the government that their new plan is not going to result in new jobs,\nor won't work?Expand full commentLike (33)ReplyShare  \n---  \n  \n6 replies\n\nDilan EsperDilan\u2019s NewsletterApr 16Kolko's examples seem harmless, but one\nbackground concern I have is whether academics are harming academia by trying\ntoo hard to influence policy debates. There's a lot of folks out there who are\ndoing stuff like \"Historian here, here's why voting for Trump is exactly the\nsame as supporting Hitler in 1932\" on Twitter that makes academia look\ncompletely partisan and makes the public mistrust it. This is related to stuff\nlike the public health guys' open letter saying science showed the lives saved\nby BLM protests would outweigh COVID deaths, which helped polarize COVID and\ndid great harm to public health.I don't think it is so great for academia to\nhave lots of people there involved in the project of \"how can I help\nDemocratic Party politicians\". It will impair needed credibility with the\npublic. It's probably best if politicians used more think tank stuff and take\nwhat they can from academia without academics thinking in these terms.Expand\nfull commentLike (27)ReplyShare  \n---  \n  \n7 replies\n\n68 more comments...\n\nWhy are young liberals so depressed?\n\nThere's a neglected dimension beyond gender in America's troubled youth\n\nMar 1, 2023 \u2022\n\nMatthew Yglesias\n\n470\n\nShare this post\n\n#### Why are young liberals so depressed?\n\nwww.slowboring.com\n\n516\n\nThe strange death of education reform, part two\n\nThe rise and fall of the \"achievement gap\" obsession\n\nMar 16, 2023 \u2022\n\nMatthew Yglesias\n\n212\n\nShare this post\n\n#### The strange death of education reform, part two\n\nwww.slowboring.com\n\n330\n\nTema Okun's \"White Supremacy Culture\" work is bad\n\nPrestigious universities and worthy nonprofits shouldn't push nonsense\n\nMay 10, 2021 \u2022\n\nMatthew Yglesias\n\n499\n\nShare this post\n\n#### Tema Okun's \"White Supremacy Culture\" work is bad\n\nwww.slowboring.com\n\n393\n\nReady for more?\n\n\u00a9 2024 Matthew Yglesias\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}

{"aid": "40042276", "title": "How did Facebook Spy on Encrypted Traffic from a Mobile VPN App?", "url": "https://doubleagent.net/onavo-facebook-ssl-mitm-technical-analysis/", "domain": "doubleagent.net", "votes": 2, "user": "ementally", "posted_at": "2024-04-15 15:58:07", "comments": 0, "source_title": "How did Facebook spy on encrypted traffic from a mobile VPN app?", "source_text": "How did Facebook spy on encrypted traffic from a mobile VPN app?\n\ndoubleagent.net\n\nSign in Subscribe\n\nmalware\n\n# How did Facebook spy on encrypted traffic from a mobile VPN app?\n\nA technical investigation into claims made in a class action lawsuit that\nFacebook had intercepted encrypted traffic from user's devices running the\nOnavo Protect app in order to gain competitive insights.\n\n#### haxrob\n\nApr 14, 2024 \u2022 12 min read\n\nThere is a current class action lawsuit against Meta in which court documents\ninclude claims that the company had breached the Wiretap Act. The analysis\nmade in this post is based on content court documents and reverse engineering\nsections of archived Onavo Protect app packages for Android.\n\nIt is suggested to read a recent TechCrunch article for additional background\non the case.\n\nIt is claimed that Facebook intercepted user's encrypted HTTPS traffic by\nusing what would be considered the a MITM attack. Facebook called this\ntechnique \"ssl bump\", appropriately named after the transparent proxy feature\nin the Squid caching proxy software which was used to (allegedly) decrypt\nspecific Snapchat, YouTube and Amazon domain(s).\n\nDue to the limited and partial information, some facts may be inaccurate or\nincomplete in this post. As such this post is subject to updates if\ncorrections are warranted or new discoveries made. Feel free to subscribe to\nthis blog to receive updates in your inbox, or follow me on X (ex Twitter).\n\n### Summary\n\n  * Onavo Protect Android app contained code to prompt the user to install a CA (certificate authority) certificate issued by \"Facebook Research\" in the user trust store of the device. This certificate was required for Facebook to decrypt TLS traffic.\n  * Some versions of the older app contain the Facebook Research CA certs as embedded assets in the distributed app from 2016. One cert is valid until 2027. Data discovery content in court documents state certificates are \"generated on the server and sent to the device\".\n  * Soon after the \"ssl bump\" feature was deployed in the Protect app, a newer version of Android was released that included improved security controls that would render this method unusable on devices with the newer operating system.\n  * A review of an old Snapchat app shows that it's analytics domain did not employ certificate pinning, meaning that MITM / \"ssl bumping\" would have worked as described.\n  * In addition to the core functionality of gathering other app's usage statistics through abusing a permission granted by the user, there also appears to be other functionality to obtain questionable sensitive data, such as the subscriber IMSI.\n\nThe setup most likely would have looked something the following diagram:\n\nAn interpretation of FB's setup based on court documents and app analysis\n\nHere we have a trusted cert installed on the device, all device traffic going\nover a VPN to Facebook controlled infrastructure, traffic redirected into a\nSquid caching proxy setup as a transparent proxy with the 'ssl bump' feature\nconfigured. We know from the documents that various domains belonging to\nSnapchat, Amazon and Youtube were of interest. It's not known if any other\nuser traffic was intercepted, or just proxied on. This type of information we\ncan't obtain from looking at the archived Onavo Protect apps, rather for the\ntime being, we have to rely on the content in the court documents made\navailable to the public.\n\nOver time the success of their strategy to employ a transparent TLS proxy was\ndiminishing due to improved security controls in Android. Additionally\ncertificate pinning adoption was said to be an issue. As an alterative,\nFacebook were considering using the Accessibility API as an alternative.\n\nPage 3 - Case 3:20-cv-08570-JD Document 736\n\nThis is what Google has to say about using the accessibility features on their\noperating system:\n\n> \"only services that are designed to help people with disabilities access\n> their device or otherwise overcome challenges stemming from their\n> disabilities are eligible to declare that they are accessibility tools.\"\n\nIt's somewhat telling of a company that would consider abusing features\ndesigned to support people with disabilities for a competitive advantage.\nGenerally, Android accessibility functionality misuse is attributed to\nmalicious applications such as banking malware.\n\n## Motivation\n\nMark Zuckerberg states the need for \"reliable analytics\" on Snapchat:\n\nThe solution? \"Kits that can be installed on iOS and Android that intercept\ntraffic for specific sub-domains\":\n\nMy take on the above is that in addition to utilizing the Onavo Protect VPN\napp to intercept traffic for specific domains, there was an intention to\nrebrand the core technology and having it distributed in other applications.\nFacebook had acquired Onavo for approximately $120M USD in 2013 and needed to\nput this technology in good use. That price point should give a clear\nindication on the value they placed on the ability to gain competitor\nintelligence from people's phones and tablets.\n\nPrior research on the iOS version notes that the Onavo VPN app was collecting\nsome usage telemetry from iPhones. On Android we can see the app was pulling\nmuch more fine grained statistics from their user's devices by utilizing\npermissions granted under the pretext of showing the user app data usage (we\nwill see how this looked in an embedded video below). But that was not enough,\nFacebook wanted to take this one step further and intercept encrypted traffic\ntowards specific competitor's analytics domains in order to obtain data on the\n\"in-app actions\".\n\nAll they would need to do is to get the user to install a custom certificate\ninto the user's phone's trust store (and be on specific Android releases).\n\n\ud83d\udca1\n\nThe wiretapping claim is new and perhaps not to be confused with the prior\ncontroversy and litigation:\n\nIn 2023, two subsidiaries of Facebook was ordered to pay a total of $20M by\nthe Australian Federal Court for \"engaging in conduct liable to mislead in\nbreach of the Australian Consumer Law\", according to the ACCC.\n\nFacebook had shutdown Onavo in 2019 after an investigation revealed they had\nbeen paying teenagers to use the app to track them. Also that year, Apple went\nas far as to revoke Facebook's developer program certificates, sending a clear\nmessage.\n\nDespite the apps being taken offline, we are able to find old archived\nversions which enabled the technical insights offered in this post.\n\n## Technical analysis\n\nWebsites and applications on end user devices trust remote websites or servers\nover HTTPS/TLS due to public certificates that are stored in the device's\ntrust store. These \"certificate authority\" certs are the \"trust anchor\" that\napplications rely on to verify they communicating with the intended party.\nThese certificates are generally distributed and stored within the operating\nsystem. By adding your own self-signed certificate to the appropriate trust\nstore, it is often possible to intercept encrypted TLS traffic. Corporations\nmay also do this as a means of inspecting outbound traffic from employee's\ndevices. Security testers may also do this on their own devices. There are\nlegitimate reasons for doing this. The question here is if what Facebook did\nwas legitimate, meaning, was it legal or not.\n\nThere is some irony that the documentation for software that Facebook is said\nto employ to do the interception contains the following warning:\n\n> HTTPS was designed to give users an expectation of privacy and security.\n> Decrypting HTTPS tunnels without user consent or knowledge may violate\n> ethical norms and may be illegal in your jurisdiction.\n\nUnlike iOS on the iPhone, Google has made numerous changes to make it\nextremely difficult to install a CA cert that will be trusted by most\napplications on the phone. In Android 11, released in September 2020, Google\nhad completely blocked the mechanism which the app used to prompt a user to\ninstall the cert and no application would trust any certificate in the user\nstore by default.\n\n\ud83d\udca1\n\nPeople have asked \"what about cert pinning? wouldn't this have prevented\nsuccessful MITM of the traffic?\"\n\nWhile that would be the case, as we will see later, at the time, the Snapchat\napp did not to cert pinning for it's analytics domain. This would likely hold\ntrue for the other app domains. So it appears Facebook had leveraged off this\ntechnical limitation / oversight by it's competitors.\n\nSo today, technically speaking, is is simply is not possible to do what\nFacebook had done back in 2016 to 2019. But it worked - so how did they do it?\nFortunately, at least with Android and the Play store ecosystem, we are able\nto often go back in time and sometimes dig up old Android app packages.\n\nThe first thing is to install the Onavo app on a test handset to see how users\nwould interact with the app. Despite the VPN connectivity not working and the\nactual backend service being down, we do get a glimpse on how the application\ncoerces the user into accepting multiple permissions:\n\n0:00\n\n/0:45\n\nWhat we see here under pretext of providing the user 'protection', two\nparticular permissions are of concern:\n\n  * Display over other apps\n  * Access past and deleted app usage\n\n> \"We need this permission to show you how much mobile data your apps use.\"\n\nWhat they didn't explain is that this feature is not so much for the benefit\nof the user who installed the app, but actually Onavo/Facebook. And this type\nof information is valuable, to the tune of $120M (what FB paid in the\nacquisition).\n\nThe Android manifest includes the uses-permission directive\nandroid.permission.PACKAGE_USAGE_STATS which is what we are agreeing to in the\nscreenshot above:\n\nContinuing with the \"application stats\" feature (assumed to be the original\ncore functionality), we can dump the schema of the local database on the\nhandset to get an idea on exactly what it was collecting on the device itself:\n\nMostly it seems they could just obtain statistics on in app usage of other\napplications and of course the network traffic usage for the apps. It's still\nsomewhat high level statistics and clearly not enough granularity for what\nMark was after, implied by one of the emails in the court documents.\nIntercepting the actual encrypted traffic towards the analytics domains of\nvarious competitors on the other hand, would do the trick. And to do this,\nFacebook would have to get a CA certificate somehow on the device.\n\nBut we don't see any prompt to install any certificate. This is because the\nVPN did not successfully connect to the remote service, which appears to be\nprecondition. Time or interest permitting, I may go back to figure out how to\ntrigger the certificate installation prompt.\n\nConnections timing out, and a tcpdump shows that all traffic from the device\nis dropped after the VPN connection is initiated\n\n### Onto the CA certificates\n\nDecompiling the app, we do see the functionality is there. In the following\nimage, the method highlighted calls KeyChain.createInstallIntent() to install\na certificate. Here a popup would appear asking the user for permission, with\nthe name \"Facebook Research\"\n\nKeyChain.createInstallIntent() stopped working in Android 7 (Nougat). A user\nwould have to manually install the certificate. It would no longer be possible\nto have Facebook's CA cert installed directly in the app.\n\nAnother notable change in Android 7 - According to the Android documentation\n(emphasis mine):\n\n> By default, secure connections (using protocols like TLS and HTTPS) from all\n> apps trust the pre-installed system CAs, and apps targeting Android 6.0 (API\n> level 23) and lower also trust the user-added CA store by default\n\nIn other words, it appears other apps would have trusted certs in the user\nstore from Android Marshmallow (Android 6) and below, but from Android 7,\nreleased in August 22, 2016, they would no longer be trusted at all by other\napplications, unless due to a security configuration in the app's manifest\nfile.\n\nAnother improvement to Android in version 7 was that it was made impossible to\ninstall certificates into the system store by any means except by fully\nrooting the device.\n\nRegardless, the functionality remained in both the older version and newer,\nall the way to the last published app in 2019. The actual MITM certificate was\nremoved in 2017. Detail in the court documents may offer plausible\nexplanation:\n\n> Where is the key generated that's used for the SSL bump and how it protected\n> from abuse? (e.g., is generated on the device, specific to that device, and\n> never leaves the device, or is there a shared key that's downloaded with the\n> app and installed)\n>\n> The certificate is generated on the server and being sent to the device\n\nPage 3 - Case 3:20-cv-08570-JD Document 736\n\nSo we need to go back to much older releases before 2019, specifically a\nversion from September 2017. The certificates in this version are found as\nassets named \"old_ca.cer\" and \"new_ca.cer\". The relevant code is found in the\nclass ResearchCertificateManager.\n\nThe can be found under the \"assets\" folder (if uncompressing the .apk as a zip\nfile). Observed in JADX:\n\nAlso observing the routine to check if the certificates have been installed or\nnot:\n\nNow why would there be two certificates? (old and new)? Here are the two\ncertificates pulled from one version of the app. Whoever had created the first\ncertificate had only issued it to be valid for one year. If this was an\noversight, they did manage to figure it out before the expiry time.\n\nold_va.cer vs new_ca.cer\n\nI have not been able to find all versions of the .apk online, but enough to\ndraw the following conclusion:\n\n  * The first certificate was valid from Sep 8th 2016, some months before Mark Zuckerberg put the call out to gain further insight into Snapchat (email dated June 9th, 2016)\n  * The second certificate was added alongside the first which was valid from Jun 8th, 2017. It will be valid until Jun 8 2027.\n  * At least from Oct 19th, 2027, there are no certs, the second cert was deleted from the app completely. As stated earlier, court documents explain certificates were obtained from the server. I have yet to locate the functionality relevant to this in the apps I have obtained from archives, and more work needs to be done here.\n\nVersions with certificates found with their respective fingerprints:\n\nThe court documents state that there was additional interception of YouTube\nand Amazon at later dates. Here we would have to dig further to find out in\nwhich apps and how this was done:\n\nPage 2, case 3:20-cv-08570-JD Document 735\n\n### Back to the pinning question\n\nAny app doing full certificate pinning would have prevented this technique\nfrom working. Around the time period in question, Snapchat was doing some\ncertificate pinning. But not everywhere.\n\nWe can go back and grab an old Snapchat app and check for ourselves. What was\nthe domain? According to one the artefacts in the document discovery, it was\nsc-analytics.appspot.com:\n\nAnd behold, in a decompilation of and old Snapchat app, traffic to this domain\ndid not use certificate pinning:\n\nAs discussed earlier, Facebook were aware of the security enhancements in\nAndroid and the wider adoption of pinning, with the statement included\n(reference earlier):\n\n> There is a general question on SSL bump long term applicability on Android\n> as SSL pinning by default is present on newer devices.\n\n## What else?\n\nThis one caught my eye, a request to obtain the subscriber IMSI. A very\nsensitive bit of data indeed:\n\nInitially I was wondering how this is even possible, and it seems at the time,\nit was actually possible with the permission READ_PHONE_STATE:\n\nWhich of course was defined in the app's manifest:\n\nGiven this discovery, there is probably more to explore.\n\n## Wrapping up\n\nWhile this is all \"old news\" in the sense that happened years ago, it is\ninteresting from a technical standpoint to see how far application developers,\nand even companies like Facebook will go to abuse permission models on mobile\nphones.\n\nAnd there is certainly is more to dig into, such as the routine to trigger the\nCA install procedure, how certs were added after 2017 and what else the Onavo\napplication was collecting. Also, it would also be nice to find iPhone version\nof the application if anyone knows where to find copies.\n\nIf the class action lawsuit progresses in an interesting way, perhaps this\ncould provide further motivation to continue the exploration.\n\nIf you are interested in receiving further updates, feel free to subscribe\nbelow with an email address, and/or follow me on X.\n\n## Sign up for doubleagent.net\n\nA telco and IoT focused security blog\n\nNo spam. Unsubscribe anytime.\n\n## Sign up for more like this.\n\nEnter your email\n\nSubscribe\n\nFeatured\n\n## GTPDOOR - A novel backdoor tailored for covert access over the roaming\nexchange\n\nDiscovery and analysis of a magic packet type implant that communicates C2\ntraffic over the GTP-C 3GPP protocol.\n\nFeb 27, 2024 13 min read\n\n## Gamified tooth brushing\n\nA quick look into a connected toothbrush. Surprisingly this one was rather\nwell behaved.\n\nFeb 10, 2024 5 min read\n\n## Battling the dynamic linker with lazy bindings and the AFL++ fuzzer\n\nNotes on fuzzing with AFL and shared libraries can't resolve symbols\n\nAug 31, 2023 8 min read\n\ndoubleagent.net \u00a9 2024\n\nPowered by Ghost\n\n", "frontpage": false}

{"aid": "39995908", "title": "Show HN: Next-token prediction in JavaScript \u2013 build fast LLMs from scratch", "url": "https://github.com/bennyschmidt/next-token-prediction", "domain": "github.com/bennyschmidt", "votes": 1, "user": "bschmidt1", "posted_at": "2024-04-10 21:27:07", "comments": 0, "source_title": "GitHub - bennyschmidt/next-token-prediction: Next-token prediction in JavaScript \u2014 build fast LLMs from scratch!", "source_text": "GitHub - bennyschmidt/next-token-prediction: Next-token prediction in\nJavaScript \u2014 build fast LLMs from scratch!\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nbennyschmidt / next-token-prediction Public\n\n  * Notifications\n  * Fork 0\n  * Star 3\n\nNext-token prediction in JavaScript \u2014 build fast LLMs from scratch!\n\n3 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# bennyschmidt/next-token-prediction\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nbennyschmidtinspiration/goalsab90ab8 \u00b7\n\n## History\n\n10 Commits  \n  \n### components\n\n|\n\n### components\n\n| init  \n  \n### examples/readline-completion\n\n|\n\n### examples/readline-completion\n\n| readline example  \n  \n### models\n\n|\n\n### models\n\n| init  \n  \n### training\n\n|\n\n### training\n\n| init  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| init  \n  \n### .nvmrc\n\n|\n\n### .nvmrc\n\n| init  \n  \n### README.md\n\n|\n\n### README.md\n\n| inspiration/goals  \n  \n### index.js\n\n|\n\n### index.js\n\n| init  \n  \n### package-lock.json\n\n|\n\n### package-lock.json\n\n| readline example  \n  \n### package.json\n\n|\n\n### package.json\n\n| readline example  \n  \n### test.js\n\n|\n\n### test.js\n\n| withFiles example  \n  \n### utils.js\n\n|\n\n### utils.js\n\n| init  \n  \n## Repository files navigation\n\n# Next-Token Prediction\n\nCreate a language model based on a body of text and get high-quality\npredictions (next word, next phrase, next pixel, etc.). With enough training\ndata and a good chat interface, this can be used instead of well-known\ndecoder-only models like GPT, Mistral, etc.\n\n## Install\n\nnpm i next-token-prediction\n\n## Usage\n\n#### Simple (from a built-in data bootstrap)\n\nPut this /training/ directory in the root of your project.\n\nNow you just need to create your app's index.js file and run it. Your model\nwill start training on the .txt files located in /training/documents/. After\ntraining is complete it will run these 4 queries:\n\n    \n    \n    const { Language: LM } = require('next-token-prediction'); const MyLanguageModel = async () => { const agent = await LM({ bootstrap: true }); // Predict the next word agent.getTokenPrediction('what'); // Predict the next 5 words agent.getTokenSequencePrediction('what is', 5); // Complete the phrase agent.complete('hopefully'); // Get a top k sample of completion predictions agent.getCompletions('The sun'); }; MyLanguageModel();\n\n#### Advanced (provide trainingData or create it from .txt files)\n\nPut this /training/ directory in the root of your project.\n\nBecause training data was committed to this repo, you can optionally skip\ntraining, and just use the bootstrapped dataset and embeddings, like this:\n\n    \n    \n    const { dirname } = require('path'); const __root = dirname(require.main.filename); const { Language: LM } = require('next-token-prediction'); const OpenSourceBooksDataset = require(`${__root}/training/datasets/OpenSourceBooks`); const MyLanguageModel = async () => { const agent = await LM({ dataset: OpenSourceBooksDataset }); // Complete the phrase agent.complete('hopefully'); }; MyLanguageModel();\n\nOr, train on your own provided text files:\n\n    \n    \n    const { dirname } = require('path'); const __root = dirname(require.main.filename); const { Language: LM } = require('next-token-prediction'); const MyLanguageModel = () => { // The following .txt files should exist in a `/training/documents/` // directory in the root of your project const agent = await LM({ files: [ 'marie-antoinette', 'pride-and-prejudice', 'to-kill-a-mockingbird', 'basic-algebra', 'a-history-of-war', 'introduction-to-c-programming' ] }); // Complete the phrase agent.complete('hopefully'); }; MyLanguageModel();\n\n## Examples\n\nReadline Completion\n\n## Videos\n\n(the following is lower quality on GitHub because it's a couple minutes long -\nthis is training & booting up the LM from 0-1)\n\n## Inspiration\n\n## Goals\n\n  1. Demystify LLMS for people, show that it's just regular code that does normal stuff\n\n  2. Actually make a pretty good LLM in JavaScript, with a version at least capable of running in a browser tab\n\n## About\n\nNext-token prediction in JavaScript \u2014 build fast LLMs from scratch!\n\n### Resources\n\nReadme\n\nActivity\n\n### Stars\n\n3 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * JavaScript 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}

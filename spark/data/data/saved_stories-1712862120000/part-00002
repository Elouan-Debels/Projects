{"aid": "40001621", "title": "Training run to compare Mixture-of-Depths, Bitnet", "url": "https://huggingface.co/0-hero/OLMo-50M-Mixture-of-Depths-Bitnet", "domain": "huggingface.co", "votes": 1, "user": "tosh", "posted_at": "2024-04-11 13:00:37", "comments": 0, "source_title": "0-hero/OLMo-50M-Mixture-of-Depths-Bitnet \u00b7 Hugging Face", "source_text": "0-hero/OLMo-50M-Mixture-of-Depths-Bitnet \u00b7 Hugging Face\n\nHugging Face\n\n#\n\n0-hero\n\n/\n\nOLMo-50M-Mixture-of-Depths-Bitnet\n\nModel card Files Files and versions Community\n\nEdit model card\n\n# Training run to compare Mixture-of-Depths, Bitnet\n\nWandb Report\n\n#### 4 Models trained for 100k steps on Dolma\n\n  * OLMo-50M - 50M parameter model\n  * OLMo-50M-bitlinear - 50M parameter bitnet model\n  * OLMo-50M-mod - 50M parameter mixture-of-depths model\n  * OLMo-50M-mod-bitlinear - 50M parameter mixture-of-depths bitnet model\n\nRepo has zip files which include training states and other files for each\nmodel. I am not the author of the mixture-of-depths implementation, it can be\nfound here This is the first run. A few things might be broken, still a work\nin progress\n\nDownloads last month\n\n    0\n\nUnable to determine this model's library. Check the docs .\n\n## Dataset used to train 0-hero/OLMo-50M-Mixture-of-Depths-Bitnet\n\n", "frontpage": false}

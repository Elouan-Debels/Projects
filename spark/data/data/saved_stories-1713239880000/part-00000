{"aid": "40046129", "title": "The Missing Guide to AWS Lambda Logs", "url": "https://betterstack.com/community/guides/logging/aws-lambda-logging/", "domain": "betterstack.com", "votes": 2, "user": "ayoisaiah", "posted_at": "2024-04-15 21:55:19", "comments": 0, "source_title": "The Missing Guide to AWS Lambda Logs | Better Stack Community", "source_text": "The Missing Guide to AWS Lambda Logs | Better Stack Community\n\nBack to Logging guides\n\n# The Missing Guide to AWS Lambda Logs\n\nAWS AWS Lambda CloudWatch\n\nAyooluwa Isaiah\n\nUpdated on April 10, 2024\n\n###### Contents\n\n  * Understanding AWS Lambda logs\n  * Accessing your Lambda logs in AWS CloudWatch\n  * Capturing Lambda logs in structured JSON format\n  * Configuring AWS Lambda log levels\n  * Customizing your Lambda log group in CloudWatch\n  * Configuring your CloudWatch log retention settings\n  * Using third-party logging frameworks\n  * Analyzing AWS Lambda logs with Better Stack\n  * Final thoughts\n\nAWS Lambda logging seems straightforward \u2013 print to the console, and it\nmagically appears in CloudWatch. However, that simplicity can lead to\nunexpected costs or difficulties locating essential information when it\nmatters most.\n\nIn this guide, you will learn about:\n\n  * Finding and interpreting the logs AWS Lambda automatically generates.\n  * Structuring your logs strategically so you can quickly zero in on problems when they happen.\n  * How Better Stack can simplify analysis and monitoring of your Lambda logs while being more cost-effective.\n\nReady to get more out of your Lambda logs? Let's dive into some practical tips\nnext!\n\nThe fastest log search on the planet\n\nBetter Stack lets you see inside any stack, debug any issue, and resolve any\nincident.\n\n## Understanding AWS Lambda logs\n\nAWS Lambda logs are records of events generated by Lambda functions. AWS\nautomatically monitors function executions and reports various logs and\nmetrics through Amazon CloudWatch as long as your function's execution role\nhas the necessary permissions.\n\nThese logs include various helpful information for monitoring and\ntroubleshooting your Lambda functions. Here's a breakdown of what you can\nexpect from AWS Lambda logs:\n\n### 1\\. System logs\n\nLambda automatically generates system logs for each function invocation. These\nlogs reveal crucial metrics like start/end times, execution duration, memory\nusage (allocated vs. actual), and billed duration. This data helps you\nunderstand function behavior, optimize for cost, and pinpoint areas for\nimprovement.\n\nHere's an example:\n\nCopied!\n\n    \n    \n    INIT_START Runtime Version: nodejs:18.v24 Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:c09960ad0af4321e1a7cf013174f7c0d7169bf09af823ca2ad2f93c72ade708a START RequestId: 765b52b4-2600-4348-9ec4-c7f7f1346c57 Version: $LATEST END RequestId: 765b52b4-2600-4348-9ec4-c7f7f1346c57 REPORT RequestId: 765b52b4-2600-4348-9ec4-c7f7f1346c57 Duration: 259.72 ms Billed Duration: 260 ms Memory Size: 128 MB Max Memory Used: 69 MB Init Duration: 189.15 ms\n\nThese AWS Lambda logs track a single function invocation. The process begins\nwith the INIT_START log, marking initialization, specifying the Node.js\nruntime version, and assigning a unique ARN to the runtime environment.\n\nNext, the START log signals execution with a unique RequestId and indicates\nthe function version ($LATEST). Finally, the END log confirms the successful\ncompletion of the function's execution for this request.\n\nFinally, the REPORT log offers a summary, showing that the function completed\nsuccessfully in 259.72 milliseconds (billed as 260ms due to rounding), with\ninitialization taking 189.15 milliseconds, and used a maximum of 69MB out of\n128MB allocated memory.\n\n### 2\\. Error logs\n\nLambda function errors can stem from two sources: unhandled exceptions thrown\ndirectly by your code or issues within the Lambda runtime environment, such as\nexceeding timeouts, memory limits, or misconfigurations.\n\nHere's an example of how uncaught errors in Node.js are logged by the Lambda\nruntime:\n\nCopied!\n\n    \n    \n    2024-04-09T07:22:49.403Z d1dd355b-74f9-4984-ad30-c5e9ae23517a ERROR Invoke Error { \"errorType\": \"Error\", \"errorMessage\": \"uncaught error\", \"stack\": [ \"Error: uncaught error\", \" at Runtime.handler (file:///var/task/index.mjs:34:13)\", \" at Runtime.handleOnceNonStreaming (file:///var/runtime/index.mjs:1173:29)\" ] }\n\n### 3\\. Application or function logs\n\nInside your Lambda function code, you can use print statements (or equivalent)\nto output custom log messages. The standard output and standard error streams\nfrom a Lambda function are automatically sent to CloudWatch Logs without\nrequiring logging drivers.\n\nFor example, the following statements\n\nCopied!\n\n    \n    \n    console.log('Fetching data from the API.'); console.log('Data fetched successfully:', responseData);\n\nWill appear as below in CloudWatch:\n\nCopied!\n\n    \n    \n    2024-04-03T00:22:41.959Z 3bcb760c-ecdb-459b-a97b-c2318b3215fe INFO Fetching data from the API. 2024-04-03T00:22:41.978Z 3bcb760c-ecdb-459b-a97b-c2318b3215fe INFO Data fetched successfully: { userId: 1, id: 1, title: 'delectus aut autem', completed: false }\n\nLambda automatically enhances function logs generated using console methods in\nNode.js by adding a timestamp, request ID, and log level to each entry.\n\n## Accessing your Lambda logs in AWS CloudWatch\n\nAWS Lambda seamlessly integrates with CloudWatch by automatically forwarding\nall logs to a log group tied specifically to each Lambda function.\n\nThe naming convention for these log groups mirrors the Lambda function's name\nby following the /aws/lambda/<function name> pattern, but this can be adjusted\nin the AWS console, as you'll see later on.\n\nTo view these logs, navigate to the CloudWatch section within the AWS\nManagement Console. Under the Logs section, click on Log groups and select\nyour function's corresponding group.\n\nWithin the Log streams tab of the selected log group, you'll find individual\nlog streams for each execution instance of your Lambda function. These streams\nare conventionally named in the format\nYYYY/MM/DD/[<FunctionVersion>]<InstanceId>.\n\nYou can click on the most recent stream to view its contents. You will observe\nthe three standard log statements generated per invocation (START, END and\nREPORT) as well as any custom logs generated by your functions:\n\nHere's a breakdown of the key parts of the above logs:\n\n  * Initialization log (INIT_START): Details the runtime setup.\n  * Start log (START): Indicates invocation start, includes a unique RequestId.\n  * Application logs: Messages generated within your function's code that provide additional context on the function's activities.\n  * End log (END): Signals invocation completion.\n  * Report log (REPORT): Provides execution metrics (duration, memory usage, etc.).\n\nThese logs demonstrate a typical successful execution pattern where the\nfunction starts, performs its task, and then completes without errors,\nproviding relevant performance data.\n\n## Capturing Lambda logs in structured JSON format\n\nBy default, AWS Lambda outputs logs in a semi-structured format, which\ncomplicates automated log analysis and monitoring efforts. To effectively\nanalyze these logs, you'd need to parse each log entry manually by looking for\nspecific string identifiers or the function invocation's request ID.\n\nFortunately, AWS Lambda now allows for a full transition to structured JSON\nlogging for both system-generated and custom function logs, which makes it\neasy to filter and analyze the log data in CloudWatch.\n\nYou can configure this behavior in the Lambda Management Console under the\nConfiguration tab. By navigating to the Monitoring and operations tools in the\nleft panel and adjusting the Log format setting, you can enable structured\nJSON logging:\n\nWhen you execute your function and view its log output, it should appear in\nthe following manner:\n\nOnce enabled, logging output for your Lambda function executions will adopt a\nJSON structure, making it much easier to parse and analyze programmatically.\n\nFor instance, a REPORT log entry in JSON format distinctly organizes each\nmetric into its property, and the entry is linked to other logs from the same\ninvocation with a common record.requestId:\n\nCopied!\n\n    \n    \n    { \"time\": \"2024-04-03T00:56:35.345Z\", \"type\": \"platform.report\", \"record\": { \"requestId\": \"88c76e69-8021-474e-a030-f8bd7490cba4\", \"metrics\": { \"durationMs\": 2226.333, \"billedDurationMs\": 2227, \"memorySizeMB\": 128, \"maxMemoryUsedMB\": 88, \"initDurationMs\": 147.316 }, \"status\": \"success\" } }\n\nAdditionally, if your application logs are structured as valid JSON objects,\nthey will be automatically parsed and placed within the message property of\nthe log output:\n\nCopied!\n\n    \n    \n    console.log(data); // Assuming 'data' is a valid JSON object from an API call\n\nOutput\n\n    \n    \n    { \"timestamp\": \"2024-04-03T01:04:49.418Z\", \"level\": \"INFO\", \"requestId\": \"ad26627c-5c74-4828-89c9-c22c17dfc61b\",\n    \n    \"message\": {\n    \n    \"userId\": 1,\n    \n    \"id\": 1,\n    \n    \"title\": \"delectus aut autem\",\n    \n    \"completed\": false\n    \n    }\n    \n    }\n\nIf the log output is not valid JSON, Lambda will instead treat and log the\nmessage as a string, still providing valuable information albeit in a less\nstructured format:\n\nCopied!\n\n    \n    \n    console.log('Data fetched successfully:', data);\n\nOutput\n\n    \n    \n    { \"timestamp\": \"2024-04-03T00:56:35.144Z\", \"level\": \"INFO\", \"requestId\": \"88c76e69-8021-474e-a030-f8bd7490cba4\",\n    \n    \"message\": \"Data fetched successfully: { userId: 1, id: 1, title: 'delectus aut autem', completed: false }\"\n    \n    }\n\n## Configuring AWS Lambda log levels\n\nAdopting structured JSON logging in AWS Lambda not only streamlines log\nformatting but also enables you to control which logs are published to\nCloudWatch through log level filters.\n\nThis configuration is accessible from the AWS Lambda console's Logging\nconfiguration section. By default, both system and application logs are set to\nthe INFO level, preventing entries logged at the DEBUG or TRACE levels from\nbeing transmitted to CloudWatch.\n\nThe level of a function log is denoted by its level property. In Node.js\nfunctions, Lambda automatically assigns the INFO level to entries generated\nusing console.log() and console.info(). Similarly, records produced by\nconsole.debug(), console.trace(), console.warn(), and console.error() are\nassigned DEBUG, TRACE, WARN, and ERROR respectively.\n\nIf you choose to log with a custom framework instead, ensure that it outputs\nJSON-structured entries with level and timestamp properties as shown below:\n\nCopied!\n\n    \n    \n    {\n    \n    \"level\": \"INFO\",\n    \n    \"timestamp\": \"2024-04-01T12:36:14.170Z\",\n    \n    \"pid\": 650073, \"hostname\": \"fedora\", \"msg\": \"an info message\" }\n\nThe level should be one of the supported application log levels and the\nprovided timestamp must be compatible with the RFC 3339 format. If the log\nlevel or timestamp is invalid or missing, Lambda will automatically assign the\nINFO level to the log entry with its own timestamp.\n\nAlso, when configuring application log-level filtering for your function, the\nselected level is stored in the AWS_LAMBDA_LOG_LEVEL environment variable. You\ncan configure your logging framework according to this variable so that it\ndoesn't output logs that the Lambda runtime would eventually discard.\n\n## Customizing your Lambda log group in CloudWatch\n\nAWS Lambda sends logs for each function to a dedicated log group named\n/aws/lambda/<function name>, but this setup can make it cumbersome to manage\nsecurity, governance, and retention policies across a large number of\nfunctions.\n\nTo streamline log management for all of the Lambda functions that make up a\nparticular application, you can opt for a shared CloudWatch log group. You can\ndo this by selecting the Custom option and providing a new name as follows:\n\nOn the next function invocation, Lambda will create the shared group and begin\nstreaming logs. Log streams within this group will include the function name\nand version in their names, allowing you to trace logs back to their\noriginating functions easily.\n\n## Configuring your CloudWatch log retention settings\n\nCloudWatch logs are stored indefinitely by default, incurring charges after\nthe first 5GB. To avoid paying unnecessarily for old logs, customize your log\nretention settings by heading to CloudWatch -> Log Groups -> -> Actions ->\nEdit retention settings.\n\nYou'll notice that with a shared log group, it's much easier to apply a\nconsistent log retention policy to a collection of functions, compared to when\neach function has a separate log group.\n\n## Using third-party logging frameworks\n\nAWS Lambda's built-in logging capabilities is a good starting point, but\nyou'll often want more control for deeper contextual analysis and\ntroubleshooting. Custom logging frameworks provide the solution.\n\nFor example, Pino is a popular logging library for Node.js programs that\nallows you to configure log levels, add contextual data, and many other\nfeatures not possible through the Console API.\n\nThe recommended approach for integrating a reusable logging solution across\nyour Lambda functions is to use an AWS Lambda Layer dependency that contains\nyour logging configuration.\n\n### Setting up a Lambda layer for logging\n\nTo get started, create a new directory in your filesystem and navigate into\nit:\n\nCopied!\n\n    \n    \n    mkdir pinojs-layer\n\nCopied!\n\n    \n    \n    cd pinojs-layer\n\nCreate a nodejs directory and navigate into it as well:\n\nCopied!\n\n    \n    \n    mkdir nodejs\n\nCopied!\n\n    \n    \n    cd nodejs\n\nWithin the nodejs directory, initiate a new Node.js project with the following\ncommand, accepting all the defaults:\n\nCopied!\n\n    \n    \n    npm init -y\n\nThen run the following to configure the project as an ES module:\n\nCopied!\n\n    \n    \n    npm pkg set type=\"module\";\n\nOnce you're done, install the pino dependency with:\n\nCopied!\n\n    \n    \n    npm install pino\n\nAfter the installation completes, create a new index.js file and configure\nPino as follows:\n\nCopied!\n\n    \n    \n    code index.js\n\nindex.js\n\nCopied!\n\n    \n    \n    import pino from 'pino'; const logger = pino({ level: process.env.AWS_LAMBDA_LOG_LEVEL || 'info', formatters: { bindings: (bindings) => { return { nodeVersion: process.version }; }, level: (label) => { return { level: label.toUpperCase() }; }, }, timestamp: () => `,\"timestamp\":\"${new Date(Date.now()).toISOString()}\"`, }); export { logger };\n\nThis Pino configuration sets up a logger instance that defaults to INFO unless\notherwise specified through the AWS_LAMBDA_LOG_LEVEL environment variable\nwhich corresponds to the application log level in the Lambda function\nsettings.\n\nIt also customizes the log output by including the Node.js version in each log\nentry under the nodeVersion property, transforming the level property to\nuppercase, and overriding the default timestamp function with a custom format.\nThe configured logger is then exported for use throughout the application.\n\nOnce you've configured Pino, return to your terminal and navigate back into\nthe pinojs-layer directory.\n\nCopied!\n\n    \n    \n    cd ..\n\nFrom the pinojs-layer directory, run the command below to archive the nodejs\ndirectory contents into a zip file as follows:\n\nCopied!\n\n    \n    \n    zip -r pino.zip nodejs/\n\nNow return to your AWS Lambda console and find the Layers option in the\nsidebar under Additional resources.\n\nCreate a new layer and populate it with the following contents, ensuring to\nselect the appropriate runtime that corresponds with your Lambda functions:\n\nOnce created, return to your Lambda function page and click the highlighted\nLayers button which will navigate you to the Layers section:\n\nClick Add a layer and fill the resulting form as follows:\n\nOnce your layer is added to the function, you will see a success message on\nthe screen.\n\nIt's now time to use the layer in your function code. You only need to import\nthe exported logger as follows:\n\nCopied!\n\n    \n    \n    import { logger } from '/opt/nodejs/index.js'; export const handler = async (event, context, callback) => { logger.info(\"Hello world!\"); };\n\nWhen your function is invoked, you will see the resulting log entry in the\nCloudWatch log stream:\n\nOutput\n\n    \n    \n    { \"level\": \"INFO\", \"timestamp\": \"2024-04-03T03:11:17.691Z\", \"nodeVersion\": \"v20.11.1\", \"msg\": \"Hello world!\" }\n\nIn this manner, you can reuse the framework configuration in all your Node.js\nfunctions to maintain a consistent log format, making log management and\nanalysis a lot more pleasant.\n\n### Logging request IDs\n\nEach Lambda function invocation is identified by a unique request ID which is\nautomatically included in the system and error logs. When writing function\nlogs through the built-in Node.js console API, the request ID is automatically\nincluded so you can link any entry to the function invocation that produced\nit.\n\nHowever, when using custom logging libraries, you must explicitly include the\nrequest ID before it will appear in the logs. The way to do this depends on\nthe logging library, but you can generally call a function that accepts the\nrequest ID and bind it to the returned logger.\n\nHere's an example with the aforementioned Pino library:\n\nCopied!\n\n    \n    \n    import pino from 'pino'; function getLogger(requestId) { return pino({ level: process.env.AWS_LAMBDA_LOG_LEVEL || 'info', formatters: { bindings: (bindings) => {\n    \n    return { nodeVersion: process.version, requestId };\n    \n    }, level: (label) => { return { level: label.toUpperCase() }; }, }, timestamp: () => `,\"timestamp\":\"${new Date(Date.now()).toISOString()}\"`, }); } export { getLogger };\n\nThe getLogger() function accepts the request ID and binds it to the logger so\nthat it is included in all logs. You can subsequently use it in your Lambda\nfunctions like this:\n\nCopied!\n\n    \n    \n    import { getLogger } from '/opt/nodejs/index.js'; export const handler = async (event, context, callback) => { const logger = getLogger(context.awsRequestId) logger.info(\"Hello world!\"); };\n\nWhen executed, this produces:\n\nOutput\n\n    \n    \n    { \"level\": \"INFO\", \"timestamp\": \"2024-04-03T03:11:17.691Z\", \"nodeVersion\": \"v20.11.1\",\n    \n    \"requestId\": \"765b52b4-2600-4348-9ec4-c7f7f1346c57\",\n    \n    \"msg\": \"Hello world!\" }\n\nOnce you've updated the Pino layer code in Lambda, ensure also to update the\nLayer version in your function's layer settings:\n\nAnother piece of information you should consider including in your logging\nconfiguration is the function name which is accessible through the\nAWS_LAMBDA_FUNCTION_NAME environmental variable:\n\nCopied!\n\n    \n    \n    import pino from 'pino'; function getLogger(requestId) { return pino({ level: process.env.AWS_LAMBDA_LOG_LEVEL || 'info', formatters: { bindings: (bindings) => { return { nodeVersion: process.version, requestId,\n    \n    function: process.env.AWS_LAMBDA_FUNCTION_NAME,\n    \n    }; }, level: (label) => { return { level: label.toUpperCase() }; }, }, timestamp: () => `,\"timestamp\":\"${new Date(Date.now()).toISOString()}\"`, }); } export { getLogger };\n\nThe resulting entries created by this configuration will now contain the\nfunction property:\n\nCopied!\n\n    \n    \n    { \"level\": \"INFO\", \"timestamp\": \"2024-04-09T17:04:50.406Z\", \"nodeVersion\": \"v18.19.1\", \"requestId\": \"95772dc0-12d6-4713-a5bd-6e9450900f2d\",\n    \n    \"function\": \"myHTTPRequestFunc\",\n    \n    \"msg\": \"Fetching data from the API.\" }\n\nThis makes it a lot easier to understand the context of each log entry\nespecially if you're shipping the logs off AWS CloudWatch to a different log\nmanagement tool.\n\n## Analyzing AWS Lambda logs with Better Stack\n\nAfter optimizing your AWS Lambda logging, consider a specialized observability\nplatform for deeper insights and cost savings. These tools offer advantages\nover CloudWatch and centralize your monitoring data.\n\nBetter Stack is a compelling option that provides log monitoring and\nintegrated incident management. This lets you track Lambda function activity,\nreceive alerts for notable events or trends, and build automated reactive\nmeasures for detected issues. You can explore its features with a free\naccount.\n\n### Forwarding your Lambda logs to Better Stack\n\nBy routing your AWS Lambda logs to Better Stack, you can consolidate, analyze,\nand monitor your logging data in a unified platform. Achieving this\nintegration is straightforward through the use of Better Stack's AWS Lambda\nextension, which leverages the Telemetry API to capture and stream your logs\ndirectly and in real-time.\n\nFor detailed guidance on deploying the Better Stack AWS Lambda extension for\nefficient log forwarding, refer to the official documentation. Following\nsetup, consider revoking your function's CloudWatch write permissions to avoid\nredundant expenses.\n\n### Exploring Lambda Logs in Better Stack\n\nOnce your AWS Lambda function logs are streaming into Better Stack, you can\nleverage its powerful filtering and search capabilities for targeted analysis\ndepending on your use case. For instance, you might want to look at REPORT\nentries to find slow function invocations or those that are nearing their\nmemory limits.\n\nThis can be done by setting up filters to isolate logs showing higher\nexecution times or memory usage close to the allocated maximum. You can also\nsearch for ERROR logs related to timeout exceptions or out-of-memory errors to\npinpoint functions that require further optimization or debugging.\n\nBeyond filtering your Lambda logs to find potential problems, you can use them\nto build high-level dashboards with custom data visualizations. This way, you\ncan get a quick, top-down perspective of your incoming logs without endlessly\nfiltering through them.\n\n### Detecting issues in real-time\n\nBetter Stack also allows you to set up alerting rules to notify you when an\nissue is detected, ensuring you're promptly informed of potential problems\nwithin your AWS Lambda functions.\n\nFor example, you can configure an alert to trigger if there's an unusual spike\nin function error rates or if any function's execution time or memory usage\nsurpasses a critical threshold, which may indicate a potential performance\nbottleneck.\n\nThese real-time alerts can be dispatched through your preferred channels, such\nas email, Slack, SMS, and others. By enabling these alerts, you'll stay ahead\nof issues and have enough context to respond adequately.\n\n## Final thoughts\n\nIn this article, we discussed finding and configuring AWS Lambda logs,\nunderstanding their structure, and integrating custom logging for enhanced\ninsights. I also emphasized several best practices along the way to help you\nstreamline your logging workflow.\n\nTo further explore Lambda monitoring with Better Stack, check out our\ncomprehensive documentation here. For additional reference, the official AWS\nLambda docs offer an in-depth resource.\n\nThanks for reading, and happy logging!\n\nArticle by\n\nAyooluwa Isaiah\n\nAyo is the Head of Content at Better Stack. His passion is simplifying and\ncommunicating complex technical ideas effectively. His work was featured on\nseveral esteemed publications including LWN.net, Digital Ocean, and CSS-\nTricks. When he\u2019s not writing or coding, he loves to travel, bike, and play\ntennis.\n\nGot an article suggestion? Let us know\n\nNext article\n\nGetting Started with AWS CloudTrail Logs\n\nLearn how to use AWS CloudTrail management events to audit your AWS account,\ntrack changes, improve security, and troubleshoot issues\n\n\u2192\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-\nShareAlike 4.0 International License.\n\n  1. Explainers\n\n    1. What is Log Management?\n\n    2. What is Log Aggregation?\n\n    3. What is Log Visualization?\n\n    4. What is Log Monitoring?\n\n    5. How to Choose a Logging Framework\n\n    6. Introduction to Logfmt\n\n    7. Introduction to JSON Logging\n\n    8. Understanding Log Levels\n\n    9. Changing Log Levels Dynamically\n\n    10. Logging in Microservices\n\n  2. Best Practices\n\n    1. 12 Logging Best Practices\n\n    2. Log Formatting Best Practices\n\n    3. Keeping Sensitive Data From Logs\n\n    4. Log Sampling Explained\n\n    5. Reducing Logging Costs\n\n  3. Linux\n\n    1. Administering System Logs on Linux\n\n    2. Rotating Logs with Logrotate\n\n    3. Viewing Logs with Journald and Journalctl\n\n    4. Logging in Apache\n\n    5. Logging in NGINX\n\n    6. Monitoring Linux Authentication Logs\n\n  4. Node.js\n\n    1. Logging with Pino\n\n    2. Logging with Winston\n\n    3. Node.js Logging Best Practices\n\n    4. 8 Best Node.js Logging Libraries\n\n  5. Python\n\n    1. Logging in Python\n\n    2. Logging with Loguru\n\n    3. Logging with Structlog\n\n    4. Logging in Django\n\n    5. Logging in Flask\n\n    6. Python Logging Best Practices\n\n    7. Best Python Logging Libraries\n\n  6. Go\n\n    1. Logging in Go (Slog)\n\n    2. Logging with Zerolog\n\n    3. Logging with Zap\n\n    4. 9 Best Go Logging Libraries\n\n  7. Ruby\n\n    1. Logging in Ruby\n\n    2. Logging in Ruby on Rails\n\n    3. Best Ruby Logging Libraries\n\n  8. .NET\n\n    1. Logging in .NET\n\n    2. Logging with Serilog\n\n    3. Logging with NLog\n\n    4. Logging with Log4net\n\n    5. Best .NET Logging Libraries\n\n  9. Java\n\n    1. Java Logging Best Practices\n\n    2. Logging with Log4j\n\n    3. Logging with Logback\n\n    4. Best Java Logging Libraries\n\n  10. PHP\n\n    1. Logging in PHP\n\n    2. Logging with Monolog\n\n    3. Logging in Laravel\n\n    4. Logging with Log4php\n\n    5. Best PHP Logging Libraries\n\n  11. Database\n\n    1. Logging in MySQL\n\n    2. Logging in PostgreSQL\n\n    3. Logging in MariaDB\n\n    4. Logging in Redis\n\n    5. Logging in MongoDB\n\n  12. Docker\n\n    1. Logging in Docker\n\n  13. Platforms\n\n    1. Logging in Heroku\n\n    2. Logging in Vercel\n\n    3. Logging in GCP\n\n    4. Logging in Azure\n\n  14. Platforms: AWS\n\n    1. Logging in AWS\n\n    2. AWS Lambda Logging\n\n    3. AWS CloudTrail Logs\n\n  15. Log Shippers\n\n    1. Vector\n\n    2. Fluentd\n\n    3. Fluent Bit\n\n    4. Logstash\n\n    5. Filebeat\n\n    6. Rsyslog\n\n    7. Logging with Rsyslog\n\n    8. Filebeat vs Logstash\n\n    9. Fluentd vs Fluent Bit\n\n    10. The Top 6 Log Shippers Explained\n\n  16. Other\n\n    1. Logging with Postfix\n\n    2. Logging in Windows\n\n#### Make your mark\n\n##### Join the writer's program\n\nAre you a developer and love writing and sharing your knowledge with the\nworld? Join our guest writing program and get paid for writing amazing\ntechnical guides. We'll get them to the right readers that will appreciate\nthem.\n\nWrite for us\n\nWriter of the month\n\nMarin Bezhanov\n\nMarin is a software engineer and architect with a broad range of experience\nworking...\n\n##### Build on top of Better Stack\n\nWrite a script, app or project on top of Better Stack and share it with the\nworld. Make a public repository and share it with us at our email.\n\ncommunity@betterstack.com\n\nor submit a pull request and help us build better products for everyone.\n\nSee the full list of amazing projects on github\n\nBetter Stack lets you see inside any stack, debug any issue, and resolve any\nincident.\n\n+1 (201) 500-2007 hello@betterstack.com\n\nTerms of Use Privacy Policy GDPR System status\n\n\u00a9 2024 Better Stack, Inc.\n\n", "frontpage": false}

{"aid": "40007282", "title": "Honeycomb and Google Gemini", "url": "https://www.honeycomb.io/blog/honeycomb-google-next-gemini", "domain": "honeycomb.io", "votes": 1, "user": "mji", "posted_at": "2024-04-11 22:00:24", "comments": 0, "source_title": "Honeycomb + Google Gemini", "source_text": "Honeycomb + Google Gemini | Honeycomb\n\nMissed Charity's Query Assistant/Gemini keynote at Google Next? Get a recap of\nthe demo here!Read More\n\nDocs Login Get Started\n\nLogin Login Start for free Book a Demo Book a Demo\n\nObservability LLMs\n\n# Honeycomb + Google Gemini\n\nBy Jessica Kerr | Last modified on April 9, 2024\n\nToday at Google Next, Charity Majors demonstrated how to use Honeycomb to find\nunexpected problems in our generative AI integration.\n\nSoftware components that integrate with AI products like Google\u2019s Gemini are\npowerful in their ability to surprise us. Nondeterministic behavior means\nthere is no such thing as \u201cfully tested.\u201d Never has there been more of a need\nfor testing in production!\n\nHoneycomb is all about helping you find problems you couldn\u2019t before, problems\nyou didn\u2019t imagine could exist\u2014the unknown unknowns. Charity showed how this\napplies to integrating with Gemini.\n\n## What\u2019s the problem?\n\nIn the Honeycomb product, people can ask questions in natural language and get\na Honeycomb query and result. We call this feature Query Assistant.\n\nPeople type in stuff like \u201cWhich users have the highest latency?\u201d and get a\ngraph and table. This comes with a Honeycomb query they can modify.\n\nQuery Assistant turns an engineer\u2019s question into a valid Honeycomb query\u2014most\nof the time. Is that good enough?\n\nHow good is the solution?\n\nWith Honeycomb, we can measure whether the feature is working. We have\ninstrumented the entire operation all the way from when the user hits enter,\nour RAG pipeline, programmatic prompt construction, AI model call, response\nparsing and validation, query construction, and submission to our query\nengine. There\u2019s a lot that can go wrong, even without the nondeterminism of\nAI!\n\nAll of this rolls up into a single Service Level Objective (SLO) we call\n\u201cQuery Assistant Availability.\u201d It tells us that Query Assistant produces a\nvalid query 95% of the time.\n\nBut what about the other 5%?\n\n## Where does it go wrong?\n\nCharity scrolls down on the SLO screen, to the view where the magic really\nhappens. We call this the SLO BubbleUp View.\n\nBubbleUp looks at every Query Assistant request and compares every single\ndimension from the requests that violate the SLO against the baseline events\nthat satisfy the SLO, and then sorts and diffs them so the differences come to\nthe top.\n\nThis answers the question: \u201cWhat is different about the ones I most care\nabout?\u201d\n\nCharity sees that \u201cError\u201d is one of the most different fields, and there are\nseveral different values. She mouses over one of them. It says \u201cunexpected end\nof JSON input.\u201d\n\nCharity clicks to add this field as a filter, and now she has a graph of only\nrequests with this error.\n\nNow, she\u2019d like to see the end of that JSON input. She types something like\n\u201calso show the user input and response\u201d into Query Assistant.\n\nQuery Assistant usually adds the right fields to the GROUP BY, and now they\nappear in the table. There\u2019s something suspicious about the end of that\napp.nlq.response value.\n\nThat response is truncated! Indeed, the JSON has ended unexpectedly.\n\nWhat\u2019s our limit on output tokens? Charity asks Query Assistant \u201calso group by\nthe output config.\u201d\n\nLooks like our configuration was just for 150 tokens from the LLM, and clearly\nthat\u2019s not enough!\n\nThat seems like an issue Charity should take to the team.\n\n## This is observability.\n\nThis flow shows just how important observability is when you\u2019re building with\ngenerative AI. We found this problem to fix, but new ones will surely come up.\n\nWhen you can use SLOs to identify something you find interesting, then slice\nand dice and explore your data, you can quickly get to the bottom of any\nissue\u2014even if it's totally new and unknown.\n\nWith Honeycomb, you can develop AI applications with confidence, in Google\nCloud or any other environment. Try it today for free.\n\n### Related Posts\n\nOpenTelemetry Observability\n\n#### Observing Core Web Vitals with OpenTelemetry: Part Two\n\nIn a previous blog post, we outlined how to set up our own auto-\ninstrumentation to send Core Web Vitals data to Honeycomb. We recently\nreleased...\n\nObservability\n\n#### Frontend Debugging Is Bad and it Should Feel Bad\n\nThere\u2019s a sentence that strikes fear into the heart of every frontend\ndeveloper I've ever met: Users are reporting issues, and we don't know how...\n\nObservability News & Announcements\n\n#### Focused Labs & Honeycomb: Better Together\n\nWe're excited to unveil a new collaboration with Focused Labs, a leap forward\nin our shared commitment to advancing modern observability practices and\nenhancing the...\n\n## Ready to get started?\n\nPick a plan Schedule Demo\n\nSUBSCRIBE TO OUR NEWSLETTER\n\n\u00a9 2024 Hound Technology, Inc. Terms of Service Acceptable Use Policy Privacy\nPolicy\n\n", "frontpage": false}

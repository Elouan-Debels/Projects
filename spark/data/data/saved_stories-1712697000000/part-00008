{"aid": "39977741", "title": "Please stop throwing money at AI founders with no commercial plan, besides AGI", "url": "https://substack.recursal.ai/cp/143397465", "domain": "recursal.ai", "votes": 1, "user": "tosh", "posted_at": "2024-04-09 09:40:41", "comments": 0, "source_title": "Dear VC\u2019s, please stop throwing money at AI founders with no commercial plan, besides AGI", "source_text": "Dear VC\u2019s, please stop throwing money at AI founders with no commercial plan,\nbesides AGI\n\nHome\n\nWe are hiring!\n\nArchive\n\nAbout\n\nShare this post\n\n#### Dear VC\u2019s, please stop throwing money at AI founders with no commercial\nplan, besides AGI\n\nsubstack.tech-talk-cto.com\n\n#### Discover more from Tech Talk CTO\n\nRandom tech topics, from a startup CTO. (Usually on Infra, Coding, Dev growth,\nRecruitment, Scaling, etc). All views are my own (and not of the company).\n\nContinue reading\n\nSign in\n\nAI Ramblings\n\n# Dear VC\u2019s, please stop throwing money at AI founders with no commercial\nplan, besides AGI\n\n### Execute a commercial plan from day 0, not next year in the future, when\nthe bank is empty\n\nEugene Cheah\n\nApr 08, 2024\n\n1\n\nShare this post\n\n#### Dear VC\u2019s, please stop throwing money at AI founders with no commercial\nplan, besides AGI\n\nsubstack.tech-talk-cto.com\n\n2\n\nShare\n\nCross-post from Tech Talk CTO\n\nThis should have been obvious: but it's a problem we see in the industry\ntoday, that needs fixing! -\n\nRecursal AI\n\n#\n\nA wave of AI foundation model companies, with half a billion dollars raised -\nreaching their end\n\nThroughout 2023, we see headline after headline. Of various all-star teams,\npulling researchers from the top of FAANG, Ivy leagues, Open AI. To create\ntheir Avengers of AI.\n\nSince 2024, we have seen the fall, one after another, after asking 100\u2019s of\nmillions after 100\u2019s of millions. Reach their end, as they run out of money\n\nBut as far as I am concerned - what weed were you VC\u2019s and Founders smoking?\n\nEveryone was trying to follow the same blueprint, of openAI oversimplified\n\n  * Step 1: Get the best researchers, Spend $XX million a month, researching and building the best model out there\n\n  * Step 2: Keep researching, get results, scale up, Ask for more money for each milestone\n\n  * Step 3: ???\n\n  * Step 4: Profit; and make a billion-dollar business\n\nThe AI market is no longer the same as it was pre-OpenAI - the formula was\nnever reliably repeatable in the first place.\n\nAI does not remove the fundamental principle of businesses needing to make\nmoney\n\nWhat was the plan?\n\n#\n\nBut, but ... we funded the team that had all the brightest AI researchers,\nfrom Google, openAI, Ivy leagues ...\n\nThat's exactly part of the problem, of how VC\u2019s oversimplified the whole\nthing. As much as I love their work, what do you think researchers will do\nwith funding.... Research!\n\nDo you not know what the life cycle for a researcher is?\n\n  * Step 1: Propose a research idea, get funding grant approval\n\n  * Step 2: Get results, Write papers, and Scale up. Ask for more money for each milestone\n\n  * Step 3: Repeat steps 1 & 2, with more ideas, or bigger ideas\n\n  * Step 4: Accumulate enough paper citations, get university tenure, retire\n\nNoticed how in the researcher's life cycle, at no point was it about\nmonetizing, making profits, or making a billion-dollar business. If anything,\nresearch by its nature is very capital-inefficient.\n\nWhile they are undoubtedly great brilliant minds in research (and I love them\nfor their contributions). They are not the right people to turn research into\ncommercial products. And inversely, ask for more and more money.\n\nWhile leaving the commercialization process to \u201csomeone else\u201d.\n\nVC\u2019s correlated PhDs & papers to commercial success. Over-indexing to OpenAI's\noutward appearance of success. When literally, some of the most profitable,\nand capital-efficient teams in AI have the inverse correlation\n\nMidjourney : is the extreme case of being arguably the most capital efficient\nteam to date. With near a 0 in AI PhDs. Bare minimum capital raise. And more\nrevenue then the vast majority of AI companies today.\n\n#\n\nWrong Conclusion: OSS / Foundation AI is too expensive?\n\nThe continuous repeat of the extremely large funding cycle of 2023, with\nlarger and larger funding cycles, from foundation model companies. Have lead\nto extremely wrong conclusions from the VC markets\n\n  * That foundation model companies require half a billion dollars and more to succeed\n\n  * Open-source AI companies can't succeed.\n\nThis could not be further from the truth. GPT-4 is estimated to have a\ntraining cost of $100 Million in GPU time. And with advancements in AI\ntechniques and technology, this cost has been going down (not up).\n\nAdd in labor, and various costs - Any company that raised beyond $250 Million\nand failed to catch up with GPT-4 is just being \u201ccapital inefficient\u201d. A\nnumber that is well below many foundation model 2023 capital raise.\n\nSo why do they keep failing? It\u2019s back to the basics of \u201clack of focus\u201d and\n\u201cfinancial discipline\u201d. And distracted by research\n\nThis can be best reflected by, a failure of the following basic test ....\n\n#\n\nLitmus Test: \u201cTime to pricing, and payment\u201d\n\nIn the same naive mistake, that countless Open Source Companies have\nencountered, foundation model companies went on the same blind trend of\n\u201cfiguring out how to make money too late\u201d.\n\nAnd I say this, not only as an observer but as a passionate User as well ...\n\n##\n\nI love you all, but ....\n\nIn Rancher's case: I have given talks, workshops, and evangelized ranchers\ninto other startups. But have contributed $0.\n\n  * I use their product daily (self-hosted), and would pay to have a good managed SaaS solution, which never existed.\n\n  * The only current way to pay them is to be a giant enterprise with a crazy expensive custom enterprise contract, which I am not.\n\nIn Stability AI case: I love you, folks. As a GPU donor recipient for the RWKV\nOSS projects (thanks!). I was literally trying to help pay you, in some shape\nand form, to help improve your numbers for your investors. But gosh do you\nmake it impossible! I had to fight your system to give you money.\n\n  * The paid image generation platform (dreamstudio), is nowhere to be found on your home page and is constantly on page 3 of Google for text-to-image. Refuses a subscription, and is only credits-based. I have to bookmark it, so I can use it every now and then when I need an AI image generated. To effectively give it a few dollars every now and then.\n\n  * The model membership, for $20/month, requires me to fill up a form that requires manual review - only to have the reviewer inform me that I do not qualify. As I was not having enough users & making enough money. In both cases I know this, I just want to give you $20/month\n\nFor Inflection AI case: How does anyone even pay you, there is no enterprise\nsales form, nor cloud sales process on your page.\n\nThere are already enough problems getting pricing right, for any SaaS/platform\ngrowth ...\n\nBut to make it impossible for customers who want to give you money, to give\nyou any. Is in my opinion the complete opposite of \u201cfinancial discipline\u201d,\nwhich is so self-damaging, it\u2019s investor harm.\n\nUnless your plan was a pure acquisition exit. If you want to make a stable\ncompany, constantly releasing wonderful open source code or AI models to the\npublic. You need to have an income stream. Employees need to be paid, Servers\n/ GPUs need to be paid. Investors need to be paid an ROI.\n\nAs a business, your number one primary goal is to make Money. We can discuss\ncommon good, altruism, etc - AFTER - we make sure your business, is stable\nenough to stay around and pay the bills while making money in excess.\n\nEven charities and non-profits need a plan on how to get donation money. So\ndoes your business, noble goals, and idealistic open source visions aside.\n\nThis is a problem not just for AI, but any large-scale open-source project in\ngeneral. A problem we have seen repeated many times. With idealistic views.\n\n##\n\nWe can do better ....\n\nOn the other spectrum, is established companies with Open Source/Core models:\nMongoDB and Elastic. WIth Open Source/Core products that I have gotten either\nmy startup or other startups I advise to be paying for.\n\nThe time to pricing, and payment is relatively straightforward within a few\nclicks.\n\nIt's so straightforward, that this revenue funnel, from one-click users to\nenterprises - makes them a revenue of $1.5 Billion / $1.1 Billion dollars per\nyear respectively, with an R&D budget of over $300M per year for both.\n\nEnough revenue, or R&D budget, to be training GPT-4 multiple times a year.\nEnough R&D spend, to outspend the 3 other companies I highlighted, that failed\nthis basic litmus test.\n\nThis is despite, having everything about their Open stack being potentially an\ninvestor nightmare\n\n  * Their software stack has been cloned by every major cloud provider and competitor\n\n  * Their open source / open core offering is complete enough, that yes - I can actually self-host everything if I want to - and I do so for my own personal cluster usage\n\nBut why do I and several others, then decide to pay them, instead of their\ncloned offerings - to a tune of billions of dollars\n\n  * Production Reliability: Scaling up AI and Databases safely and reliably is incredibly hard, especially in production where you cannot afford any downtime.\n\n  * Convenience in scaling up and down: Related to production reliability\n\n  * Convenience from the Source: Ease of upgrade and access to updates, before any other providers\n\n  * Reasonable Pricing: Without crazy per-seat pricing, it's not much cheaper to get the same performance/service offering on your own, once you factor in upgrade processes required, hardware redundancy, etc. Both Elastic, and MongoDB inversely, get to leverage their economics at scale, and benefits as part of their margins.\n\n  * Multi-cloud offering: allow me to easily move between AWS, GCP, and Azure if needed\n\n  * Enterprise compliance and security (ISO, and SOC certification processes)\n\nEssentially make it more attractive for me to use your solution and hardware.\nThen my own cloud hardware, and we the user will pay.\n\n##\n\nWrong Conclusion: Is the pricing page all I need?\n\nIt is a start and is infinitely better than being user-hostile in making\nmoney.\n\nIt may be sufficient to get to the thousands, or maybe millions in revenue.\nBut if you want to reach billions, it's all about the details ...\n\n#\n\nMoving from research to production, and sales is a muscle!\n\nA muscle that rarely any one company gets right the first time round, a muscle\nthat needs to be constantly trained and iterated.\n\nNotice the list of reasons previously, on why I and many others choose to pay\nfor the commercial offering. Despite even having the expertise to self-host on\nour own?\n\nWithout exercising the muscles from converting a research product into\nproduction and sales, it is easy to make the following mistakes\n\n  * Poor production reliability: Rate limits, Downtime, all constantly puts off users\n\n  * Missing features that the customer wants: from paid offerings, which the open source offerings provide\n\n  * Poor pricing: Users are not idiots, we will shop around, and get pricing drastically wrong compared to your peers. And we will switch. Inversely, price too low, and the company gets burnt.\n\n  * Missing conveniences: A better UX/DX, is a very large reason why your commercial offering will be preferred over DIY.\n\n  * Bad sales processes: Your enterprise sales team, needs time to find Product Market Fit, needs time to scale.\n\nWhile I can sing the praises of Mongo, elastic, or even supabase (Postgres). I\ncan also point out various open-source technology projects, which failed on\nsome version of these points badly enough. That their users were pushed into\nself-hosting or other solutions.\n\nThere is no one-size-fits-all solution to these issues, there is only going to\nmarket, and iterating with the users. Getting this right for B2B / developers\nand enterprises is complicated enough entire investors and courses is\nspecializing in this segment (eg. heavybit)\n\nWe know all of these things, We have learned it through the cycles of various\ndeep tech startups, and B2B SaaS. Sure investors may have been blinded by\ngreed to repeat OpenAI, through oversimplified pattern matching ( Big name +\nAI = Profit ?? ).\n\nBut why do founders, even business founders, avoid building those muscles -\nwhen they know better ???\n\n#\n\nThe problem of incentives from VC\u2019s ...\n\nFoundation model / AI companies by their very nature are deep tech. It\nrequires a fairly deep capital of 50M and up.\n\nOn the flip side, consumers are very demanding, and besides notable\nexceptions, are mostly only willing to consider paying once a model reaches\nGPT 3.5 class and up approximately.\n\n##\n\n1) VC\u2019s Overfitting to the Product Market Fit revenue rocket\n\nOne of the notable issues, that founders constantly discuss - is that once you\nhave revenue - VC\u2019s tend to only focus on the revenue and Product Market Fit\ncurve. Which boils down to: Is it a rocket or not?\n\nThis creates a weird situation, where strategically speaking we founders are\naware of the uphill sales cycle for anything below a GPT 3.5 class model.\n\nAs such, It makes more sense to avoid any revenue until you have an AI model\napproaching the GPT 3.5 class, after which you can start building a platform.\nThis process is something even several VCs will advise founders on, to\nmaintain focus ...\n\nKnowing the tall task involved, many opted to focus on benchmark and open\nsource adoption first before any commercialization ... but that has its own\nweaknesses ...\n\n###\n\n2) Worry about the revenue later instead? You are only to get sniped.\n\nWhich is what happened to Mistral, as they scaled their model up to Mixtral\n...\n\nOnly to find a competing providers, to not only enter the market first to the\npublic before them. But to do so at a lower price point. With their model.\n\nAll of which was to be partially expected - while Mistral was busy entirely\njust creating the model - they never built that muscle for bringing their very\nown model into production and optimizing the user convenience to the sales\nprocess. They were isolated from the users.\n\nInversely, together AI has already been, running the Mistral 7B model.\nIterating with the users, on every factor, from convenience to price. It may\nnot have been a major success, but they have gotten the iteration process\ngoing. As such, when the mixtral model came out, they were more prepared than\nthe mistral team to publish their API for the model.\n\nTogether AI has been exercising the production shipping, and commercial\nmuscle. Mistral didn\u2019t\n\n###\n\n3) Making it worse: build it close source, behind the scenes? Scale up when we\nare ready\n\nBasically what Inflection, and a few others did.\n\n  * If they avoided revenue, they were forced to be working on the model, without user feedback ...\n\n  * If they accepted revenue, they will face an uphill task of making consumers care ... because they were neither GPT 3.5 class nor open source which they can tinker with ... Additionally investors would be doubting them in the early stages due to 1)\n\n  * This is also why - nearly every AI startup is a \u201cbeta\u201d in the early stages, to have some form of customer users and feedback loop. Without committing to the revenue hockey stick.\n\nBasically, you escalate the stakes. You either clearly beat and provide a\nstrong reason to move from the existing close source model with a Unique\nSelling Point. With very limited user feedback, till you get to that point.\n\nAnd if you fail, you will have ended up creating a model, which no one wanted\n(as it was not adapted to user feedback). A model and platform that no one\ncared about (as it is not open source), with little to no revenue nor user\nadoption.\n\nSounds hard right? Well there is an answer ... An alternative ...\n\n##\n\nHow Should it be done then? How does one build a foundation model company?\n\nYou need a founding CEO\n\n  * who has both enough domain expertise and respect in AI to lead an AI team\n\n  * with business sensibility,\n\n    * to actually steer the company to profit\n\n    * and not burn more than 100~200 M to make GPT4 class AI\n\n> Why not a business CEO, with a AI researcher CTO? You will need them both to\n> be very very aligned. Hard decisions will need to be made that involves a\n> quarter to half of the company capital. A decision which can only be made\n> with informed context of both the AI training process and business goals.\n> Decisions which either side may fear making or misjudge, due to lack of\n> context of the other side.\n\nWith a founding CEO / CTO / Team, that has some mix of the following\n\n  * dataset and AI model training and scaling experience\n\n  * who has experience building and scaling resource-hungry infrastructure platforms (for inference)\n\n  * sales and marketing muscles with either (or both)\n\n    * a DevRel team to help promote the platform adoption\n\n    * or an Enterprise sales and partnership team to close the deals\n\n> What if there are talents lacking in specific segments? That is fine, its\n> hard enough to find the combination of talent required for building and\n> scaling AI models (There are less then 1000 individuals who has experience\n> training a 7B and above model from scratch). Let alone everything else.\n> Discuss with the founding team, a recruitment plan for the required gaps in\n> the team.\n\nWith a plan to scale in steps, both the model and platform\n\n  * Stage 1: Something to prove the concept / technical approach\n\n  * Stage 2: Initial platform and model, which can start closing some customers (even if it is ineffective, unscalable, or slow)\n\n    * This can ideally be within a specific market niche or use case\n\n    * Helps ensure all initial scaling issues on the platform are tackled, and sorted out\n\n  * Stage 3: Scaled up, highly performant model and platform, tuned heavily to the user needs (where the hockey stick begins)\n\n    * Ramping up on sales and customer adoption\n\n    * Maybe split into smaller sub-stages (eg. GPT 3.5 class, GPT 4 class)\n\n  * All in under 2 years, because AI moves fast\n\n  * With Investors, who are willing to commit to such a plan, step by step.\n\n> Can\u2019t we skip stage 1 & 2, and go straight to 3? Unless you are able to find\n> the required talents who have done it all before. Which you do not, as they\n> are all concentrated within OpenAI and Anthropic (not even google counts).\n> Across all the various key disciplines. Then maybe you can remove stage 1 &\n> 2?\n>\n> And even then, that would be a high risk move to an already high risk\n> endeavor. Its better to just sort out the bumps, across a few months, and\n> the customer feedback loop. To get this right.\n>\n> For context, openAI had the time between 2018-2020 for stage 1 (GPT-1 & 2).\n> Followed by 2 years+ of stage 2, with early user traction and iteration\n> (GPT-3) between 2020-2022 And only stage 3, towards the end of 2022, early\n> 2023.\n>\n> But yea, many VC\u2019s loved to ignore the first few stages, and only focus on\n> replicating the last stretch. Without realizing how hard and essential it is\n> to make sure to sort out the platform at scale. After all this is not just a\n> \u201cSaaS template\u201d + SuperBase combo. The success and failure is in the\n> details.\n\n##\n\nAnd dun forget to make a profit?\n\nBy selling the AI product, at a price point that - actually makes money this\ntime!\n\n> OpenAI is reported to be making losses of near $500M a year, or over a\n> million dollar a day. According to various reports, including\n> buisnessinsiders.com\n\nThe last part of making profits, making money, over the cost of goods - is\nimportant because\n\n  * You can cover all bills, to be default alive\n\n  * You can funnel the revenue to future models, and customer growth, To grow future revenue\n\n  * And recursively scale up the business, and AI model in the process.\n\nBecause why not? The market is hungry, over a 100 billion dollars a year\nhungry, if you get the pricing and scaling right even with existing AI models\n(GPT 3.5 and GPT 4 class)\n\nSounds like a saner business plan - better than trying to raise 7 Trillion\ndollars right?\n\nA self-fullfilling loop that keep scaling past even AGI?\n\n##\n\nWell, do we have something for you ...\n\nGuess what! - that's basically what, me and my team are doing here are\nRecursal AI are doing.\n\n  * We are built using a new AI architecture: That can make a profit, as it\u2019s 100x++ cheaper on inference compared to existing AI architecture (transformers).\n\n  * We plan to make not just revenue, but profits: Its part of our founding story, we grew from the ashes of un-stable AI companies. And never want that to happen again\n\n  * We do not plan to raise more than $250M: Because, we have always been capital-efficient, and plan to stay that way.\n\n  * We just finished Stage 1 (while spending <$2.5M):\n\n    * We proved our architecture, can be scaled like transformers and even outperform LLaMA 2 7B\n\n    * We achieved SOTA status, as a 7B multi-lingual model\n\n    * Multiple orders of magnitude more capital efficient then any LLM group\n\n  * We are now at Stage 2:\n\n    * We have our initial commercial cloud platform, and strategic partnerships (more details to come)\n\n    * We have initial customers, giving us a tight feedback loop, and pays us\n\n    * We intend to find PMF with our Unique Selling Point at this stage, across either:\n\n      * Affordable, High throughput support\n\n      * SOTA Multi-lingual support\n\n      * Support for enterprise private cloud / on-premise deployment support\n\n  * We are scaling to GPT 3.5 for Stage 3A, Followed by GPT 4 for Stage 3B\n\n  * All while building the open-source AI model, open source under the Linux Foundation\n\n  * And creating that looping wheel, of profits, powering model improvements, in a stable recursive manner.\n\n    * That makes both investors and employees happily rewarded.\n\n    * A loop I wish to see repeated across more competing open source models.\n\nIf that makes sense to you, feel free to reach out\n\n  * For investors: founders@recursal.ai\n\n  * For those who want to join us: hr@recursal.ai\n\nRecursively: Making AI, for everyone, in every language\n\n~ Until next time \ud83d\udd96 live long and prosper\n\n### Subscribe to Tech Talk CTO\n\nBy Eugene Cheah \u00b7 Launched a year ago\n\nRandom tech topics, from a startup CTO. (Usually on Infra, Coding, Dev growth,\nRecruitment, Scaling, etc). All views are my own (and not of the company).\n\n1\n\nShare this post\n\n#### Dear VC\u2019s, please stop throwing money at AI founders with no commercial\nplan, besides AGI\n\nsubstack.tech-talk-cto.com\n\n2\n\nShare\n\n\ud83e\udd85 EagleX 1.7T : Soaring past LLaMA 7B 2T in both English and Multi-lang evals\n(RWKV-v5)\n\nA linear transformer has just cross the gold standard in transformer models,\nLLaMA 7B, with less tokens trained in both English and multi-lingual evals...\n\nMar 16 \u2022\n\nEugene Cheah\n\n6\n\nShare this post\n\n#### \ud83e\udd85 EagleX 1.7T : Soaring past LLaMA 7B 2T in both English and Multi-lang\nevals (RWKV-v5)\n\nsubstack.recursal.ai\n\n10\n\nRecursal.AI is hiring! (For Q1 2024)\n\nWe are building, and growing a team, to provide serverless RWKV inference,\ntuning, and distillation of RWKV models. At a fraction of OpenAI cost...\n\nDec 1, 2023 \u2022\n\nRecursal AI\n\nShare this post\n\n#### Recursal.AI is hiring! (For Q1 2024)\n\nsubstack.recursal.ai\n\nPublic RWKV 3B Models via OpenRouter\n\nOur free RWKV 3B models, are now accessible with OpenRouter\n\nDec 12, 2023 \u2022\n\nRecursal AI\n\nand\n\nEugene Cheah\n\nShare this post\n\n#### Public RWKV 3B Models via OpenRouter\n\nsubstack.recursal.ai\n\n\u00a9 2024 Recursal AI\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great writing\n\nShare\n\n", "frontpage": false}

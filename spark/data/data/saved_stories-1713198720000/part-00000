{"aid": "40038679", "title": "The Beauty of OLAP SQL", "url": "https://taki-mekhalfa.github.io/misc/2024/04/14/beauty_of_olap_sql.html", "domain": "taki-mekhalfa.github.io", "votes": 1, "user": "saynomore_", "posted_at": "2024-04-15 10:29:41", "comments": 0, "source_title": "The beauty of OLAP SQL", "source_text": "The beauty of OLAP SQL | Debugging the Universe\n\nDebugging the Universe\n\n# The beauty of OLAP SQL\n\nApr 14, 2024\n\nIn my daily job, I develop backends for analytical dashboards that show graphs\nto users to help them better understand their data. I want to share with you a\nreal case scenario using SQL to write powerful OLAP queries.\n\nImagine you sell Pizza brands, and you are interested in comparing with your\ncompetitors to see how much of the pizza shelf your products are occupying.\nSome interesting questions for you would be:\n\n  * What is your share of assortment in the pizza category? Is 50% of distributed pizza products on Walmart yours? Is it only 5%?\n  * On average, how many of your pizza products are distributed in Kroger? You have 5 different products but only 2 are available on average? Maybe more/less?\n  * How is your share of the assortment evolving in time? Are you +10% or -5% with respect to the last year? last month?\n  * Who are the competitors detaining the majority of the shelf? How well do you compare with them?\n  * Who is putting new products the market? Who is putting less?\n  * Which of your brands is successful? Which one needs to be taken out of the market or enhanced with ads/better prices, etc...\n\nThe data looks like the following (you can find it in a parquet file in here):\n\n    \n    \n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 p_id \u2506 manufacturer \u2506 category \u2506 brand \u2506 retailer \u2506 period \u2506 distributed_days \u2502 \u2502 --- \u2506 --- \u2506 --- \u2506 --- \u2506 --- \u2506 --- \u2506 --- \u2502 \u2502 i64 \u2506 i64 \u2506 i64 \u2506 i64 \u2506 i64 \u2506 str \u2506 i64 \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 6581 \u2506 61 \u2506 20 \u2506 273 \u2506 1 \u2506 2023_52 \u2506 31407 \u2502 \u2502 8563 \u2506 34 \u2506 4 \u2506 274 \u2506 1 \u2506 2023_52 \u2506 27515 \u2502 \u2502 8411 \u2506 11 \u2506 6 \u2506 276 \u2506 1 \u2506 2023_52 \u2506 30693 \u2502 \u2502 20163 \u2506 21 \u2506 4 \u2506 277 \u2506 1 \u2506 2023_52 \u2506 61 \u2502 \u2502 5669 \u2506 56 \u2506 4 \u2506 278 \u2506 1 \u2506 2023_52 \u2506 20665 \u2502 \u2502 ... \u2506 ... \u2506 ... \u2506 ... \u2506 ... \u2506 ... \u2506 ... \u2502 \u2502 8932 \u2506 2 \u2506 23 \u2506 2 \u2506 1 \u2506 2024_1 \u2506 25584 \u2502 \u2502 8927 \u2506 2 \u2506 2 \u2506 2 \u2506 1 \u2506 2024_1 \u2506 27163 \u2502 \u2502 8923 \u2506 2 \u2506 14 \u2506 2 \u2506 1 \u2506 2024_1 \u2506 21691 \u2502 \u2502 8918 \u2506 2 \u2506 3 \u2506 2 \u2506 1 \u2506 2024_1 \u2506 31407 \u2502 \u2502 8910 \u2506 2 \u2506 3 \u2506 2 \u2506 1 \u2506 2024_1 \u2506 17 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nThis is anonymized data and represents a subset of scraped products from\nretailers websites (Walmart, Kroger, ...). In this specific case, we are\ninterested in analyzing the share of assortment of each brand manufacturer\nwith respect to different variables.\n\nEach line contains data about a product:\n\n  * Unique ID of the product\n  * The Manufacturer\u2019s ID\n  * Categorization of the product : Toothpaste, Deodorants, Sauces, ...\n  * Brand of the product, for example: Dove, Pepsi, KitKat, ...\n  * Retailer and the week where data was scraped. Data here represents Last week of 2023 and first week of 2024.\n  * Distributed days: The number of the days we\u2019ve seen the product on the website during the period and over all shops of that retailer. For example if Walmart has 1000 shops in the US and the product was available on all shops during the entire week, the number of distributed days would be 1000 * 7 = 7000 days. We will see how is this used to compute share of assortment later.\n\nIn the following I will be using DuckDB. An amazing and powerful embedded\nquery engine.\n\n#### 1) How many unique products distributed by manufacturer for both weeks\nover all retailers?\n\nThis an easy query, we just have to take distinct products and group by the\nmanufacturer\n\n    \n    \n    SELECT manufacturer, COUNT(DISTINCT p_id) AS nb_unique_products -- the number of unique products FROM product_details GROUP BY ALL -- A powerful construct provided by DuckDB ORDER BY nb_unique_products DESC LIMIT 10; -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 manufacturer \u2502 nb_unique_products \u2502 -- \u2502 int64 \u2502 int64 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 7 \u2502 3463 \u2502 <-- The big players -- \u2502 34 \u2502 2688 \u2502 -- \u2502 2 \u2502 2368 \u2502 -- \u2502 26 \u2502 1227 \u2502 -- \u2502 39 \u2502 978 \u2502 -- \u2502 6 \u2502 783 \u2502 -- \u2502 58 \u2502 727 \u2502 -- \u2502 21 \u2502 499 \u2502 -- \u2502 57 \u2502 372 \u2502 <-- Let's say this is me -- \u2502 3 \u2502 333 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 10 rows 2 columns \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n#### 2) How are my products distributed over the different categories?\n\nFilter on my products only, and then count the number of unique products\ngrouping by the product category.\n\nIt\u2019s good to see the percentage each category accounts for. A window function\nis an amazing tool. It applies an aggregate like computation over a window of\nrows.\n\nImportant: The rows considered by a window function are those produced WHERE,\nGROUP BY, and HAVING clauses if any. You can think of it as if the window\nfunction was run the last.\n\nnb_unique_products / SUM(nb_unique_products) OVER () means:\n\n> Take the current row\u2019s nb_unique_productsand divide it by the sum of\n> nb_unique_products of all rows in the window. The window here is all\n> categories.\n    \n    \n    SELECT category, COUNT(DISTINCT p_id) AS nb_unique_products, ROUND( 100 * nb_unique_products / SUM(nb_unique_products) OVER (), 2 ) AS \"% of products\" FROM product_details WHERE manufacturer = 57 GROUP BY category ORDER BY nb_unique_products DESC -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 nb_unique_products \u2502 % of products \u2502 -- \u2502 int64 \u2502 int64 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 4 \u2502 203 \u2502 54.57 \u2502< products concentrated on -- \u2502 3 \u2502 50 \u2502 13.44 \u2502< these two categories. -- \u2502 18 \u2502 23 \u2502 6.18 \u2502 -- \u2502 16 \u2502 22 \u2502 5.91 \u2502 -- \u2502 22 \u2502 22 \u2502 5.91 \u2502 -- \u2502 2 \u2502 22 \u2502 5.91 \u2502 -- \u2502 1 \u2502 18 \u2502 4.84 \u2502 -- \u2502 11 \u2502 10 \u2502 2.69 \u2502 -- \u2502 5 \u2502 2 \u2502 0.54 \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nNow, imagine you are responsible for categories 1, 2, 3 and 4 only. You don\u2019t\nwant to see other categories. You might be tempted by doing:\n\n    \n    \n    SELECT category, COUNT(DISTINCT p_id) AS nb_unique_products, ROUND( 100 * nb_unique_products / SUM(nb_unique_products) OVER (), 2 ) AS \"% of products\" FROM product_details WHERE manufacturer = 57 AND category IN (1, 2, 3, 4) -- You added this GROUP BY category ORDER BY nb_unique_products DESC; -- which gives: -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 nb_unique_products \u2502 % of products \u2502 -- \u2502 int64 \u2502 int64 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 4 \u2502 203 \u2502 69.28 \u2502 -- \u2502 3 \u2502 50 \u2502 17.06 \u2502 -- \u2502 2 \u2502 22 \u2502 7.51 \u2502 -- \u2502 1 \u2502 18 \u2502 6.14 \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nWhat happened? Share of products went from: 54.57% to 69.28%. As I said,\nwindow function is evaluated on rows after the WHERE and GROUP BY clauses were\nexecuted. In this case, it means you are considering the share on only these\ncategories (1, 2, 3 and 4).\n\nThere are two ways of doing this:\n\n  * Use a sub query:\n    \n        SELECT * FROM (<PREVIOUS QUERY>) WHERE category IN (1, 2, 3, 4);\n\n  * Use QUALIFY provided by DuckDB:\n    \n        SELECT category, COUNT(DISTINCT p_id) AS nb_unique_products, ROUND( 100 * nb_unique_products / SUM(nb_unique_products) OVER (), 2 ) AS \"% of products\" FROM product_details WHERE manufacturer = 57 GROUP BY category QUALIFY -- At last filter on window function result using the following: category IN (1, 2, 3, 4) ORDER BY nb_unique_products DESC -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 nb_unique_products \u2502 % of products \u2502 -- \u2502 int64 \u2502 int64 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 4 \u2502 203 \u2502 54.57 \u2502 -- \u2502 3 \u2502 50 \u2502 13.44 \u2502 -- \u2502 2 \u2502 22 \u2502 5.91 \u2502 -- \u2502 1 \u2502 18 \u2502 4.84 \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n#### 3) Since I am competing on categories 3 and 4, who am I competing with?\n\nWe have seen that we are distributing products mainly in two catagories (for\nexample: Toothpaste and Mouthwash) I should care more about competitors on\nthese categories only.\n\nLet\u2019s start simple:\n\n    \n    \n    SELECT category, manufacturer, COUNT( DISTINCT p_id) as nb_unique_products FROM product_details WHERE category IN (3, 4) GROUP BY ALL ORDER BY category, nb_unique_products DESC LIMIT 5; -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 manufacturer \u2502 nb_unique_products \u2502 -- \u2502 int64 \u2502 int64 \u2502 int64 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 3 \u2502 2 \u2502 196 \u2502 -- \u2502 3 \u2502 39 \u2502 185 \u2502 -- \u2502 3 \u2502 41 \u2502 124 \u2502 -- \u2502 3 \u2502 67 \u2502 119 \u2502 -- \u2502 3 \u2502 34 \u2502 92 \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nThis gives us the number of unique products distributed by all manufacturers\nin categories 3 and 4.\n\nLet\u2019s try to only get the top 3 manufacturers on each category, which are\ncompetitors we need to worry about the most.\n\n    \n    \n    SELECT category, manufacturer, COUNT(DISTINCT p_id) as nb_unique_products, -- over the category+manufacturer, row_number() OVER ( PARTITION BY category -- rank inside the category ORDER BY -- more products = better position nb_unique_products DESC ) as position, ROUND( 100 * nb_unique_products / SUM(nb_unique_products) OVER ( PARTITION BY category ), 2 ) as \"% of the market\" FROM product_details WHERE category IN (3, 4) GROUP BY category, manufacturer QUALIFY position <= 3 -- top 3 competitors OR manufacturer = 57 -- and me please ORDER BY category, position -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 manufacturer \u2502 nb_unique_products \u2502 position \u2502 % of the market \u2502 -- \u2502 int64 \u2502 int64 \u2502 int64 \u2502 int64 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 3 \u2502 2 \u2502 196 \u2502 1 \u2502 18.23 \u2502 -- \u2502 3 \u2502 39 \u2502 185 \u2502 2 \u2502 17.21 \u2502 -- \u2502 3 \u2502 41 \u2502 124 \u2502 3 \u2502 11.53 \u2502 -- \u2502 3 \u2502 57 \u2502 50 \u2502 7 \u2502 4.65 \u2502< this is me -- \u2502 4 \u2502 34 \u2502 452 \u2502 1 \u2502 23.12 \u2502 -- \u2502 4 \u2502 7 \u2502 303 \u2502 2 \u2502 15.5 \u2502 -- \u2502 4 \u2502 2 \u2502 278 \u2502 3 \u2502 14.22 \u2502 -- \u2502 4 \u2502 57 \u2502 203 \u2502 5 \u2502 10.38 \u2502< this is me -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSo, this allows you to see for example that you are 5th on category 4 and\nallows you to see whore are the ones with the highest share on it.\n\nLet\u2019s deconstruct this query:\n\n  1. Filter on categories 3 and 4: WHERE\n  2. Get the number of unique products per manufacturer per category: GROUP BY\n  3. Rank each manufacturer on the category: row_number() over a window partitioned by category and ordered by the number of unique products we compute at step 1. We have to partition by category to not take both categories into account. So each manufacturer will have 2 positions: one on category 2 and another one on category 3\n  4. Just like step 3, compute the share of products for a manufacturer on a given category.\n  5. QUALIFY to only return top 3 manufacturers\n\n#### 4) Distributed products at multi-levels?\n\nImagine you want the number of your unique products:\n\n  * Per retailer per category\n  * Per retailer for all categories\n  * Per category for all retailers\n  * For all retailers for all categories\n\nYou can compute each one independently and union everything but there is a\nsimpler way.\n\n    \n    \n    SELECT COALESCE(retailer, 0) AS retailer, -- convert nulls to a readable id COALESCE(category, 0) AS category, -- convert nulls to a readable id COUNT(DISTINCT p_id) AS nb_unique_products FROM product_details GROUP BY GROUPING SETS ( -- per retailer per category (category, retailer), -- per category for all retailers (category), -- per retailer for all categories (retailer), -- for all categories for all retailers () ) ORDER BY ALL -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 retailer \u2502 category \u2502 nb_unique_products \u2502 -- \u2502 int64 \u2502 int64 \u2502 int64 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 0 \u2502 0 \u2502 17428 \u2502 -- \u2502 0 \u2502 1 \u2502 136 \u2502 -- \u2502 0 \u2502 2 \u2502 2105 \u2502 -- \u2502 0 \u2502 3 \u2502 1075 \u2502 -- \u2502 0 \u2502 4 \u2502 1955 \u2502 -- \u2502 \u00b7 \u2502 \u00b7 \u2502 \u00b7 \u2502 -- \u2502 \u00b7 \u2502 \u00b7 \u2502 \u00b7 \u2502 -- \u2502 \u00b7 \u2502 \u00b7 \u2502 \u00b7 \u2502 -- \u2502 2 \u2502 11 \u2502 346 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 x rows (xx shown) 3 columns \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nGrouping sets is equivalent to the union of different GROUP BYs.\n\nThe result will contain NULL for the dimension not included in the grouping\nset. So results for the group (category) will have retailer set as NULL.\n\nIf you are using all possible grouping sets, than you can simplify syntax by\nusing CUBE:\n\n    \n    \n    SELECT COALESCE(retailer, 0) AS retailer, COALESCE(category, 0) AS category, COUNT(DISTINCT p_id) AS nb_unique_products FROM product_details GROUP BY -- This is equivalent to all possible grouping sets: -- (category, retailer), (category), (retailer), (category), () CUBE(retailer, category) ORDER BY ALL\n\nROLLUP is another grouping construct but it works differently than CUBE by\nrestricting the possible grouping sets. ROLLUP(x, y) is defined as:\n\n  * (x, y)\n  * (x)\n  * ()\n\n(y) would be included by CUBE but not by ROLLUP.\n\nThis is more useful in cases when there is a hierarchical relationship between\nthe different dimensions as in:\n\n  * SUM(population) GROUP BY ROLLUP(county, region, city)\n\nIn which case the grouping set (region) won\u2019t make a lof of sense as a region\nis linked to one country and that would be equivalent to (country, region).\n\n#### 5) Since I am competing on categories 3 and 4, what\u2019s my share of\nassortment (SOA)?\n\nWe have seen a query to look at the number of unique distributed products in\ncategories 3 and 4.\n\nHaving more unique distributed products is not completely correlated with your\nshare of assortment.\n\nImagine you have 15 unique frozen food products and a competitor who has only\n3 unique frozen food products, and there is only you too on the market.\n\nIf at a given retailer (Walmart for e.g.), they always put 2 of you\ncompetitor\u2019s products and 1 of your products. In this case you will only have\n1/3=33% of SOA while your competitor will have 2/3=77% of the frozen food\nshelf. Although you detain a big share on the number of unique products\n15/18=83%, you are being surpassed by your competitor.\n\nShare of assortment can be defined as:\n\n    \n    \n    SOA = SUM(distributed days of my products) / SUM(distributed days of my products + competitors' products)\n\nHere is a query to get top 3 competitors in categories 3 and 4 with respect to\nSOA:\n\n    \n    \n    WITH soa_per_category_per_manufacturer AS ( SELECT category, manufacturer, SUM(distributed_days) as _total_ddays, -- total ddays per each manufacturer ROUND( 100 * _total_ddays / SUM(_total_ddays) OVER (PARTITION BY category), 2 ) as soa -- this is exactly the SOA formula, FROM product_details WHERE category IN (3, 4) GROUP BY category, manufacturer ) SELECT * EXCLUDE(_total_ddays), -- Thanks DuckDB for EXCLUDE :) row_number() OVER ( PARTITION BY category ORDER BY soa DESC ) as position -- order then by soa on the category FROM soa_per_category_per_manufacturer QUALIFY position <= 3 -- top 3 competitors OR manufacturer = 57 -- and me please -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 manufacturer \u2502 soa \u2502 position \u2502 -- \u2502 int64 \u2502 int64 \u2502 double \u2502 int64 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 3 \u2502 39 \u2502 22.12 \u2502 1 \u2502 -- \u2502 3 \u2502 2 \u2502 16.04 \u2502 2 \u2502 -- \u2502 3 \u2502 67 \u2502 14.36 \u2502 3 \u2502 -- \u2502 3 \u2502 57 \u2502 3.95 \u2502 8 \u2502< I am no longer 7th on the market -- \u2502 4 \u2502 34 \u2502 24.6 \u2502 1 \u2502 -- \u2502 4 \u2502 7 \u2502 17.27 \u2502 2 \u2502 -- \u2502 4 \u2502 2 \u2502 10.9 \u2502 3 \u2502 -- \u2502 4 \u2502 57 \u2502 10.36 \u2502 5 \u2502< Still 5th -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nThis query uses CTEs which are a way to organize your queries to make them\nreadable and in some cases avoid recomputing the same results over and over if\nmaterialized and used in many places (check Materialized CTEs).\n\n#### 6) Temporal evolution!\n\nImagine now you want to compare SOA on your categories between the selected\nweek 2024_1 with respect to previous week 2023_52.\n\n    \n    \n    WITH soa_per_period_category_per_manufacturer AS ( SELECT period, category, manufacturer, SUM(distributed_days) as _total_ddays, ROUND( 100 * _total_ddays / SUM(_total_ddays) OVER ( PARTITION BY period, -- notice adding period here :) category ), 2 ) as soa, FROM product_details GROUP BY period -- and here too :), category, manufacturer ), soa_variation AS ( SELECT * EXCLUDE (_total_ddays), -- notice the use of a defined window to -- simplify the query especially if it's used in many places. soa - lag(soa, 1, 0) OVER period_window as variation_soa, FROM soa_per_period_category_per_manufacturer -- define the window and assign a name to it WINDOW period_window AS ( PARTITION BY category, -- Notice that we need manufacturer here -- since the variation is by manufacturer by category manufacturer ORDER BY -- this is very important as variation is -- current soa - previous soa. The order -- of the values in the window should be like that -- to be able to use soa - lag(soa, 1, 0). -- notice also that '2023_52' < '2024_1' period ) -- take this week only after the window function -- as tha variation is linked to it QUALIFY period = '2024_1' ORDER BY period ) SELECT -- thanks DuckDB for EXCLUDE/REPLACE :) * EXCLUDE (period) REPLACE (ROUND(variation_soa, 2) as variation_soa), row_number() OVER ( PARTITION BY category ORDER BY variation_soa DESC ) as position -- order then by soa on the category FROM -- take first from each category soa_variation QUALIFY position = 1 ORDER BY category LIMIT 10; -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 category \u2502 manufacturer \u2502 soa \u2502 variation_soa \u2502 position \u2502 -- \u2502 int64 \u2502 int64 \u2502 double \u2502 double \u2502 int64 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 1 \u2502 39 \u2502 34.19 \u2502 3.11 \u2502 1 \u2502< 39 is getting better -- \u2502 2 \u2502 39 \u2502 11.68 \u2502 1.37 \u2502 1 \u2502< over multiple categories -- \u2502 3 \u2502 39 \u2502 24.8 \u2502 5.64 \u2502 1 \u2502 -- \u2502 4 \u2502 6 \u2502 11.84 \u2502 2.41 \u2502 1 \u2502 -- \u2502 5 \u2502 39 \u2502 40.07 \u2502 6.52 \u2502 1 \u2502 -- \u2502 6 \u2502 39 \u2502 42.08 \u2502 10.42 \u2502 1 \u2502< That's a good improvement -- \u2502 7 \u2502 34 \u2502 6.29 \u2502 3.65 \u2502 1 \u2502 -- \u2502 8 \u2502 6 \u2502 51.29 \u2502 0.86 \u2502 1 \u2502 -- \u2502 9 \u2502 3 \u2502 52.69 \u2502 9.33 \u2502 1 \u2502 -- \u2502 10 \u2502 3 \u2502 42.24 \u2502 6.81 \u2502 1 \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 10 rows 5 columns \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nThis query get\u2019s the manufacturer with the best variation over each category.\nNotice the multiple CTEs to organize the query.\n\nlag(n) is a window function to allow using the value of the previous n row\ninside the window.\n\n#### 6) Not all retailers are equal!\n\nImagine you have SOA by retailer, and you want an average but not just a\nnormal average, because retailers don\u2019t have the same importance (number of\nshops, zones, contracts, ...) you would like to compute the weighted average\nover the different retailers.\n\nImagine you have these weights (you can find the data here):\n\n    \n    \n    select * from retailer_w; -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 retailer \u2502 w \u2502 -- \u2502 int32 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 2 \u2502 1.0 \u2502 -- \u2502 1 \u2502 3.0 \u2502< 3 times more important than retailer 2 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAverage SOA would be then:\n\n    \n    \n    avg_soa = SUM(retailer_i * w_i) / SUM(w_i) for all (retailer_i, w_i)\n    \n    \n    WITH soa_per_retailer_per_manufacturer AS ( SELECT retailer, manufacturer, SUM(distributed_days) as _total_ddays, -- total ddays per each manufacturer ROUND( 100 * _total_ddays / SUM(_total_ddays) OVER (PARTITION BY retailer), 2 ) as soa -- this is exactly the SOA formula, FROM product_details GROUP BY retailer, manufacturer ) SELECT manufacturer, ROUND( -- we are grouping my manufacturer so we can just -- do this to have the weighted average SUM(soa * w) / SUM(w), 2 ) as avg_soa, FROM soa_per_retailer_per_manufacturer JOIN retailer_w USING(retailer) GROUP BY manufacturer ORDER BY avg_soa DESC LIMIT 5; -- \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 -- \u2502 manufacturer \u2502 avg_soa \u2502 -- \u2502 int64 \u2502 double \u2502 -- \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 -- \u2502 7 \u2502 22.52 \u2502 -- \u2502 34 \u2502 16.03 \u2502 -- \u2502 2 \u2502 12.8 \u2502 -- \u2502 26 \u2502 7.56 \u2502 -- \u2502 39 \u2502 6.72 \u2502 -- \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n### That\u2019s it. Hope you had fun reading this :)\n\n### Taki\n\n## Debugging the Universe\n\n  * Debugging the Universe\n  * takiedd.mekhalfa@gmail.com\n\n  * taki-mekhalfa\n  * taki-mekhalfa-7809a4189\n\nInsights on Programming and Engineering and Life.\n\n", "frontpage": false}

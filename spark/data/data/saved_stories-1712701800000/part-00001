{"aid": "39981105", "title": "Neural operators for accelerating scientific simulations and design", "url": "https://www.nature.com/articles/s42254-024-00712-5", "domain": "nature.com", "votes": 1, "user": "Anon84", "posted_at": "2024-04-09 16:29:05", "comments": 0, "source_title": "Neural operators for accelerating scientific simulations and design", "source_text": "Neural operators for accelerating scientific simulations and design | Nature Reviews Physics\n\nSkip to main content\n\nThank you for visiting nature.com. You are using a browser version with\nlimited support for CSS. To obtain the best experience, we recommend you use a\nmore up to date browser (or turn off compatibility mode in Internet Explorer).\nIn the meantime, to ensure continued support, we are displaying the site\nwithout styles and JavaScript.\n\nAdvertisement\n\n  * View all journals\n  * Search\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n    * Explore articles by subject\n    * Find a job\n    * Guide to authors\n    * Editorial policies\n\n  * Log in\n\n  * Explore content\n  * About the journal\n  * Publish with us\n  * Subscribe\n\n  * Sign up for alerts\n  * RSS feed\n\n  * Perspective\n  * Published: 08 April 2024\n\n# Neural operators for accelerating scientific simulations and design\n\n  * Kamyar Azizzadenesheli^1,\n  * Nikola Kovachki^1,\n  * Zongyi Li^2,\n  * Miguel Liu-Schiaffini^2,\n  * Jean Kossaifi^1 &\n  * ...\n  * Anima Anandkumar ORCID: orcid.org/0000-0002-6974-6797^2\n\nNature Reviews Physics (2024)Cite this article\n\n  * 21 Altmetric\n\n  * Metrics details\n\n## Abstract\n\nScientific discovery and engineering design are currently limited by the time\nand cost of physical experiments. Numerical simulations are an alternative\napproach but are usually intractable for complex real-world problems.\nArtificial intelligence promises a solution through fast data-driven surrogate\nmodels. In particular, neural operators present a principled framework for\nlearning mappings between functions defined on continuous domains, such as\nspatiotemporal processes and partial differential equations. Neural operators\ncan extrapolate and predict solutions at new locations unseen during training.\nThey can be integrated with physics and other domain constraints enforced at\nfiner resolutions to obtain high-fidelity solutions and good generalization.\nNeural operators are differentiable, so they can directly optimize parameters\nfor inverse design and other inverse problems. Neural operators can therefore\naugment, or even replace, existing numerical simulators in many applications,\nsuch as computational fluid dynamics, weather forecasting and material\nmodelling, providing speedups of four to five orders of magnitude.\n\nThis is a preview of subscription content, access via your institution\n\n## Access options\n\nAccess through your institution\n\nChange institution\n\nBuy or subscribe\n\nAccess Nature and 54 other Nature Portfolio journals\n\nGet Nature+, our best-value online-access subscription\n\n24,99 \u20ac / 30 days\n\ncancel any time\n\nLearn more\n\nSubscribe to this journal\n\nReceive 12 digital issues and online access to articles\n\n99,00 \u20ac per year\n\nonly 8,25 \u20ac per issue\n\nLearn more\n\nRent or buy this article\n\nPrices vary by article type\n\nfrom$1.95\n\nto$39.95\n\nLearn more\n\nPrices may be subject to local taxes which are calculated during checkout\n\nFig. 1: Spectral overall analysis.\n\nFig. 2: Comparison of neural networks with neural operators.\n\nFig. 3: Diagram comparing a pseudospectral solver, a Fourier neural operator\nand the general neural operator architecture.\n\n### Similar content being viewed by others\n\n### Physics-informed machine learning\n\nArticle 24 May 2021\n\nGeorge Em Karniadakis, Ioannis G. Kevrekidis, ... Liu Yang\n\n### Physics-enhanced deep surrogates for partial differential equations\n\nArticle 04 December 2023\n\nRapha\u00ebl Pestourie, Youssef Mroueh, ... Steven G. Johnson\n\n### Accelerating phase-field-based microstructure evolution predictions via\nsurrogate models trained by machine learning methods\n\nArticle Open access 04 January 2021\n\nDavid Montes de Oca Zapiain, James A. Stewart & R\u00e9mi Dingreville\n\n## Code availability\n\nA reference implementation for various neural operators including and examples\non how to get started can be found at: Neural Operator Library,\nhttps://github.com/neuraloperator/.\n\n## References\n\n  1. Evans, L. C. Partial Differential Equations Vol. 19 (American Mathematical Society, 2022).\n\n  2. Batchelor, G. K. An Introduction to Fluid Dynamics (Cambridge Univ. Press, 1967).\n\n  3. Schneider, T. et al. Climate goals and computing the future of clouds. Nat. Clim. Change 7, 3\u20135 (2017).\n\nArticle ADS Google Scholar\n\n  4. Tarantola, A. Inverse Problem Theory and Methods for Model Parameter Estimation (Society for Industrial and Applied Mathematics, 2004).\n\n  5. Brunton, S. L., Noack, B. R. & Koumoutsakos, P. Machine learning for fluid mechanics. Annu. Rev. Fluid Mech. 52, 477\u2013508 (2020).\n\nArticle ADS MathSciNet Google Scholar\n\n  6. Kochkov, D. et al. Machine learning\u2013accelerated computational fluid dynamics. Proc. Natl Acad. Sci. USA 118, e2101784118 (2021).\n\nArticle MathSciNet Google Scholar\n\n  7. Vinuesa, R. & Brunton, S. L. Enhancing computational fluid dynamics with machine learning. Nat. Comput. Sci. 2, 358\u2013366 (2022).\n\nArticle Google Scholar\n\n  8. Brunton, S. L., Proctor, J. L. & Kutz, J. N. Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proc. Natl Acad. Sci. USA 113, 3932\u20133937 (2016).\n\nArticle ADS MathSciNet Google Scholar\n\n  9. Vlachas, P. R., Byeon, W., Wan, Z. Y., Sapsis, T. P. & Koumoutsakos, P. Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks. Proc. R. Soc. A 474, 20170844 (2018).\n\nArticle ADS MathSciNet Google Scholar\n\n  10. Pathak, J. et al. Hybrid forecasting of chaotic processes: using machine learning in conjunction with a knowledge-based model. Chaos 28, 041101 (2018).\n\nArticle ADS MathSciNet Google Scholar\n\n  11. Li, Z. et al. Fourier neural operator for parametric partial differential equations. In Proc. 9th International Conference on Learning Representations (ICLR, 2021).\n\n  12. Kovachki, N. B. et al. Neural operator: learning maps between function spaces with applications to PDEs. J. Mach. Learn. Res. 24, 1\u201397 (2023).\n\nMathSciNet Google Scholar\n\n  13. Dally, W. J., Keckler, S. W. & Kirk, D. B. Evolution of the graphics processing unit (GPU). IEEE Micro 41, 42\u201351 (2021).\n\nArticle Google Scholar\n\n  14. Pathak, J. et al. FourCastNet: a global data-driven high-resolution weather model using adaptive Fourier neural operators. In Proc. Platform for Advanced Scientific Computing Conference (PASC) (ACM, 2023).\n\n  15. Li, Z. et al. Geometry-informed neural operator for large-scale 3D PDEs. In Advances in Neural Information Processing Systems 36 (NeurIPS, 2023).\n\n  16. Wen, G. et al. Real-time high-resolution CO_2 geological storage prediction using nested Fourier neural operators. Energy Environ. Sci. 16, 1732\u20131741 (2023).\n\nArticle Google Scholar\n\n  17. Bonev, B. et al. Spherical Fourier neural operators: learning stable dynamics on the sphere. In Proc. 40th International Conference on Machine Learning Vol. 202, 2806\u20132823 (PMLR, 2023).\n\n  18. Pathak J. et al. Open-Source FourCastNet v2 Weather Model Hosted on ECMWF (Github, 2023); https://github.com/ecmwf-lab/ai-models-fourcastnetv2.\n\n  19. Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems Vol. 30 6000\u20136010 (eds Guyon, I. et al.) (Curran Associates, 2017).\n\n  20. Esmaeilzadeh, S. et al. MeshfreeFlowNet: a physics-constrained deep continuous space-time super-resolution framework. In SC\u201920: Proc. International Conference for High Performance Computing, Networking, Storage and Analysis 1\u201315 (IEEE, 2020).\n\n  21. Haarsma, R. J. et al. High Resolution Model Intercomparison Project (HighResMIP v1. 0) for CMIP6. Geosci. Model Dev. 9, 4185\u20134208 (2016).\n\nArticle ADS Google Scholar\n\n  22. Yuan, Y. et al. HRFormer: high-resolution vision transformer for dense predict. Adv. Neural Inf. Process. Syst. 34, 7281\u20137293 (2021).\n\nGoogle Scholar\n\n  23. Li, Z. et al. Neural operator: graph kernel network for partial differential equations. J. Mach. Learn. Res. 24, 1\u201397 (2023).\n\nGoogle Scholar\n\n  24. Li, Z. et al. Physics-informed neural operator for learning partial differential equations. ACM J. Data Sci. https://doi.org/10.1145/3648506 (2024).\n\n  25. Bartolucci, F. et al. Representation equivalent neural operators: a framework for alias-free operator learning. In Advances in Neural Information Processing Systems 36 (NeurIPS 2023).\n\n  26. Fanaskov, V. & Oseledets, I. Spectral neural operators. Dokl. Math. https://doi.org/10.1134/S1064562423701107 (2024).\n\n  27. Hersbach, H. et al. The ERA5 global reanalysis. Q. J. R. Meteorol. Soc. 146, 1999\u20132049 (2020).\n\nArticle ADS Google Scholar\n\n  28. Nair, V. & Hinton, G. E. Rectified linear units improve restricted Boltzmann machines. In Proc. 27th International Conference on Machine Learning (ICML-10) 807\u2013814 (ICML, 2010).\n\n  29. Lanthaler, S., Li, Z. & Stuart, A. M. The nonlocal neural operator: universal approximation. Preprint at https://doi.org/10.48550/arXiv.2304.13221 (2023).\n\n  30. Lanthaler, S., Molinaro, R., Hadorn, P. & Mishra, S. Nonlinear reconstruction for operator learning of PDEs with discontinuities. In 11th International Conference on Learning Representations https://openreview.net/forum?id=CrfhZAsJDsZ (ICLR, 2023).\n\n  31. Kingma, D. P. & Ba, J. Adam: A method for stochastic optimization. In Proc. 3rd International Conference on Learning Representations (ICLR 2015).\n\n  32. Lu, L., Jin, P., Pang, G., Zhang, Z. & Karniadakis, G. E. Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators. Nat. Mach. Intell. 3, 218\u2013229 (2021).\n\nArticle Google Scholar\n\n  33. Lanthaler, S., Mishra, S. & Karniadakis, G. E. Error estimates for DeepONets: a deep learning framework in infinite dimensions. Trans. Math. Appl. 6, tnac001 (2022).\n\n  34. Lu, L. et al. A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data. Comput. Methods Appl. Mech. Eng. 393, 114778 (2022).\n\nArticle ADS MathSciNet Google Scholar\n\n  35. Battaglia, P. et al. Interaction networks for learning about objects, relations and physics. In 30th Conference on Neural Information Processing Systems (NIPS 2016).\n\n  36. Li, Z. et al. Multipole graph neural operator for parametric partial differential equations. Adv. Neural Inf. Process. Syst. 33, 6755\u20136766 (2020).\n\nGoogle Scholar\n\n  37. Kress, R., Maz\u2019ya, V. & Kozlov, V. Linear Integral Equations Vol. 82 (Springer, 1989).\n\n  38. Greengard, L. & Rokhlin, V. A new version of the fast multipole method for the Laplace equation in three dimensions. Acta Numer. 6, 229\u2013269 (1997).\n\nArticle ADS MathSciNet Google Scholar\n\n  39. Trefethen, L. Spectral Methods in MATLAB. Software, Environments, and Tools (Society for Industrial and Applied Mathematics, 2000).\n\n  40. Kovachki, N., Lanthaler, S. & Mishra, S. On universal approximation and error bounds for Fourier neural operators. J. Mach. Learn. Res. 22, 1\u201376 (2021).\n\nMathSciNet Google Scholar\n\n  41. Leonard, A. in Turbulent Diffusion in Environmental Pollution. Advances in Geophysics Vol. 18, 237\u2013248 (Elsevier, 1975).\n\n  42. Temam, R. Navier\u2013Stokes Equations: Theory and Numerical Analysis (Elsevier, 2016).\n\n  43. Chen, T. & Chen, H. Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems. EEE Trans. Neural Netw. 6, 911\u2013917 (1995).\n\nArticle Google Scholar\n\n  44. Lingsch, L., Michelis, M., Perera, S. M., Katzschmann, R. K. & Mishra, S. A Structured matrix method for nonequispaced neural operators. Preprint at https://doi.org/10.48550/arXiv.2305.19663 (2023).\n\n  45. Li, Z., Huang, D. Z., Liu, B. & Anandkumar, A. Fourier neural operator with learned deformations for PDEs on general geometries. J. Mach. Learn. Res. 388, 1\u221226 (2023).\n\nGoogle Scholar\n\n  46. Sun, H., Ross, Z. E., Zhu, W. & Azizzadenesheli, K. Next-generation seismic monitoring with neural operators. Preprint at https://doi.org/10.48550/arXiv.2305.03269 (2023).\n\n  47. Zou, C., Azizzadenesheli, K., Ross, Z. E. & Clayton, R. W. Deep neural Helmholtz operators for 3D elastic wave propagation and inversion. Preprint at https://doi.org/10.48550/arXiv.2311.09608 (2023).\n\n  48. Kossaifi, J., Kovachki, N. B., Azizzadenesheli, K. & Anandkumar, A. Multi-grid tensorized Fourier neural operator for high resolution PDEs. Preprint at https://doi.org/10.48550/arXiv.2310.00120 (2022).\n\n  49. Rahman, M. A., Ross, Z. E. & Azizzadenesheli, K. U-no: U-shaped neural operators. Preprint at https://arxiv.org/abs/2204.11127 (2023).\n\n  50. Raoni\u0107, B., Molinaro, R., Rohner, T., Mishra, S. & de Bezenac, E. Convolutional neural operators. Advances in Neural Information Processing Systems 36 (NeurIPS) (2023).\n\n  51. Cao, S. Choose a transformer: Fourier or Galerkin. Adv. Neural Inf. Process. Syst. 34, 24924\u201324940 (2021).\n\nGoogle Scholar\n\n  52. Li, Z., Meidani, K. & Farimani, A. B. Transformer for partial differential equations\u2019 operator learning. Preprint at https://arxiv.org/abs/2205.13671 (2023).\n\n  53. Lee, S. Mesh-independent operator learning for partial differential equations. In ICML 2022 2nd AI for Science Workshop. https://openreview.net/pdf?id=JUtZG8-2vGp (ICML, 2022).\n\n  54. Hao, Z. et al. GNOT: A general neural operator transformer for operator learning. In Proc. 40th International Conference on Machine Learning Vol. 202, 12556\u201312569, (PMLR, 2023).\n\n  55. Dosovitskiy, A. et al. An image is worth 16\u00d716 words: transformers for image recognition at scale. In Proc. 9th International Conference on Learning Representations (ICLR, 2021).\n\n  56. Guibas, J. et al. Adaptive Fourier neural operators: efficient token mixers for transformers. In Proc. 10th International Conference on Learning Representations (ICLR, 2022).\n\n  57. Lagaris, I. E., Likas, A. & Fotiadis, D. I. Artificial neural networks for solving ordinary and partial differential equations. IEEE Trans. Neural Netw. 9, 987\u20131000 (1998).\n\nArticle Google Scholar\n\n  58. Karniadakis, G. E. et al. Physics-informed machine learning. Nat. Rev. Phys. 3, 422\u2013440 (2021).\n\nArticle Google Scholar\n\n  59. Sirignano, J. & Spiliopoulos, K. Dgm: A deep learning algorithm for solving partial differential equations. J. Comput. Phys. 375, 1339\u20131364 (2018).\n\nArticle ADS MathSciNet Google Scholar\n\n  60. Yu, B. et al. The deep ritz method: a deep learning-based numerical algorithm for solving variational problems. Commun. Math. Stat. 6, 1\u201312 (2018).\n\nArticle ADS MathSciNet Google Scholar\n\n  61. Du, Y. & Zaki, T. A. Evolutional deep neural network. Phys. Rev. E 104, 045303 (2021).\n\nArticle ADS MathSciNet Google Scholar\n\n  62. Mildenhall, B. et al. Nerf: representing scenes as neural radiance fields for view synthesis. Commun. ACM 65, 99\u2013106 (2021).\n\nArticle Google Scholar\n\n  63. Sitzmann, V., Martel, J., Bergman, A., Lindell, D. & Wetzstein, G. Implicit neural representations with periodic activation functions. Adv. Neural Inf. Process. Syst. 33, 7462\u20137473 (2020).\n\nGoogle Scholar\n\n  64. Jeong, Y. et al. PeRFception: perception using radiance fields. Adv. Neural Inf. Process. Syst. 35, 26105\u201326121 (2022).\n\nGoogle Scholar\n\n  65. Srinivasan, P. P. et al. NeRV: neural reflectance and visibility fields for relighting and view synthesis. In Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 7495\u20137504 (IEEE, 2021).\n\n  66. Chen, P. Y. et al. CROM: continuous reduced-order modeling of PDEs using implicit neural representations. In Proc. 11th International Conference on Learning Representations (ICLR, 2023).\n\n  67. Serrano, L. et al. Operator learning with neural fields: tackling PDEs on general geometries. In 37th Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n  68. Fang, Z., Wang, S. & Perdikaris, P. Learning only on boundaries: a physics-informed neural operator for solving parametric partial differential equations in complex geometries. Neural Comput. 36, 475\u2013498 (2024).\n\nArticle MathSciNet Google Scholar\n\n  69. Raissi, M., Perdikaris, P. & Karniadakis, G. E. Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. J. Comput. Phys. 378, 686\u2013707 (2019).\n\nArticle ADS MathSciNet Google Scholar\n\n  70. Han, J., Jentzen, A. & E, W. Solving high-dimensional partial differential equations using deep learning. Proc. Natl Acad. Sci. USA 115, 8505\u20138510 (2018).\n\nArticle ADS MathSciNet Google Scholar\n\n  71. Smith, J. D., Azizzadenesheli, K. & Ross, Z. E. EikoNet: solving the Eikonal equation with deep neural networks. IEEE Trans. Geosci. Remote Sens. 59, 10685\u201310696 (2020).\n\nArticle ADS Google Scholar\n\n  72. Gao, H., Sun, L. & Wang, J.-X. PhyGeoNet: physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain. J. Comput. Phys. 428, 110079 (2021).\n\nArticle MathSciNet Google Scholar\n\n  73. Krishnapriyan, A., Gholami, A., Zhe, S., Kirby, R. & Mahoney, M. W. Characterizing possible failure modes in physics-informed neural networks. Adv. Neural Inf. Process. Syst. 34, 26548\u201326560 (2021).\n\nGoogle Scholar\n\n  74. Wang, S., Wang, H. & Perdikaris, P. Learning the solution operator of parametric partial differential equations with physics-informed DeepONets. Sci. Adv. 7, eabi8605 (2021).\n\nArticle ADS Google Scholar\n\n  75. Goswami, S., Bora, A., Yu, Y. & Karniadakis, G. E. Physics-Informed Deep Neural Operator Networks (Springer,2023); https://doi.org/10.1007/978-3-031-36644-4_6 (2023).\n\n  76. Berner, J., Dablander, M. & Grohs, P. Numerically solving parametric families of high-dimensional Kolmogorov partial differential equations via deep learning. Adv. Neural Inf. Process. Syst. 33, 16615\u201316627 (2020).\n\nGoogle Scholar\n\n  77. Han, J., Nica, M. & Stinchcombe, A. R. A derivative-free method for solving elliptic partial differential equations with deep neural networks. J. Comput. Phys. 419, 109672 (2020).\n\nArticle MathSciNet Google Scholar\n\n  78. Beck, C., Becker, S., Grohs, P., Jaafari, N. & Jentzen, A. Solving the Kolmogorov PDE by means of deep learning. J. Sci. Comput. 88, 1\u201328 (2021).\n\nArticle MathSciNet Google Scholar\n\n  79. Richter, L. & Berner, J. Robust SDE-based variational formulations for solving linear PDEs via deep learning. In International Conference on Machine Learning, 18649\u201318666 (PMLR, 2022).\n\n  80. Zhang, R. et al. Monte Carlo neural operator for learning PDEs via probabilistic representation. Preprint at https://doi.org/10.48550/arXiv.2302.05104 (2023).\n\n  81. Rahman, M. A., Florez, M. A., Anandkumar, A., Ross, Z. E. & Azizzadenesheli, K. Generative adversarial neural operators. Preprint at https://arxiv.org/abs/2205.03017 (2022).\n\n  82. Lim, J. H. et al. Score-based diffusion models in function space. Preprint at https://doi.org/10.48550/arXiv.2302.07400 (2023).\n\n  83. Seidman, J. H., Kissas, G., Pappas, G. J. & Perdikaris, P. Variational autoencoding neural operators. Proc. 40th International Conference on Machine Learning Vol. 202, 30491\u201330522 (PMLR, 2023).\n\n  84. Shi, Y., Lavrentiadis, G., Asimaki, D., Ross, Z. E. & Azizzadenesheli, K. Broadband ground motion synthesis via generative adversarial neural operators: development and validation. Preprint at https://doi.org/10.48550/arXiv.2309.03447 (2023).\n\n  85. Lam, R. et al. Learning skillful medium-range global weather forecasting. Science 382, 1416\u20131421 (2023).\n\nArticle ADS MathSciNet Google Scholar\n\n  86. How AI models are transforming weather forecasting: a showcase of data-driven systems. ECMWF www.ecmwf.int/en/about/media-centre/news/2023/how-ai-models-are-transforming-weather-forecasting-showcase-data (6 September 2023).\n\n  87. Grady, T. J. et al. Model-parallel Fourier neural operators as learned surrogates for large-scale parametric PDEs. Comput. Geosci. 178, 105402 (2023).\n\n  88. Renn, P. I. et al. Forecasting subcritical cylinder wakes with Fourier neural operators. Preprint at https://doi.org/10.48550/arXiv.2301.08290 (2023).\n\n  89. Li, Z., Peng, W., Yuan, Z. & Wang, J. Fourier neural operator approach to large eddy simulation of three-dimensional turbulence. Theor. Appl. Mech. Lett. 12, 100389 (2022).\n\nArticle Google Scholar\n\n  90. Peng, W. et al. Fourier neural operator for real-time simulation of 3D dynamic urban microclimate. Preprint at https://doi.org/10.48550/arXiv.2308.03985 (2023).\n\n  91. Liu, B. et al. A learning-based multiscale method and its application to inelastic impact problems. J. Mech. Phys. Solids. 158, 104668 (2022).\n\nArticle MathSciNet Google Scholar\n\n  92. Rashid, M. M., Pittie, T., Chakraborty, S. & Krishnan, N. A. Learning the stress-strain fields in digital composites using Fourier neural operator. iScience 25 105452 (2022).\n\nArticle ADS Google Scholar\n\n  93. Liu, M. et al. An adversarial active sampling-based data augmentation framework for manufacturable chip design. In 36th Conference on Neural Information Processing Systems (NeurIPS 2022); https://doi.org/10.48550/arXiv.2210.15765.\n\n  94. Yang, H. et al. Generic lithography modeling with dual-band optics-inspired neural networks. In Proc. 59th ACM/IEEE Design Automation Conference 973\u2013978 (IEEE, 2022).\n\n  95. Guan, S., Hsu, K.-T. & Chitnis, P. V. Fourier neural operator networks: a fast and general solver for the photoacoustic wave equation. Algorithms 16, 124 (2023).\n\nArticle Google Scholar\n\n  96. Gu, J. et al. Neurolight: a physics-agnostic neural operator enabling parametric photonic device simulation. Adv. Neural Inf. Process. Syst. 35, 14623\u201314636 (2022).\n\nGoogle Scholar\n\n  97. Gopakumar, V. et al. Fourier neural operator for plasma modelling. Nuclear Fission https://doi.org/10.1088/1741-4326/ad313a (2024).\n\n  98. Li, Z. et al. Learning chaotic dynamics in dissipative systems. Adv. Neural Inf. Process. Syst. 35, 16768\u201316781 (2022).\n\nADS Google Scholar\n\n  99. Lippe, P., Veeling, B. S., Perdikaris, P., Turner, R. E. & Brandstetter, J. PDE-refiner: achieving accurate long rollouts with neural PDE solvers. In 37th Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n  100. Liu-Schiaffini, M. et al. Tipping point forecasting in non-stationary dynamics on function spaces. Preprint at https://doi.org/10.48550/arXiv.2308.08794 (2023).\n\n  101. Rosen, P. A., Gurrola, E., Sacco, G. F. & Zebker, H. The InSAR scientific computing environment. In EUSAR 2012; 9th European Conference on Synthetic Aperture Radar 730\u2013733 (VDE, 2012).\n\n  102. Palmer, T. Stochastic weather and climate models. Nat. Rev. Phys. 1, 463\u2013471 (2019).\n\nArticle Google Scholar\n\n  103. Salvi, C., Lemercier, M. & Gerasimovics, A. Neural stochastic pdes: Resolution-invariant learning of continuous spatiotemporal dynamics. Adv. Neural Inf. Process. Syst. 35, 1333\u20131344 (2022).\n\nGoogle Scholar\n\n  104. Ngom, M. & Marin, O. Fourier neural networks as function approximators and differential equation solvers. Statist. Anal. Data Mining 14, 647\u2013661 (2021).\n\nArticle MathSciNet Google Scholar\n\n  105. Shi, Y. et al. Machine learning accelerated PDE backstepping observers. In 2022 IEEE 61st Conference on Decision and Control (CDC) 5423\u20135428 (IEEE, 2022).\n\n  106. Cotter, S., Roberts, G., Stuart, A. & White, D. MCMC methods for functions: modifying old algorithms to make them faster. Statist. Sci. 28, 424\u2013446 (2012).\n\n  107. Hinze, M., Pinnau, R., Ulbrich, M. & Ulbrich, S. Optimization with PDE Constraints. Mathematical Modelling: Theory and Applications (Springer, 2008).\n\n  108. Kaltenbach, S., Perdikaris, P. & Koutsourelakis, P.-S. Semi-supervised invertible neural operators for Bayesian inverse problems. Computational Mechanics 1\u201320 (2023).\n\n  109. Zhou, T. et al. AI-aided geometric design of anti-infection catheters. Sci. Adv. 10, adj1741 (2024).\n\n  110. Yang, Y. et al. Seismic wave propagation and inversion with neural operators. Seism. Rec. 1, 126\u2013134 (2021).\n\nArticle Google Scholar\n\n  111. Sun, H., Yang, Y., Azizzadenesheli, K., Clayton, R. W. & Ross, Z. E. Accelerating time-reversal imaging with neural operators for real-time earthquake locations. Preprint at https://doi.org/10.48550/arXiv.2210.06636 (2022).\n\n  112. Yang, Y., Gao, A. F., Azizzadenesheli, K., Clayton, R. W. & Ross, Z. E. Rapid seismic waveform modeling and inversion with neural operators. IEEE Trans. Geosci. Remote Sens. https://doi.org/10.1109/TGRS.2023.3264210 (2023).\n\n  113. Yin, Z., Orozco, R., Louboutin, M. & Herrmann, F. J. Solving multiphysics-based inverse problems with learned surrogates and constraints. Adv. Model. Simul. Eng. Sci. 10, 14 (2023).\n\nArticle Google Scholar\n\n  114. Otness, K. et al. An extensible benchmark suite for learning to simulate physical systems. In 35th Conference on Neural Information Processing Systems (NeurIPS 2021).\n\n  115. Takamoto, M. et al. PDEbench: an extensive benchmark for scientific machine learning. Adv. Neural Inf. Process. Syst. 35, 1596\u20131611 (2022).\n\nGoogle Scholar\n\n  116. Gupta, J. K. & Brandstetter, J. Towards multi-spatiotemporal-scale generalized PDE modeling. Preprint at https://doi.org/10.48550/arXiv.2209.15616 (2022).\n\n  117. Hao, Z. et al. Pinnacle: a comprehensive benchmark of physics-informed neural networks for solving PDEs. Preprint at https://doi.org/10.48550/arXiv.2306.08827 (2023).\n\n  118. Huang, Z. et al. A Large-Scale Benchmark for the Incompressible Navier\u2013Stokes Equations (SSRN, 2022); https://doi.org/10.2139/ssrn.4030476.\n\n  119. Ren, P. et al. Superbench: a super-resolution benchmark dataset for scientific machine learning. Preprint at https://doi.org/10.48550/arXiv.2306.14070 (2023).\n\n  120. Wang, Z., Bovik, A. C., Sheikh, H. R. & Simoncelli, E. P. Image quality assessment: from error visibility to structural similarity. IEEE Trans. Image Process. 13, 600\u2013612 (2004).\n\nArticle ADS Google Scholar\n\n  121. Hassan, S. M. S. et al. BubbleML: a multi-physics dataset and benchmarks for machine learning. Preprint at https://doi.org/10.48550/arXiv.2307.14623 (2023).\n\n  122. Dulny, A., Hotho, A. & Krause, A. Dynabench: A Benchmark Dataset for Learning Dynamical Systems From Low-Resolution Data Vol. 14169 (Springer, 2023); https://doi.org/10.1007/978-3-031-43412-9_26.\n\n  123. Thiyagalingam, J., Shankar, M., Fox, G. & Hey, T. Scientific machine learning benchmarks. Nat. Rev. Phys. 4, 413\u2013420 (2022).\n\nArticle Google Scholar\n\n  124. Kurth, T. et al. FourCastNet: accelerating global high-resolution weather forecasting using adaptive Fourier neural operators. In PASC \u201923: Proc. Platform for Advanced Scientific Computing Conference https://doi.org/10.1145/3592979.3593412 (ACM, 2023).\n\n  125. White, C. et al. Speeding up Fourier neural operators via mixed precision. Preprint at https://doi.org/10.48550/arXiv.2307.15034 (2023).\n\nDownload references\n\n## Acknowledgements\n\nA.A. is supported by a Bren named professor chair at Caltech and AI 2050\nsenior fellowship by Schmidt Sciences. Z.L. is supported by an NVIDIA\nfellowship. M.L.-S. is supported by the Mellon Mays undergraduate fellowship.\nWe thank B. Jenik for creating Fig. 2 and for general discussions.\n\n## Author information\n\n### Authors and Affiliations\n\n  1. NVIDIA, Santa Clara, CA, USA\n\nKamyar Azizzadenesheli, Nikola Kovachki & Jean Kossaifi\n\n  2. Caltech, Pasadena, CA, USA\n\nZongyi Li, Miguel Liu-Schiaffini & Anima Anandkumar\n\nAuthors\n\n  1. Kamyar Azizzadenesheli\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  2. Nikola Kovachki\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  3. Zongyi Li\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  4. Miguel Liu-Schiaffini\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  5. Jean Kossaifi\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  6. Anima Anandkumar\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n### Contributions\n\nThe authors contributed equally to all aspects of the article.\n\n### Corresponding author\n\nCorrespondence to Anima Anandkumar.\n\n## Ethics declarations\n\n### Competing interests\n\nThe authors declare no competing interests.\n\n## Peer review\n\n### Peer review information\n\nNature Reviews Physics thanks Cristopher Salvi and the other, anonymous,\nreviewer(s) for their contribution to the peer review of this work.\n\n## Additional information\n\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional\nclaims in published maps and institutional affiliations.\n\n## Rights and permissions\n\nSpringer Nature or its licensor (e.g. a society or other partner) holds\nexclusive rights to this article under a publishing agreement with the\nauthor(s) or other rightsholder(s); author self-archiving of the accepted\nmanuscript version of this article is solely governed by the terms of such\npublishing agreement and applicable law.\n\nReprints and permissions\n\n## About this article\n\n### Cite this article\n\nAzizzadenesheli, K., Kovachki, N., Li, Z. et al. Neural operators for\naccelerating scientific simulations and design. Nat Rev Phys (2024).\nhttps://doi.org/10.1038/s42254-024-00712-5\n\nDownload citation\n\n  * Accepted: 20 February 2024\n\n  * Published: 08 April 2024\n\n  * DOI: https://doi.org/10.1038/s42254-024-00712-5\n\n### Share this article\n\nAnyone you share the following link with will be able to read this content:\n\nSorry, a shareable link is not currently available for this article.\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\n### Subjects\n\n  * Computer science\n  * Mathematics and computing\n\nAccess through your institution\n\nChange institution\n\nBuy or subscribe\n\nAdvertisement\n\nNature Reviews Physics (Nat Rev Phys) ISSN 2522-5820 (online)\n\n## nature.com sitemap\n\n### About Nature Portfolio\n\n  * About us\n  * Press releases\n  * Press office\n  * Contact us\n\n### Discover content\n\n  * Journals A-Z\n  * Articles by subject\n  * Protocol Exchange\n  * Nature Index\n\n### Publishing policies\n\n  * Nature portfolio policies\n  * Open access\n\n### Author & Researcher services\n\n  * Reprints & permissions\n  * Research data\n  * Language editing\n  * Scientific editing\n  * Nature Masterclasses\n  * Research Solutions\n\n### Libraries & institutions\n\n  * Librarian service & tools\n  * Librarian portal\n  * Open research\n  * Recommend to library\n\n### Advertising & partnerships\n\n  * Advertising\n  * Partnerships & Services\n  * Media kits\n  * Branded content\n\n### Professional development\n\n  * Nature Careers\n  * Nature Conferences\n\n### Regional websites\n\n  * Nature Africa\n  * Nature China\n  * Nature India\n  * Nature Italy\n  * Nature Japan\n  * Nature Korea\n  * Nature Middle East\n\n  * Privacy Policy\n  * Use of cookies\n  * Legal notice\n  * Accessibility statement\n  * Terms & Conditions\n  * Your US state privacy rights\n  * Cancel contracts here\n\n\u00a9 2024 Springer Nature Limited\n\nSign up for the Nature Briefing newsletter \u2014 what matters in science, free to\nyour inbox daily.\n\nGet the most important science stories of the day, free in your inbox. Sign up\nfor Nature Briefing\n\n", "frontpage": false}

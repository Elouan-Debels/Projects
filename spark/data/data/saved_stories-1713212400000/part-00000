{"aid": "40040855", "title": "Self-Hosted Apps: Shared Tenancy Scheduled Tasks in Docker", "url": "https://tech.davidgorski.ca/scheduled-tasks-in-docker/", "domain": "davidgorski.ca", "votes": 2, "user": "dgski", "posted_at": "2024-04-15 14:19:17", "comments": 0, "source_title": "Self-Hosted Apps: Shared Tenancy Scheduled Tasks in Docker", "source_text": "Self-Hosted Apps: Shared Tenancy Scheduled Tasks in Docker - Tech @ DG\n\nTech @ DG\n\nDavid Gorski\n\nApr 15, 2024\n\n# Self-Hosted Apps: Shared Tenancy Scheduled Tasks in Docker\n\nI host a few small web projects using CapRover, a simple web-based container\norchestration framework built upon Docker Services. For non-critical hobby\napps, it is perfect. I simply run CapRover on a virtual private server (VPS)\nwith DigitalOcean and containerize all my running applications; forgoing all\nsystemd setup and dependency installation.\n\nMost managed application platforms (AWS, Google Cloud, Render, etc) provide\nthe ability to schedule tasks to be performed on a repeated, regular basis.\nUnfortunately, CapRover does not provide this (It is a simple Docker service\nmanager). If I want to schedule some tasks I have to use my VPS\u2019s crontab. I\ndidn\u2019t want to do this. Why? For the sake of consistency, I want all my\napplications to be running within Docker containers. I don\u2019t want any host-\nspecific configuration, dependency installation, command-running or\ntroubleshooting. This agnosticism will also allow easier migration to any\nother managed docker service manager down the line if my hobby project makes\nit big, and I want better reliability.\n\nLuckily, containers can run cron themselves. So, first step: I create a\nDockerfile that installs a crontab to the container:\n\n    \n    \n    FROM alpine:3.15 COPY crontab /etc/crontabs/root\n\nI could now just edit the crontab file as needed and add it to every project\nrepository to add scheduled tasks. If wanted my crontabs scattered across all\nmy app repos, this would be fine. But what I really wanted was one centralized\ncrontab that enables a \u2018multi-tenant\u2019 scheduling system. It could be easier to\ngrasp and troubleshoot, especially for projects I rarely update.\n\nOne solution would be moving the code of different jobs from their respective\napp repos into a new cronservice repo, but that would be kind of gross. I\ndon\u2019t want to be separating app-specific job code from the rest of its\ncodebase. I realized that all my apps were REST endpoints and I could leverage\nthat somehow. So I did.\n\nI moved the job code behind an endpoint. Of course, this would allow anyone to\ntrigger the job, which is simply not acceptable. I could have added a fully\nrealized api key and authentication system, but I didn\u2019t want to spend too\nmuch time on this. These were just hobby apps after all. This is what I\nsettled on:\n\n  1. The cronservice contaier runs a rest API with a single endpoint: \u2018/confirm\u2019. This will accept a job key parameter and respond whether this is a genuine request.\n  2. When the crontab runs a task, it will first generate a job key, insert it into a sqlite database, and send an HTTP request to the app endpoint.\n  3. When the app receives the request, it will first query the cronservice \u2018/confirm\u2019 endpoint to see whether this is a genuine job running request using the job key.\n  4. If yes, it will run the task, and respond with the success status. Otherwise it will refuse to run the task.\n  5. The crontab task will remove the entry from the sqlite database and return 0.\n\nI wrapped this up in three python files:\n\n  * pending_job_queue.py: defining a simple API around sqlite.\n  * job_token_confirmation_api.py: a FastAPI that checks the queue if the key is valid.\n  * init_remote_job.py: a helper script that simply \u2018pings\u2019 an HTTP endpoint with a generated job key. Also prevents duplicate job running.\n\nAnd usage in the crontab looks like:\n\n    \n    \n    0 2 * * * ./init_remote_job.py https://sampleurl.com/jobEndpoint\n\nI like what I came up with. It is easy to reason about and understand. It\nleaves the job specific code with the specific app while centralizing all the\nscheduling in one file (within the cronservice repo). The use of the db also\nprevents running a job if the previous didn\u2019t complete yet.\n\nI am not running critical apps, so I didn\u2019t care to add persistence of the\nsqlite database. Of course if one would be scaling this and needed to\nguarantee some jobs fully complete, or that the API could be restarted at\nwill, they would need to mount a persistent volume or use an external\ndatabase. Additionally, while the above solution is sound from a security\nstandpoint, it probably would be better to put the jobs behind an unexposed\nendpoint. In this case, I was aiming for reduction in overhead.\n\nThis article was updated on Apr 15, 2024\n\nFacebook Twitter Pinterest LinkedIn\n\n### Related post\n\nDavid Gorski\n\nMar 25, 2024 docker\n\n## Self-Hosted Apps: Programmatic Email\n\nI host a few small web projects using CapRover, a simple web-based...\n\nDavid Gorski\n\nApr 1, 2024\n\n## Self-Hosted Apps: Configuration Management With Secrets\n\nI host a few small web projects using CapRover, a simple web-based...\n\n### New Book Available Now!\n\nIntroduction To Low Latency Programming: Learn The Fundamental Ideas Behind\nHigh-Performance C++ Code\n\n### Newsletter Subscription Options\n\n  * RSS\n  * Email Via Substack\n\nTwitter LinkedIn\n\n\u00a9 David Gorski, 2024\n\n", "frontpage": false}

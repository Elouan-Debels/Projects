{"aid": "40043879", "title": "LLM-Powered Django Admin Fields", "url": "https://blog.untrod.com/2024/04/llm-chatgpt-powered-django-admin-fields.html", "domain": "untrod.com", "votes": 1, "user": "numlocked", "posted_at": "2024-04-15 18:15:19", "comments": 0, "source_title": "LLM-Powered Django Admin Fields - Untrod", "source_text": "LLM-Powered Django Admin Fields - Untrod\n\nUntrod\n\nAbout Projects\n\n# LLM-Powered Django Admin Fields\n\nBy Chris Clark, 04/14/2024, in Everything else\n\nNote: All relevant code can be found in the corresponding Github repo.\n\nI work at Grove Collaborative -- an ecommerce company that sells thousands of\ndifferent products. We use Django and the Django admin as our product\ninformation system to manage, among other things, all of the copy on our\nProduct Detail Pages (PDPs). In order to more efficiently and consistently\nwrite copy for different PDP sections, we integrated ChatGPT directly into the\nDjango Admin.\n\nWhile not quite encapsulated enough to make it a standalone Django plugin, the\ncode is generic enough to quickly integrate ChatGPT with any Django text\nfield, and provides a number of affordances to Django admin users to modify\nand test the underlying prompts.\n\n## What we did\n\nIn short, we now have little buttons next to Django Admin text fields that\nwill generate copy according to a specific prompt and data payload. For\nexample, we have a section on our PDPs titled \"Why we believe in this\nproduct\", backed by an attribute on the Product model called why_we_believe.\nIn the Django Admin, when viewing a Product model, there is a button that our\nmerchandising team can use to populate the field. The text is editable and\nreviewable; ChatGPT provides initial copy, but humans are still very much in\nthe loop.\n\nEach \"LLM-enabled\" text field is mapped to a specific prompt and bespoke data\npayload that provides the model-specific context to ChatGPT.\n\nWe also have prompts and buttons for fields like \"review summary\" (summarizes\nthe pros and cons of a product based on customer reviews), \"hero ingredients\",\nand more. The underlying prompts are editable in the admin so our merchants\nand tweak the output without engineering involvement:\n\nFinally, a playground area allows admin users to test the prompts out without\nleaving Django:\n\nWe can quickly add GPT-powered copywriting to any text field, on any model, in\nthe Django Admin. The relevant code is available in a Github repo, with some\ninstructions on how to get started. The balance of this post simply explicates\nthe code and patterns.\n\n## How it works\n\nNote that some of the code below is slightly simplified from what's in the\nrepo in order to aid comprehension.\n\nFirst up, a simple model to store and manage the prompts that will power each\ntext field:\n\n    \n    \n    class GPTPrompt(CoreModel): system_message_template = models.TextField(blank=False) human_message_template = models.TextField(blank=False) key = models.CharField(blank=False, unique=True, max_length=100) model = models.IntegerField(choices=GPT_MODELS, default=GPT3) def prompt(self): return ChatPromptTemplate.from_messages( [ SystemMessagePromptTemplate.from_template(self.system_message_template), HumanMessagePromptTemplate.from_template(self.human_message_template), ] ) @property def model_name(self): return GPT_MODELS[self.model][1] def __str__(self): return self.key\n\nAfter registering the model in the Django admin, the prompts are now editable.\n\nThere is a bit of magic to the \"key\" value, which maps to a hard-coded value\non a class that knows how to inject the proper contextual data for a given\nprompt. For example, the prompt in the screenshot above needs to know how to\nget product_json. So we write a little class that can provide that data (one\nclass for each prompt):\n\n    \n    \n    class BelievePromptData(object): PROMPT_KEY = \"WHY_WE_BELIEVE_PROMPT\" def __init__(self, model_id): self.product = Product.objects.get(pk=model_id) def __call__(self): keys = [\"name\", \"selling_points\", \"manufacturer_description\", \"ingredients\"] return {\"product_json\": json.dumps({k: str(getattr(self.product, k)) for k in keys})}\n\nA single Django view will handle all of the client-side text-generation\nrequests coming from the admin buttons:\n\n    \n    \n    def generic_llm_prompt_view(request, promptDataCls=None): prompt = GPTPrompt.objects.get(key=promptDataCls.PROMPT_KEY) prompt.prompt_data = promptDataCls(request.GET.get(\"model_id\")) return HttpResponse(json.dumps({\"text\": prompt.get_text()}), content_type=\"application/json\")\n\nThe correct PromptData class is injected when registering the URLs:\n\n    \n    \n    from functools import partial urlpatterns += [ re_path(r\"^generate-believe-text/\", partial(generic_llm_prompt_view, promptDataCls=BelievePromptData), name=\"generate-believe-text\"), ]\n\nNote in the repo, there are also URLs registered for the playground.\n\nTo recap:\n\n  1. A request comes in to e.g. generate-believe-text/?model_id=123\n  2. The generic llm_prompt_view passes the model_id into the PromptData object specified in the URL endpoint (in this case BelievePromptData)\n  3. BelievePromptData gets the relevant model and turns it into the JSON blob that we want to inject into our prompt. The key of the PromptData class maps to the correct GPTPrompt object.\n  4. The GPTPrompt gets loaded, merges in the JSON blob, and calls out to ChatGPT to generate the text.\n\nThis pattern makes it really easy to add more prompts; an admin user can\ncreate a new prompt (and test it out in the playground), and an engineer adds\na corresponding PromptData class and new URL.\n\n## Hooking it up to the Django Admin UI\n\nLastly, we have to add the actual button next to the relevant field. Torturing\nthe Django admin is never particularly fun, so we created a widget you can\nstick next to arbitrary model text fields, and map to the different URLs,\ncorresponding to the various PromptData classes. The Widget is simple:\n\n    \n    \n    class LLMTextAreaWidget(Textarea): template_name = \"widgets/llm_text_area_widget.html\" def __init__(self, req_url, *args, **kwargs): self.llm_req_url = req_url super().__init__(*args, **kwargs) def get_context(self, name, value, attrs): context = super().get_context(name, value, attrs) context[\"widget\"][\"llm_req_url\"] = self.llm_req_url context[\"widget\"][\"btn_class\"] = f\"{name}-generate-btn\" return context\n\nThe corresponding JavaScript is kind of a mess -- but functional. The HTML and\nJS for the widget can be found in the complete repo.\n\nThen simply add the widget to the admin form. E.g.\n\n    \n    \n    class ProductForm(forms.ModelForm): class Meta: model = Product fields = \"__all__\" widgets = { \"why_we_believe\": LLMTextAreaWidget(req_url=\"/llm/generate-believe-text/\"), }\n\nAnd voila! Our merchandisers can click the button to generate text and pre-\npopulate the field. This fields remain a 'normal' text field; it's still\noverridable by the admin user. Merchants often use the buttons to get started,\nand then tweak the copy from there.\n\n#### Like what you read? Join the newsletter and get updated when there's\nsomething new.\n\n  * Categories\n  * Archives\n  * About\n\n  * Github\n  * LinkedIn\n  * Twitter\n\n\u00a9 untrod.com 2024\n\n", "frontpage": false}

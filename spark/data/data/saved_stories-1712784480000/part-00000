{"aid": "39991777", "title": "Semantic Sound Synthesis with Agents", "url": "https://montyanderson.net/writing/synthesis", "domain": "montyanderson.net", "votes": 1, "user": "montyanderson", "posted_at": "2024-04-10 15:25:37", "comments": 0, "source_title": "Monty Anderson", "source_text": "Monty Anderson\n\nmontyanderson.net\n\n# Semantic Sound Synthesis with Agents\n\n## April 2024\n\nIn March last year, with my long-time collaborator Barney Hill, I released\nVroom VST \u2e3a a text-to-sound plugin created for producers. It leveraged the at-\nthe-time cutting edge AI model AudioLDM. However, after getting it in the\nhands of musicians, it became obvious that text-to-sound is limited in\napplication; labeled sound samples already exist in abundance with companies\nlike Splice providing access to over 400 million for a monthly subscription.\n\nAfter chatting with educators like Tim at You Suck At Producing , we decided\nthat we needed a tool that guides and teaches you to shape sound using the\nwide variety of traditional instruments and effects that already exist rather\nthan the raw generation of sound from scratch. We knew we wanted it to\nintegrate with Ableton Live but to an extent we were in limbo, until Barney\nfound Daniel Jones' AbletonOSC library that lets you read and write to\nAbleton's internal state via the OSC network protocol.\n\n> An early prototype of Vroom Live .\n>\n> \u201cmake my synth brighter\u201d opens up the filter on Ableton's Analog synth.\n\nOur design was to make an agent that presents a familiar chat interface to the\nuser with the thesis was that we could build on top of a rich history of synth\ninterface design and the wide training set that LLMs have. This includes\nextensive discussion on forums like ModWiggler , where users have long debates\nabout the differences and uses of parameters and controls on every type of\ninstrument.\n\nAs early as the 1960s, pioneers like Don Buchla made synthesizers that have\nnatural and unique interfaces with fuzzy controls like tambre or novel,\nambiguous graphics that serve to defocus the underlying eletronics and\nprivilege human intention. This radical idea, that an interface should be\nsymbolic and intuative at the expense of accuracy, is commonplace in software\nengineering \u2e3a we just call it abstraction.\n\n> A Buchla modular synthesizer at NAMM 2007 posted by the Synthesizers flickr\n> user. Authentic to the original 1960s/1970s designs.\n\nAfter a weekend of hacking, Vroom Live was born. Under the hood, it uses\nOpenAI's function calling although it could be ported to work with any\navailable language model. It particularly shines when you have descriptive\nsamples and effects so it can infer what genre or style of music you're\nworking on. It also works great with virtual recreations of traditional\nsynthesizers; it is perfect for translating the broadest of sonic wishes to\ntheir interfaces.\n\nAre you interested in using Vroom Live or working with us? Send us an email .\n\n> Vroom Live \u2e3a watch the 'amount' control on the multiband compressor.\n\n", "frontpage": false}
